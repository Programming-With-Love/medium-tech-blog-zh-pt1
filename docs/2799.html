<html>
<head>
<title>Customer Churn Prediction Using PySpark MLlib</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PySpark MLlib进行客户流失预测</h1>
<blockquote>原文：<a href="https://medium.com/edureka/pyspark-mllib-tutorial-759391dbb08a?source=collection_archive---------6-----------------------#2018-07-24">https://medium.com/edureka/pyspark-mllib-tutorial-759391dbb08a?source=collection_archive---------6-----------------------#2018-07-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/5a08d27d8f50da03b4be140ee3935b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*4rKAUTm5nZSXHuZYB2zhxw.jpeg"/></div></figure><p id="76bd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">机器学习经历了许多最近的发展，正变得日益流行。包括计算机科学、数学和管理在内的所有领域的人们都在各种项目中使用机器学习来寻找数据中隐藏的信息。Apache Spark使用其MLlib库跳入Python的机器学习游戏只是时间问题。因此，在这个PySpark MLlib教程中，我将讨论以下主题:</p><ul class=""><li id="fcac" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">什么是机器学习？</li><li id="d3cb" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">PySpark MLlib是什么？</li><li id="cbe3" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">机器学习(Python)工业用例</li><li id="99c4" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">机器学习生命周期</li><li id="fd39" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">PySpark MLlib特性和算法</li><li id="0cd3" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">使用PySpark MLlib查找黑客</li><li id="4ee4" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">使用PySpark MLlib进行客户流失预测</li></ul><h1 id="ea39" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">什么是机器学习？</h1><p id="4428" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">机器学习是一种自动建立分析模型的数据分析方法。使用从数据中迭代学习的算法，机器学习允许计算机<strong class="in hi">找到隐藏的洞察力</strong>，而无需显式编程去哪里寻找。它专注于开发计算机程序，这些程序可以让T2在接触到新数据时自学成长和变化。机器学习使用这些数据来检测数据集中的模式，并相应地调整程序操作。</p><p id="c771" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">大多数处理大量数据的行业都认识到了机器学习技术的价值。通过从这些数据中收集见解(通常是实时的),组织能够更高效地工作，或者获得超越竞争对手的优势。</p><p id="f312" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在你已经对什么是机器学习有了一个简单的概念，让我们继续这篇文章，了解什么是MLlib，它有什么特性？</p><h1 id="5ed9" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">PySpark MLlib是什么？</h1><p id="0c16" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">PySpark MLlib是一个机器学习库。它是PySpark核心上的一个包装器，使用机器学习算法进行数据分析。它适用于分布式系统，并且是可扩展的。我们可以在PySpark MLlib中找到分类、聚类、线性回归和其他机器学习算法的实现。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es la"><img src="../Images/4725dd395f37646d2c72248d39c3a98d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*us-gytTZlbr_mZletfh9yQ.png"/></div></figure><h1 id="5699" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">机器学习(Python)工业用例</h1><p id="4fd3" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated"><a class="ae lf" href="https://www.edureka.co/blog/machine-learning-algorithms?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pyspark-mllib-tutorial" rel="noopener ugc nofollow" target="_blank">机器学习算法</a>，应用和平台正在帮助制造商寻找新的商业模式，微调产品质量，优化生产运作到车间层面。所以让我们继续我们的文章，了解各个行业是如何使用机器学习的。</p><h2 id="ec64" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated"><strong class="ak">政府:</strong></h2><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/39a324d2a6567f11a410af2a6735af40.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*VEzC8_5pA4KHWxiRyaohpw.png"/></div></figure><p id="972c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">公共安全和公共事业等政府机构对机器学习有着特殊的需求。他们用它来进行人脸检测、安全和欺诈检测。公共部门机构正在将机器学习用于政府计划，以获得对政策数据的重要见解。</p><h2 id="27f0" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated"><strong class="ak">营销与电子商务:</strong></h2><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/00aaf591ffcef1cddffb7979cfd6c598.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*flMZ5EY3s3YIhOeDXvLgTA.png"/></div></figure><p id="4b65" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">网上购物的数量正在稳步增长，这使得公司能够收集整个客户体验的详细数据。根据以前的购买情况推荐你可能喜欢的商品的网站正在使用机器学习来分析你的购买历史，并推广你感兴趣的其他商品。</p><h2 id="be02" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated"><strong class="ak">运输:</strong></h2><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/c38db702c46b0a112570af063900563b.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*EhpWXNcTd_4JjZWSg6Nhpg.png"/></div></figure><p id="e649" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">分析数据以识别模式和趋势是运输行业的关键，这依赖于使<strong class="in hi">路线更有效</strong>和预测潜在问题以增加盈利能力。公司使用ML来实现高效的拼车市场，识别可疑或欺诈账户，建议最佳的上车点和下车点。</p><h2 id="0572" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated"><strong class="ak">金融:</strong></h2><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/3feccf438091a2efa7598c431bb728ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*HkTb7M_FdtEhqfFkJz_YcQ.png"/></div></figure><p id="211c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">今天，机器学习已经在金融生态系统的许多阶段发挥了不可或缺的作用，从批准贷款到管理资产，再到评估风险。银行和金融行业的其他业务使用机器学习技术来<strong class="in hi">防止欺诈。</strong></p><h2 id="3770" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated"><strong class="ak">医疗保健:</strong></h2><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/6ad8ed4e4a6ccc5bc4423864a461d1d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*0GjClGavzKtt-jYgar7FfQ.png"/></div></figure><p id="6300" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">由于可穿戴设备和传感器的出现，机器学习是医疗保健行业的一个快速发展趋势，这些设备和传感器可以使用数据来实时评估患者的健康状况。<strong class="in hi">谷歌</strong>开发了一种机器学习算法，帮助识别乳房x光照片上的癌性肿瘤。<strong class="in hi">斯坦福</strong>正在使用深度学习算法识别皮肤癌。</p><p id="ed82" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">既然你对什么是机器学习以及它在行业中的各个领域有了概念，让我们继续我们的文章，并了解典型的机器学习生命周期是什么样子的。</p><h1 id="7e8e" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">机器学习生命周期</h1><p id="c618" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">典型的机器学习周期主要包括两个阶段:</p><ul class=""><li id="9c00" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">培养</li><li id="ac8b" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">测试</li></ul><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lv"><img src="../Images/4f655d23f2758014cf65497ff909f6f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6lX2SdJzuwzhok3V8umkAQ.png"/></div></div></figure><p id="4778" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在机器学习中，我们基本上试图创建一个模型来预测测试数据。因此，我们用训练数据来拟合模型，用测试数据来检验模型。生成的模型用来预测未知的结果，称为测试集。正如您所指出的，数据集分为训练集和测试集，以便通过对其进行训练和测试来检查准确性和精确度。</p><ol class=""><li id="09a0" class="jj jk hh in b io ip is it iw jl ja jm je jn ji ma jp jq jr bi translated"><strong class="in hi">训练集</strong>:这里有完整的训练数据集。你可以提取特征和训练来适应模型等等。</li><li id="ad82" class="jj jk hh in b io js is jt iw ju ja jv je jw ji ma jp jq jr bi translated"><strong class="in hi">测试集</strong>:这里，一旦获得模型，就可以使用在训练集上获得的模型进行预测。</li></ol><p id="f8d7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，您对典型的机器学习生命周期的工作原理有了一个概念，让我们继续我们关于MLlib特性及其支持的各种语言的文章。</p><h1 id="8a09" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">MLlib功能和算法</h1><p id="8227" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们知道PySpark适合迭代算法。使用迭代算法，许多机器学习算法已经在PySpark MLlib中实现。除了PySpark的效率和可伸缩性，PySpark MLlib APIs非常用户友好。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/613c6ddc4322b1c414ee886425cbfdb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D08wKE8Yu2i_Awt4NRbEOA.png"/></div></figure><h1 id="d54f" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">使用MLlib查找黑客</h1><p id="00e5" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">一家公司的系统遭到黑客攻击，大量数据被盗。幸运的是，黑客用来连接的每个会话的元数据都被记录下来，可供我们使用。有3个潜在的黑客，甚至更多。</p><p id="8ce3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">黑客们的一个普遍做法是权衡工作。这意味着黑客攻击的次数大致相同。所以这里我们要用聚类来找出黑客的数量。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/7e28ca19a1b22ea1e7691e54f8652c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*Xb41c6g_GloJ0ufPH7txUA.png"/></div></figure><h2 id="de48" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">初始化Spark会话</h2><p id="8c12" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">首先，我们需要初始化spark会话。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="ff98" class="lg jy hh me b fi mi mj l mk ml">from pyspark.sql import SparkSession <br/>spark = SparkSession.builder.appName('find_hacker').getOrCreate()</span></pre><h2 id="3d43" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">导入KMeans库并加载数据集</h2><p id="1c77" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们将使用Kmeans算法进行分析，为此，我们需要导入Kmeans库，然后我们将使用<strong class="in hi"> spark.read </strong>方法加载数据集。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="ae42" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.clustering import KMeans <br/>dataset = spark.read.csv("file:///home/edureka/Downloads/hack_data.csv",header=True,inferSchema=True)</span></pre><h2 id="af91" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">检索的数据的架构</h2><p id="e637" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们看一下数据的模式，以便更好地理解我们正在处理的内容。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="76a1" class="lg jy hh me b fi mi mj l mk ml">dataset.printSchema()</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/2cc0514875a03fe98c8cc26c6ec6dead.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*JS9zfhAqvXUWMAdWk7QE_Q.png"/></div></figure><h2 id="4f56" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">导入VectorAssembler并创建我们的特征</h2><p id="9f1c" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们必须使用VectorAssembler函数将数据转换为一列，其中数据帧的每一行都包含一个特征向量。为了创建我们的集群，我们需要选择列，然后基于这些列创建我们的features列。这里我们使用的是列:</p><ul class=""><li id="af6a" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">会话连接时间</li><li id="9c1f" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">传输的字节数</li><li id="6661" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">Kali_Trace_Used</li><li id="5ccd" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">服务器_损坏</li><li id="9b67" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">页面_损坏</li><li id="bb07" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">WPM _打字_速度:每分钟字数</li></ul><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="938e" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.linalg import Vectors<br/>from pyspark.ml.feature import VectorAssembler<br/> <br/>feat_cols = ['Session_Connection_Time', 'Bytes Transferred', 'Kali_Trace_Used',<br/>'Servers_Corrupted', 'Pages_Corrupted','WPM_Typing_Speed']<br/> <br/>vec_assembler = VectorAssembler(inputCols = feat_cols, outputCol='features')<br/> <br/>final_data = vec_assembler.transform(dataset)</span></pre><h2 id="605a" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">导入StandardScaler库并创建Scaler</h2><p id="24e9" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">通过计算训练集中样本的相关统计数据，对每个特征独立进行居中和缩放。然后，使用变换方法存储平均值和标准偏差，以便在以后的数据中使用。</p><p id="0d40" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">数据集的标准化是许多机器学习评估器的共同要求:如果单个特征看起来或多或少不像标准的正态分布数据，它们可能表现不好。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="629d" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.feature import StandardScaler <br/>scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures", withStd=True, withMean=False)</span></pre><h2 id="296c" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">计算汇总统计数据</h2><p id="2c4d" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们通过安装标准缩放器来计算汇总统计数据。然后归一化每个特征，使其具有单位标准偏差。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="8c54" class="lg jy hh me b fi mi mj l mk ml">scalerModel = scaler.fit(final_data)<br/> <br/>cluster_final_data = scalerModel.transform(final_data)<br/> <br/>kmeans3 = KMeans(featuresCol='scaledFeatures',k=3)<br/>kmeans2 = KMeans(featuresCol='scaledFeatures',k=2)</span></pre><h2 id="ffab" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">构建KMeans模型并计算WSSE(在一组平方误差内)</h2><p id="3941" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们必须首先建立我们的模型。然后将所需的聚类数传递给算法。然后我们在设定的误差平方和(WSSSE)内进行计算。我们使用从这些数据中得出的值来判断我们是有2个还是3个黑客。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="c706" class="lg jy hh me b fi mi mj l mk ml">model_k3 = kmeans3.fit(cluster_final_data)<br/>model_k2 = kmeans2.fit(cluster_final_data)<br/> <br/>wssse_k3 = model_k3.computeCost(cluster_final_data)<br/>wssse_k2 = model_k2.computeCost(cluster_final_data)<br/> <br/>print("With K=3")<br/>print("Within Set Sum of Squared Errors = " + str(wssse_k3))<br/>print('--'*30)<br/>print("With K=2")<br/>print("Within Set Sum of Squared Errors = " + str(wssse_k2))</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/2b1ed36e317408444d283a7663247066.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*TE42AEVGypNqmPd83WwAdA.png"/></div></figure><h2 id="e891" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">检查肘点(WSSSE)</h2><p id="a700" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们将检查WSSSE的值2到8，看看我们是否在列表中有一个肘。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="e668" class="lg jy hh me b fi mi mj l mk ml">for k in range(2,9):<br/>kmeans = KMeans(featuresCol='scaledFeatures',k=k)<br/>model = kmeans.fit(cluster_final_data)<br/>wssse = model.computeCost(cluster_final_data)<br/>print("With K={}".format(k))<br/>print("Within Set Sum of Squared Errors = " + str(wssse))<br/>print('--'*30)</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/543078113c0cbce2e463d7634c33abdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*iWnb_0rflyHWtQ9fnCB3QA.png"/></div></figure><p id="133e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里我们可以看到，WSSSE的值在不断减少，我们没有肘。所以K的值很可能是2而不是3。让我们继续这个PySpark MLlib教程，得出结论。</p><h2 id="4fd7" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">黑客数量的最终检查</h2><p id="0a1e" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们根据黑客攻击的数量来找出有多少黑客参与其中。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="7363" class="lg jy hh me b fi mi mj l mk ml">model_k3.transform(cluster_final_data).groupBy('prediction').count().show()</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/b358a02ceba2b473d601b5411ef7e96d.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*D28qHq8E50m0Dht-S-lsXA.png"/></div></figure><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="30ce" class="lg jy hh me b fi mi mj l mk ml">model_k2.transform(cluster_final_data).groupBy('prediction').count().show()</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mq"><img src="../Images/e3c28ca17fbd1fe899275afa3041aad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/format:webp/1*mlUYsW-3n3F-eKxHSlTX9w.png"/></div></div></figure><p id="cb76" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里我们可以看到，对于3名黑客，我们的模型分别产生了167、79和88次攻击。这是不可能的，因为黑客通常在他们之间分配任务。在我们的模型中，K =2，我们得到167次黑客攻击。因此，只有2名黑客参与其中。</p><p id="27bc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们继续我们的文章，解决许多公司面临的另一个问题。客户流失。</p><h1 id="58c4" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">基于MLlib的客户流失预测</h1><p id="e0e4" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">客户流失预测是一项大业务。它通过预测哪些客户可能会取消某项服务的订购来最大限度地减少客户流失。虽然最初用于电信行业，但现在已经成为银行、ISP、保险公司和其他垂直行业的普遍做法。</p><p id="01f7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">预测过程在很大程度上是由数据驱动的，并且经常利用先进的机器学习技术。在这里，我们将了解通常使用哪些类型的客户数据，对数据进行一些初步分析，并生成流失预测模型——所有这些都使用PySpark及其机器学习框架。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es la"><img src="../Images/535a7c7ef7fdf8fce86165f74055f537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*dFtn5qpUTsaepcy-jssb3A.png"/></div></figure><p id="243e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一家营销机构有许多客户使用他们的服务为客户/顾客网站制作广告。他们已经注意到他们有相当多的客户流失。他们现在基本上随机分配客户经理，但希望您创建一个机器学习模型，帮助预测哪些客户将流失(停止购买他们的服务)，以便他们可以正确分配最有风险的客户流失客户经理。幸运的是，他们有一些历史资料。</p><p id="e0c2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">那么，你能帮助他们吗？</p><h2 id="df3c" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">加载库</h2><p id="923b" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们加载所需的库。这里我们将使用逻辑回归。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="6641" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.classification import LogisticRegression</span></pre><h2 id="8bc1" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">读取训练和测试数据</h2><p id="8387" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们加载训练数据和测试数据(用于测试目的的输入数据)</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="0d18" class="lg jy hh me b fi mi mj l mk ml">input_data=spark.read.csv('file:///home/edureka/Downloads/customer_churn.csv',header=True,inferSchema=True)<br/> <br/>test_data=spark.read.csv('file:///home/edureka/Downloads/new_customers.csv',header=True,inferSchema=True)</span></pre><h2 id="afc3" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">数据模式</h2><p id="732a" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">我们将查看数据的模式，以便更好地理解我们正在处理的内容。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="1176" class="lg jy hh me b fi mi mj l mk ml">input_data.printSchema() //training data</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/e8b5d701c6c91a78a7a5c8c277335356.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*JrJgalNz3vXBPgmLiiD2dQ.png"/></div></figure><p id="2a39" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这里我们有列搅动。让我们看看测试数据的模式。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="d155" class="lg jy hh me b fi mi mj l mk ml">test_data.printSchema() //testing data</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/549fe303793c1d2345364761cd1dba68.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*L-ty15C1d7YJopcYpyWhjg.png"/></div></figure><h2 id="18d9" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">使用矢量汇编器</h2><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="72b1" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.linalg import Vectors<br/>from pyspark.ml.feature import VectorAssembler<br/> <br/>assembler=VectorAssembler(inputCols=['Age','Total_Purchase','Account_Manager','Years','Num_Sites'],outputCol='features')<br/> <br/>output_data=assembler.transform(input_data)</span></pre><h2 id="a748" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">输出数据的模式</h2><p id="8525" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">让我们看看输出数据的模式。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="f9a7" class="lg jy hh me b fi mi mj l mk ml">output_data.printSchema()</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/b7e3da5d009a3658bcc8b3e11c9d1f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*6JAjxKZJ8blstVSJwJ4jUQ.png"/></div></figure><p id="181d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">正如你们所看到的，我们在这里有一个功能栏，分类将基于它进行。</p><h2 id="bdc7" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">对数据使用逻辑回归</h2><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="d20f" class="lg jy hh me b fi mi mj l mk ml">final_data=output_data.select('features','churn')         //creating final data with only 2 columns<br/> <br/>train,test=final_data.randomSplit([0.7,0.3])          //splitting data<br/> <br/>model=LogisticRegression(labelCol='churn')           //creating model<br/> <br/>model=model.fit(train)        //fitting model on training dataset<br/> <br/>summary=model.summary<br/> <br/>summary.predictions.describe().show()         //summary of the predictions on training data</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/441d09ea3ad0b7dd6e946da2bbd4c26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*hAg__sAgT3DG-MOU5Byf-w.png"/></div></figure><h2 id="216d" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">导入BinaryClassificationEvaluator库并测试</h2><p id="0d1c" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">二元分类器的评估比较了分配二元属性的两种方法，其中一种通常是标准方法，另一种正在研究中。有许多度量可用于测量分类器或预测器的性能；由于不同的目标，不同的领域对具体指标有不同的偏好。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="8436" class="lg jy hh me b fi mi mj l mk ml">from pyspark.ml.evaluation import BinaryClassificationEvaluator predictions=model.evaluate(test)</span></pre><p id="7ead" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，我们将创建一个赋值器，并使用二元分类赋值器来预测流失。</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="42e8" class="lg jy hh me b fi mi mj l mk ml">evaluator=BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='churn')<br/> <br/>evaluator.evaluate(predictions.predictions)<br/> <br/>model1=LogisticRegression(labelCol='churn')<br/>model1=model1.fit(final_data)<br/> <br/>test_data=assembler.transform(test_data)</span></pre><h2 id="0ac5" class="lg jy hh bd jz lh li lj kd lk ll lm kh iw ln lo kl ja lp lq kp je lr ls kt lt bi translated">查找结果</h2><p id="da47" class="pw-post-body-paragraph il im hh in b io kv iq ir is kw iu iv iw kx iy iz ja ky jc jd je kz jg jh ji ha bi translated">现在，我们将使用该模型来评估新数据</p><pre class="lb lc ld le fd md me mf mg aw mh bi"><span id="92e7" class="lg jy hh me b fi mi mj l mk ml">results=model1.transform(test_data) results.select('Company','prediction').show()</span></pre><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/233f509a0a233926bc24b9b35bc01efe.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*5qhnd64oxL8fnFsl92auCQ.png"/></div></figure><p id="4712" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，在这里我们可以看到可能离开组织的潜在客户，通过这一分析，我们来到本文的结尾。</p><p id="26ad" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我希望你喜欢这篇文章。如果你正在读这篇文章，那么恭喜你！你不再是PySpark MLlib的新手。现在就在您系统上尝试这些简单的例子。</p><p id="44a6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="27e8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请留意本系列中的其他文章，它们将解释PySpark的各个方面。</p><blockquote class="mw mx my"><p id="60fe" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">1.<a class="ae lf" rel="noopener" href="/edureka/pyspark-tutorial-87d41dab9657"> PySpark教程</a></p><p id="b279" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">2.<a class="ae lf" rel="noopener" href="/edureka/pyspark-dataframe-tutorial-9335f3d09b4"> PySpark Dataframe教程</a></p><p id="7e12" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">3.<a class="ae lf" rel="noopener" href="/edureka/pyspark-rdd-ef9edd060a25">py spark中的RDDs】</a></p><p id="72b6" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">4.<a class="ae lf" rel="noopener" href="/edureka/pyspark-programming-e007e68fbccb"> PySpark编程</a></p></blockquote></div><div class="ab cl nd ne go nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ha hb hc hd he"><p id="b7d9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="mz">原载于2018年7月24日</em><a class="ae lf" href="https://www.edureka.co/blog/pyspark-mllib-tutorial/" rel="noopener ugc nofollow" target="_blank"><em class="mz">www.edureka.co</em></a><em class="mz">。</em></p></div></div>    
</body>
</html>