<html>
<head>
<title>HierTCN: Deep learning models for dynamic recommendations and inferring user interests</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HierTCN:用于动态推荐和推断用户兴趣的深度学习模型</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/hiertcn-deep-learning-models-for-dynamic-recommendations-and-inferring-user-interests-a31e8cd4b71e?source=collection_archive---------1-----------------------#2019-05-17">https://medium.com/pinterest-engineering/hiertcn-deep-learning-models-for-dynamic-recommendations-and-inferring-user-interests-a31e8cd4b71e?source=collection_archive---------1-----------------------#2019-05-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2500" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Aditya Pal和Pong Eksombatchai |应用科学</p><p id="b6d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们构建视觉发现引擎时，理解用户意图并通过推荐系统提供相关内容是至关重要的，推荐系统不断从数据的横截面中学习，以动态预测Pinner会喜欢的下一个想法。然而，我们发现现有的方法受到缺乏速度和内存消耗的限制，并且不包含跨会话信息。此外，一个关键的挑战是用户兴趣会随着时间的推移而动态变化和发展(如图1所示)。我们的目标是建立适应大规模用户兴趣模式变化的技术。</p><p id="aa7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为回应，我们开发了分层时态卷积网络(HierTCN)，这是一种深度学习架构，可以根据用户与物品的顺序多会话交互进行动态推荐。这项工作介绍了一个层次模型，采用递归神经网络(RNN)和TCN，以有效地捕捉用户的短期和长期兴趣。我们发现HierTCN在离线环境下的表现优于几个基线模型。</p><p id="4a36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我们将分享更多关于我们的方法。此外，你可以在本周发表的一篇论文中找到我们工作的详细信息，该论文与在三藩市召开的网络会议结合在一起<a class="ae jc" href="https://www2019.thewebconf.org/" rel="noopener ugc nofollow" target="_blank">:</a><a class="ae jc" href="https://dl.acm.org/citation.cfm?id=3313747" rel="noopener ugc nofollow" target="_blank">用于动态推荐系统的层次时态卷积网络</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/8bc41f711fd038d7213f6f5a2ed3284a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CpPG-fF7uqOyF645aPqh0g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx"><em class="jt">Figure 1. A sample sequence of actions of a randomly selected user.</em></figcaption></figure><p id="e439" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的方法是基于这样的观察:用户在会话间的兴趣取决于他们的长期兴趣，而他们的短期会话内兴趣往往会迅速发展。因此，一个理想的用户模型应该捕捉不同层次的用户动态。我们通过考虑两级卷积网络(HierTCN)模型来实现这一观察，该模型使用递归神经网络(RNN)来聚合会话间的信息，使用时间卷积网络(TCN)来聚合会话内的信息。</p><p id="d11f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的模型的输入是用户与之交互(保存或点击)的一系列pin(带有会话信息)。输入pin通过其<a class="ae jc" rel="noopener" href="/pinterest-engineering/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48"> PinSage嵌入</a>建模，主要目标是在与PinSage相同的潜在空间中学习用户嵌入。图2描述了HierTCN的架构。这里的高级模型是GRU，它通过使用函数AGG(.).低层模型基于GRU隐藏状态和当前会话中的交互，使用TCN来预测每个时间步的用户嵌入。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ju"><img src="../Images/045c01c8159854874e22bf3167853806.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aCwVGsWPdG6WeKAv7Mn4A.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx"><em class="jt">Figure 2: HierTCN</em></figcaption></figure><p id="7ee6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练目标是将直到时间t的用户交互序列作为输入，以生成可以预测下一个交互pin的嵌入u_t。为了简化这一训练目标，我们考虑一种负采样方法，其中序列中的每个交互引脚都有一组相关联的负引脚，这些负引脚的等级应该更低(通常是相应会话期间的印象引脚)。</p><p id="f0bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图3显示了我们的模型在野外的工作情况。第一行是交互pin的序列，随后的行显示不同模型的排名。我们注意到，基于移动平均线的模型对基于食品的大头针排序更高(长期兴趣)，而TCN以家庭装饰大头针为支点(短期兴趣)。另一方面，HierTCN能够更好地融合这些短期和长期利益。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jv"><img src="../Images/4470f1511b43a9c06c8e36e98a12bc68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0CzNqeXgP-mahWLZ3vtbZw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">Figure 3</figcaption></figure><p id="5703" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不同模型的大规模离线验证(图3)显示，HierTCN在所有评估指标上都比竞争基准有10–15%的持续提升。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl jw"><img src="../Images/51337884c88767a1ff13c2c7bb9c9554.png" data-original-src="https://miro.medium.com/v2/0*BmoOuA4Gk9U0lL2x"/></div></figure><p id="6355" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论</strong></p><p id="36d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最终，HierTCN是为拥有数十亿项目和数亿用户的web级系统而设计的。它由两个层次的模型组成:高层模型使用递归神经网络(RNN)来聚合用户在不同会话中不断发展的长期兴趣，而低层模型使用时间卷积网络(TCN)来实现，利用会话中的长期兴趣和短期交互来预测下一次交互。我们在一个公共XING数据集和一个包含600万用户和16亿次交互的大规模Pinterest数据集上进行了大量实验。</p><p id="904d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们发现HierTCN比基于RNN的模型快2.5倍，使用的数据内存比基于TCN的模型少90%。我们进一步开发了一个有效的数据缓存方案和一个基于队列的小批量生成器，这使得我们的模型能够在24小时内在单个GPU上进行训练。我们的模型始终优于最先进的动态推荐方法，召回率提高了18%，平均倒数排名提高了10%。</p><p id="5c67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们正致力于生产该模型，以在Pinterest内提供大规模推荐。</p><p id="9cc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jx">鸣谢:本工作的核心贡献者有:游嘉轩、、Aditya Pal、Pong Eksombatchai、Chuck Rosenberg、Jure Leskovec。</em></p></div></div>    
</body>
</html>