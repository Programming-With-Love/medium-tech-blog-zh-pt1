<html>
<head>
<title>Improving HBase backup efficiency at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高Pinterest的HBase备份效率</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954?source=collection_archive---------1-----------------------#2018-03-30">https://medium.com/pinterest-engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954?source=collection_archive---------1-----------------------#2018-03-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9cbb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">徐|软件工程师，存储和缓存团队</p><p id="7905" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinterest拥有业内最大的HBase生产部署之一。HBase是我们基础设施的基础构建模块之一，为我们的许多关键服务提供支持，包括我们的图形数据库(Zen)、我们的通用键值存储(UMS)、我们的时间序列数据库以及其他一些服务。尽管可用性很高，我们还是会定期将生产HBase集群备份到S3上，以用于灾难恢复目的。</p><p id="3ddd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本帖中，我们将介绍如何通过从备份路径中删除中间HDFS集群和使用离线重复数据删除工具来消除重复的快照文件，从而显著提高HBase备份效率。最终，这简化了备份流程，将端到端备份时间缩短了一半，降低了运营开销，并将S3存储使用量减少了两个数量级。</p><p id="87ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们开始之前，我们想指出，由于历史原因，备份管道由两个步骤组成:</p><ol class=""><li id="6251" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">将HBase表快照和预写日志(wal)导出到专用备份HDFS集群。</li><li id="d5ee" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">将数据从备份群集上传到S3。随着数据量(约为PBs)的增长，S3和备份集群的存储成本也在不断增加。</li></ol><h1 id="b207" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">简化备份管道</h1><h2 id="d018" class="ko jr hh bd js kp kq kr jw ks kt ku ka ip kv kw ke it kx ky ki ix kz la km lb bi translated">历史</h2><p id="1cb1" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">当我们第一次基于HBase 0.94版构建备份管道时，没有现成的工具可以将h base快照直接导出到S3。唯一支持的方法是将快照导出到HDFS群集。这是我们最初采取两步走办法的主要原因。然而，随着系统的发展，专用的HDFS集群成为了单点故障，并导致了大量的操作开销。因此，我们不得不不断增加机器来容纳不断增长的数据量。</p><p id="bac1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近，我们完成了HBase从0.94版到1.2版的升级。除了许多错误修复和性能改进，新版本的HBase还提供了直接将表快照导出到S3的原生支持。借此机会，我们通过从备份路径中删除HDFS集群来优化我们的备份渠道。此外，我们创建了一个名为PinDedup的工具，该工具可以跨备份周期(稍后描述)对S3上的冗余快照文件进行异步重复数据删除，以减少我们的S3占用空间。</p><h2 id="22fe" class="ko jr hh bd js kp kq kr jw ks kt ku ka ip kv kw ke it kx ky ki ix kz la km lb bi translated">挑战和方法</h2><p id="ed68" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">我们在迁移中遇到的一个主要挑战是最大限度地减少对生产HBase集群的影响，因为它们服务于在线请求。使用类似于<a class="ae lh" href="https://hadoop.apache.org/docs/current/hadoop-distcp/DistCp.html" rel="noopener ugc nofollow" target="_blank"> distcp </a>的MapReduce作业完成表导出。为了增加上传吞吐量，我们使用带有快速上传选项的S3A客户端。在实验过程中，我们观察到，直接S3上传往往是非常CPU密集型的，特别是对于传输大文件，如HFiles。当一个大文件被分解成多个块时就会发生这种情况，每个块在上传之前都需要被散列和签名。如果我们使用的线程数量超过了机器上的内核数量，执行上传的regionserver将会饱和并可能崩溃。为了缓解这个问题，我们限制了每台主机的并发线程和纱线容器的最大数量，以便备份导致的最大CPU开销低于30%。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es li"><img src="../Images/24a7011490cd7f5c748a32377151ae6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EgyXtipakXjhb3Hv."/></div></div></figure><h1 id="ecc9" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">删除S3上的重复文件</h1><h2 id="fd39" class="ko jr hh bd js kp kq kr jw ks kt ku ka ip kv kw ke it kx ky ki ix kz la km lb bi translated">大文件很少改变</h2><p id="759c" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">对HBase快照进行重复数据消除的想法是受观察到的大型HFiles在整个备份周期中通常保持不变的启发。虽然增量更新与小压缩合并，但占存储使用量最大的大型HFiles仅在大压缩期间合并。因此，相邻的备份日期通常包含许多重复的大型HFiles，尤其是对于读取量大的HBase集群。</p><p id="3a3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于这一观察，我们提出并实现了一个简单的文件级重复数据删除工具，称为PinDedup。它跨相邻备份周期异步检查重复的S3文件，并用引用替换较旧的文件。为了提高重复数据删除的效率，我们调整了主要的压缩策略，使其不那么激进，只在必要时触发。</p><h2 id="0cd3" class="ko jr hh bd js kp kq kr jw ks kt ku ka ip kv kw ke it kx ky ki ix kz la km lb bi translated">设计选择</h2><p id="c9a3" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">尽管PinDedup很简单，但我们必须考虑一些设计选择。</p><p id="aac8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">文件级与区块级重复数据删除</strong>。PinDedup中使用的文件级重复数据消除方法提供了足够好的压缩率。也实现了可变大小的分块，但是它只带来了边际效益，增加了系统的复杂性。这主要是因为在主要的压缩过程中，合并的更改(尽管总数据量很小)会遍布整个文件，并修改大多数块。</p><p id="e335" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">在线与离线重复数据删除。</strong>在线重复数据删除是指在数据上传到S3之前进行重复数据删除。当存在重复时，这可能会避免将大文件传输到S3。我们选择离线重复数据消除，因为它允许我们控制何时进行重复数据消除。由于客户端团队经常使用最新的快照进行离线分析，我们可以将重复数据消除延迟到分析作业完成之后。</p><p id="7d2a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">保持最新副本不变。</strong>当识别两个重复文件时，一个重要的问题是是否用引用替换旧的或新的文件。我们选择了前者，因为最新的文件更有可能被访问。我们将这种方法称为“正向重复数据消除链”与其对应的方法相比，这种方法在访问最新数据时不会产生开销，同时避免了由于保留而删除旧快照时的悬空指针问题。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lu"><img src="../Images/295b44b1111259525d13b56448817157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QxWJ6bWQvqPAIaMR."/></div></div></figure><h1 id="8453" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结果</h1><p id="14bf" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">备份管道顺利升级，没有造成任何事故(谢天谢地！).移除HDFS备份群集减少了运营开销，并将端到端备份时间缩短了大约50%。PinDedup推广到S3上的所有HBase备份，并实现了从1/3到1/137的存储缩减。这两者相结合，大大节省了基础设施成本。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div class="er es lv"><img src="../Images/c2e708437034ef3a06c845ca00e483ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*VS-SIyipZqIIfQYxAvva3A.png"/></div></figure><p id="a8fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lw">鸣谢:非常感谢张天英和Chiyoung Seo的支持和技术指导，感谢梁成进和劳拉·比斯特的知识转移和代码审查，感谢安德鲁·邓勒普帮助建立测试环境，感谢存储和缓存团队的其他成员在设计和实现过程中提供的宝贵反馈。</em></p></div></div>    
</body>
</html>