<html>
<head>
<title>Deep Learning With Python - A Comprehensive Guide to Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python深度学习——深度学习综合指南</h1>
<blockquote>原文：<a href="https://medium.com/edureka/deep-learning-with-python-2adbf6e9437d?source=collection_archive---------0-----------------------#2019-02-19">https://medium.com/edureka/deep-learning-with-python-2adbf6e9437d?source=collection_archive---------0-----------------------#2019-02-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/e5727bb0b45608d40be15f87dabc27d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*TcN-6LZt42D8tnRIjaC9Mw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Deep Learning with Python - Edureka</figcaption></figure><p id="95c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">深度学习</strong>是2018-19年最热门的话题之一，理由很充分。在工业中已经有了如此多的进步，其中机器或计算机程序实际上代替人类的时代已经到来。这篇使用Python的<strong class="ir hi"> <em class="jn">深度学习</em> </strong>文章将帮助您了解深度学习到底是什么，以及这种转变是如何实现的。在本文中，我将涉及以下主题:</p><ul class=""><li id="8b78" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">数据科学及其组成部分</li><li id="fff2" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">对深度学习的需求</li><li id="f5f7" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">什么是深度学习？</li><li id="e9a5" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">感知器和人工神经网络</li><li id="9d0d" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">深度学习的应用</li><li id="a7dc" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">为什么用Python做深度学习？</li><li id="8b49" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">使用Python进行深度学习:感知器示例</li><li id="e084" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">用Python进行深度学习:创建深度神经网络</li></ul><h1 id="fd3f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">数据科学及其组成部分</h1><p id="69e3" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">数据科学已经存在很长时间了。数据科学是通过使用不同的技术和算法从数据中提取知识。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lf"><img src="../Images/4548721a439dfa10f52a1ab14ac2989f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gXwmn9C9VaipvlvhgfPWtg.png"/></div></div></figure><p id="5b33" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">人工智能是一种使机器能够模仿人类行为的技术。人工智能背后的想法相当简单却又令人着迷，那就是制造能够自己做出决定的智能机器。多年来，人们认为计算机永远比不上人脑的能力。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/c6e51c074228216832f95faebf03164b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*LUJ86RXA2UmHzr0HSHCwdw.png"/></div></figure><p id="d639" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">嗯，当时我们没有足够的数据和计算能力，但现在随着大数据的出现和GPU的出现，人工智能成为可能。</p><p id="a95c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">机器学习</strong>是人工智能技术的一个子集，它使用统计方法使机器能够随着经验而改进。</p><p id="e51f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">深度学习</strong>是ML的子集，使得多层神经网络的计算变得可行。它使用神经网络来模拟类似人类的决策。</p><h1 id="c5dd" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">对深度学习的需求</h1><p id="d988" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">迈向人工智能的一步是机器学习。机器学习是人工智能的一个子集，它基于这样一种想法，即机器应该能够访问数据，应该能够自己学习和探索。它处理从大型数据集中提取模式。处理大型数据集不是问题。</p><ul class=""><li id="9fd4" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">机器学习算法<strong class="ir hi">无法处理高维数据</strong>——我们有大量的输入和输出:对数千维进行舍入。处理和加工这种类型的数据变得非常复杂，而且会耗尽资源。这被称为<strong class="ir hi">维数灾难。</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/0169dffe7681fc23144bdf85b7a81564.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*sXOPThEMkZhEav31GDTrcg.png"/></div></figure><ul class=""><li id="f09f" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">面临的另一个挑战是，指定要提取的<strong class="ir hi">特征</strong>。这在预测结果以及实现更高的准确性方面起着重要的作用。因此，如果没有特征提取，对程序员的挑战会增加，因为算法的有效性在很大程度上取决于程序员的洞察力。</li></ul><p id="b910" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，这就是深度学习来拯救我们的地方。深度学习<strong class="ir hi">能够处理高维数据</strong>，并且在<strong class="ir hi">专注于正确的特征</strong>方面也很有效。</p><h1 id="9598" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">什么是深度学习？</h1><p id="ba9f" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">深度学习是机器学习的一个子集，其中类似的机器学习算法用于训练<strong class="ir hi">深度神经网络</strong>，以便在前者表现不达标的情况下实现更好的准确性。基本上，<strong class="ir hi">深度学习模仿我们大脑的运作方式</strong>，即它从经验中学习。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/33a05189c8598db71cbc3f1c63060ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*j8rroqJMDf0V0rkLq-GBxw.png"/></div></figure><p id="5aa6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如你所知，我们的大脑是由数十亿个神经元组成的，这些神经元让我们能够做出惊人的事情。即使小孩子的大脑也能解决复杂的问题，而这些问题即使使用超级计算机也很难解决。那么，我们如何在一个程序中实现同样的功能呢？现在，这就是我们理解<strong class="ir hi">人工神经元(感知器)</strong>和<strong class="ir hi">人工神经网络的地方。</strong></p><h1 id="46a1" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">感知器和人工神经网络</h1><p id="b9d2" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">深度学习研究大脑的基本单元，称为脑细胞或神经元。现在，让我们了解生物神经元的功能，以及我们如何在感知或人工神经元中模仿这种功能。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/32143c67b5cd6d9f86356efcd39fde8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*vChu0htpiCejLYbW4mfkbg.png"/></div></figure><ul class=""><li id="cdb0" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">树突:</strong>接收来自其他神经元的信号</li><li id="6760" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">单元体:</strong>对所有输入求和</li><li id="cdbe" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">轴突:</strong>用于向其他细胞传递信号</li></ul><p id="ebf0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">人工神经元或<strong class="ir hi">感知器</strong>是用于二元分类的线性模型。它模拟了一个有一组输入的神经元，每个输入都有一个特定的权重。神经元对这些<strong class="ir hi">加权</strong>输入计算一些函数，并给出输出。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/2b9d8b8809421e902d2f4292b5a2eea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*bcqDZOLv4RlIw8HUFntSXA.png"/></div></figure><p id="2013" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它接收n个输入(对应于每个特征)。然后，它将这些输入相加，应用一个变换并产生一个输出。它有两个功能:</p><ul class=""><li id="8938" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">总和</li><li id="4bc8" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">转化(激活)</li></ul><p id="3d52" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">权重显示了特定输入的有效性。<strong class="ir hi">输入的权重越多，对神经网络的影响就越大</strong>。另一方面，<strong class="ir hi"> Bias </strong>是感知器中的一个<strong class="ir hi">附加参数</strong>,用于调整输出以及神经元输入的加权和，这有助于模型最适合给定数据。</p><p id="f24c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">激活功能</strong>将输入转化为输出。它使用阈值来产生输出。有许多功能可用作激活功能，例如:</p><ul class=""><li id="74ec" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">线性或恒等式</li><li id="5677" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">单位或二进制步长</li><li id="c0cc" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">乙状结肠或逻辑</li><li id="348b" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">双曲正切</li><li id="95cb" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">热卢</li><li id="80fc" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">Softmax</li></ul><p id="c6ef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好吧。如果你认为感知器解决了问题，那你就错了。有两个主要问题:</p><ul class=""><li id="ca95" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">单层感知器<strong class="ir hi">无法对非线性可分离数据点</strong>进行分类。</li><li id="786a" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">涉及<strong class="ir hi">大量参数</strong>的复杂问题是单层感知器无法解决的。</li></ul><p id="88cc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑一下这个例子，以及营销团队做出决策所涉及的参数的复杂性。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lt"><img src="../Images/2597b1b3dacda0239579c473df8b6254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yfXjrIw_Atpv4hSndfcvVw.png"/></div></div></figure><p id="fa7e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个神经元不能接受这么多的输入，这就是为什么要用一个以上的神经元来解决这个问题。神经网络实际上只是感知器的<strong class="ir hi">组合，以不同的方式</strong>连接，并对不同的激活功能进行操作。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/67fb9d91a935348bef5bfee99ecc1867.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*GZXpi9lCCzMgPw6zxj59AA.png"/></div></figure><ul class=""><li id="a1b8" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">输入节点</strong>向网络提供来自外界的信息，统称为“输入层”。</li><li id="c9c7" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">隐藏节点</strong>执行计算并将信息从输入节点传输到输出节点。隐藏节点的集合形成了“隐藏层”。</li><li id="f108" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">输出节点</strong>统称为“输出层”，负责计算并将信息从网络传输到外部世界。</li></ul><p id="ae02" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你对感知机的行为方式、涉及的不同参数和神经网络的不同层有了一个概念，让我们通过Python博客继续这个深度学习，看看深度学习的一些很酷的应用。</p><h1 id="a386" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">深度学习的应用</h1><p id="6919" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">深度学习在行业中有各种各样的应用，这里有几个在我们日常任务中存在的重要应用。</p><ul class=""><li id="1f97" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">语音识别</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/014707bd3f203ad3502b5e76809ee87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*8pDvjvBlppLLjnIgLvRzRQ.png"/></div></figure><ul class=""><li id="b72b" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">机器翻译</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/7ada2446af1951177f7ee6399742c0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*_c__ow2sot2387LpAX4O4A.png"/></div></figure><ul class=""><li id="698e" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">面部识别和自动标记</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/7448ab78c6ec8ad84dd0e826a16ffc97.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*UdzcMRStOa89gwEYNIu2QA.png"/></div></figure><ul class=""><li id="8591" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">虚拟个人助理</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/ff87e1cda723096f6a61f57cee3a818c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*exLcoBxCsy32XW1NlrwOgw.png"/></div></figure><ul class=""><li id="767e" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">自动驾驶汽车</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/f99862461139b739bb47d584527071bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*-NjPHaceSh4kAqCjaWmF1Q.png"/></div></figure><ul class=""><li id="8522" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">聊天机器人</strong></li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/a2357ccb650aaa6a91a3f4fa9902e058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*sNpLSOtmyWeQ_rMCAjg_1Q.png"/></div></figure><h1 id="a27a" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">为什么用Python做深度学习？</h1><ul class=""><li id="1e71" class="jo jp hh ir b is la iw lb ja lw je lx ji ly jm jt ju jv jw bi translated">Python就是这样一种工具，它有一个独特的属性，即作为一种通用编程语言，在进行分析和定量计算时容易使用。</li><li id="1063" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">很容易理解</li><li id="0355" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">Python是<strong class="ir hi">动态类型的</strong></li><li id="91b2" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">巨大的<strong class="ir hi">社区支持</strong></li><li id="6402" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">各种不同用途的库，如Numpy、Seaborn、Matplotlib、Pandas和Scikit-learn</li></ul><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lz"><img src="../Images/d404902d9e43305da63ef9d40437c235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iW4_tX0XKc0cKEmKN6r_JA.png"/></div></div></figure><p id="1c84" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，理论已经足够了，让我们看看如何通过一个小而令人兴奋的例子开始用Python进行深度学习。</p><h1 id="045a" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">感知器示例</h1><p id="be38" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">现在我相信你们一定很熟悉“<strong class="ir hi">或“</strong>门”的工作原理。如果任何输入也是<strong class="ir hi"> 1，则输出为<strong class="ir hi"> 1 </strong>。</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/3f8bc71bd4b9e3b698c69553fdf68bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/1*RHWnBhcIMn2xfmQSAC0KqQ.png"/></div></figure><p id="5e1e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，感知器可用作分隔符或判定线，将or门的输入集分为两类:</p><p id="e93a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第1类:</strong>输出为0的输入位于判定线以下。<br/> <strong class="ir hi">第2类:</strong>输入输出为1，位于判定线或分隔符之上。</p><p id="299d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">到目前为止，我们知道线性感知器可以用来将输入数据集分为两类。但是，它是如何对数据进行分类的呢？</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/b3b4aafd005e2e2772428e878a4b6ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*e6NVpmXXSn7ixTEpPSARTg.png"/></div></figure><p id="be04" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在数学上，感知器可以被认为是一个权重、输入和偏差的等式。</p><h2 id="c2d0" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤1:导入所有需要的库</h2><p id="d3ac" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">这里我将只导入一个库，即。张量流</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="b1ec" class="mb kd hh mq b fi mu mv l mw mx">import tensorflow as tf</span></pre><h2 id="7a26" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤2:定义输入和输出的向量变量</h2><p id="93e6" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">接下来，我们需要创建变量来存储感知器的输入、输出和偏差。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="765d" class="mb kd hh mq b fi mu mv l mw mx">train_in = [<br/>[0,0,1],<br/>[0,1,1],<br/>[1,0,1],<br/>[1,1,1]]<br/> <br/> <br/> <br/>train_out = [<br/>[0],<br/>[1],<br/>[1],<br/>[1]]</span></pre><h2 id="ed90" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤3:定义权重变量</h2><p id="b8d6" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">这里，我们将为我们的权重定义形状为3×1的张量变量，并最初为其分配一些随机值。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="d467" class="mb kd hh mq b fi mu mv l mw mx">w = tf.Variable(tf.random_normal([3, 1], seed=15))</span></pre><h2 id="6ba9" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤4:为输入和输出定义占位符</h2><p id="aaad" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们需要定义占位符，以便它们可以在运行时接受外部输入。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="004a" class="mb kd hh mq b fi mu mv l mw mx">x = tf.placeholder(tf.float32,[None,3])<br/>y = tf.placeholder(tf.float32,[None,1])</span></pre><h2 id="2c91" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤5:计算输出和激活函数</h2><p id="abe0" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">如前所述，感知器接收的输入首先乘以各自的权重，然后，所有这些加权的输入相加在一起。然后，该求和值被馈送到激活，以获得最终结果。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/0f268f9283b653f1a92e712af73f2c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*J8lAmGG-EbfTlPH3R9OjBQ.png"/></div></figure><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="1310" class="mb kd hh mq b fi mu mv l mw mx">output = tf.nn.relu(tf.matmul(x, w))</span></pre><p id="0e4d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">注意:在这种情况下，我使用了<strong class="ir hi"> <em class="jn"> relu </em> </strong>作为我的激活函数。您可以根据需要自由使用任何激活功能。</p><h2 id="4cb0" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">第六步:计算成本或误差</h2><p id="6566" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们需要计算成本=均方差，也就是感知器输出和期望输出之差的平方。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="9f83" class="mb kd hh mq b fi mu mv l mw mx">loss = tf.reduce_sum(tf.square(output - y))</span></pre><h2 id="c52c" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">第七步:尽量减少错误</h2><p id="cafc" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">感知器的目标是最小化损失或成本或错误。这里我们将使用梯度下降优化器。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="02e2" class="mb kd hh mq b fi mu mv l mw mx">optimizer = tf.train.GradientDescentOptimizer(0.01)<br/>train = optimizer.minimize(loss)</span></pre><h2 id="327c" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤8:初始化所有变量</h2><p id="04cc" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">变量只能用<em class="jn"> tf.Variable. </em>来定义，所以，我们需要初始化定义的变量。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="fa9d" class="mb kd hh mq b fi mu mv l mw mx">init = tf.global_variables_initializer()<br/>sess = tf.Session()<br/>sess.run(init)</span></pre><h2 id="3145" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">步骤9:在迭代中训练感知器</h2><p id="ccfd" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们需要训练我们的感知器，即在连续迭代中更新权重和偏差的值，以最小化误差或损失。在这里，我将用100个纪元来训练我们的感知机。</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="cd3c" class="mb kd hh mq b fi mu mv l mw mx">for i in range(100):<br/>sess.run(train, {x:train_in,y:train_out})<br/>cost = sess.run(loss,feed_dict={x:train_in,y:train_out})<br/>print('Epoch--',i,'--loss--',cost)</span></pre><h2 id="d184" class="mb kd hh bd ke mc md me ki mf mg mh km ja mi mj kq je mk ml ku ji mm mn ky mo bi translated">第十步:输出</h2><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es my"><img src="../Images/16c5152e5d2e8b35aed04eb90420f5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*jpRH10YggaxrF3B2iOIQjg.png"/></div></figure><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mz"><img src="../Images/f6220310c901775bc41b198925da1fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*bHPvA0IK_U5stkSaIfnY6w.png"/></div></figure><p id="ab55" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如你所见，损失开始于<strong class="ir hi"> 2.07 </strong>，结束于<strong class="ir hi"> 0.27 </strong></p><h1 id="a5c3" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">创建一个深度神经网络</h1><p id="be47" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">现在，我们已经成功地创建了一个感知器，并训练它用于或门。让我们继续这篇文章，看看如何可以从头开始创建我们自己的神经网络，我们将创建一个输入层，隐藏层和输出层。</p><p id="19da" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将使用MNIST的数据集。MNIST数据集由<strong class="ir hi"> 60，000个训练</strong>样本和<strong class="ir hi"> 10，000个手写数字图像测试</strong>样本组成。图像尺寸为<strong class="ir hi"> 28×28像素</strong>，输出可以在<strong class="ir hi">0–9</strong>之间。</p><p id="f067" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">这里的任务是训练一个模型，它可以准确地识别图像上出现的数字</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/be5ac0a1b4361300eaa9ab7e3a85cd66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*YLESWJky4iDbcu1B1T2neQ.png"/></div></figure><p id="cb13" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先，我们将使用下面的导入将打印功能从Python 3引入Python 2.6+。__future__语句需要放在文件的顶部附近，因为它们改变了语言的基本特性，所以编译器需要从一开始就了解它们</p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="caa9" class="mb kd hh mq b fi mu mv l mw mx">from __future__ import print_function</span></pre><p id="216c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">下面是每一步都有注释的代码</strong></p><pre class="lg lh li lj fd mp mq mr ms aw mt bi"><span id="bc6b" class="mb kd hh mq b fi mu mv l mw mx"># Import MNIST data<br/>from tensorflow.examples.tutorials.mnist import input_data<br/>mnist = input_data.read_data_sets("/tmp/data/", one_hot=True)<br/> <br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/> <br/># Parameters<br/>learning_rate = 0.001<br/>training_epochs = 15<br/>batch_size = 100<br/>display_step = 1<br/> <br/># Network Parameters<br/>n_hidden_1 = 256 # 1st layer number of features<br/>n_hidden_2 = 256 # 2nd layer number of features<br/>n_input = 784 # MNIST data input (img shape: 28*28)<br/>n_classes = 10 # MNIST total classes (0-9 digits)<br/> <br/># tf Graph input<br/>x = tf.placeholder("float", [None, n_input])<br/>y = tf.placeholder("float", [None, n_classes])<br/> <br/># Create model<br/>def multilayer_perceptron(x, weights, biases):<br/>    # Hidden layer with RELU activation<br/>    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])<br/>    layer_1 = tf.nn.relu(layer_1)<br/>    # Hidden layer with RELU activation<br/>    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])<br/>    layer_2 = tf.nn.relu(layer_2)<br/>    # Output layer with linear activation<br/>    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']<br/>    return out_layer<br/> <br/># Store layers weight &amp; bias<br/>weights = {<br/>    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),<br/>    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),<br/>    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))<br/>}<br/> <br/>biases = {<br/>    'b1': tf.Variable(tf.random_normal([n_hidden_1])),<br/>    'b2': tf.Variable(tf.random_normal([n_hidden_2])),<br/>    'out': tf.Variable(tf.random_normal([n_classes]))<br/>}<br/> <br/># Construct model<br/>pred = multilayer_perceptron(x, weights, biases)<br/> <br/># Define loss and optimizer<br/>cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))<br/>optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)<br/> <br/># Initializing the variables<br/>init = tf.global_variables_initializer()<br/> <br/>#create an empty list to store the cost history and accuracy history<br/>cost_history = []<br/>accuracy_history = []<br/> <br/># Launch the graph<br/>with tf.Session() as sess:<br/>    sess.run(init)<br/> <br/>    # Training cycle<br/>    for epoch in range(training_epochs):<br/>        avg_cost = 0.<br/>        total_batch = int(mnist.train.num_examples/batch_size)<br/>        # Loop over all batches<br/>        for i in range(total_batch):<br/>            batch_x, batch_y = mnist.train.next_batch(batch_size)<br/> <br/>            # Run optimization op (backprop) and cost op (to get loss value)<br/>            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,y: batch_y})<br/>            # Compute average loss<br/>            avg_cost += c / total_batch<br/>        # Display logs per epoch step<br/>        if epoch % display_step == 0:<br/> <br/>            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))<br/>            # Calculate accuracy<br/>            accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))<br/>            acu_temp = accuracy.eval({x: mnist.test.images, y: mnist.test.labels})<br/>            #append the accuracy to the list<br/>            accuracy_history.append(acu_temp)<br/>            #append the cost history<br/>            cost_history.append(avg_cost)<br/>            print("Epoch:", '%04d' % (epoch + 1), "- cost=", "{:.9f}".format(avg_cost), "- Accuracy=",acu_temp)<br/> <br/> <br/> <br/>    print("Optimization Finished!")<br/>    #plot the cost history<br/>    plt.plot(cost_history)<br/>    plt.show()<br/>    #plot the accuracy history<br/>    plt.plot(accuracy_history)<br/>    plt.show()<br/> <br/>    # Test model<br/>    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))<br/>    # Calculate accuracy<br/>    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))<br/>    print("Accuracy:", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))</span></pre><p id="af1b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es na"><img src="../Images/cafa36c1d82648d1b7f53da2bc6aef6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*2MMfmbcU2Id9cGdsBj6VSw.png"/></div></figure><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es nb"><img src="../Images/08900e95adf29dfee168556620efb430.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*W2Lox_PYI8SFHGWLp29gMw.png"/></div></figure><p id="b09a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">至此，我们结束了这篇关于Python深度学习的文章。我希望你理解了深度学习的各个组成部分，它是如何开始的，以及我们如何使用Python来创建简单的感知机和深度神经网络。</p><p id="dc2b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释深度学习的各个其他方面。</p><blockquote class="nd ne nf"><p id="1554" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">1.<a class="ae nc" rel="noopener" href="/edureka/tensorflow-tutorial-ba142ae96bca"> TensorFlow教程</a></p><p id="6741" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">2.<a class="ae nc" rel="noopener" href="/edureka/pytorch-tutorial-9971d66f6893"> PyTorch教程</a></p><p id="950e" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">3.<a class="ae nc" rel="noopener" href="/edureka/perceptron-learning-algorithm-d30e8b99b156">感知器学习算法</a></p><p id="3f97" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">4.<a class="ae nc" rel="noopener" href="/edureka/neural-network-tutorial-2a46b22394c9">神经网络教程</a></p><p id="f680" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">5.<a class="ae nc" rel="noopener" href="/edureka/backpropagation-bd2cf8fdde81">什么是反向传播？</a></p><p id="7157" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">6.<a class="ae nc" rel="noopener" href="/edureka/convolutional-neural-network-3f2c5b9c4778">卷积神经网络</a></p><p id="602d" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">7.<a class="ae nc" rel="noopener" href="/edureka/capsule-networks-d7acd437c9e">胶囊神经网络</a></p><p id="810d" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">8.<a class="ae nc" rel="noopener" href="/edureka/recurrent-neural-networks-df945afd7441">递归神经网络</a></p><p id="1eb4" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">9.<a class="ae nc" rel="noopener" href="/edureka/autoencoders-tutorial-cfdcebdefe37">自动编码器教程</a></p><p id="4e56" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">10.<a class="ae nc" rel="noopener" href="/edureka/restricted-boltzmann-machine-tutorial-991ae688c154">受限玻尔兹曼机教程</a></p><p id="2a11" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">11.<a class="ae nc" rel="noopener" href="/edureka/pytorch-vs-tensorflow-252fc6675dd7"> PyTorch vs TensorFlow </a></p><p id="5668" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">12.<a class="ae nc" rel="noopener" href="/edureka/tensorflow-object-detection-tutorial-8d6942e73adc">tensor flow中的对象检测</a></p><p id="fd49" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">13.<a class="ae nc" rel="noopener" href="/edureka/artificial-intelligence-tutorial-4257c66f5bb1">人工智能教程</a></p><p id="99cd" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">14.<a class="ae nc" rel="noopener" href="/edureka/tensorflow-image-classification-19b63b7bfd95">张量流图像分类</a></p><p id="25f8" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">15.<a class="ae nc" rel="noopener" href="/edureka/artificial-intelligence-applications-7b93b91150e3">人工智能应用</a></p><p id="212c" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">16.<a class="ae nc" rel="noopener" href="/edureka/become-artificial-intelligence-engineer-5ac2ede99907">如何成为一名人工智能工程师？</a></p><p id="6090" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">17.<a class="ae nc" rel="noopener" href="/edureka/q-learning-592524c3ecfc">问学</a></p><p id="f553" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">18.<a class="ae nc" rel="noopener" href="/edureka/apriori-algorithm-d7cc648d4f1e"> Apriori算法</a></p><p id="ff19" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">19.<a class="ae nc" rel="noopener" href="/edureka/introduction-to-markov-chains-c6cb4bcd5723">用Python实现马尔可夫链</a></p><p id="f515" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">20.<a class="ae nc" rel="noopener" href="/edureka/artificial-intelligence-algorithms-fad283a0d8e2">人工智能算法</a></p><p id="ed59" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">21.<a class="ae nc" rel="noopener" href="/edureka/best-laptop-for-machine-learning-a4a5f8ba5b">机器学习的最佳笔记本电脑</a></p><p id="02ba" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">22.<a class="ae nc" rel="noopener" href="/edureka/top-artificial-intelligence-tools-36418e47bf2a">12大人工智能工具</a></p><p id="b2c6" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">23.<a class="ae nc" rel="noopener" href="/edureka/artificial-intelligence-interview-questions-872d85387b19">人工智能(AI)面试问题</a></p><p id="cf79" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">24.<a class="ae nc" rel="noopener" href="/edureka/theano-vs-tensorflow-15f30216b3bc"> Theano vs TensorFlow </a></p><p id="ed84" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">25.<a class="ae nc" rel="noopener" href="/edureka/what-is-a-neural-network-56ae7338b92d">什么是神经网络？</a></p><p id="3a46" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">26.<a class="ae nc" rel="noopener" href="/edureka/pattern-recognition-5e2d30ab68b9">模式识别</a></p><p id="da86" class="ip iq jn ir b is it iu iv iw ix iy iz ng jb jc jd nh jf jg jh ni jj jk jl jm ha bi translated">27.<a class="ae nc" rel="noopener" href="/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a">人工智能中的阿尔法贝塔剪枝</a></p></blockquote></div><div class="ab cl nj nk go nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ha hb hc hd he"><p id="92ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jn">原载于2019年2月19日</em><a class="ae nc" href="https://www.edureka.co/blog/deep-learning-with-python/" rel="noopener ugc nofollow" target="_blank"><em class="jn">www.edureka.co</em></a><em class="jn">。</em></p></div></div>    
</body>
</html>