<html>
<head>
<title>Discovering and Classifying In-app Message Intent at Airbnb</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Airbnb发现和分类应用内信息意图</h1>
<blockquote>原文：<a href="https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c?source=collection_archive---------1-----------------------#2019-01-22">https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c?source=collection_archive---------1-----------------------#2019-01-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3891" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">对话式人工智能正在激励我们重新思考我们平台上的客户体验。</h2></div><p id="1f9d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">作者:</strong> <a class="ae js" rel="noopener" href="/@michelle.du"> <em class="jt">杜</em></a><em class="jt"/><a class="ae js" rel="noopener" href="/@yaoshijing"><em class="jt">【石井瑶】</em> </a></p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/ce2a7fb629a2f40c0f22719a7d8f9416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e6K-2_rqi8xBjjMEpiFjNA.jpeg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">Get embraced by plenty of natural light, brick, and plant in our new office in downtown Seattle.</figcaption></figure><p id="9769" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Airbnb的使命是创造一个每个人都可以属于任何地方的世界。确保客人和主人之间的良好沟通是培养归属感的关键之一，也是为客人提供顺畅无忧的旅行体验的关键之一。数百万客人和主人在Airbnb消息平台上交流各种话题，包括预订安排、支付请求、旅行计划、服务反馈，甚至与新朋友分享经验。因此，为平台上的客人改善体验的一个巨大机会是预测和理解他们给主人的信息的意图。</p><p id="ee79" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">考虑以下情况。还有两周就是圣诞节了。你正计划最后一次去夏威夷的家庭旅行，你在Airbnb上找到了檀香山的一栋可爱的海滨别墅。列表说明没有显示有多少床位。在Airbnb移动应用程序中，你问“你的房子有足够的床位容纳六个人吗？”，并焦急地等待主持人回复。但是，主持人太忙，无法立即回复。你开始担心，因为在等待回复的过程中，你可能会错过其他的列表。</p><p id="cae6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在另一种情况下，你和你最好的朋友提前预定了去巴黎的夏季旅行。然而出乎意料的是，就在旅行的前几天，你的朋友告诉你，你可能需要改变行程，因为她受伤了。您正在考虑取消预订，但您不确定是否会全额退款。你通过一个应用内消息问主持人关于取消政策的问题，希望他们能快点回复。然而，你必须等好几个小时，因为现在是巴黎时间的午夜。</p><p id="8b4d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们认识到这些情况会导致焦虑和困惑，并相信有更好的方法来解决它们。在上述两种情况下，以实时方式回答问题是特别理想的。当出现这种不方便的情况时，Airbnb的应用内消息平台是促进沟通的重要渠道。另一方面，要求所有主人立即回应客人会给他们带来很多负担，更不用说这是不现实的。</p><p id="a589" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">利用最近的对话式人工智能技术，Airbnb的三个团队——共享产品、应用机器学习和机器学习基础设施——共同开发了一个机器学习框架，可以缓解这个问题。该框架能够自动分类某些客人信息，以帮助我们更好地理解客人的意图。因此，它可以帮助大大缩短来宾的响应时间，并减少主机所需的总体工作量。它还允许Airbnb提供必要的指导，从而为客人和主人提供无缝的交流体验。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es kk"><img src="../Images/a8502460312f29c6bfdbf37b87ee4138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rAg_GNQYzqNLzCUE"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Figure 1: A concept that illustrates a guest asking a host for dining recommendations nearby.</em></figcaption></figure><h1 id="023c" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">识别消息意图</h1><p id="30fd" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">发送的每条信息背后都有一个意图，无论是制定后勤计划、澄清细节，还是与主人联系。为了改善现有的交流体验，作为第一步，人工智能正确识别这种“意图”是至关重要的。然而，这是一项具有挑战性的任务，因为很难识别可能存在于数百万条消息中的详尽意图集。</p><p id="840e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了应对这一挑战，我们分两个阶段建立我们的解决方案:在<strong class="iy hi">阶段1 </strong>中，我们使用了一种经典的无监督方法——<a class="ae js" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配(LDA)</a>——来发现大型消息语料库中的潜在主题(意图)。在<strong class="iy hi">第二阶段</strong>，我们转向监督学习技术，但是使用从第一阶段得出的主题作为每条信息的意图标签。具体来说，我们使用规范的卷积神经网络(CNN)架构构建了一个多类分类模型。这两个阶段为我们准确理解消息平台上的文本数据创建了一个强大的框架。</p><h2 id="3828" class="lj kn hh bd ko lk ll lm ks ln lo lp kw jf lq lr ky jj ls lt la jn lu lv lc lw bi translated">意图发现</h2><p id="8d7b" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">这个问题的第一个挑战是在没有先验知识的情况下，从庞大的消息语料库中发现现有的主题(意图)。人们可能会想到使用嵌入技术来生成消息级集群，从而生成主题。然而，这里的一个关键假设是，一条消息中只存在一个主要主题，这不适用于Airbnb数据。在Airbnb上，人们倾向于在开始输入核心信息之前设置上下文，一条信息包含几条彼此不太相关的信息是很常见的。</p><p id="d5ee" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里有一个例子。一位客人实际上想问他们如何存放行李以便提前入住。但他们可能会先告诉主人自己的到达时间，再问真正的入住问题。对于人类来说，分解话题，搞清楚关键话题是“提前入住的可能性”相对容易。然而，对于嵌入方法，无论是单个嵌入向量还是几个不同嵌入向量的代数集合都不能代表关键主题。我们真正需要的是一种算法，它可以检测出不同的潜在主题，并根据概率得分来决定哪一个是主要主题。</p><p id="70fe" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，LDA成为我们的自然选择。首先，LDA是一个概率模型，它给出了消息中主题的概率组成。第二，LDA假设每个单词都是从某个单词分布中抽取的，该分布描述了一个独特的主题，并且每条消息可以包含许多不同的主题(参见下面的图2，其中显示了变量的联合分布)。单词distribution允许人们在决定每个主题的含义时进行判断。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lx"><img src="../Images/672e01b73081f759cb68388756712ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_hEBEBI_8605dEWzjlqueA.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">Figure 2: A graphical model representation of LDA by <a class="ae js" href="http://www.cs.columbia.edu/~blei/papers/BleiLafferty2009.pdf" rel="noopener ugc nofollow" target="_blank">David Blei et al.</a> along with the joint probabilities of the observed (shaded nodes) and hidden (unshaded nodes) units</figcaption></figure><p id="69de" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">图3显示了使用<a class="ae js" href="https://github.com/bmabey/pyLDAvis" rel="noopener ugc nofollow" target="_blank"> pyLDAvis </a>生成的主题的2D可视化。我们确定LDA中的主题数量(超参数<em class="jt"> K </em>)是在验证集上产生最高<a class="ae js" href="http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf" rel="noopener ugc nofollow" target="_blank">一致性分数</a>的主题。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ly"><img src="../Images/133058779f25b9872b00c6d4a73d9a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5GTxk9AnRYIrSVI8wwuQpw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Figure 3: A 2D visualization of inter-topic distances </em><a class="ae js" href="https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf" rel="noopener ugc nofollow" target="_blank"><em class="kl">calculated based on topic-term distribution and projected via principal component analysis (PCA)</em></a><em class="kl">. The size of the circle is determined by the prevalence of the topic.</em></figcaption></figure><p id="2b0e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于时间限制，我们没有在像<a class="ae js" href="https://arxiv.org/abs/1405.4053" rel="noopener ugc nofollow" target="_blank"> doc2vec </a>和<a class="ae js" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank"> BERT </a>这样的方法上投入太多时间。尽管这些方法有如上所述的限制，但是它们确实考虑了词序，并且对于意图发现目的来说可能是有吸引力的备选方案。我们对这些方法持开放态度，并计划在以后重新审视它们。</p><h2 id="3690" class="lj kn hh bd ko lk ll lm ks ln lo lp kw jf lq lr ky jj ls lt la jn lu lv lc lw bi translated"><strong class="ak">贴标签:从无监督到有监督</strong></h2><p id="8b2b" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">标记是阶段2的关键组成部分，因为它建立了从无监督解决方案到有监督解决方案的关键过渡。尽管阶段1中的意图空间的草图已经被检测到，但是由于其无监督的性质，我们不能完全控制粒度。如果某些Airbnb产品需要处理在阶段1中可能没有检测到的特定消息意图，这就特别成问题。在没有明确预定义的消息意图标签作为基础事实的情况下，也很难评估每个消息的LDA结果的功效。</p><p id="fafc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如意图发现一样，标记的第一个挑战是确定定义什么标签。更重要的是，我们需要确保标签的高质量。我们的解决方案是执行一个迭代过程，从LDA发现的主题开始，但利用产品反馈来生成最终的标签集。首先，我们<em class="jt">对</em>一个小样本进行试点标记，让多个人对每条消息进行标记，以评估标记质量。然后，我们基于<a class="ae js" href="https://en.wikipedia.org/wiki/Inter-rater_reliability" rel="noopener ugc nofollow" target="_blank"> <em class="jt">评分者间协议</em> </a>为每个意图标签细化标签定义，并以更大的数据量开始正式标注。在正式的一轮中，每条消息都被审查一次，以获得大部分数据。我们保留了一小部分由多个审查者标记的消息，以便我们能够<em class="jt">确定由于人为错误</em>而导致的我们的模型能够达到的预测准确性的限制。每封邮件都完全匿名，个人身份信息(PII)在整个过程中被删除。</p><p id="7dd4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在标签资源方面，我们确保我们的内部产品专家能够为消息数据提供高质量的标签服务。与第三方供应商相比，标签服务更加可定制和可靠，也体现了公司不同组织之间的良好合作。</p><p id="9051" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在标记过程中，我们发现大约13%的目标信息具有多重意图。<strong class="iy hi">多重意图</strong>是指人们在一条信息中提出两个或更多不同意图的问题。当多重意图出现时，我们要求我们的专家将每个特定的意图分配给相应的句子。在建立意图分类模型时，具有单一意图的句子被用作独立的训练样本。我们在<em class="jt">生产化</em>部分演示了如何在实时服务中处理它们(图6)。</p><h2 id="7519" class="lj kn hh bd ko lk ll lm ks ln lo lp kw jf lq lr ky jj ls lt la jn lu lv lc lw bi translated"><strong class="ak">CNN的意向分类</strong></h2><p id="5a9e" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">卷积神经网络(CNN)和递归神经网络(RNN)已经成为NLP任务中非常流行的方法。在这项工作中，我们将重点放在CNN，因为它的实现简单，报道的高精度，特别是快速(在训练和推理时间)。<a class="ae js" href="https://arxiv.org/pdf/1807.01337.pdf" rel="noopener ugc nofollow" target="_blank"> Piero Molino等人，2018 </a>表明，在相同的数据集和硬件上，Word CNN的性能比Char C-RNN差不到1%，而在训练和推理过程中的速度都快了约9倍。在我们的例子中，验证误差收敛平均需要10分钟，而RNN收敛到相同水平平均需要60分钟。当考虑超参数调整时，这会导致模型迭代和开发慢得多。</p><p id="683f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在模型精度方面，<a class="ae js" href="https://arxiv.org/pdf/1702.01923.pdf" rel="noopener ugc nofollow" target="_blank">尹等，2017 </a>在不同的文本分类任务上对CNN和做了深入的比较。他们发现，当通过一些关键短语而不是理解整个远程语义来确定分类时，CNN实际上比RNN表现得更好。在我们的案例中，我们通常不需要了解客人信息的全部内容来确定他们问题的意图。相反，意图主要取决于关键短语，如“你有多少张床？”或者“有街边停车场吗？”</p><p id="65bd" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">经过广泛的文献回顾，我们决定采用<a class="ae js" href="https://arxiv.org/pdf/1408.5882.pdf" rel="noopener ugc nofollow" target="_blank"> Yoon Kim，2014 </a>和<a class="ae js" href="https://arxiv.org/pdf/1510.03820.pdf" rel="noopener ugc nofollow" target="_blank">张烨等人，2016 </a>，其中提出了一个简单的单层CNN，然后是一个1-max池层。与最初的工作不同，我们设计了4种不同的过滤器尺寸，每种尺寸有100个过滤器。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es kk"><img src="../Images/4f5834ab20906dbaf49ec6b6f4a8600a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qaPnMYBFQQQe1Aku"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Figure 4: Illustration of a CNN architecture for sentence classification from Ye Zhang et al.</em></figcaption></figure><p id="7c69" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了准备嵌入层，我们基于大样本外Airbnb消息传递语料库预训练单词嵌入。我们进行了仔细的文本预处理，发现某些预处理步骤(如标记某些信息)特别有助于减少噪音，因为它们将URL、电子邮件、日期、时间、电话号码等信息规范化。下面是由word2vec模型生成的与单词<code class="du lz ma mb mc b">house</code>最相似的单词的示例，该模型在没有和有这样的预处理步骤的情况下被训练:</p><figure class="jv jw jx jy fd jz"><div class="bz dy l di"><div class="md me l"/></div><figcaption class="kg kh et er es ki kj bd b be z dx">Most similar words for “house” generated by word2vec models trained without / with extra preprocessing steps</figcaption></figure><p id="c25f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了保持一致，我们在训练单词嵌入、消息意图分类器的离线训练以及实时消息的在线推断中使用了相同的预处理步骤。我们即将开源的Bighead库使所有这些成为可能。</p><p id="fb75" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">第1和第2阶段解决方案的总体准确度约为70%,比第1阶段解决方案高出50-100%。它还超过了基于标签分布的预测的准确度约400%。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mf"><img src="../Images/d1ec08fd284f5110b83ab51053b7627b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F1i8MJzWS_Q3jkQi9GA2pw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Table 1: Comparison on overall accuracy between Phase-1&amp;2, Phase-1 Only, and Predict by Label Distribution. Pre-trip: before a trip starts. On-trip: during a trip.</em></figcaption></figure><p id="b3b9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们逐类评估分类精度，尤其是当数据集在不同类之间不平衡时。图5是上面提到的出行模型的混淆矩阵。我们用<code class="du lz ma mb mc b">category_1</code>、<code class="du lz ma mb mc b">category_2</code>等来掩盖实际的类别名称。出于保密原因。正如你可以看到的，可以发现一个清晰的对角线模式，这意味着大部分的类预测与地面真相相匹配。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es kk"><img src="../Images/6392ed61f4fd7512fe3f0a2e3bad4194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z2jbIjtjuC2cf3qd"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Figure 5: The normalized confusion matrix for the on-trip model results</em></figcaption></figure><p id="7d31" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">表2显示了一些预测良好的示例类别。在这些类别中，关键短语是信息意图的强有力指标，CNN模型捕捉得非常好。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mg"><img src="../Images/b818717d8542dcb81232a903bacefaa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oM1eKz6ZNT8-vCxngpxeJQ.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">Table 2: Example categories that are well predicted</figcaption></figure><p id="71c5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面的表3显示了一些没有被很好预测的示例类别。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mh"><img src="../Images/bc4f01e03ded1f2514d2f20a69d4c177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Q_zVIHggtoUTQ2n05B1VQ.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">Table 3: Example categories that are not so well predicted</figcaption></figure><p id="85fd" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">错误分类有两个主要的根本原因:</p><p id="9621" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">1.标签中的人为错误。例如，一些贴标签者错误地认为“你有徒步旅行或乘船旅游的推荐吗？”是一个一般的问题，但是这种类型的问题在我们的分类中被认为是特定的问题。</p><p id="265d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2.标签歧义。例如，“你能推荐一些在这个地区可以做的事情吗？我们想去一个公共海滩或湖泊”，可以作为一个通用问题，因为第一句话，“你能推荐一些在该地区做的事情吗？”，是将军问的。然而，同一条信息中的下一句话，“我们想去公共海滩或湖泊”，显然有非常具体的意图。该信息不能作为一个整体整齐地放入任何一个标签(特定的或一般的)。</p><h1 id="120d" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated"><strong class="ak">生产化——在线服务</strong></h1><p id="a2eb" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">我们使用由Airbnb的ML基础设施团队开发的综合ML基础设施工具<a class="ae js" href="https://conferences.oreilly.com/strata/strata-ny-2018/public/schedule/detail/69383" rel="noopener ugc nofollow" target="_blank"> Bighead </a>来生产我们的框架。这些模型是通过Deep think提供的，Deep think是Bighead的在线推理组件。将会有一篇单独的博客文章详细介绍Bighead敬请期待！</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mi"><img src="../Images/a95d491329a3ec1eb19c05296e0bca01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZXJykjU62lCovpyr"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx"><em class="kl">Figure 6: The offline training &amp; online serving workflow of Phase II.</em></figcaption></figure><h1 id="c87c" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated"><strong class="ak">应用</strong></h1><p id="bc0f" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">下面是一些正在进行或计划在不久的将来进行的应用的一瞥。</p><ul class=""><li id="6d3a" class="mj mk hh iy b iz ja jc jd jf ml jj mm jn mn jr mo mp mq mr bi translated">利用信息意图历史预测客户支持问题</li><li id="8745" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">通过尽早识别此类意图，指导取消/支付/退款流程</li><li id="efa8" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">通过识别顾客关注的问题改善预订体验</li><li id="225c" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">通过识别客人/主人的需求，提供即时的智能响应</li></ul><h1 id="c6b8" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated"><strong class="ak">结论</strong></h1><p id="db84" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">我们已经开发了一个用于消息意图理解的框架，该框架使用无监督和有监督的学习技术从意图发现发展到意图分类。这项工作使各种产品应用程序能够通过Airbnb的消息平台促进无缝通信体验。以下是一些要点:</p><ul class=""><li id="4173" class="mj mk hh iy b iz ja jc jd jf ml jj mm jn mn jr mo mp mq mr bi translated">无监督学习可以是为监督学习解决方案提供标签的强大工具。</li><li id="b291" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">当使用定制的文本语料库训练单词嵌入时，文本预处理可以起到关键作用。</li><li id="cab4" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">标签质量是模型性能的关键。如果问题的瓶颈首先在于标注的准确性，那么找出正确的方法来减少标注过程中的人为错误可能会对模型的准确性产生巨大的影响。</li></ul><p id="34eb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们计划从几个方面进一步改进我们的解决方案:</p><ul class=""><li id="a46a" class="mj mk hh iy b iz ja jc jd jf ml jj mm jn mn jr mo mp mq mr bi translated">通过试验更多的语言表示模型(如doc2vec、BERT)来改进无监督学习结果，以实现意图发现</li><li id="670a" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">通过带有半监督学习的增强型标注工具提高标注效率</li><li id="11ae" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">通过更严格的定义和专业培训提高标签质量</li><li id="93b0" class="mj mk hh iy b iz ms jc mt jf mu jj mv jn mw jr mo mp mq mr bi translated">探索主人的意图，超越客人的意图</li></ul><p id="f543" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随着我们对Airbnb文本数据理解的加深，我们不断发现新的领域，我们可以利用这项技术来改进Airbnb产品。我们还计划支持其他语言来帮助我们在世界各地的社区。</p><h1 id="4196" class="km kn hh bd ko kp kq kr ks kt ku kv kw in kx io ky iq kz ir la it lb iu lc ld bi translated">确认</h1><p id="bd75" class="pw-post-body-paragraph iw ix hh iy b iz le ii jb jc lf il je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">这部作品是与<em class="jt">约翰·派克</em>和<a class="ae js" rel="noopener" href="/@samshadwell">T3】萨姆·沙德威尔T5】合作的。我们还要感谢</a><a class="ae js" rel="noopener" href="/@joycmu/"> <em class="jt">欢乐张</em> </a> <em class="jt">彼得·甘农</em><a class="ae js" rel="noopener" href="/@patricksrail"><em class="jt">帕特里克·斯瑞尔</em></a><em class="jt"/><a class="ae js" rel="noopener" href="/@junshuoliao"><em class="jt">廖俊硕</em> </a> <em class="jt">、安德鲁·霍</em> <a class="ae js" rel="noopener" href="/@darrick.brown"> <em class="jt">达里克·布朗</em> </a> <em class="jt">、阿图尔·卡莱</em> <a class="ae js" rel="noopener" href="/@jtfeng"> <em class="jt">杰夫·冯</em>我们还要感谢</a><a class="ae js" rel="noopener" href="/@XiaohanZeng"> <em class="jt">曾晓涵</em> </a> <em class="jt">、戴莉、</em>和<em class="jt">丽贝卡·罗森菲尔特</em>对校对工作的鼎力相助！</p></div><div class="ab cl mx my go mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ha hb hc hd he"><p id="515c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Airbnb一直在寻求优秀的人加入我们的团队！如果你有兴趣解决本文中的问题，请查看我们在数据科学和分析领域的<a class="ae js" href="https://www.airbnb.com/careers/departments/data-science-analytics" rel="noopener ugc nofollow" target="_blank">空缺职位</a>，并发送你的申请！</p></div></div>    
</body>
</html>