<html>
<head>
<title>Scaling Kubernetes with Assurance at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Pinterest安全扩展Kubernetes</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/scaling-kubernetes-with-assurance-at-pinterest-a23f821168da?source=collection_archive---------0-----------------------#2021-04-08">https://medium.com/pinterest-engineering/scaling-kubernetes-with-assurance-at-pinterest-a23f821168da?source=collection_archive---------0-----------------------#2021-04-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a086" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Anson Qian|软件工程师，云运行时</p><h1 id="7ad2" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">介绍</h1><p id="6823" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">自从我们在Pinterest 分享我们的<a class="ae kf" rel="noopener" href="/pinterest-engineering/building-a-kubernetes-platform-at-pinterest-fb3d9571c948"> Kubernetes之旅以来，已经一年多了。从那时起，我们提供了许多功能来促进客户采用，确保可靠性和可扩展性，并积累运营经验和最佳实践。</a></p><p id="7eec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总的来说，Kubernetes平台用户给予了积极的反馈。根据我们的用户调查，用户分享的三大优势是减轻管理计算资源的负担、更好的资源和故障隔离以及更灵活的容量管理。</p><p id="17c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">到2020年底，我们在我们的Kubernetes集群中协调了<strong class="ig hi"> 35K+ pods </strong>和<strong class="ig hi"> 2500+节点</strong>——支持广泛的Pinterest业务——有机增长仍然很高。</p><h1 id="0e9c" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">短篇小说中的2020</h1><p id="b64f" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">随着用户采用率的增长，工作负载的种类和数量也在增加。它要求Kubernetes平台具有更高的可伸缩性，以便跟上工作负载管理、pods调度和放置以及节点分配和取消分配带来的不断增长的负载。随着Kubernetes平台上的业务关键型工作负载越来越多，对平台可靠性的期望自然上升到了一个新的水平。</p><p id="ff53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">平台范围的中断确实发生了。在2020年初，我们的一个集群经历了pod创建的突然激增(比计划容量高出约3倍)，导致集群autocalor启动900个节点来满足需求。<a class="ae kf" href="https://kubernetes.io/docs/concepts/overview/components/#kube-apiserver" rel="noopener ugc nofollow" target="_blank"> kube-apiserver </a>开始首先经历延迟峰值和错误率增加，然后由于资源限制而导致内存不足(OOM)死亡。Kubelets的非绑定重试导致kube-apiserver负载增加了7倍。写入的激增导致<a class="ae kf" href="https://etcd.io/" rel="noopener ugc nofollow" target="_blank"> etcd </a>达到其总数据大小限制，并开始拒绝所有写入请求，平台在工作负载管理方面失去了可用性。为了减轻事故，我们必须执行etcd操作，如压缩旧版本、整理过多的空间以及禁用警报来恢复它。此外，我们不得不暂时扩大Kubernetes主节点的规模，以减少资源限制。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/88bd625c5d075b353920ef20f6c3fa27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HdAKrJV53QBeelLF"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 1: Kubernetes API Server Latency Spikes</figcaption></figure><p id="799e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在2020年晚些时候，一个基础架构组件在kube-apiserver集成中出现了一个错误，导致对kube-apiserver的昂贵查询(列出所有pod和节点)激增。这导致Kubernetes主节点资源使用量激增，kube-apiserver进入OOMKilled状态。幸运的是，有问题的组件很快被发现并回滚。但是在该事件中，平台性能下降，包括延迟的工作负载执行和过时的状态服务。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/871fa68304df6ade72a5f05c4d92441a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1gigns-zIDLjz6M7"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 2: Kubernetes API Server OOMKilled</figcaption></figure><h1 id="a117" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">为规模化做好准备</h1><p id="0222" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在整个旅程中，我们不断反思我们的平台治理、弹性和可操作性，尤其是当事故发生并重创我们最薄弱的环节时。凭借一支工程资源有限的敏捷团队，我们不得不深入挖掘，找出根本原因，确定容易实现的成果，并根据回报和成本确定解决方案的优先级。我们处理复杂的Kubernetes生态系统的策略是尽最大努力减少与社区提供的内容的差异，并为社区做出贡献，但永远不排除编写我们自己的内部组件的选择。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/14e9e081009aacd3bac6a7296189eaea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ARhaNPp-Jl33ZVcN"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 3: Pinterest Kubernetes Platform Architecture (blue is in-house, green is open source)</figcaption></figure><h1 id="7113" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">管理</h1><h2 id="3d01" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">资源配额实施</h2><p id="b6a3" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Kubernetes已经提供了<a class="ae kf" href="https://kubernetes.io/docs/concepts/policy/resource-quotas/" rel="noopener ugc nofollow" target="_blank">资源配额</a>管理，以确保任何名称空间都不能请求或占用大多数维度的<strong class="ig hi">无限</strong>资源:pods、cpu、内存等。正如我们在之前的事件中提到的，单个名称空间中pod创建的激增可能会使kube-apiserver过载并导致级联故障。为了确保稳定性，在每个名称空间中限制资源使用是很关键的。</p><p id="57ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们面临的一个挑战是，在每个名称空间中强制实施资源配额隐含地要求所有的pod和containers具有指定的<a class="ae kf" href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits" rel="noopener ugc nofollow" target="_blank">资源请求和限制</a>。在Pinterest Kubernetes平台中，不同名称空间中的工作负载由不同项目的不同团队拥有，平台用户通过Pinterest CRD配置他们的工作负载。我们通过为CRD转换层中的所有pod和容器添加默认资源请求和限制来实现这一点。此外，我们还拒绝了CRD验证层中任何没有资源请求和限制的pod规范。</p><p id="11d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们克服的另一个挑战是简化跨团队和组织的配额管理。为了安全地启用资源配额实施，我们查看历史资源使用情况，在峰值之上添加20%的余量，并将其设置为每个项目的资源配额的初始值。我们创建了一个cron作业来监控配额使用情况，并在项目使用接近某个限制时向项目所有团队发送工作时间警报。这鼓励项目所有者更好地进行容量规划，并请求资源配额变更。资源配额更改在签署后会得到手动审查和自动部署。</p><h2 id="1476" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">客户端访问实施</h2><p id="93fa" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们强制所有KubeAPI客户遵循Kubernetes已经提供的最佳实践:</p><h2 id="c8e2" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">控制器框架</h2><p id="b022" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated"><a class="ae kf" href="https://github.com/operator-framework" rel="noopener ugc nofollow" target="_blank">控制器框架</a>为优化读取操作提供了一个可共享的缓存，它利用了<a class="ae kf" href="https://godoc.org/k8s.io/client-go/informers" rel="noopener ugc nofollow" target="_blank">信息器-反射器-缓存架构</a>。<strong class="ig hi">告密者</strong>被设置来从kube-apiserver列出并观看感兴趣的对象。<strong class="ig hi">反射器</strong>将对象变化反映到底层<strong class="ig hi">缓存</strong>中，并将观察到的事件传播到事件处理程序。同一个控制器中的多个组件可以从Informers中注册OnCreate、OnUpdate和OnDelete事件的事件处理程序，并从缓存中获取对象，而不是直接从Kube-apiserver中获取。因此，它减少了进行不必要的和多余的呼叫的机会。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lk"><img src="../Images/d377b6ae30df90bb8b77ebc43e806f50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fC8_ET2XZJQvEkjz"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 4: Kubernetes Controller Framework</figcaption></figure><h2 id="a2bc" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">限速</h2><p id="c468" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Kubernetes API客户端通常由不同的控制器共享，API调用由不同的线程进行。Kubernetes的API客户端附带了一个<a class="ae kf" href="https://en.wikipedia.org/wiki/Token_bucket" rel="noopener ugc nofollow" target="_blank">令牌桶速率限制器</a>，它支持可配置的QPS和突发。超出阈值的API调用将被抑制，这样单个控制器就不会阻塞kube-apiserver的带宽。</p><h2 id="b409" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">共享缓存</h2><p id="8d47" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">除了控制器框架自带的kube-apiserver内置缓存，我们还在平台API中添加了另一个基于informer的直写缓存层。这是为了防止不必要的读调用重创kube-apiserver。服务器端缓存重用也避免了应用程序代码中的胖客户端。</p><p id="e0cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于来自应用的kube-apiserver访问<strong class="ig hi">，我们强制所有请求通过平台API，以利用共享服务并为访问控制和流量控制分配安全身份。对于来自<strong class="ig hi">工作负载控制器</strong>的kube-apiserver访问，我们强制所有控制器基于具有速率限制的控制框架来实现。</strong></p><h1 id="4ce5" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">弹性</h1><h2 id="d71a" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">硬化库伯莱</h2><p id="77f9" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Kubernetes的控制平面进入级联故障的一个关键原因是遗留反射器实现在处理错误时有<strong class="ig hi">无限制的</strong>重试。这种缺陷可能会被夸大，特别是当API服务器被破坏时，这很容易导致集群中反射器的同步。</p><p id="0ea7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这个问题，我们与社区密切合作，报告<a class="ae kf" href="https://github.com/kubernetes/kubernetes/issues/87794" rel="noopener ugc nofollow" target="_blank">问题</a>，讨论解决方案，并最终审核和合并pr(<a class="ae kf" href="https://github.com/kubernetes/kubernetes/pull/87829" rel="noopener ugc nofollow" target="_blank">1</a>，<a class="ae kf" href="https://github.com/kubernetes/kubernetes/pull/87795" rel="noopener ugc nofollow" target="_blank"> 2 </a>)。这个想法是用jitter reflector的ListWatch重试逻辑添加指数补偿，这样kubelet和其他控制器就不会在kube-apiserver过载和请求失败时试图敲打kube-apiserver。这种弹性改进通常是有用的，但是我们发现随着Kubernetes集群中节点和pod数量的增加，这种改进在kubelet方面非常关键。</p><h2 id="8380" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">优化并发请求</h2><p id="630d" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们管理的节点越多，创建和销毁工作负载的速度就越快，QPS服务器需要处理的API调用就越多。我们首先根据估计的工作负载增加了变异和非变异操作的最大并发API调用设置。这两个设置将强制处理的API调用数量不超过配置的数量，因此将kube-apiserver的CPU和内存消耗保持在某个阈值。</p><p id="4acf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Kubernetes的API请求处理链中，每个请求的第一步都会通过一组过滤器。过滤器链是强制执行最大动态API调用的地方。对于超过配置阈值的API调用突发，将向客户端返回“请求过多”(429)响应，以触发适当的重试。作为未来的工作，我们计划对具有更细粒度准入控制的<a class="ae kf" href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#eventratelimit" rel="noopener ugc nofollow" target="_blank"> EventRateLimit特性</a>进行更多的研究，并提供更好的服务质量。</p><h2 id="47b5" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">缓存更多历史记录</h2><p id="d3a3" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Watch cache是kube-apiserver内部的一种机制，它将每种类型的资源的过去事件缓存在一个环形缓冲区中，以便尽最大努力为来自特定版本的Watch调用提供服务。缓存越大，服务器中可以保留的事件就越多，并且在连接中断的情况下，更有可能无缝地向客户端提供事件流。考虑到这一事实，我们还改进了kube-apiserver的目标RAM大小，根据为更健壮的事件流提供服务的试探法，它在内部最终被转移到观察器缓存容量。Kube-apiserver提供了<a class="ae kf" href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/" rel="noopener ugc nofollow" target="_blank">更详细的方式</a>来配置细粒度的观察缓存大小，这可以进一步用于特定的缓存需求。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ll"><img src="../Images/a525e18ade5c0d55ddeaf0b5b937e5c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kIBn-GVvX_nQbLCS"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 5: Kubernetes Watch Cache</figcaption></figure><h1 id="99ae" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">可操作性</h1><h2 id="98d9" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">可观察性</h2><p id="8c9b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">为了减少事件检测和缓解时间，我们不断努力提高Kubernetes控制平面的可观察性。挑战在于平衡故障覆盖率和信号灵敏度。对于现有的Kubernetes指标，我们筛选并选择重要的指标进行监控和/或提醒，以便我们能够更主动地发现问题。此外，我们使用kube-apiserver来覆盖更详细的区域，以便快速缩小根本原因的范围。最后，我们调整警报统计数据和阈值，以减少噪音和错误警报。</p><p id="ec95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在高层次上，我们通过观察QPS和并发请求、错误率和请求延迟来监控kube-apiserver负载。我们可以按照资源类型、请求动词和相关的服务帐户来划分流量。对于像列表这样昂贵的流量，我们也通过对象计数和字节大小来测量请求负载，因为它们很容易使kube-apiserver过载，即使QPS很小。最后，我们监控etcd观察事件处理QPS和延迟处理计数作为重要的服务器性能指标。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es lm"><img src="../Images/ab86fa17a0b4fc514ac4053086aef1ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T7Rvvb--VHS0MKog"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 6: Kubernetes API calls by type</figcaption></figure><h2 id="70a4" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">可调试性</h2><p id="2cd0" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">为了更好地了解Kubernetes控制平面的性能和资源消耗，我们还使用<a class="ae kf" href="https://github.com/etcd-io/bbolt" rel="noopener ugc nofollow" target="_blank"> boltdb </a>库和<a class="ae kf" href="https://github.com/brendangregg/FlameGraph" rel="noopener ugc nofollow" target="_blank"> flamegraph </a>构建了etcd数据存储分析工具，以可视化数据存储分解。数据存储分析的结果为平台用户提供了优化使用的见解。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/a199350705945b6e3575bfe41fdee704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xOhDMF51YIh3g5aa"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 7: Etcd Data Usage Per Key Space</figcaption></figure><p id="3d6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我们启用了golang分析<a class="ae kf" href="https://blog.golang.org/pprof" rel="noopener ugc nofollow" target="_blank"> pprof </a>并可视化了堆内存占用。我们能够快速识别资源最密集的代码路径和请求模式，例如，在列表资源调用时转换响应对象。作为kube-apiserver OOM调查的一部分，我们发现的另一个重要警告是，kube-apiserver使用的<a class="ae kf" href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt" rel="noopener ugc nofollow" target="_blank">页面缓存</a>被计入一个cgroup的内存限制，匿名内存使用可以窃取同一个cgroup的页面缓存使用。因此，即使kube-apiserver只有20GB的堆内存使用，整个cgroup也可以看到200GB的内存使用达到了极限。虽然当前的内核默认设置不是主动回收分配的页面以实现高效重用，但我们目前正在研究基于memory.stat文件的设置监控，并在内存使用接近限制时强制cgroup回收尽可能多的页面。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ln"><img src="../Images/dad1650cbff9e682989f854b1717836b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gj8_6QhwUjpIagms"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Figure 8: Kubernetes API Server Memory Profiling</figcaption></figure><h1 id="03cb" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">结论</h1><p id="242b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">凭借我们在治理、弹性和可操作性方面的努力，我们能够显著减少计算资源的突然使用激增，控制平面带宽，并确保整个平台的稳定性和性能。优化部署后，kube-apiserver QPS(主要是读取)减少了90%(如下图所示)，这使得kube-apiserver的使用更加稳定、高效和健壮。对Kubernetes内部的深入了解和我们获得的额外见解将使团队能够更好地进行系统操作和集群维护。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/948e4a3ced3829d64d6594d3755bd19e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h_rpg23ZQ1mcU8EN"/></div></div></figure><p id="23d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图9:优化展示后Kube-apiserver QPS减少</p><p id="34e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是一些关键要点，希望可以帮助您解决Kubernetes的可伸缩性和可靠性问题:</p><ol class=""><li id="99a9" class="lo lp hh ig b ih ii il im ip lq it lr ix ls jb lt lu lv lw bi translated">诊断问题，找到问题的<strong class="ig hi">根源</strong>。在决定“做什么”之前，先关注“是什么”解决问题的第一步是了解瓶颈是什么，为什么。如果你找到了根本原因，你就成功了一半。</li><li id="d4a1" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated">首先关注<strong class="ig hi">小的增量改进</strong>比立即致力于彻底的架构改变几乎总是值得的。这很重要，尤其是当你有一个敏捷的团队时。</li><li id="0fc4" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated">当您计划或优先考虑调查和修复时，做出<strong class="ig hi">数据驱动的</strong>决策。正确的遥测技术有助于更好地决定首先关注和优化什么。</li><li id="6b33" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated">关键基础设施组件的设计应考虑弹性。分布式系统容易出现故障，最好<strong class="ig hi">总是做最坏的打算</strong>。正确的护栏有助于防止连锁故障，并将爆炸半径降至最低。</li></ol><h1 id="2c0a" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">展望未来</h1><h2 id="50b9" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">联盟</h2><p id="d2af" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">随着我们的规模稳步增长，单一集群体系结构已不足以支持不断增加的工作负载。在确保高效、强大的单集群环境之后，让我们的计算平台能够横向扩展是我们前进的下一个里程碑。通过利用联合框架，我们的目标是以最小的操作开销将新的集群插入到环境中，同时保持最终用户的平台界面稳定。我们的联合集群环境目前正在开发中，我们期待它在产品化后带来更多的可能性。</p><h2 id="557a" class="kw jd hh bd je kx ky kz ji la lb lc jm ip ld le jq it lf lg ju ix lh li jy lj bi translated">容量规划</h2><p id="ce7e" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们当前实施资源配额的方法是一种简化的反应式容量规划方式。随着用户工作负载和系统组件的增加，平台动态会发生变化，项目级别或集群范围的容量限制可能会过时。我们希望探索基于历史数据、增长轨迹和复杂容量模型进行预测的主动容量规划，该模型不仅可以涵盖资源配额，还可以涵盖API配额。我们希望更主动、更准确的容量规划能够防止平台过度使用和交付不足。</p><h1 id="34f1" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">承认</h1><p id="bd45" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinterest的许多工程师帮助扩展了Kubernetes平台，以赶上业务增长。除了云运行时团队June Liu、、Suli Xu、和Quentin Miao努力工作以实现我们今天拥有的可扩展和稳定的计算平台之外，Balaji Narayanan、Roberto Alcala和Rodrigo Menezes领导我们的站点可靠性工程(SRE)工作，他们共同努力确保计算平台的坚实基础。领导容量工程工作的Kalim Moghul和Ryan Albrecht为项目身份管理和系统级配置做出了贡献。负责安全工程工作的Cedric Staub和Jeremy Krach保持了高标准，这样我们的工作负载就可以在多租户平台上安全运行。最后，我们的平台用户Dinghang Yu、Karthik Anantha Padmanabhan、Petro Saviuk、Michael Benedict、Jasmine Qin和许多其他人提供了许多有用的反馈和要求，并与我们一起努力实现可持续的业务增长。</p></div></div>    
</body>
</html>