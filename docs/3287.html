<html>
<head>
<title>What is Cross-Validation in Machine Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是机器学习中的交叉验证？</h1>
<blockquote>原文：<a href="https://medium.com/edureka/cross-validation-in-machine-learning-d629dec3f497?source=collection_archive---------0-----------------------#2019-12-23">https://medium.com/edureka/cross-validation-in-machine-learning-d629dec3f497?source=collection_archive---------0-----------------------#2019-12-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/1205fdb91b05c0a726be035c8e0576e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*Ris0zInGQn_c--kUHS8QOw.jpeg"/></div></figure><p id="a1c3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">机器学习中验证技术的问题在于，它没有给出学习者将如何推广到看不见的数据的任何指示。这就是交叉验证发挥作用的地方。本文涵盖了机器学习中交叉验证的基本概念，本文讨论了以下主题:</p><ol class=""><li id="b562" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">什么是交叉验证？</li></ol><p id="0d40" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">2.交叉验证的类型</p><ul class=""><li id="098e" class="jj jk hh in b io ip is it iw jl ja jm je jn ji js jp jq jr bi translated">k倍交叉验证</li><li id="6f3c" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">保持方法</li><li id="49cc" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">遗漏交叉验证</li><li id="e25d" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">遗漏一项交叉验证</li></ul><p id="ba6b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">3.交叉验证应用编程接口</p><p id="87c5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">4.如何度量模型的偏差方差？</p><p id="bba3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">5.交叉验证的局限性</p><p id="6f21" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">6.交叉验证应用程序</p><h1 id="8cfc" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">什么是交叉验证？</h1><p id="f6a2" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">对于机器学习中的任何模型，<em class="lb">如果用独立的数据集对模型进行测试，则被认为是最佳实践。</em>通常情况下，任何预测模型都是基于一个已知的数据集，即训练集。</p><p id="d0d5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但在现实生活中，将使用完全不同和独特的数据集测试该模型的效率和准确性。在这种情况下，您希望您的模型足够高效，或者至少与它为训练集显示的效率相当。基本上，这种测试被称为机器学习中的交叉验证，因此它适用于未来的任何模型。</p><p id="6564" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们也可以称其为一种技术，用于<strong class="in hi">断言统计模型如何推广到独立的数据集</strong>。既然我们已经知道了交叉验证的含义，让我们试着用简单的术语来理解交叉验证。</p><p id="9091" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">交叉验证的基本目的是评估模型在未知数据集下的表现。例如，你试图在一个空的目标中得分。这看起来很容易，你甚至可以从很远的地方得分。但是真正的考验是从一个守门员和一群防守队员开始的。这就是为什么你需要在一场真正的比赛中接受训练，面对所有的压力，仍然要进球。</p><p id="04d6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">类似地，统计模型的训练方式使得它在使用交叉验证处理其他未知数据集时效率更高。</p><h1 id="fdb7" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">交叉验证的类型</h1><p id="8db8" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">机器学习中有两种类型的交叉验证技术。</p><ol class=""><li id="8ba9" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi">穷举交叉验证</strong>——该方法基本上是通过将原始数据集划分为训练集和验证集，用尽一切可能的方式对模型进行测试。示例:遗漏交叉验证，遗漏交叉验证。</li><li id="9872" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">非穷尽性交叉验证</strong>——该方法不将原始数据集分解为所有可能的排列和组合。示例:K倍交叉验证，保持方法。</li></ol><p id="91af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们更详细地了解机器学习中各种类型的交叉验证。</p><h2 id="1557" class="lc jz hh bd ka ld le lf ke lg lh li ki iw lj lk km ja ll lm kq je ln lo ku lp bi translated">k-折叠交叉验证</h2><p id="9cb0" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">在机器学习中，永远没有足够的数据来训练模型。即使这样，如果我们删除一些数据，它也会对机器学习模型造成过度拟合的威胁。如果没有为训练阶段提供足够的数据，也可能无法识别主要模式。</p><p id="88fa" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通过减少数据，我们也面临着由于偏差引起的误差而降低精确度的风险。为了克服这个问题，我们需要一种方法来提供足够的训练数据和一些测试数据。k倍交叉验证正是这样做的。</p><p id="e282" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">它是如何工作的？</p><p id="0326" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这种交叉验证技术中，数据被分成k个子集。我们从这些数据中选择一个子集，并将其作为模型的验证集。我们保留k-1个子集用于训练模型。</p><p id="ffeb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对所有“k次试验”的误差估计进行平均，以获得模型的有效准备状态。每个k子集将在验证集中至少出现一次。它也包含在k-1训练集中至少一次。这大大降低了由偏置引起的误差。它还减少了方差，因为在验证中使用了k个子集的每一个。</p><p id="4ac9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">分层K倍交叉验证</strong></p><p id="9a2a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这种技术中，k倍交叉验证有一点小小的变化。它会发生变化，使得每个折叠在整个集合中具有每个目标类的大约相等百分比的样本。在预测问题的情况下，平均响应值在所有折叠中近似相等。</p><p id="b181" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在某些情况下，响应变量存在很大的不平衡。让我们用一个例子来理解这一点。在房屋定价问题中，一些房屋的价格可能比其他房屋的价格高得多。此外，在分类问题中，样本的负样本可能比正样本多。为了解决这种差异，我们遵循机器学习中的分层k-fold交叉验证技术。</p><h2 id="4dca" class="lc jz hh bd ka ld le lf ke lg lh li ki iw lj lk km ja ll lm kq je ln lo ku lp bi translated">保持方法</h2><p id="7dfc" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">这是所有方法中最简单的交叉验证方法。在这种方法中，我们将数据点随机分配给两个数据集。在这种情况下，大小无关紧要。</p><p id="e670" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这背后的基本思想是从您的训练集中删除一部分，并使用它从基于其余数据训练的模型中获得预测。这种方法有很大的差异，因为它只需要运行一次就可以完成所有这些。它也可能给出误导性的结果。</p><h2 id="8bff" class="lc jz hh bd ka ld le lf ke lg lh li ki iw lj lk km ja ll lm kq je ln lo ku lp bi translated">遗漏交叉验证</h2><p id="5d26" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">在这种方法中，<strong class="in hi"> p </strong>个数据点被排除在训练数据之外。假设数据集中有<strong class="in hi"> m </strong>个数据点，那么<strong class="in hi"> m-p </strong>个数据点用于训练阶段。并且将<strong class="in hi"> p </strong>数据点保存为验证集。</p><p id="a56f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这种技术相当详尽，因为对原始数据集中所有可能的组合重复上述过程。为了检查模型的整体有效性，对所有试验的误差进行平均。</p><p id="8e7e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这在计算上变得不可行，因为模型需要为所有可能的组合和相当大的<strong class="in hi"> p </strong>进行训练和验证。</p><h2 id="3250" class="lc jz hh bd ka ld le lf ke lg lh li ki iw lj lk km ja ll lm kq je ln lo ku lp bi translated">留一交叉验证</h2><p id="53db" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">这种交叉验证的方法类似于不考虑p的交叉验证，但唯一的区别是在这种情况下<strong class="in hi"> p = 1 </strong>。它实际上节省了很多时间，这是一个很大的优势。</p><p id="2a80" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">尽管如果样本数据太大，仍然会花费很多时间。但是它仍然比留p-out交叉验证法要快。</p><p id="5ff1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">既然我们已经讨论了不同类型的交叉验证技术，让我们来看看交叉验证API。</p><h1 id="c2f9" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">交叉验证API</h1><p id="6576" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">我们不必手动实现交叉验证，Python中的Scikit-Learn库提供了一个简单的实现，可以相应地拆分数据。根据不同的交叉验证策略，可以使用交叉验证迭代器。</p><ul class=""><li id="9717" class="jj jk hh in b io ip is it iw jl ja jm je jn ji js jp jq jr bi translated">k-fold交叉验证:KFold() scikit-learn类</li><li id="291f" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">Leave-one-out交叉验证:LeaveOneOut() scikit-learn类</li><li id="7b36" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">Leave-p-out交叉验证:LeavePOut() scikit-Learn类</li><li id="0ff4" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji js jp jq jr bi translated">分层K折叠交叉验证:StratifiedKFold() scikit-learn类</li></ul><p id="bbf3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">例如，让我们尝试使用python中的Kfold来创建训练集和验证集。</p><pre class="lq lr ls lt fd lu lv lw lx aw ly bi"><span id="678d" class="lc jz hh lv b fi lz ma l mb mc"><strong class="lv hi">from</strong> <!-- -->numpy <strong class="lv hi">import</strong> <!-- -->array<br/><strong class="lv hi">from</strong> <!-- -->sklearn.model_selection <strong class="lv hi">import</strong> <!-- -->KFold</span><span id="68c6" class="lc jz hh lv b fi md ma l mb mc"># sampling the data<br/>data <strong class="lv hi">=</strong> <!-- -->array([0.10, 0.22, 0.31, 0.43, 0.52, 0.63,0.72,0.85,0.92,0.99])</span><span id="ed4f" class="lc jz hh lv b fi md ma l mb mc"># Splittinf the data<br/>kfold <strong class="lv hi">=</strong> <!-- -->KFold(3, True, 1)</span><span id="4439" class="lc jz hh lv b fi md ma l mb mc"># enumerating the splits<br/><strong class="lv hi">for</strong> <!-- -->train, test <strong class="lv hi">in</strong> <!-- -->kfold.split(data):<br/>print('train: %s, test: %s'<!-- --> <strong class="lv hi">%</strong> <!-- -->(data[train], data[test]))</span></pre><p id="3a01" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">输出:</strong></p><figure class="lq lr ls lt fd ii er es paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="er es me"><img src="../Images/0d5a86f7f32f7d9302b0b88b1022f834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/0*cE6dLdycwDiAVvbQ.png"/></div></div></figure><p id="abcf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">类似地，我们可以根据需求和数据类型选择其他交叉验证迭代器。现在让我们试着理解如何计算模型的偏差和方差。</p><h1 id="b3f2" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">如何度量模型的偏差-方差</h1><p id="632d" class="pw-post-body-paragraph il im hh in b io kw iq ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji ha bi translated">如果做k重交叉验证，会得到k个不同的估计误差。在理想的情况下，这些误差总和为零，但是得到这样的结果是非常不可能的。为了得到偏差，我们取所有估计误差的平均值。</p><p id="81fd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了计算模型的方差，我们取所有误差的标准差。如果我们得到一个较低的标准差值，这意味着我们的模型不会随着不同的训练数据集而有很大的变化。</p><p id="8789" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">重点应该是保持模型的偏差和方差之间的平衡。这可以通过将方差减小到最小并控制偏差来实现。这种权衡通常会产生更好的预测模型。</p><p id="a6bf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但是交叉验证也有一些限制。让我们看看交叉验证的各种限制。</p><h1 id="8237" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">交叉验证的局限性</h1><ol class=""><li id="b8a4" class="jj jk hh in b io kw is kx iw mj ja mk je ml ji jo jp jq jr bi translated">在理想情况下，交叉验证会产生最佳结果。但是在<strong class="in hi">数据</strong>不一致的情况下，结果可能会大相径庭。模型会遇到什么样的数据是相当不确定的。</li><li id="e9b7" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">预测建模通常需要在数据方面进行<strong class="in hi">进化</strong>，这可以极大地改变训练和验证集。</li><li id="4d2a" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">结果可能<strong class="in hi">因数据集</strong>的特征而异。假设我们制作了一个预测模型来检测一个人的疾病，然后用一组特定的人群来训练它。它可能随一般人群而变化，导致不一致和效率降低。</li></ol><p id="ba46" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">以下是交叉验证面临的一些限制:</p><h1 id="0e4f" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">交叉验证应用程序</h1><ol class=""><li id="e59f" class="jj jk hh in b io kw is kx iw mj ja mk je ml ji jo jp jq jr bi translated">我们可以用它来比较一组预测建模过程的性能。</li><li id="4fda" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">交叉验证在医学研究领域表现出色。</li><li id="3728" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">它可以用于荟萃分析，因为许多数据分析师已经在使用交叉验证。</li></ol><p id="5ab3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对于防止机器学习模型过拟合和欠拟合的过度应用，下面列出了交叉验证的几个其他应用:</p><ol class=""><li id="da21" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">我们可以用它来比较一组预测建模过程的性能。</li><li id="fdc3" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">交叉验证在医学研究领域表现出色。</li><li id="27b3" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">它可以用于荟萃分析，因为许多数据分析师已经在使用交叉验证。</li></ol><p id="0ccc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这就把我们带到了本文的结尾，在这里我们学习了机器学习中的交叉验证。我希望你清楚本教程中与你分享的所有内容。如果你想查看更多关于Python、DevOps、Ethical Hacking等市场最热门技术的文章，那么你可以参考<a class="ae mm" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=cross-validation-in-machine-learning" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="ec09" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请留意本系列中的其他文章，它们将解释数据科学的各个方面。</p><blockquote class="mn mo mp"><p id="7d4d" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 1。</em> <a class="ae mm" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="ffc1" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 2。</em> <a class="ae mm" rel="noopener" href="/edureka/math-and-statistics-for-data-science-1152e30cee73"> <em class="hh">数据科学的数学与统计</em> </a></p><p id="2976" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 3。</em><a class="ae mm" rel="noopener" href="/edureka/linear-regression-in-r-da3e42f16dd3"><em class="hh">R中的线性回归</em> </a></p><p id="0837" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 4。</em> <a class="ae mm" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="7aa8" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 5。</em><a class="ae mm" rel="noopener" href="/edureka/logistic-regression-in-r-2d08ac51cd4f"><em class="hh">R中的逻辑回归</em> </a></p><p id="addb" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 6。</em> <a class="ae mm" rel="noopener" href="/edureka/classification-algorithms-ba27044f28f1"> <em class="hh">分类算法</em> </a></p><p id="1cf8" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 7。</em> <a class="ae mm" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林</em> </a></p><p id="f907" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 8。</em> <a class="ae mm" rel="noopener" href="/edureka/a-complete-guide-on-decision-tree-algorithm-3245e269ece"> <em class="hh">决策树中的R </em> </a></p><p id="ba59" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 9。</em> <a class="ae mm" rel="noopener" href="/edureka/introduction-to-machine-learning-97973c43e776"> <em class="hh">机器学习入门</em> </a></p><p id="7715" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">10。 <a class="ae mm" rel="noopener" href="/edureka/naive-bayes-in-r-37ca73f3e85c"> <em class="hh">朴素贝叶斯在R </em> </a></p><p id="f3bb" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 11。</em> <a class="ae mm" rel="noopener" href="/edureka/statistics-and-probability-cf736d703703"> <em class="hh">统计与概率</em> </a></p><p id="dc46" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 12。</em> <a class="ae mm" rel="noopener" href="/edureka/decision-trees-b00348e0ac89"> <em class="hh">如何创建一个完美的决策树？</em> </a></p><p id="1d47" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">13。 <a class="ae mm" rel="noopener" href="/edureka/data-scientists-myths-14acade1f6f7"> <em class="hh">关于数据科学家角色的10大误区</em> </a></p><p id="44ae" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 14。</em><a class="ae mm" rel="noopener" href="/edureka/machine-learning-algorithms-29eea8b69a54"><em class="hh">5大机器学习算法</em> </a></p><p id="e5a6" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">15。 <a class="ae mm" rel="noopener" href="/edureka/data-analyst-vs-data-engineer-vs-data-scientist-27aacdcaffa5"> <em class="hh">数据分析师vs数据工程师vs数据科学家</em> </a></p><p id="e747" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 16。</em> <a class="ae mm" rel="noopener" href="/edureka/types-of-artificial-intelligence-4c40a35f784"> <em class="hh">人工智能的类型</em> </a></p><p id="4676" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 17。</em><a class="ae mm" rel="noopener" href="/edureka/r-vs-python-48eb86b7b40f"><em class="hh">R vs Python</em></a></p><p id="5f98" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 18。</em> <a class="ae mm" rel="noopener" href="/edureka/ai-vs-machine-learning-vs-deep-learning-1725e8b30b2e"> <em class="hh">人工智能vs机器学习vs深度学习</em> </a></p><p id="fcc7" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 19。</em> <a class="ae mm" rel="noopener" href="/edureka/machine-learning-projects-cb0130d0606f"> <em class="hh">机器学习项目</em> </a></p><p id="49cb" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 20。</em> <a class="ae mm" rel="noopener" href="/edureka/data-analyst-interview-questions-867756f37e3d"> <em class="hh">数据分析师面试问答</em> </a></p><p id="e974" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 21。</em> <a class="ae mm" rel="noopener" href="/edureka/data-science-and-machine-learning-for-non-programmers-c9366f4ac3fb"> <em class="hh">面向非程序员的数据科学和机器学习工具</em> </a></p><p id="1e4d" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 22。</em> <a class="ae mm" rel="noopener" href="/edureka/top-10-machine-learning-frameworks-72459e902ebb"> <em class="hh">十大机器学习框架</em> </a></p><p id="bf34" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 23。</em> <a class="ae mm" rel="noopener" href="/edureka/statistics-for-machine-learning-c8bc158bb3c8"> <em class="hh">用于机器学习的统计</em> </a></p><p id="4bfa" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 24。</em> <a class="ae mm" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="5608" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 25。</em> <a class="ae mm" rel="noopener" href="/edureka/breadth-first-search-algorithm-17d2c72f0eaa"> <em class="hh">广度优先搜索算法</em> </a></p><p id="4537" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 26。</em><a class="ae mm" rel="noopener" href="/edureka/linear-discriminant-analysis-88fa8ad59d0f"><em class="hh">R中的线性判别分析</em> </a></p><p id="0367" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">27。 <a class="ae mm" rel="noopener" href="/edureka/prerequisites-for-machine-learning-68430f467427"> <em class="hh">机器学习的先决条件</em> </a></p><p id="f4d0" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">28。 <a class="ae mm" rel="noopener" href="/edureka/r-shiny-tutorial-47b050927bd2"> <em class="hh">互动WebApps使用R闪亮</em> </a></p><p id="40d5" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 29。</em> <a class="ae mm" rel="noopener" href="/edureka/top-10-machine-learning-books-541f011d824e"> <em class="hh">十大机器学习书籍</em> </a></p><p id="df50" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">三十岁。 <a class="ae mm" rel="noopener" href="/edureka/unsupervised-learning-40a82b0bac64"> <em class="hh">无监督学习</em> </a></p><p id="a62f" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated"><em class="hh"> 31.1 </em> <a class="ae mm" rel="noopener" href="/edureka/10-best-books-data-science-9161f8e82aca"> <em class="hh"> 0最佳数据科学书籍</em> </a></p><p id="1a5b" class="il im lb in b io ip iq ir is it iu iv mq ix iy iz mr jb jc jd ms jf jg jh ji ha bi translated">32。 <a class="ae mm" rel="noopener" href="/edureka/supervised-learning-5a72987484d0"> <em class="hh">监督学习</em> </a></p></blockquote></div><div class="ab cl mt mu go mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ha hb hc hd he"><p id="8a28" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="lb">原载于2019年12月23日https://www.edureka.co</em><a class="ae mm" href="https://www.edureka.co/blog/cross-validation-in-machine-learning/" rel="noopener ugc nofollow" target="_blank"><em class="lb"/></a><em class="lb">。</em></p></div></div>    
</body>
</html>