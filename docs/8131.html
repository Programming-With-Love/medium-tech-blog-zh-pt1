<html>
<head>
<title>Walmart’s Cassandra CDC Solution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">沃尔玛的Cassandra CDC解决方案</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/walmarts-cassandra-cdc-solution-6fc650031a3?source=collection_archive---------1-----------------------#2022-07-25">https://medium.com/walmartglobaltech/walmarts-cassandra-cdc-solution-6fc650031a3?source=collection_archive---------1-----------------------#2022-07-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="3a54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看由<a class="jc jd ge" href="https://medium.com/u/dc06a7dcace9?source=post_page-----6fc650031a3--------------------------------" rel="noopener" target="_blank"> Scott Harvester </a>和<a class="jc jd ge" href="https://medium.com/u/b1aa4bb4f125?source=post_page-----6fc650031a3--------------------------------" rel="noopener" target="_blank"> Nitin Chhabra </a>用Cassandra捕获的变更数据。</p><h1 id="3053" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">数据采集</h1><p id="b0d0" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">“释放我的数据”可能是沃尔玛在构建其现代数据平台时的口号。该平台的目标之一是提供集成的、高性能的、自动化的变更数据捕获(CDC)解决方案，这些解决方案从事务性数据库中提取数据，并将这些数据交付给企业数据湖。解决方案是逐个数据库地打破数据孤岛。例如，Google Spanner的实现将启用数据管道的时间从几天减少到了几个小时。</p><p id="3591" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">沃尔玛的团队最近解决了从Cassandra捕获数据变化的问题。在本文中，我们将探讨Cassandra CDC面临的挑战、选择和方法。具体来说，我们将重点关注Cassandra 4.x。</p><h1 id="8ab9" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">挑战</h1><p id="634a" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">尽管Cassandra 4.x比Cassandra 3.x提供了显著的CDC改进，但与其他数据库技术相比，Cassandra CDC仍处于起步阶段。有几个挑战需要解决。其中包括:</p><p id="2ec6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">重复数据</strong> —随着数据在Cassandra节点之间复制，单个更改(CRUD操作)会生成多个CDC记录。这意味着下游处理将需要支持比源系统上生成的更多的数据更改。例如，如果Cassandra跨3个区域部署(3个环，每个区域1个),复制因子为3(沃尔玛的典型部署),则每个更改将在3个区域环中的每个环中复制3次。这意味着一个更改将生成9个CDC日志记录。我们将在“我们的方法”一节中讨论如何处理重复。</p><p id="e703" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">仅更改列</strong>—Cassandra CDC的一个限制是CDC日志仅包含已更改的列。如果您的系统需要交付整个数据库对象，您将需要开发一种方法来填充该对象。幸运的是，我们的数据管道可以只处理变更列，并合并整个对象。</p><p id="6868" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">无序【Cassandra CDC不保证变更的顺序。下游系统将需要支持接收无序的数据更改。同样，我们的下游系统已经支持这个用例。</strong></p><p id="2e35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">运行本地</strong> — CDC由Cassandra通过CDC提交日志公开。要读取提交日志，最好在本地运行代理。这意味着您需要在Cassandra部署的每个节点上运行CDC日志阅读器。此外，您需要确保CDC日志阅读器正在主动删除CDC提交日志，因为如果本地文件系统被CDC提交日志填满，它将<a class="ae kh" href="https://cassandra.apache.org/doc/latest/cassandra/operating/cdc.html#warnings" rel="noopener ugc nofollow" target="_blank">关闭Cassandra节点</a>。</p><p id="3189" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">遗漏变更</strong> —请注意，并非所有的数据变更都不会被捕获。CDC提交日志中既不会捕获TTL、范围删除、静态列、触发器、实体化视图、辅助索引，也不会捕获轻量级事务。由于我们不使用这些功能，所以我们不必担心这一点。</p><h1 id="b1cb" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">选项</h1><p id="dff3" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">当我们第一次开始查看Cassandra 4.x CDC时，只有几个选项— <a class="ae kh" href="https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/db/commitlog/CommitLogReader.java" rel="noopener ugc nofollow" target="_blank"> Cassandra提交日志阅读器</a>和<a class="ae kh" href="https://github.com/datastax/cdc-apache-cassandra" rel="noopener ugc nofollow" target="_blank">Apache Cassandra的数据税务变更代理</a>。Cassandra提交日志读取器要求我们为读取器实现一个代理，并为数据更改创建处理程序。DataStax解决方案走得更远，但它与Pulsar而不是沃尔玛大量投资的Kafka结合在一起。</p><p id="53ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">幸运的是，我们注意到一个将Cassandra 4.x提交日志阅读器添加到<a class="ae kh" href="https://debezium.io/" rel="noopener ugc nofollow" target="_blank"> Debezium </a>的pull请求。Debezium是最流行的开源CDC平台之一。pull请求被合并到Debezium 1.9版本中。</p><p id="45ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这对我们来说是一个完美的解决方案，因为我们一直在积极使用Debezium作为其他数据库技术的CDC框架来发布对Kafka的更改。这给了我们捕捉Cassandra的变化并将这些变化发布到Kafka的能力，但是仍然有一些我们必须跨越的障碍，如下一节所述。</p><h1 id="f704" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">我们的方法</h1><p id="941b" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">Debezium提供了一种机制来读取Cassandra生成的CDC提交日志，并将这些更改发布到Kafka，但是我们仍然有两个障碍:接近实时的处理和重复的数据更改。</p><h1 id="3f46" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">近实时处理</h1><p id="a51b" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">图1概述了我们如何在Cassandra节点上运行Debezium。Debezium监控Cassandra CDC提交日志目录的变化。特别是卡珊德拉4号。X Debezium连接器等待。在处理实际提交日志文件之前要标记为完成的idx文件。的。idx文件在其名称中引用了原始日志文件。例如，在下图中。idx文件Commit Log-7–1647924600284 _ cdc . idx跟踪CDC提交日志文件Commit Log-7–1647924600284 . Log的状态。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ki"><img src="../Images/62ce5f3bf3d7698768a7a2a8fccae0ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tUfjYf7lnzi44l_sMTC4gg.png"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx">Diagram 1: Debezium on Cassandra Node</figcaption></figure><p id="c375" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们对现有的Debezium Cassandra方法进行了改进，修改了代码，以便在新数据可用时继续处理提交日志，参考:<a class="ae kh" href="https://cassandra.apache.org/doc/latest/cassandra/operating/cdc.html#overview" rel="noopener ugc nofollow" target="_blank"> Cassandra4 CDC </a>。这意味着在将CDC消息发送到Kafka之前，该过程不会等待CDC提交日志被标记为完成。</p><p id="8346" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将来，我们计划修改实现来并行处理文件。这将有助于CDC处理在处理高数据量或追赶情况时跟上Cassandra。</p><h1 id="ae60" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">重复数据更改</h1><p id="9998" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">重复数据消除的关键要求是规模和状态保留。因为我们每秒可以接收60，000次数据更改。状态保留，因为我们不想发送已经处理过的数据，即使我们的进程因为崩溃而丢失了状态。</p><p id="b959" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Flink似乎是一个合理的解决方案，但我们决定采用一种更简单的方法。我们的内部数据采集工具(简称DAQ)已经通过数据划分支持流程扩展。这种能力使DAQ能够扩展以捕捉沃尔玛最关键和高容量电子商务数据库的数据变化。DAQ也支持定制插件。问题是，我们能否利用DAQ体系结构并使用插件来处理重复数据消除？</p><p id="32c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">答案是肯定的。通过在缓存中维护状态，我们能够向DAQ添加重复数据消除逻辑。我们用来维护状态的缓存是Redis。我们将在后面讨论Redis的优点。</p><p id="6ec2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图2显示了从Cassandra开始，通过DAQ进行重复数据删除，然后将数据发送到Kafka的更改数据流。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ky"><img src="../Images/85fcc852e2f2b70fc5215f312ff2faec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrZ4eqJpmJeoE5vJSUkVLA.jpeg"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx">Diagram 2: Cassandra to Kafka Data Flow</figcaption></figure><p id="e6e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Redis帮助我们使用RedisBloom来处理规模，RedisBloom是Bloom过滤器的一种实现。布隆过滤器是可以确定元素是否是集合成员的存储器结构。布隆过滤器的最大优点是内存非常小。在Redis中使用Bloom filter的另一个很大的优点是，我们可以进行批量调用来检查是否已经发现了数据更改。这减少了我们的进程和Redis之间的网络对话。</p><p id="2b99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法有缺点。首先，不可能从布隆过滤器中删除数据。为了避免删除数据，我们按事务时间对Bloom过滤器进行了分区。我们使用Redis的TTL(生存时间)设置来自动删除旧的Bloom过滤器。这意味着如果我们保留3天的布隆过滤器，我们将有72个布隆过滤器(3*24)。但是，Bloom filters占用的内存如此之小，我们没有看到按小时划分Bloom filters的任何负面影响(例如，根据配置，我们看到72个Bloom filters占用Redis中大约5 GB的内存)。事实上，与长时间使用布隆过滤器相比，它有助于减少我们可能会看到的误报数量。</p><p id="2e99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这给我们带来了另一个缺点——错误率。布隆过滤器是一种概率数据结构。这意味着布隆过滤器可以认为它看到了以前没有看到的数据变化。在我们的例子中，通过使用Bloom filter，我们的进程可以确定它已经看到了以前从未处理过的数据更改。为了降低错误率，如上所述，我们每小时轮换布隆过滤器，并且我们设置非常高的错误率(例如:1/1000000)。在我们的测试中，我们可以处理大量的数据，而不会遗漏任何数据。但是因为仍然存在丢失数据的可能性，我们小心地确保我们使用Bloom filter的用例可以接受一些丢失的数据。如果用例不能接受任何数据丢失，我们建议使用最近最少使用的(LRU)缓存来代替布隆过滤器。</p><h1 id="5811" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">绩效结果</h1><h1 id="a9f6" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Debezium Cassandra4 CDC性能</h1><p id="a07d" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">我们通过使用<a class="ae kh" href="https://cassandra.apache.org/doc/latest/cassandra/tools/cassandra_stress.html" rel="noopener ugc nofollow" target="_blank"> cassandra-stress-tool </a>运行不同的负载和流量模式来分析Debezium Cassandra4连接器，并测量Cassandra节点上的性能和资源利用率。cassandra-stress工具仅在一个cassandra节点上运行，以生成更高的工作负载。所有集群都在Azure中提供。下面是测试环境设置:</p><p id="cf73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> CDC卡夫卡:</strong> 24分区</p><p id="d5d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Cassandra节点:</strong> 3个节点，复制因子:3，每个节点有8个内核/28G内存</p><p id="ea69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从从Cassandra复制接收更改/CDC数据的节点之一获得结果。结果如下:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kz"><img src="../Images/ed5e4657d3d6d629ac8f4a87c58eaab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ckP_CHCFV2ITZF60r3Q1Ew.png"/></div></div></figure><p id="19f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中:</p><p id="5776" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.Debezium Processing Rate是Debezium处理邮件的吞吐量。</p><p id="d570" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.Cassandra CPU使用率:Debezium停止运行，以测量Cassandra CPU的最大使用率。</p><p id="3732" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.Debezium CPU使用率:第四名的总CPU使用率和Cassandra CPU使用率之间的差异</p><p id="8e0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.总CPU使用率是Cassandra Replication和Debezium运行/处理消息时的最大CPU使用率。</p><p id="d746" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Debezium的JVM堆内存使用率低于1.75G，速率为300K/min。</p><h1 id="5c23" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">重复数据删除性能结果</h1><p id="8538" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">为了演示重复数据消除解决方案的性能，我们将看3个实验。实验1改变了重复数据删除处理的批量大小。实验2考察了更改错误对性能和重复数据删除结果的影响。实验3测试扩展重复数据删除流程。</p><p id="c5c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这些测试，所有集群都在Azure中提供。为简单起见，为了对基于Redis的重复数据删除进行压力测试(每分钟150万条已删除重复的记录)，我们在前两个实验中禁用了写入已删除重复的Kafka(参见图2)。下面是测试环境的设置方式:</p><p id="7ac2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> CDC卡夫卡:</strong> 15分区</p><p id="31a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> DAQ重复数据删除虚拟机配置:</strong> 2个节点，8个核心虚拟机，24GB内存</p><p id="1153" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Redis实例:</strong> 6节点集群(3个主节点+ 3个副本节点)，每个节点配置8个核心/16GB。</p><h1 id="a1cc" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">实验1:错误率固定的不同CDC Kafka批量</h1><p id="d308" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">对于这个测试，我们配置布隆过滤器错误率= 0.00001，布隆过滤器容量= 1000万。下表显示了结果:</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es la"><img src="../Images/a03136a1b226e2622d05188be31c5f86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERZWGOY91vDoQtvNXHOm_A.png"/></div></div></figure><p id="b5f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中:</p><p id="04f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">速率是重复数据消除过程的吞吐量</p><p id="a525" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Avg Deduplication Time是一个批处理通过重复数据删除过程的平均时间</p><p id="5223" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DAQ虚拟机上的最大CPU使用率是性能测试期间观察到的最大CPU使用率</p><p id="024a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上述测试运行中，我们将误报率配置为1/100K(0.00001)，在上述3个场景中，误报率为0。</p><h1 id="b38d" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">实验2:固定CDC Kafka批量的不同错误率</h1><p id="2f64" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">对于这个测试，我们配置了Bloom Filter容量= 1000万，Kafka批量大小=3.5K</p><figure class="kj kk kl km fd kn er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es lb"><img src="../Images/dd367cd16609d73b333d23535be24e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXGxSVjVUni2agqanGyzxQ.png"/></div></div></figure><p id="85e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们设置了一个较低的错误率(1/10)时，我们确实看到了假阳性。此外，请注意，重复数据删除处理时间略有下降，因为我们降低了错误率以提高准确性。</p><h1 id="0add" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">实验3:扩展重复数据删除流程</h1><p id="6c95" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">在这个实验中，我们启用了24个分区的重复数据删除Kafka，并将CDC Kafka中的分区数量增加到24个。我们在3台Azure虚拟机上运行了重复数据删除应用，布隆过滤器错误率为1/100万，容量= 2000万。下表显示了结果:</p><p id="d80b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">每批加工时间:</strong> 2秒</p><p id="a48e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">速率:</strong> 623K/min</p><p id="abfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中:</p><p id="7df4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每批处理时间:所有3个DAQ节点的第95个百分位数的平均总处理时间(从CDC Kafka读取+重复数据删除+加载到重复数据删除的Kafka)</p><p id="0555" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">速率是流程的吞吐量。</p><p id="2ae7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些数字表示从Kafka提取Debezium记录，通过基于Redis的bloom filter对其进行重复数据删除，并将经过重复数据删除的记录加载到Kafka。该解决方案通过向Kafka添加分区和添加DAQ虚拟机进行线性扩展。</p><h1 id="a997" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">布隆过滤器内存使用</h1><p id="93d4" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">在我们的实验中，错误率为百万分之一(0.000001)，bloom filter容量为2000万，bloom filter每小时旋转一次，每个Bloom Filter使用的内存约为67MB，与<a class="ae kh" href="https://hur.st/bloomfilter" rel="noopener ugc nofollow" target="_blank"> Bloom Filter计算器</a>报告的内存大致相同。具有上述配置的72个布隆过滤器将在分布式Redis节点中占用5.2GB的内存，这是非常小的。</p><h1 id="9733" class="je jf hh bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">结论</h1><p id="f905" class="pw-post-body-paragraph ie if hh ig b ih kc ij ik il kd in io ip ke ir is it kf iv iw ix kg iz ja jb ha bi translated">卡珊德拉疾控中心是一个有趣的挑战。我们开始这个项目时，没有一个好的解决方案来从Cassandra中提取变更，也没有一个非常复杂的设计来删除重复的数据变更。本着奥卡姆剃刀的精神，我们将需求和设计精简为最简单的解决方案。结果是一个可扩展的解决方案，我们可以针对新的使用情形不断增强。</p><p id="2355" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">展望未来，我们将通过添加对从提交日志文件中读取增量更改的<a class="ae kh" href="https://issues.redhat.com/browse/DBZ-5410" rel="noopener ugc nofollow" target="_blank">支持，计划添加用于重复数据删除的LRU缓存选项，并继续优化流程，为Debezium项目做出贡献。</a></p></div></div>    
</body>
</html>