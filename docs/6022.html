<html>
<head>
<title>Creating a Mask Detection Model on OCI with YOLOv5: Data Labeling with RoboFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用YOLOv5在OCI上创建一个掩膜检测模型:用RoboFlow进行数据标记</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/creating-a-cmask-detection-model-on-oci-with-yolov5-data-labeling-with-roboflow-5cff89cf9b0b?source=collection_archive---------0-----------------------#2022-12-22">https://medium.com/oracledevs/creating-a-cmask-detection-model-on-oci-with-yolov5-data-labeling-with-roboflow-5cff89cf9b0b?source=collection_archive---------0-----------------------#2022-12-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="468e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="48c2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我一直对在我的一些项目中使用Vision ML很好奇。我梦想知道特斯拉自动驾驶仪内部是如何工作的，以及我是否可以在人生的某个时刻制作自己的人工智能系统。我厌倦了做梦，所以决定以身作则(动手)学习。</p><p id="7735" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我把重点放在重新学习我所知道的关于视觉ML的一切(这就是我所说的以某种方式与机器学习相关的图像/视频处理)。</p><p id="f78a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我认为像这样的文章会让像你这样的人进入这些话题——有时被认为“太难”的话题。通过这几篇文章，我会让你知道自己做这件事并没有那么难(而且也不贵！).</p><p id="7edd" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">计算机视觉自提出以来一直是一个不断发展的产业，视觉ML是计算机视觉的众多组成部分之一。如果您对这样的内容感兴趣，请务必关注我，并继续关注第2部分(更多信息在最后)。</p><p id="b43a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">今天，我们将学习如何在多媒体中检测不同的面具佩戴状态，包括:</p><ul class=""><li id="9f45" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">一个带着面具的人，我们将其标记为<code class="du ko kp kq kr b">mask</code>。</li><li id="5c4c" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">一个戴着面具的人，但是<em class="kx">戴错了</em>(见下面的例子)，我们将其标记为<code class="du ko kp kq kr b">incorrect</code>。</li><li id="46ce" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">一个完全没有面具的人，我们称之为<code class="du ko kp kq kr b">no mask</code>。</li></ul><p id="3d07" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我已经附上了我的模型和相应的结果的一些图像的例子。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/18548eac4a2fc59e2bf809f224173e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vxAug2Y7ATTuPif5.jpg"/></div></div></figure><p id="b382" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">请注意，我们为每个案例标记了这些数据:</p><ul class=""><li id="866b" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">‘0’代表<code class="du ko kp kq kr b">incorrect</code>。</li><li id="9de9" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">‘1’代表<code class="du ko kp kq kr b">mask</code>。</li><li id="9b7c" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">‘2’代表<code class="du ko kp kq kr b">no mask</code>。</li></ul><p id="2ea6" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将在文章中更深入地讨论细节。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/3912c237a352188f35d0fd83b7523dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LyVvbI6CGDyqkS4V.jpg"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: </em>as you can see, the little girl on the second row, third column is wearing the mask with their nose showing, which is <em class="lo">incorrect</em>. We want our custom model to detect cases like these, which are also the hardest to represent, as there are a lot of pictures of people with and without masks, but there aren’t as many of people wearing masks incorrectly on the Internet; which causes our dataset to be imbalanced. We’ll talk about how to fix an imbalanced dataset in the next article.</figcaption></figure><p id="fc9c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将对大量图像遵循这一过程，希望我们的计算机成为我们的“第三只眼”，最终使用CPU或GPU资源来进行这些预测。</p><p id="c311" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在今天的教程中，我们将特别关注如何标注这些数据。为了让机器学习(ML)模型正常工作，我们需要<em class="kx">教会</em>一个人戴着面具、没有戴面具以及面具戴错的时候是什么样子。我们将需要每个类的多个例子，我们将告诉计算机每个对象在图像中的位置，使用<strong class="je hi">边界框</strong>(也就是我们试图检测的对象顶部的矩形)。</p><p id="dfb6" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我将使用<a class="ae lp" href="https://roboflow.com" rel="noopener ugc nofollow" target="_blank"> RoboFlow </a>来标记和收集数据。我发现这个平台明显比CVAT、Label Studio或其他任何“竞争对手”的标签工具要好。</p><p id="e13a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我还可以选择使用通用模型或定制检测模型。我决定使用定制模型来解决这个挑战。</p><p id="7784" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最后，我将使用OCI (Oracle Cloud Infrastructure)来手动训练我的模型(在下一篇文章中会详细介绍)，并作为存储模型的最佳执行版本的地方。</p><p id="46fd" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">所以，让我们开始吧！</p><h1 id="46c2" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">为什么是定制型号？</h1><p id="26c9" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">定制检测机器学习(ML)模型可以在各种应用中提供许多好处。</p><ul class=""><li id="a88e" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">当我们将这些模型与<em class="kx">通用</em>模型进行比较时，一个主要的好处是提高了准确性和性能。定制检测模型是专门为任务和手头的数据定制的，允许它们学习和适应数据中的特定特征和模式。这可以导致比前面提到的通用模型更高的精度和更好的性能，通用模型不是为任务定制的。</li><li id="b3c8" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">此外，定制的检测模型将需要较少的资源来<em class="kx">训练</em>它，以及在模型被训练后进行预测。</li><li id="1f42" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">最后，没有一个通用的模型能够检测遮罩的位置，所以我们必须使用自定义模型。</li></ul><h1 id="f04e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">YOLOv5是什么？</h1><p id="3168" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">YOLO(你只看一次)是一个流行的实时对象检测系统，由约瑟夫·雷德蒙和阿里·法尔哈迪开发。这是YOLO系统的最新版本之一，于2021年发布。</p><p id="a105" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">和其他版本的YOLO一样，<a class="ae lp" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLOv5 </a>是为快速、准确、<strong class="je hi">实时</strong>的物体检测而设计的。它使用<em class="kx">单</em>卷积神经网络(CNN)来预测图像或视频中对象的边界框和分类概率。该模型被训练来预测输入图像中对象的位置，并将它们分配给预定义的类别，例如“汽车”、“人”或“建筑物”</p><p id="2d0f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">根据我的个人经验，尽管YOLOv5不是最新的检测系统，但它是具有最低<em class="kx">开放问题与关闭问题比率</em>的系统，这意味着，对于每个开放问题，超过25个问题已经被关闭。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lq"><img src="../Images/d61b883169e092aa5bed8f544f9cc3c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6v9LQSI9_EhrpxQ-.jpg"/></div></div></figure><p id="ae8c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">YOLOv5通过使用更高效的网络架构和优化技术对以前的版本进行了改进，从而实现了更快、更准确的对象检测。它还包括在低功耗设备上运行的能力。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lr"><img src="../Images/56a9cc1d5fd76b5088298016e533ae30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2TpgMIAOoSbzcAS7.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: this is a figure detailing the performance and accuracy of YOLOv5 compared to EfficientDet, and the </em><a class="ae lp" href="https://github.com/ultralytics/yolov5#why-yolov5" rel="noopener ugc nofollow" target="_blank"><em class="lo">different variations of YOLOv5</em></a><em class="lo"> (these are different checkpoints).</em></figcaption></figure><p id="d4e8" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">YOLOv5已被广泛采用，用于各种应用，包括自动驾驶汽车、机器人和安全系统，这就是为什么我决定从这个检测系统开始，而不是其他任何系统。</p><p id="7e92" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">你可能会问自己:“为什么是YOLOv5而不是其他的？”嗯，我将YOLOv5与YOLOv7进行了比较，yolov 7是在今年(2022年)开发的，比YOLOv5更新。但目前其开/闭发行比<a class="ae lp" href="https://github.com/WongKinYiu/yolov7/issues" rel="noopener ugc nofollow" target="_blank"> 3.59 </a>，<em class="kx">比YOLOv5 </em>高87倍！。因此，我推荐YOLOv5入门，因为它是完整的，而且开源社区更多地基于这个项目。</p><h1 id="d134" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">创建数据集</h1><p id="9e96" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">当我开始从事这个项目时，我首先寻找的是数据。我需要数百张(如果不是数千张的话)以不同方式戴着面具的人的照片，并给他们贴上标签。但是，在没有任何帮助的情况下，从头开始创建这个数据集将需要我自己花费数十个小时来标记数据。</p><p id="cc90" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，我决定寻找一些有相同想法的项目，并试图将所有这些图像“协调”成一个单一的模型(希望是我的)。</p><p id="f1b1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我进入了<a class="ae lp" href="https://universe.roboflow.com/" rel="noopener ugc nofollow" target="_blank"> RoboFlow Universe </a>(他们的开源视觉ML数据集和API的集合)寻找一些已经标记的数据。</p><p id="2991" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我发现这两个项目看起来非常有趣:</p><ul class=""><li id="e290" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated"><a class="ae lp" href="https://universe.roboflow.com/features-dataset/incorrect-mask-outside-mosiac-clean" rel="noopener ugc nofollow" target="_blank">拼接干净的计算机视觉项目</a>外蒙片不正确，有346张图像准备训练，</li><li id="72ff" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated"><a class="ae lp" href="https://universe.roboflow.com/ditworkspace/face-mask-jk4nr" rel="noopener ugc nofollow" target="_blank">面罩计算机视觉项目</a>，3660张图像(2800张用于训练，800张用于验证，75张用于测试)</li></ul><p id="a570" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">然而，第一个问题出现了:每个数据集的类都有<em class="kx">不同的标签</em>，这是我们不希望的:我们希望我们的模型只预测三个类。让我来演示一下:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ls"><img src="../Images/d33e80c720816a830d012da980db3670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x2IBO-fkYT0XYCfw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: example of an image from the first dataset. The corresponding labels were: </em>NoMask<em class="lo">, </em>Mask<em class="lo">, </em>IncorrectMask<em class="lo">.</em></figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lt"><img src="../Images/7bb6f176c43a0a467b306f7402d8a44e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gR2Iuzn37lEBufpx.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: example of an image from the second dataset. The corresponding labels were: </em>Masque<em class="lo">, </em>PasMasque<em class="lo">, </em>NotCorrect<em class="lo">.</em></figcaption></figure><p id="bd69" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为了解决这个标签不匹配的问题，我将两个存储库都克隆到我的计算机上，并提取它们:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lu"><img src="../Images/f5a2a33c4bbf66ba826e9dd6fc0216ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AkEVQzIET9MEyNbt.png"/></div></div></figure><p id="66e3" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">理论上，我们应该已经从数据集中下载了所有图像，这些图像被分成<code class="du ko kp kq kr b">train</code>、<code class="du ko kp kq kr b">test</code>和<code class="du ko kp kq kr b">validation</code>组。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es lv"><img src="../Images/b8e6215b3c575a7226f97294d032b5a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/0*4bpv-r4NTiKZ9udT.png"/></div></figure><p id="b105" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">此外，我们有一个名为<code class="du ko kp kq kr b">data.yaml</code>的文件，其结构如下:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lw"><img src="../Images/74dddec1e804d38386b4427fcc7fb99f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MV5r0MVh41PJ8ovI.png"/></div></div></figure><p id="0fd2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，我修改了YAML文件，以包含我想要的类名，确保标签的顺序也得以保留。我看了一些图片，确定<em class="kx"> PasMasque </em>实际上代表了面具的缺失，其他的职业也正确的代表了。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lx"><img src="../Images/3e2bc69b10ae662462706861646ab839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eQvCiG8G57-fUTmo.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: modified YAML file. Also note that if the number of classes varies, we also have to modify the variable </em><strong class="bd ig"><em class="lo">nc</em></strong><em class="lo"> accordingly, which represents the total number of classes that the dataset is trained to recognize.</em></figcaption></figure><p id="2025" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我对第二个数据集做了同样的修改，一旦我的类的名字协调好了，我就进入RoboFlow并导入两个数据集。现在我们有了相同的数据集标签，它们工作得完美无缺，我的数据集已经增加到大约2800张图片。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ly"><img src="../Images/b75460c6ce23740143ba090ce6c1fd4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zqb3LrJIsvw2bNE2.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: after importing, I see all my images have been labeled correctly and are ready for training.</em></figcaption></figure><h1 id="06a1" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">扩充数据集</h1><p id="3b90" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">现在所有的数据标注都已经完成，我想提一下RoboFlow提供的另一个很棒的功能，那就是自动<strong class="je hi">数据集扩充</strong>。</p><p id="877d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我访问了<a class="ae lp" href="https://universe.roboflow.com/jasperan/public-mask-placement" rel="noopener ugc nofollow" target="_blank">我的RoboFlow公共项目</a>，在<strong class="je hi"> Generate </strong>选项卡下生成了一个新的数据集版本:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lz"><img src="../Images/78d60d06670b694f871b5e77a9353b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2R95glpYr8lzgRPU.png"/></div></div></figure><p id="6ee4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">增强为您的模型创建新的训练示例以供学习。在第四步中，为了生成新的数据集，我选择了以下扩展:</p><ul class=""><li id="661e" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated"><strong class="je hi">灰度</strong>(应用于我10%的训练数据):通过这个，我的目标是用旧的摄像机/硬件设备复制来自CCTV摄像机或视频源的可能的未来输入。希望在用灰度代替彩色训练了10%的数据后，我还会允许B &amp; W相机测试我的模型。</li><li id="1ff6" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated"><strong class="je hi">虚化</strong>(高达1.25px):训练模型很好地对抗戴口罩的失焦人群。1.25像素不是一个极端的变换，但它平滑边缘。</li><li id="35f7" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">边界框<strong class="je hi">噪声</strong>:这将噪声<em class="kx">添加到我的训练数据集中的边界框</em>内，并生成变化以帮助我的模型对相机伪影更有弹性。我还想在直接从Twitch流或类似的直播流源分析视频时“模拟”低比特率。</li></ul><p id="8430" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">以下是不使用增强和使用增强之间的区别:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ma"><img src="../Images/2ce6fa54820f57708dfcdf689241df2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/0*uR15fBinZRcqAZdC.png"/></div></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mb"><img src="../Images/9c47e953b1358d2f79bcf7ba0651e67b.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/0*zqzVaKDvKJV8E5eS.png"/></div></figure><p id="f35f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我发现的另一个非常有用的增强功能是<strong class="je hi">马赛克</strong>增强功能，特别是如果你正在努力检测<em class="kx">小物体</em>的话，它将把几幅图像放在一起模拟马赛克，这样当这些物体占据屏幕的一小部分时，模型就会学习检测我们想要的物体。</p><p id="6914" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最后，在应用了所有这些数据集增强之后，是时候让RoboFlow能够生成这些增强的图像了。感谢他们<em class="kx">惊人的</em>支持(谢谢RoboFlow团队！)，他们免费给了我一些训练积分，并允许我生成高达<em class="kx"> 5x </em>的增强(训练数据集中每幅图像5次增强):</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mc"><img src="../Images/6b719e717fa703e70f5579ffd86289cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/0*JgVhqG0oTmC-1fWK.png"/></div></div></figure><p id="828b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在生成这个新版本一段时间后，我们可以使用RoboFlow自动训练模型，并检查每个类的<a class="ae lp" href="https://learnopencv.com/mean-average-precision-map-object-detection-model-evaluation-metric/" rel="noopener ugc nofollow" target="_blank">平均精度(mAP) </a>，包括一些其他有趣的统计数据，这些数据将有助于以后迭代我们的模型:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es md"><img src="../Images/6a3339543389c43094b75ad44e954481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2OHcjJ1-Bd4kGMaw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx">Generating Images</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es me"><img src="../Images/5766e1b8d9d91ea61e26e66e6e6e1905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*teYn4NoI5pGRWYDi.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx">Generated Version</figcaption></figure><h1 id="07ba" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用RoboFlow进行训练</h1><p id="15bf" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">因为我有一些免费的培训学分，所以我决定用其中一个来看看我的模型最初的表现如何:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mf"><img src="../Images/18fcbb2dc0947ec708d0bf03e69af125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*pnKxuG-3ripBbxhv.png"/></div></figure><p id="53c3" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我决定从检查点开始训练，因为COCO数据集(具有46.7%的地图)是一个非常著名的数据集，它已经用真实世界的数据进行了训练，这意味着参与检测元素的卷积神经网络将“知道”(至少以基本的方式)检测与人相对应的边缘和元素。</p><p id="2de7" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">神经网络的最后一个时期将被我的定制模型教导来检测元素。</p><p id="a6a4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">经过培训，我看到了以下内容:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mg"><img src="../Images/4e24e18aca74af237db3871fdeaf6a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7y-m19js7XIk01VK.png"/></div></div></figure><p id="af97" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">更详细地说，我们得到了按验证和测试集细分的平均精度:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mh"><img src="../Images/1a7847f18388d5448d202204533929e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/0*xbyOhcB8aAEOzn2T.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: </em>since the validation set had fewer pictures than the test set, and the validation set has a lower precision, this leads me to believe that the lower precision on the validation set is caused by having too few pictures, and not by the model being inaccurate on detections. We will fix this in the next article, where we will make a more balanced split for our dataset.</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mi"><img src="../Images/0eb76082be326308455a6616d8792716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*iQUIYHCpWyXzDpEe.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: </em>also note that — across validation and test set — the “incorrect” label has a constant precision of 49%. This makes sense, as it’s the hardest class to predict of the three — it’s very easy to see the difference between someone with our without a mask, but incorrectly-placed masks are harder to detect even for us. Thus, some pictures we may fail to be recognized as humans. We take note of this and we’ll find a way to try and improve the precision for this specific class in the future.</figcaption></figure><h1 id="dac9" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结论</h1><p id="b2f2" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">训练之后，我们有了数据集的最终初始版本。这是培训期间所有指标的完整细节，由RoboFlow自动提供，但我将在下一篇文章中教您如何自己生成这些数据:</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lr"><img src="../Images/d9e895704852ea1d6d6383e77640a428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tyNzPIEF04JPo0Pi.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx"><strong class="bd ig"><em class="lo">Note</em></strong><em class="lo">: </em>the lower the loss, the better. Loss is a metric that represents the inverse of accuracy. So the lower the accuracy, the higher the loss, and vice versa. We can also observe that the training loss decreases correctly; never increases, which is good, and both training and validation losses follow the same curve, which also means that overfitting or underfitting isn’t happening in our case.</figcaption></figure><p id="621a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最后，我通常喜欢检查一些东西，以查看我的模型是否经过适当的训练，这些东西是:</p><ul class=""><li id="ee2f" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">[ ]我的培训损失是否高于测试损失？-&gt;这将表明<strong class="je hi">不符合</strong>。</li><li id="a640" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">[ ]我的培训损失是否低于测试损失？-&gt;这将表明<strong class="je hi">过度拟合</strong>。</li></ul><p id="5dd2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">由于两个损失非常相似，我们可以得出结论，我们的模型非常适合，我们将努力改善每个类别的地图。</p><p id="187a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在下一篇文章中，我们将学习如何:</p><ul class=""><li id="79ff" class="kf kg hh je b jf ka jj kb jn kh jr ki jv kj jz kk kl km kn bi translated">用图形处理器在OCI上从头开始训练这个面具检测模型的改进版本。</li><li id="a073" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">如何扩展/改进数据集并生成改进的v2。</li><li id="ba73" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated">实时使用模型(通过摄像头、YouTube之类的视频、标准视频或逐个图像)。</li></ul><p id="1cad" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在轮到你准备一些你想从头开始检测的东西了(我很感谢对我的数据集做出贡献的人)，并按照我在本教程中的步骤为2023年即将到来的事情做准备。</p><p id="9db5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">如果你像我一样对甲骨文开发人员在他们的自然栖息地发生的事情感到好奇，来加入我们公共Slack频道的<a class="ae lp" href="https://bit.ly/odevrel_slack" rel="noopener ugc nofollow" target="_blank">！</a>我们不介意成为你的鱼缸:热带鱼:</p><p id="41d4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">敬请关注…</p><h1 id="607c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">感谢</h1><ul class=""><li id="90c7" class="kf kg hh je b jf jg jj jk jn mj jr mk jv ml jz kk kl km kn bi translated"><strong class="je hi">作者</strong> — Nacho Martinez，数据科学倡导者@ Oracle DevRel</li><li id="a6d4" class="kf kg hh je b jf ks jj kt jn ku jr kv jv kw jz kk kl km kn bi translated"><strong class="je hi">最后更新时间/日期</strong>—2022年12月22日</li></ul></div></div>    
</body>
</html>