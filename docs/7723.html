<html>
<head>
<title>How we build a robust analytics platform using Spark, Kafka and Cassandra</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们如何使用Spark、Kafka和Cassandra构建强大的分析平台</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/how-we-build-a-robust-analytics-platform-using-spark-kafka-and-cassandra-lambda-architecture-70c2d1bc8981?source=collection_archive---------0-----------------------#2018-08-06">https://medium.com/walmartglobaltech/how-we-build-a-robust-analytics-platform-using-spark-kafka-and-cassandra-lambda-architecture-70c2d1bc8981?source=collection_archive---------0-----------------------#2018-08-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/4e4ff026d9c6ae5fd4547f7382209b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Tj7bMRpOElRFwoer1lBNaw.jpeg"/></div></figure><div class=""/><p id="78eb" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在今天的网上世界，供应链是任何网上商店最重要的支柱之一。不仅仅是高质量的产品，顾客也希望快速交货。这需要在关键地点保持物品的可用性，以便这些物品能够在尽可能短的时间内到达客户手中。这也将允许企业用户持续监控库存可用性。</p><p id="8141" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">鉴于沃尔玛网站上的商品数量庞大，在SKU个人层面上跟踪它们可能会变得很困难。业务用户需要的是一个仪表板，他们可以在其中看到可用性的汇总数据。</p><p id="da07" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jj">在这篇博客中，我们将详细介绍这一点——我们构建了一个平台，为用户提供可视化功能来跟踪商品的可用性。</em></p><h1 id="a523" class="jk jl ho bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">我们最关心的是什么？</h1><p id="d832" class="pw-post-body-paragraph il im ho in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">有了这个新平台，我们必须解决一些问题。以下是对他们和我们所做的选择的调查:</p><ul class=""><li id="fab3" class="kn ko ho in b io ip is it iw kp ja kq je kr ji ks kt ku kv bi translated">高数据流</li></ul><p id="92a0" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">鉴于沃尔玛网站上每秒都有大量订单，商品的可用性也经常变化。更新数据(可能是每秒100 MB)意味着将信息实时传输到分析平台。</p><p id="8999" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hp"> <em class="jj">那么，我们是如何解决这个问题的呢？</em> </strong>我们为它选择了<a class="ae kw" href="http://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡</a>。Kafka是一个分布式、可扩展的容错消息传递系统，默认情况下提供流支持。</p><ul class=""><li id="b294" class="kn ko ho in b io ip is it iw kp ja kq je kr ji ks kt ku kv bi translated">存储万亿字节的数据，并频繁更新</li></ul><p id="2ad7" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了存储商品可用性数据，我们需要能够在不影响性能的情况下处理大量追加销售的数据存储。为了生成报告，数据必须每隔几个小时处理一次，因此读取速度也必须很快。</p><p id="5348" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">虽然RDBMS可以存储大量数据，但是它不能提供可靠的上插和读取性能。我们过去和卡桑德拉有过很好的经验，因此，这是第一选择。<a class="ae kw" href="http://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Cassandra </a>拥有最佳的读写性能。像卡夫卡一样，它是分布式的、高度可扩展的和容错的。</p><ul class=""><li id="792d" class="kn ko ho in b io ip is it iw kp ja kq je kr ji ks kt ku kv bi translated">处理大量数据</li></ul><p id="d685" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">数据处理必须在流水线的两个地方进行。首先，在写入期间，我们必须从Kafka传输数据，对其进行处理并保存到Cassandra。第二，在生成业务报告时，我们必须读取完整的Cassandra表，将它与其他数据源连接起来，并在多个列中聚合它。</p><p id="2e58" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对于这两个需求，<a class="ae kw" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>是一个完美的选择。这是因为Spark使用最先进的DAG调度程序、查询优化器和物理执行引擎，实现了批处理和流数据的高性能。</p><h1 id="3915" class="jk jl ho bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">体系结构</h1><p id="6296" class="pw-post-body-paragraph il im ho in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">下面(图1)是我们使用上述技术构建的<strong class="in hp">分析平台</strong>的最终架构。</p><p id="58e1" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">维护项目可用性的应用程序在kafka主题中发布项目可用性更新。Spark流处理kafka消息并在cassandra中保存数据。</p><p id="c8ee" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Spark批处理作业被安排为每6小时运行一次，它从cassandra可用性表中读取数据，并将聚集的数据以T4的格式写入T2的swift存储器中。</p><p id="ee49" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了可视化，我们利用<a class="ae kw" href="https://www.tableau.com/" rel="noopener ugc nofollow" target="_blank">画面</a>。创建Hive表是为了读取spark sql中的swift存储数据。为了连接tableau和spark sql，我们在spark端使用thrift server，在tableau端使用spark sql连接器。</p><figure class="ky kz la lb fd hj er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kx"><img src="../Images/c129b93909b4d2881a396fa8bef56c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPo-Q-lMZ3dbfTe5_Av9tA.jpeg"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Figure 1: All components of platform</figcaption></figure><h1 id="6ffc" class="jk jl ho bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">就这样结束了！</h1><p id="b8ea" class="pw-post-body-paragraph il im ho in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">总之，使用Spark、Kafka和Cassandra可以帮助我们实现实时和批处理。继续尝试这个平台来帮助您解决您的流和批处理问题！</p></div></div>    
</body>
</html>