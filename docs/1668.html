<html>
<head>
<title>K-Nearest Neighbors (KNN) Algorithm for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的k-最近邻(KNN)算法</h1>
<blockquote>原文：<a href="https://medium.com/capital-one-tech/k-nearest-neighbors-knn-algorithm-for-machine-learning-e883219c8f26?source=collection_archive---------1-----------------------#2019-04-22">https://medium.com/capital-one-tech/k-nearest-neighbors-knn-algorithm-for-machine-learning-e883219c8f26?source=collection_archive---------1-----------------------#2019-04-22</a></blockquote><div><div class="ds gx gy gz ha hb"/><div class="hc hd he hf hg"><div class=""/><p id="3d93" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">机器学习算法介绍系列的第1部分</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/ffa71a53ef5727c2b3bf88d725038375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5y_rQpKAYXp47xon"/></div></div></figure><h1 id="650d" class="jq jr hj bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="9a3e" class="pw-post-body-paragraph ig ih hj ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hc bi translated">如果你熟悉机器学习和该领域使用的基本算法，那么你可能听说过k-最近邻算法，或KNN。该算法是机器学习中使用的更简单的技术之一。这是业内许多人首选的方法，因为它易于使用且计算时间短。</p><p id="77bf" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">什么是KNN？KNN是一种根据最相似的点对数据点进行分类的模型。它使用测试数据对未分类点应分类为什么做出“有根据的猜测”。</p><p id="06bf" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated"><strong class="ii hk">优点:</strong></p><ul class=""><li id="5f8b" class="kt ku hj ii b ij ik in io ir kv iv kw iz kx jd ky kz la lb bi translated">好用。</li><li id="ccc2" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">计算时间快。</li><li id="d02e" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">不对数据做出假设。</li></ul><p id="f8c0" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated"><strong class="ii hk">缺点:</strong></p><ul class=""><li id="5d23" class="kt ku hj ii b ij ik in io ir kv iv kw iz kx jd ky kz la lb bi translated">准确性取决于数据的质量。</li><li id="822a" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">必须找到一个最佳的k值(最近邻的数量)。</li><li id="c40a" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">不擅长对边界内的数据点进行分类，而这些数据点可以以某种方式进行分类。</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/cc7780a27fd60aad145b437a95fe366c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*2vWmEmMPiW9uKNOT"/></div></figure><p id="7f86" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">KNN是一种被认为是非参数的算法，也是懒惰学习的一个例子。这两个术语到底是什么意思？</p><ul class=""><li id="585b" class="kt ku hj ii b ij ik in io ir kv iv kw iz kx jd ky kz la lb bi translated"><a class="ae li" href="https://en.wikipedia.org/wiki/Nonparametric_statistics" rel="noopener ugc nofollow" target="_blank">非参数化</a>意味着它不做任何假设。该模型完全是由提供给它的数据组成的，而不是假设它的结构是正常的。</li><li id="058e" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">懒惰学习意味着算法不进行归纳。这意味着使用这种方法时几乎不需要培训。因此，当使用KNN时，所有的训练数据也用于测试。</li></ul><h1 id="5576" class="jq jr hj bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">在哪里使用KNN</h1><p id="3ea0" class="pw-post-body-paragraph ig ih hj ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hc bi translated">KNN通常用于简单的推荐系统、图像识别技术和决策模型。这是网飞或亚马逊等公司用来推荐不同电影或书籍的算法。网飞甚至发起了Netflix有奖竞赛，奖励创造最准确推荐算法的团队100万美元！</p><p id="ba77" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">你可能想知道，<em class="lj">“但是这些公司是怎么做到的呢？”嗯，这些公司会将KNN应用到你在他们网站上看过的电影或买过的书的数据集上。然后，这些公司会输入你现有的客户数据，并将其与看过类似电影或买过类似书籍的其他客户进行比较。然后，根据他们过去使用KNN的情况，该数据点将被归类为某个简档。推荐的电影和书籍将取决于算法如何分类该数据点。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/f1a362294787f083ae27f4cc61bedafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*AXRXmhsvIUvkUpdw"/></div></figure><p id="7106" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">上图展示了KNN在尝试根据给定的数据集对数据点进行分类时的工作方式。将它与其最近的点进行比较，并根据它最接近和最相似的点进行分类。在这里，您可以看到点Xj将根据其与每组点的距离被分类为W1(红色)或W3(绿色)。</p><h1 id="9194" class="jq jr hj bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">KNN背后的数学</strong></h1><p id="0488" class="pw-post-body-paragraph ig ih hj ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hc bi translated">就像几乎所有其他东西一样，KNN的工作是因为它使用了根深蒂固的数学理论。当实现KNN时，第一步是将数据点转换成特征向量，或者它们的数学值。然后，该算法通过找出这些点的数学值之间的距离来工作。找到这个距离最常用的方法是欧几里德距离，如下所示。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/681022d4536d596a224f52bbb85aefc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/0*afh-89Pe_pFauS28"/></div></figure><p id="f21c" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">KNN运行这个公式来计算每个数据点和测试数据之间的距离。然后，它会找出这些点与测试数据相似的概率，并根据哪些点共享最高概率对其进行分类。</p><p id="dfa8" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">为了形象化这个公式，它应该是这样的:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/34638729d6c87907bd32750aef7db997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*wrYJ9Wqm3FAOsBIw"/></div></figure><h1 id="7c2d" class="jq jr hj bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="052b" class="pw-post-body-paragraph ig ih hj ii b ij ko il im in kp ip iq ir kq it iu iv kr ix iy iz ks jb jc jd hc bi translated">现在你知道了一个最基本的机器学习算法的基本原理。当第一次学习基于不同的数据集构建模型时，这是一个很好的起点。如果你有一个包含许多不同点和准确信息的数据集，这是一个开始用KNN探索机器学习的好地方。</p><p id="c944" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">当开始使用这种算法时，请记住以下三点:</p><ul class=""><li id="bdf1" class="kt ku hj ii b ij ik in io ir kv iv kw iz kx jd ky kz la lb bi translated">首先，找到一个易于使用的数据集，最好是包含大量不同点和标记数据的数据集。</li><li id="6591" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">第二，找出哪种语言最容易用来解决问题。我最熟悉的是在R中使用KNN，但Python也是机器学习专业人士的流行语言。</li><li id="7c10" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated">第三，做你的研究。了解使用该算法的正确做法非常重要，这样您就可以从数据集中找到最准确的结果。</li></ul><p id="301f" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">已经进行了关于如何改进该算法的各种研究。这些研究的目的是让你可以不同地衡量类别，以便进行更准确的分类。这些类别的权重根据距离的计算方式而有所不同。</p><p id="01eb" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">总之，这是一个基本的机器学习算法，它是可靠的，因为许多原因，如易于使用和快速计算时间。在开始探索机器学习的世界时，这是一个很好的算法，但它仍有改进和修改的空间。</p><p id="1542" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">有关更多资源，请查看一些使用k近邻的项目:</p><ul class=""><li id="ab2a" class="kt ku hj ii b ij ik in io ir kv iv kw iz kx jd ky kz la lb bi translated"><a class="ae li" href="https://www.youtube.com/watch?v=ZD_tfNpKzHY" rel="noopener ugc nofollow" target="_blank">手写数字识别</a></li><li id="5271" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated"><a class="ae li" href="https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/neighbors" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a></li><li id="4dae" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated"><a class="ae li" href="https://github.com/div3125/k-nearest-neighbors" rel="noopener ugc nofollow" target="_blank"> KNN使用Python </a></li></ul></div><div class="ab cl ll lm gq ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="hc hd he hf hg"><h1 id="07b3" class="jq jr hj bd js jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn bi translated">相关:</h1><ul class=""><li id="6191" class="kt ku hj ii b ij ko in kp ir lx iv ly iz lz jd ky kz la lb bi translated"><a class="ae li" rel="noopener" href="/capital-one-tech/k-means-clustering-algorithm-for-machine-learning-d1d7dc5de882">用于机器学习的K-Means聚类算法</a></li><li id="123e" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated"><a class="ae li" rel="noopener" href="/capital-one-tech/naives-bayes-classifiers-for-machine-learning-2e548bfbd4a1">用于机器学习的朴素贝叶斯分类器</a></li><li id="7f17" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated"><a class="ae li" rel="noopener" href="/capital-one-tech/random-forest-algorithm-for-machine-learning-c4b2c8cc9feb">机器学习的随机森林算法</a></li><li id="06aa" class="kt ku hj ii b ij lc in ld ir le iv lf iz lg jd ky kz la lb bi translated"><a class="ae li" rel="noopener" href="/capital-one-tech/artificial-neural-networks-for-machine-learning-79c67d0681e9">用于机器学习的人工神经网络</a></li></ul><p id="b698" class="pw-post-body-paragraph ig ih hj ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hc bi translated">披露声明:2019首创一。观点是作者个人的观点。除非本帖中另有说明，否则Capital One不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</p></div></div>    
</body>
</html>