<html>
<head>
<title>Upgrading Data Warehouse Infrastructure at Airbnb</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">升级Airbnb的数据仓库基础设施</h1>
<blockquote>原文：<a href="https://medium.com/airbnb-engineering/upgrading-data-warehouse-infrastructure-at-airbnb-a4e18f09b6d5?source=collection_archive---------0-----------------------#2022-09-26">https://medium.com/airbnb-engineering/upgrading-data-warehouse-infrastructure-at-airbnb-a4e18f09b6d5?source=collection_archive---------0-----------------------#2022-09-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f157" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本博客旨在介绍Airbnb将数据仓库基础设施升级到Spark和Iceberg的经验。</p><p id="56fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由:<a class="ae jc" href="https://www.linkedin.com/in/huirong-ronnie-zhu-97b0a980/" rel="noopener ugc nofollow" target="_blank">罗尼·朱</a>，<a class="ae jc" href="https://www.linkedin.com/in/edgarrd/" rel="noopener ugc nofollow" target="_blank">埃德加·罗德里格斯</a>，<a class="ae jc" href="https://www.linkedin.com/in/qiang-jason-xu-7101b025/" rel="noopener ugc nofollow" target="_blank">杰森·徐</a>，<a class="ae jc" href="https://www.linkedin.com/in/gustavo-torres-torres/" rel="noopener ugc nofollow" target="_blank">古斯塔沃·托雷斯</a>，<a class="ae jc" href="https://www.linkedin.com/in/kerimoktay" rel="noopener ugc nofollow" target="_blank">克里姆·奥克泰</a>，<a class="ae jc" href="https://www.linkedin.com/in/zhangxu325/" rel="noopener ugc nofollow" target="_blank">徐张</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e979ebed03a7f1fb4d1c0d5bab6e6cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ky-obyCnt-A0R4qjnoY1_g.jpeg"/></div></div></figure><h1 id="7abc" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">介绍</h1><p id="0829" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在这篇博客中，我们将介绍我们将数据仓库基础设施升级到Spark 3和Iceberg的动机。我们将简要描述Airbnb数据仓库基础设施的现状和面临的挑战。然后，我们将分享我们从升级一个关键生产工作负载中获得的经验:事件数据摄取。最后，我们将分享结果和经验教训。</p><h1 id="7ca3" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">语境</h1><p id="ad7a" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">Airbnb的数据仓库(DW)存储之前从传统的<a class="ae jc" rel="noopener" href="/airbnb-engineering/data-infrastructure-at-airbnb-8adfb34f169c"> HDFS集群</a>迁移到S3，以提供更好的稳定性和可扩展性。虽然我们的团队一直在不断提高在S3处理数据的工作负载的可靠性和稳定性，但这些工作负载及其所依赖的基础架构的某些特征带来了用户经常遇到的可扩展性和工作效率限制。</p><h2 id="1cb4" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">挑战</h2><h2 id="b5fe" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">Hive Metastore</h2><p id="46e8" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">随着分区数量的增加，Hive后端DBMS的负载已经成为一个瓶颈，分区操作的负载也是如此(例如，查询数千个分区以获得一个月的数据)。作为一种变通方法，我们通常添加一个每日聚合阶段，并为不同时间粒度(例如每小时和每天)的查询保留两个表。为了节省存储空间，我们将当天的Hive表限制为短期保留(三天)，而将每日表保留更长时间(几年)。</p><h2 id="604f" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">蜂巢/S3互动</h2><p id="c3ab" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">Hive最初不是为对象存储而设计的。相反，在实现重命名和文件列表等功能时，围绕HDFS做了许多假设。因此，当我们从HDFS迁移到S3时，需要一定的保证来确保数据集在写入后列表操作中是一致的。我们定制了Hive写入S3的方式，首先写入HDFS临时集群，然后通过优化的distcp进程将数据移动到S3，该进程在提交阶段写入唯一的位置，将文件列表信息存储在单独的存储中以便快速访问。这一过程在过去两年中表现良好，但它需要额外的群集资源来运行。</p><h2 id="848f" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">图式进化</h2><p id="0e36" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在Airbnb，我们使用三个计算引擎来访问我们数据仓库中的数据:Spark、Trino和Hive。由于每个计算引擎处理模式更改的方式不同，对表模式的更改几乎总是会导致数据质量问题，或者需要工程师执行代价高昂的重写。</p><h2 id="6fd0" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">分割</h2><p id="1b27" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">Hive表由固定列分区，分区列不能轻易更改。如果需要对数据集进行重新分区，必须创建一个新表并重新加载整个数据集。</p><h1 id="9517" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">新数据堆栈</h1><p id="74dc" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">这些挑战促使我们将我们的数据仓库基础设施升级到基于Iceberg和Spark 3的新堆栈，这解决了这些问题，并提供了可用性改进。</p><h2 id="094b" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">冰山</h2><p id="edb1" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">Apache Iceberg是一种表格格式，旨在解决传统的基于文件系统的数据仓库存储格式(如Hive)的一些缺点。Iceberg旨在为大型分析表提供高性能读取，具有可序列化隔离、基于快照的时间旅行和可预测的模式演变等特性。一些重要的冰山特征有助于应对前面提到的一些挑战:</p><ul class=""><li id="fe83" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">分区信息不存储在配置单元metastore中，因此消除了metastore的大量负载。</li><li id="e4cd" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">Iceberg表不需要S3列表，这消除了写后列表一致性要求，从而消除了对额外discp作业的需要，并完全避免了列表操作的延迟。</li><li id="ed07" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">在<a class="ae jc" href="https://iceberg.apache.org/spec/#schema-evolution" rel="noopener ugc nofollow" target="_blank"> Iceberg spec </a>中定义了一致的表模式，这保证了跨计算引擎的一致行为，避免了更改列时的意外行为。</li></ul><h2 id="46dd" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">火花3</h2><p id="5114" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated"><a class="ae jc" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>已经成为过去10年大数据处理事实上的标准。Spark 3是2020年发布的一个新的主要版本，它有一长串的功能——新功能、错误修复和性能改进。这里我们重点介绍自适应查询执行(AQE );你可以在<a class="ae jc" href="https://databricks.com/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html" rel="noopener ugc nofollow" target="_blank">数据博客</a>上找到更多信息。</p><p id="80ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AQE是一种查询优化技术，它使用运行时统计信息来优化Spark查询执行计划。这解决了Spark基于成本的优化的最大难题之一——在查询开始之前收集的不准确的统计数据通常会导致次优的查询计划。随着查询的运行，AQE将找出数据特征并改进查询计划，从而提高查询性能。</p><p id="cc84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Spark 3也是冰山采用的先决条件。使用Spark SQL的Iceberg表读写支持只在Spark 3上可用。</p><p id="2298" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下图显示了我们所做的更改:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lu"><img src="../Images/fcf4177cefd884a87c58df2f0d461939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cIYLTqi2XeFm3vxb"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr"><em class="lz">Figure 1.</em></strong><em class="lz"> Evolution of data compute and storage tech stack</em></figcaption></figure><h1 id="c179" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">生产案例研究—数据摄取</h1><p id="da99" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在Airbnb，基于Hive的数据摄取框架每天处理超过350亿条Kafka事件消息和1，000多个表格，并将从千字节到万亿字节的数据集放入每小时和每天的分区中。不同规模的数据集的数量和覆盖范围以及时间粒度要求使该框架成为从我们的Spark+Iceberg技术堆栈中受益的良好候选。</p><h1 id="7ba9" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">火花3</h1><p id="9b68" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">迁移到前面提到的Spark+Iceberg计算技术堆栈的第一步是将我们的Hive查询迁移到Spark。这带来了新的挑战:火花调谐。与依赖于数据量统计的Hive不同，Spark使用预设的洗牌分区值来确定任务分割大小。因此，在Spark上调优事件数据摄取框架时，选择适当数量的混洗分区成为一大挑战。不同事件的数据量变化很大，并且一个事件的数据大小也随着时间而变化。图2显示了处理100个不同类型事件的样本的Spark作业的shuffle数据大小的高方差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/979ec7d46b5b1f799445f6f548fbcef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*qAIItnnv9VtcG9nz"/></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Figure 2.</strong> High variance of raw data size of 100 randomly sampled events; each bar represents a single dataset</figcaption></figure><p id="8127" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于摄取框架中的所有事件，没有固定数量的混洗分区能够很好地工作；如果我们为所有的摄取作业选择一个固定的数字，那么这个数字对于某些作业来说可能太大，而对于另一些作业来说又太小，这两种情况都会导致低性能。当我们探索不同的解决方案来调整shuffle分区参数时，我们发现自适应查询执行可能是一个完美的解决方案。</p><h2 id="f740" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">AQE如何提供帮助？</h2><p id="f486" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在Spark 3.0中，AQE框架附带了几个关键特性，包括动态切换连接策略和动态优化偏斜连接。然而，对于我们的用例来说，最重要的新特性是动态合并混洗分区，这可以确保每个Spark任务操作的数据量大致相同。它通过在运行时将相邻的小分区合并成更大的分区来实现这一点。由于混洗数据可以在作业的不同阶段动态增长或收缩，AQE通过在作业的整个生命周期内进行合并，不断地重新优化每个分区的大小。这带来了巨大的性能提升。</p><p id="3670" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AQE很好地处理了我们的数据摄取框架中的所有情况，包括尖峰事件和新事件的边缘情况。需要注意的是，嵌套列的展平和文件存储格式的压缩(在我们的例子中，是GZIP拼花)可能会为小任务分割生成相当小的输出文件。为了确保输出文件足够大，能够被有效地访问，我们可以相应地增加AQE建议洗牌分区的大小。</p><h2 id="0aab" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">AQE调音体验</h2><p id="c29c" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">让我们通过一个例子来更好地理解AQE及其调优体验。假设我们运行示例查询来加载一个数据集。该查询有一个Map阶段用于扁平化事件，另一个Reduce阶段用于处理重复数据删除。在采用AQE并在Spark中运行作业后，我们可以看到两个突出显示的步骤被添加到物理计划中。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/8e5d328485136af2c27620bd8c9bd0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZWObyyGiQUBqgKNP7HSQw.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Figure 3.</strong> Change of physical plan of the example Spark job</figcaption></figure><p id="f575" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们仔细看看我们的调优阶段。如表1所示，我们经历了几次参数设置的迭代。根据我们的经验，如果实际使用的shuffle分区等于我们设置的初始分区号，我们应该增加初始分区号，以便更多地拆分初始任务，并将它们合并。如果平均输出文件太小，我们可以增加建议分区的大小来生成更大的随机分区，从而生成更大的输出文件。通过检查每个任务的混洗数据，我们还可以减少执行器的内存和执行器的最大数量。</p><p id="4a9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还在不同大小的数据集上试验了调整后的作业参数，如表2和表3所示。从结果中，我们可以看到，调整后，AQE在从零字节大小到TB大小的数据集上表现良好，同时使用了一组作业参数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mc"><img src="../Images/999f0023e5e4340eb5805a2a25199e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eZu1Q9D0lyD5ZEVE"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Table 1.</strong> Tuning AQE using example medium-size dataset</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/011bdf2747fb08763d733a875159353e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K6Ff5uiN90I_ci_o"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Table 2.</strong> Job stats of example small-size dataset</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/4fd0c67278fa358dc133191afc76c2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-whu7KM8AK8w1N-f"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Table 3.</strong> Job stats of example empty-size dataset</figcaption></figure><p id="66ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从我们的结果来看，很明显，AQE可以在Reduce阶段将洗牌拆分大小调整到非常接近我们预定义的值，从而生成我们期望的目标文件大小的输出。此外，由于每次洗牌拆分都接近预定义的值，我们还可以从默认值降低执行器内存，以确保有效的资源分配。作为该框架的一个额外的巨大优势，我们不需要做任何特殊的处理来装载新的数据集。</p><h1 id="f547" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">Iceberg —分区规格和压缩</h1><h2 id="3c6a" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">冰山有什么帮助？</h2><p id="4952" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在我们的数据摄取框架中，我们发现我们可以利用Iceberg的灵活性来定义多个分区规范，以便随着时间的推移合并摄取的数据。写在分区Iceberg表中的每个数据文件都属于一个分区，但是我们可以随时控制分区值的粒度。摄取的表以每小时的粒度(ds/hr)写入新数据，每天的自动化过程在每天的分区(ds)上压缩文件，而不会丢失每小时的粒度，该粒度稍后可以作为残差过滤器应用于查询。</p><p id="a424" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的压缩过程足够智能，可以确定是否需要重写数据来达到最佳文件大小，否则只需重写元数据，将已经存在的数据文件分配给每日分区。这简化了接收事件数据的过程，并在同一表格中为用户提供了数据的统一视图。另一个好处是，我们通过这种方法在整个过程中实现了成本节约。</p><p id="38f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如下图所示，在整合的Iceberg表中，我们在一天结束时将分区规范从ds/hr切换到ds。此外，现在用户查询更容易编写，并且能够访问具有完整历史记录的更新数据。仅保留一份数据拷贝还有助于提高计算和存储效率，并确保数据一致性。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/e8a207bb87dcabc81cb64d6731ebafda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mrwb_94NNQWrs_mF"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Figure 4.</strong> Change of table storage format for table consolidation</figcaption></figure><h2 id="6140" class="ks jq hh bd jr kt ku kv jv kw kx ky jz ip kz la kd it lb lc kh ix ld le kl lf bi translated">表格合并体验</h2><p id="1161" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">将每小时和每天的数据整合到一个Iceberg表中需要改变写入和读取路径。对于写入路径，为了减轻前面提到的由小文件引起的问题，我们在分区规范切换期间强制运行压缩。表4和表5比较了智能压缩作业的统计数据和完全重写与每日分区相关的所有数据文件的成本。对于一些大型表，我们通过利用Iceberg的能力避免压缩期间的数据复制，节省了90%以上的资源。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mf"><img src="../Images/4b7a611058055e1d14a75e4f672ec3d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/0*yNW6DneHRxWZdlwq"/></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Table 4.</strong> Compaction job comparison of example small-size dataset</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/5b3e202613790cf467b411e6534cbc88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/0*R8NW6NHCpI2OUUxm"/></div><figcaption class="lv lw et er es lx ly bd b be z dx"><strong class="bd jr">Table 5.</strong> Compaction job comparison of example large-size dataset</figcaption></figure><p id="cd06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于读取路径，由于大多数数据消费者使用Airflow的分区传感器，我们更新了分区感测的实现。具体来说，我们实现了一个信号系统来检测Iceberg表中的空分区，而不是像以前那样在Hive metastore中将每个Hive分区作为一个实际行来查找。</p><h1 id="1e01" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结果</h1><p id="1408" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">对比之前的TEZ和Hive堆栈，我们发现，在我们的数据摄取框架中，Spark 3和Iceberg节省了50%以上的计算资源，减少了40%的作业运行时间。从可用性的角度来看，我们通过利用Iceberg的原生模式和分区进化功能，使消费存储数据变得更加简单和快速。</p><h1 id="dd1c" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="f81c" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">在这篇文章中，我们分享了我们对Airbnb的数据计算和存储技术堆栈进行的升级。我们希望读者喜欢了解我们的事件数据摄取框架如何受益于自适应查询执行和Iceberg，并希望他们考虑将类似的技术堆栈更改应用于涉及不同大小和时间粒度的数据集的用例。</p><p id="7f68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你对这类工作感兴趣，请点击此处查看我们的空缺职位<a class="ae jc" href="https://careers.airbnb.com/" rel="noopener ugc nofollow" target="_blank"/>！</p><h1 id="e7b4" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">感谢</h1><p id="8593" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">特别感谢布鲁斯·金、、亚当·科洛斯基和卢经纬一直以来的指导和支持！</p><p id="6843" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也非常感谢Mark Giangreco，Surashree Kulkarni和Shylaja Ramachandra为帖子提供编辑和很好的建议！</p></div><div class="ab cl mh mi go mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ha hb hc hd he"><p id="fceb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]一个警告是，Spark AQE有一个处理空输入的错误(<a class="ae jc" href="https://issues.apache.org/jira/browse/SPARK-35239" rel="noopener ugc nofollow" target="_blank"> SPARK-35239 </a>)，3.2中提供了修复程序。因此，为了在较低的Spark版本中充分利用AQE，我们需要反向移植<a class="ae jc" href="https://github.com/apache/spark/pull/32362" rel="noopener ugc nofollow" target="_blank">修复1 </a>和<a class="ae jc" href="https://github.com/apache/spark/pull/31994" rel="noopener ugc nofollow" target="_blank">修复2 </a>。</p></div></div>    
</body>
</html>