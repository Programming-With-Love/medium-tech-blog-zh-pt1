<html>
<head>
<title>Multi-task Learning for Related Products Recommendations at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pinterest上相关产品推荐的多任务学习</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/multi-task-learning-for-related-products-recommendations-at-pinterest-62684f631c12?source=collection_archive---------1-----------------------#2020-12-01">https://medium.com/pinterest-engineering/multi-task-learning-for-related-products-recommendations-at-pinterest-62684f631c12?source=collection_archive---------1-----------------------#2020-12-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7464" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">陈昊宇| Pinterest实验室研究实习生，购物探索部<br/> Pedro Silva |软件工程师，购物探索部<br/> Somnath Banerjee |购物探索部主管</p><p id="7f73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人们总是来Pinterest寻找购物灵感，多年来我们已经取得了很大的进步，尽可能使其无缝，以便Pinners(用户)可以从灵感到购买，包括发展可购物的产品pin，改进推荐，并使商家更容易上传他们的目录，以管理和展示他们的产品。Pinterest购物团队的愿景是让Pinners能够发现高质量的产品，并让他们能够轻松自信地购买。作为实现这一目标的关键步骤，我们构建了相关产品模块，根据Pinners当前查看的Pin，向他们推荐我们认为他们会喜欢的产品。该模块在整个应用程序中显示为“同类商店”和“更多商店”。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/70efcdd299925db3cf40f8a23e78e85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uC_9ES8b0XCJAWjB"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 1: Related Products recommendations for a home decor Pin</figcaption></figure><p id="b67b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相关产品推荐可以被认为是两个高级组件。第一个是候选生成，在给定当前上下文、Pin和用户的情况下，我们生成一组数百个与该用户相关的产品。第二个组成部分是产品排名:从上一步生成的产品集中，我们应该如何为每个Pinner对它们进行排名，以便顶部的产品在给定的上下文中更相关，帮助他们轻松地发现他们喜欢的产品。在本文中，我们将重点关注这个过程的第二个组成部分，并解释我们如何使用多任务学习[1][2]，校准[3]和贝叶斯优化[4]来构建一个灵活，可解释，可扩展的相关产品推荐候选排名解决方案。</p><h1 id="ee48" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">背景</h1><p id="e7cf" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">在Pinterest，有不同类型的参与:<em class="kv">特写</em>是指点击Pin以进行近距离查看，<em class="kv">保存</em>是指将Pin保存到板上，<em class="kv">点击</em>是指点击Pin以访问链接的网站，<em class="kv">长按</em>是指用户长时间不在现场的点击。以前，我们将参与度预测视为二元分类任务，其中没有参与度的印象是负面的，而有任何参与度的印象是正面的。然后，我们根据每种参与类型的商业价值，在损失函数中选择一个重要性权重。例如，我们可以选择为长点击参与度设置较高的权重，因为这表明用户可能已经在链接的网站上进行了购买。大小为n的一批样品的损失为</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kw"><img src="../Images/7e65aa4093e907f7a25d5f73213123ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EiNzp6gI_oZ06PoDeZGZfA.png"/></div></div></figure><p id="b708" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中ImportanceWeight(i)由样本<em class="kv"> i </em>的参与类型决定，y ⁽ᶦ⁾二进制是真正的二进制标签，对于参与的印象(<em class="kv">特写</em>、<em class="kv">保存</em>、<em class="kv">点击</em>或<em class="kv">长点击</em>)为1，否则为0，ŷ ⁽ᶦ⁾ <strong class="ig hi"> </strong>二进制是样本<em class="kv"> i </em>的预测分数。最后，我们使用历史用户、查询和候选人pin特征来训练深度神经网络(图2 ),以最大限度地减少定义的损失，并使用预测的分数来排名和推荐候选人。</p><p id="f90b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种简化的方法易于实现，并且与模型无关，但它会导致一系列问题:</p><ol class=""><li id="b1f7" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">通过将不同的参与类型组合成一个二元标签，我们丢失了信息。如果用户保存并长时间点击一个Pin，我们必须删除用户的一个操作，因为每个示例只能选择一种参与类型。一种替代方法是使用每个样本的不同参与度来复制训练数据。</li><li id="94d1" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">预测的分数是不可解释的。它告诉我们候选人有多“吸引人”,但它的确切含义取决于我们选择的重要性权重。</li><li id="5659" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">参与度预测的任务与商业价值相结合。如果我们想要尝试一组不同的重要性权重，我们需要重新训练模型，这对开发人员和实验速度是有害的。</li></ol><p id="9545" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决所有这些缺点，我们尝试了一种多任务学习模式。</p><h1 id="f41d" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">多任务学习模式</h1><p id="3e47" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">我们保留了二元分类器的特征和完全连接的层，但是改变了输出头层。多任务模型不是输出单个分数<em class="kv"> y⁽ᶦ⁾二进制</em>，而是输出四个分数<em class="kv"> ŷ⁽ᶦ⁾救球</em>、<em class="kv"> y⁽ᶦ⁾click </em>、<em class="kv"> y⁽ᶦ⁾long点击</em>，以及y ⁽ᶦ⁾ <em class="kv">特写</em>——每种交战类型一个(图2)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ll"><img src="../Images/780e1efffe2056f0e137ff5689d68fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*d8ACfc7_s5t_IlJk"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 2: Architecture of the binary classifier (left) and the multi-task learning model (right).</figcaption></figure><p id="9e5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失函数于是变成:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lm"><img src="../Images/c4fd07c7e30c8a7ccd860d353d9e3396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7cCWG8e8vkrCJm_Qq29KsA.png"/></div></div></figure><p id="b2af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<em class="kv"> y ⁽ᶦ⁾t </em>是每个啮合类型<em class="kv"> t </em>的标签，而<em class="kv"> TaskWeight(t) </em>是一个调谐参数，用于组合四个输出头的对数损耗。我们尝试了手动调整损失权重和使用同方差不确定性权重的思想自动学习它们[5][6]，但是增益是微妙的，因为四个任务彼此相似。因此，为了简单起见，我们最终对损失使用了相等的权重。</p><p id="3131" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">等式2中的损失函数与等式1中的损失函数之间的关键区别在于，我们不会丢失交战信息。四个输出头可以通过共享前面的层来相互借用知识，与为每种接合类型拟合一个模型相比，这也将缓解过拟合问题。</p><h1 id="b64f" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">校准和可解释性</h1><p id="28d9" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">既然每个输出头都是针对单一类型的参与训练的，那么预测的分数可以自然地解释为具有这种参与的概率。然而，当评估数据的标签分布与训练数据的标签分布不同时，我们仍然需要一个额外的步骤——称为校准——来将预测的分数转换为概率。这是AutoML DNN模型的一个常见问题[7]。在我们的例子中，这个问题主要是由训练数据中的负下采样引起的，可以通过一种简单而强大的方法来纠正[3]。假设我们只对负片的<em class="kv"> α </em>部分进行采样，同时保留所有的正片。校准后的分数为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/6a4e77e8c59e0be93910b762c39c8d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*6fg_ryT6MSaxhlWKZsTL7Q.png"/></div></figure><p id="0087" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图3中的校准图比较了不同头部的概率预测的校准情况。可以看出，<em class="kv"> p̂⁽ᶦ⁾t </em>与阳性的分数(即真实概率)几乎相同，这意味着该公式预测的分数是校准良好的。我们还在图例中显示了每个头的欧石南得分。该分数衡量校准，分数越低意味着校准越好。图3中的底部曲线显示了每个小容器中阳性样品的比例，按其校准分数分组<em class="kv"> p̂⁽ᶦ⁾t. </em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lo"><img src="../Images/ccf7f916d8047a1d49516019674212cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/0*MVwUgmtSs7QmoLyu"/></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 3: Calibration plot and score distribution of the calibrated scores from a multi-task learning model.</figcaption></figure><h1 id="3c48" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结果</h1><p id="8945" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">为了给候选人排名，我们仍然需要一个单一的分数。这里，我们将预测概率的线性组合视为效用得分:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lp"><img src="../Images/42cb946bfa8d90b102f077c3d04eeda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AA2X-g5PRlKDPhnDMK2psQ.png"/></div></div></figure><p id="6dc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然排名分数是在模型训练之后计算的，我们最终可以将业务价值从参与度预测中分离出来。这意味着，如果我们希望将预测转向特定的参与类型，我们不必重新训练模型来调整效用权重。</p><p id="6e6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与之前的二元分类器相比，转向多任务架构显著影响了相关产品的参与度指标，所有<strong class="ig hi">参与度类型的倾向和数量都有所增加。下面的表1总结了相对于相同神经网络的单个头部模型观察到的所有度量增益，其中使用重要性权重(等式1)来组合不同的正面约定。这些指标是通过在线A/B实验获得的。</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lq"><img src="../Images/84d3166195c7773ec131cb3a0190c706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TopB0R0EflQx5DVD0DW1fw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Table 1: Summary of the engagement gains for the multi-task model observed via an online A/B experiment.</figcaption></figure><p id="2ac0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这项工作开启了新的可能性，例如向模型添加更多的任务来预测pin被隐藏的概率，导致结帐，以及其他类型的参与。添加更多任务有助于提高模型的泛化能力，并防止过度拟合。当我们有消极的参与类型(如隐藏)时，我们也可以考虑使用更复杂的模型架构，如前面层的软共享[2]。这种新方法最有趣的问题之一是回答如何优化效用函数权重。我们将在下一节对此进行更深入的探讨。</p><h1 id="25f1" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">效用函数和贝叶斯优化</h1><p id="b531" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">正如我们之前解释的，我们利用预测概率的线性组合作为多任务学习模型的效用分数来对候选人进行排序。也就是说，通过尝试所有可能的组合，仍然很难挑选出最佳的效用权重。目标是在效用函数中优化每种参与类型的权重，使得球瓶将被排序的最终得分将球瓶从最有可能被参与到最不可能被参与排序。这是一个经典的超参数调优问题，贝叶斯优化已经被成功地用于解决。[4]</p><p id="5447" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用贝叶斯优化的主要目的是用最少的试验次数来解决上述问题。对于目标函数具有未知但平滑的形式，并且在整个参数空间上评估该函数是昂贵的情况，这是最有用的。在我们的例子中，假设我们想要最大化精确召回曲线下的长点击区域，这是效用权重wt上的未知函数f。贝叶斯优化时，<em class="kv"> f(w保存，w点击，w长点击，w特写)</em>建模为高斯过程(GPs)。假设我们先选取一些随机效用权重wt，对其进行评估，得到相应的目标值<em class="kv"> f(wt) </em>。然后，我们可以将模型更新为后验GPs，给出观察到的<em class="kv"> wt，f(wt) </em>对(参见图4中的图示)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/d1c0476a1309aae6b46c598b36752a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_IoKgprSExh7O44W"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 4: The prior, observed data, and posterior of the Gaussian Processes.</figcaption></figure><p id="ceed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">后验模型可用于预测未观察到的<em class="kv"> wt </em>的<em class="kv"> f </em>，并量化它们周围的不确定性(图4中的灰色区域)。预测和不确定性估计被组合以导出获取函数，该函数用于挑选下一个候选<em class="kv"> wt </em>进行评估。在重复这个过程更多步骤后，我们可以得到一个不确定性更小的更好的模型，并且能够选择最有希望的<em class="kv"> wt </em>，它可以最大化<em class="kv"> f. </em></p><p id="5385" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用Ax库[8]来实现效用权重选择的贝叶斯优化。除了GPs建模和候选选择，Ax库还支持向参数和次要目标添加约束。我们的优化问题被描述为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lr"><img src="../Images/bcfb4e84706c95fc1840fd0dec175f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*upDRrBDA7R2tz8yQFMVKAw.png"/></div></figure><p id="38e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设你有一个基线模型b，你试图用这种方法超越它。例如，它可以是最后一个生产模型，也可以是带有手工挑选的实用功能权重的模型。在这种情况下，<em class="kv"> bclick、</em> <strong class="ig hi"> <em class="kv"> </em> </strong> <em class="kv"> bsave、</em>和<em class="kv"> bclose-up </em>是基线模型的每个头部的性能。<em class="kv"> cclick、csave </em>和<em class="kv"> cclose-up </em>是我们用来调整次级物镜的参数。例如，设置<em class="kv"> csave </em> =0.9，<em class="kv"> cclick </em> =1，<em class="kv"> cclose-up </em> =1意味着我们愿意牺牲一点保存性能来换取更好的长点击性能，但我们不想损害点击或特写。S1到S5是我们为此优化定义的次要目标。S1将迫使权重增加到一个常数，因为如果我们将所有权重乘以相同的数，排名不会改变，这有助于可解释性(可以是任何常数)。S2划定了重量的范围。S3、S4、S5优化了点击、保存、特写的性能，我们分别表示为<em class="kv"> fclick、fsave、</em>和<em class="kv"> fclose-up、</em>。</p><p id="8b64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管我们做出了努力，但在在线A/B实验中，使用效用函数和使用贝叶斯优化选择的权重的多任务学习模型并没有在参与倾向或量方面胜过手动选择效用权重的模型。我们假设，我们没有通过贝叶斯优化实现最佳效用权重，因为我们只使用了离线优化，其中我们根据来自过去约定的样本生成和评估权重集。这项工作的下一个自然步骤是通过在线指标的贝叶斯优化来进一步优化效用权重，这将产生一组新的最优权重。总的来说，我们至少需要再做两次实验。第一个是收集建立贝叶斯模型所需的知识:我们生成效用权重的伪随机集合，并使用它们来设置治疗组。在从每个组收集指标并将其发送回Ax平台后，我们可以拟合贝叶斯模型并为下一个实验生成候选权重。然后，我们将等待第二个实验完成，并选择表现最好的一组作为生产候选，如果它的表现优于手工挑选的效用权重。</p><h1 id="ac73" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><p id="baa5" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">将相关产品排名模型的架构从单头模型发展为多任务神经网络提高了所有参与类型的参与度，同时也为我们提供了更多可解释的输出，这不仅有助于调试，也有助于模型性能分析。这项工作还允许我们继续探索和扩展模型，以随着用例的发展适应新的任务和新的架构。我们还了解到，离线贝叶斯优化并不总是优于其他权重选择方法。然而，这一过程让我们相信，当前的权重与我们对Pinners在购物表面发现的吸引人和鼓舞人心的东西的理解是一致的。我们将使用在线贝叶斯优化方法来跟进这项工作，该方法已被证明在解决类似问题时比离线方法成功得多。</p><p id="1ad8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鸣谢:作者要感谢以下人员的贡献:范林、赛晓、奥努尔·京格尔、奥拉维尔·古德蒙德松、陈晨和金·托伊。</p><p id="e530" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献</strong></p><p id="16b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]卡鲁阿纳，富有。<a class="ae ls" href="https://link.springer.com/content/pdf/10.1023/A:1007379606734.pdf" rel="noopener ugc nofollow" target="_blank">多任务学习。</a>《机器学习》28.1(1997):41–75。</p><p id="7029" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]赵，哲等.<a class="ae ls" href="https://daiwk.github.io/assets/youtube-multitask.pdf" rel="noopener ugc nofollow" target="_blank">推荐接下来看什么视频:多任务排序系统。</a><em class="kv">第13届ACM推荐系统会议论文集</em>。2019.</p><p id="324b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3] Dal Pozzolo，Andrea等.“<a class="ae ls" href="https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf" rel="noopener ugc nofollow" target="_blank">利用欠采样校准不平衡分类的概率。</a>“2015 IEEE计算智能系列研讨会。IEEE，2015。</p><p id="d04e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4] Snoek、Jasper、Hugo Larochelle和Ryan P. Adams。<a class="ae ls" href="https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf" rel="noopener ugc nofollow" target="_blank">实用贝叶斯优化机器学习算法。</a>“神经信息处理系统的进展”。2012.</p><p id="6001" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5]肯德尔、亚历克斯、亚林·加尔和罗伯托·奇波拉。<a class="ae ls" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank">使用不确定性衡量场景几何和语义损失的多任务学习。</a><em class="kv">IEEE计算机视觉与模式识别会议论文集</em>。2018.</p><p id="24fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[6]李贝尔、卢卡斯和马尔科·科尔纳。<a class="ae ls" href="https://arxiv.org/pdf/1805.06334.pdf" rel="noopener ugc nofollow" target="_blank">多任务学习中的辅助任务。</a><em class="kv">arXiv预印本arXiv:1805.06334 </em> (2018)。</p><p id="678f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[7]郭，c，普莱斯，g，孙，y和温伯格，K.Q..(2017).<a class="ae ls" href="http://proceedings.mlr.press/v70/guo17a.html" rel="noopener ugc nofollow" target="_blank">谈现代神经网络的校准</a>"<em class="kv">第34届机器学习国际会议论文集，PMLR，70:1321–1330</em></p><p id="73b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae ls" href="https://ax.dev/docs/bayesopt.html" rel="noopener ugc nofollow" target="_blank">https://ax.dev/docs/bayesopt.htm</a></p></div></div>    
</body>
</html>