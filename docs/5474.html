<html>
<head>
<title>Lessons From Alpha Zero (part 6) — Hyperparameter Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Alpha Zero的教训(第六部分)——超参数调谐</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/lessons-from-alpha-zero-part-6-hyperparameter-tuning-b1cfcbe4ca9a?source=collection_archive---------0-----------------------#2018-07-11">https://medium.com/oracledevs/lessons-from-alpha-zero-part-6-hyperparameter-tuning-b1cfcbe4ca9a?source=collection_archive---------0-----------------------#2018-07-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/96be482f38cbc6b85b220ec660bd1ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kbH-YXBGERvFJqvb"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@denisseleon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Denisse Leon</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="439e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是我们从实施AlphaZero中学到的经验系列的第六部分。查看 <a class="ae it" rel="noopener" href="/oracledevs/lessons-from-implementing-alphazero-7e36e9054191"> <em class="js">第一部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-connect-four-e4a0ae82af68"><em class="js">第二部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5"><em class="js">第三部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-4-improving-the-training-target-6efba2e71628"><em class="js">第四部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e"><em class="js">第五部分</em> </a> <em class="js">。</em></p><p id="0613" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本帖中，我们总结了使我们在Connect Four中获得最佳训练性能的配置和超参数选择。</p><h1 id="337b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">概观</h1><p id="929f" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">当我们实现AlphaZero时，我们花了一些时间才意识到该算法有多挑剔，因为即使当你远离所有的超参数时，它仍然可以学习，尽管很慢。此外，还有相当多的超参数，其中许多在AZ论文中没有得到充分解释。</p><p id="de98" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">多亏了我们的<a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e">性能优化努力</a>，我们能够比刚开始时更快地生成游戏。但它仍然需要许多代模型来创建一个近乎完美的连接4播放器。这是一个类似于我们原始配置的运行图。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kw"><img src="../Images/2c0da41abdd5ff05131f9b5fcd49f7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-y57w0omVQ0VSsVzbwdxQ.png"/></div></div></figure><p id="4417" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于大约150代模型，以每代12分钟计算，我们花了一天多的时间来执行上面的运行。</p><p id="ebfb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在上一篇文章中，我们研究了加快训练周期的方法。现在，我们将看看我们实际上减少获得专家算法所需的训练周期数的方法。</p><h1 id="1525" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">我们的改进</h1><p id="9bd0" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在深入了解我们每项改进的细节之前，让我们先来看一张总结了我们所有调整的图表:</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lb"><img src="../Images/9062c9b1e2707f3a1736721fec0588cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wL1D8sn6nQGwsJIo8nDc_g.png"/></div></div></figure><p id="1d2a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">没有单一的银弹，而是参数调整的组合导致了我们的训练加速。</p><h1 id="6f80" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">循环学习率</h1><p id="ecaa" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在AlphaZero中，作者用一个固定的学习速率训练他们的网络，并定期调整。尽管我们是从这种方法开始的，但我们最终还是实施了一个1周期学习率计划，如下文<a class="ae it" href="https://arxiv.org/abs/1803.09820" rel="noopener ugc nofollow" target="_blank">所述</a>。这背后的想法是，我们不是为训练选择一个单一的学习率，而是随着训练的进展明确地上下改变学习率。我们尝试了一些循环调度，比如带重启的余弦调度，但是发现1cycle是我们尝试过的最好的方法。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lc"><img src="../Images/6c76657a50879f3ffe7d7910c92ff26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s1JyknTBipuYaeK232bm1A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Cyclical Schedule with base learning rate of 0.02</figcaption></figure><p id="0119" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">虽然1个周期的调度通常应用于多个时期，但我们发现即使在单个时期内对多个批次进行调整时，它也是有帮助的。</p><p id="1715" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随着训练的进行，我们确实降低了我们的基础学习率，但发现我们不必像没有1个周期时那样精确或频繁。</p><h1 id="98d4" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">C-PUCT</h1><p id="0069" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在播出期间，MCTS使用PUCT，UCT的一种变体，来平衡探索与开发。关于算法如何工作的细节，请参见我们的<a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5#8e97">之前关于这个主题的帖子</a>。</p><p id="d885" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我们的实验中，我们尝试了各种C-PUCT值，但最终发现C在3-4范围内是一个最佳点。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lc"><img src="../Images/0bb69adaeca45695ee7609604fc1c6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeoQ_lenm-N9xtILH_AYMg.png"/></div></div></figure><h1 id="43d5" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">希腊字母的第一个字母</h1><p id="471f" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">Dirichlet噪声的使用是AlphaGo的一项有趣的创新，它在游戏播出期间将噪声添加到根节点的先验中。在推荐的配置中，这种噪声往往是尖锐的，产生的噪声集中了从根节点到偏离策略路径的一个小子集的探索，这种特性对于鼓励在具有高分支因子的游戏中集中探索可能特别有用。要了解更多关于狄利克雷噪声和阿尔法的信息，请查看我们的<a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5#9847">之前的帖子</a>。</p><p id="8b96" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是不同α值的学习曲线图。我们发现在我们的测试中，α值为1的表现最好。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ld"><img src="../Images/74994484e9f77711501794c2a6ca7afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-AajM0k40wKs0e8gV4_5A.png"/></div></div></figure><h1 id="a829" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">位置平均</h1><p id="21a4" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在我们实验的某个时候，我们开始跟踪训练集中出现的独特位置的数量，以此来监控AlphaZero的各种探索参数的效果。例如，当C=1时，我们会在生成的位置中观察到大量的冗余，这表明该算法以高频率选择相同的路径，并且可能没有进行足够的探索。在C=4时，重复位置的数量较低。一般来说，对于Connect Four，您的培训窗口中有大约30–50%的重复数据并不罕见。</p><p id="3d63" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当在您的训练窗口中发现重复的位置时，它们可能来自不同的模型代，这意味着它们相关的先验和值可能不同。通过向神经网络呈现这些具有不同目标的位置，我们有效地要求它为我们平均目标值。</p><p id="0976" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们没有要求我们的网络自行平均数据，而是尝试在将数据呈现给网络之前执行重复数据删除和平均。理论上，这减少了网络的工作量，因为它不需要自己学习这个平均值。此外，重复数据删除允许我们在每个培训周期向网络呈现更多独特的职位。</p><h1 id="dd46" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">额外的最后一层过滤器</h1><p id="6163" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在AlphaZero的论文中，神经网络获取游戏输入，然后通过20个残差卷积层运行它。这些剩余卷积层的输出然后被馈送到卷积策略和值头，它们分别具有2个和1个滤波器。</p><p id="2580" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们最初实现了该模型及其头部网络，如论文中所述。基于Leela Chess报告的发现，我们将头部网络中的过滤器数量增加到32个，这大大加快了训练速度。</p><p id="c152" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">添加额外的头部过滤器有意想不到的副作用，也减少了INT8训练期间的精度误差，这使我们可以在整个训练周期中使用TensorRT+INT8。更多关于这个<a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e#4ceb">这里</a>。</p><h1 id="caa8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">每一代多个时代</h1><p id="2be2" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在游戏生成之后，进行训练，这样我们的模型可以从最近生成的数据中学习，在下一个周期中创建更精细的游戏示例。我们发现，每个窗口样本使用2个时期的训练比单个时期的训练在学习方面提供了很好的提升，而不会使我们的同步训练周期长时间处于瓶颈状态。</p><h1 id="f627" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">慢速窗口</h1><p id="bbd3" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在AlphaZero中，作者使用了一个大小为50万场比赛的滑动窗口，从中统一采样他们的训练数据。在我们的第一个实现中，我们使用了由20代数据组成的滑动训练窗口，这相当于143360场比赛。在我们的实验中，我们注意到，在模型21中，训练错误会有很大的下降，评估性能会有明显的提升，就像可用数据量超过训练窗口大小，旧数据开始被删除一样。这似乎暗示着旧的、不太精确的数据可能会阻碍学习。</p><p id="2706" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了抵消这一点，我们实现了一个缓慢增加的采样窗口，窗口的大小开始时很小，然后随着模型代数的增加而慢慢增加。这允许我们在固定窗口大小之前快速淘汰非常早期的数据。我们从窗口大小为4开始，因此到了模型5，第一代(也是最差的)数据被淘汰。然后，我们每两个模型增加一个历史大小，直到我们在第35代达到20个模型的历史大小。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es le"><img src="../Images/4253740761c721223825fdcdeeed8f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04e2vNMUTPrXJHNpNmA7zw.png"/></div></div></figure><p id="49cf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">实现类似的另一种方法是改变我们的采样分布，尽管我们选择上述方法是因为它简单。</p><h1 id="c594" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">把它放在一起</h1><p id="c982" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">有了这些调整，我们能学得多快呢？几乎快了4倍:过去训练一个Connect Four玩家需要大约150代，现在我们可以训练大约40代。</p><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lf"><img src="../Images/5e1c64825c7c20a84abf220e30282856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLWvWcElT1YdiUiZwkMmQQ.png"/></div></div></figure><p id="0428" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对我们来说，这相当于从77个GPU小时减少到21个GPU小时。我们估计我们原来的训练，没有这里或者上一篇文章提到的改进(比如INT8，并行缓存等。)，将花费超过450个GPU小时。</p><p id="75ff" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过调整这些参数的练习，我们感受到了超参数调整在Alpha Zero中的重要性。希望我们能够将这些知识应用到更大的游戏中。</p></div></div>    
</body>
</html>