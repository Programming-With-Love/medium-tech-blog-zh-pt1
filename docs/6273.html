<html>
<head>
<title>Manas HNSW Realtime: Powering Realtime Embedding-Based Retrieval</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Manas HNSW实时:支持基于嵌入的实时检索</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/manas-hnsw-realtime-powering-realtime-embedding-based-retrieval-dc71dfd6afdd?source=collection_archive---------1-----------------------#2021-01-22">https://medium.com/pinterest-engineering/manas-hnsw-realtime-powering-realtime-embedding-based-retrieval-dc71dfd6afdd?source=collection_archive---------1-----------------------#2021-01-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7a64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tim Koh |软件工程师，核心产品服务基础架构<br/>吴仲强|软件工程师，核心产品服务基础架构<br/> Michael Mi |技术主管，核心产品服务基础架构</p><p id="5b7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们之前的<a class="ae jc" rel="noopener" href="/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f">博客文章</a>中，我们介绍了我们的内部搜索引擎——Manas——并分享了我们如何大规模提供基于术语的搜索。自推出以来，Manas已经发展成为Pinterest的主要候选生成器之一，服务于许多超出其最初目的的用例。</p><p id="41a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特别是，基于嵌入的检索是Pinterest的发现和推荐引擎的关键组成部分。Manas传统上支持通过基于倒排索引的位置敏感散列(LSH)的近似最近邻(ANN)搜索，这是基于搜索引擎的自然扩展。在发布了像<a class="ae jc" href="https://arxiv.org/abs/1603.09320" rel="noopener ugc nofollow" target="_blank">分层可导航小世界图(HNSW) </a>这样的最新技术后，我们在Manas中建立了一个灵活的基于嵌入的检索框架，这使我们可以轻松地采用新的人工神经网络技术。我们使用新框架将HNSW应用于我们的批量索引集群(索引延迟从几分钟到几天不等),与LSH相比，在服务成本和延迟减少方面节省了大量成本。</p><p id="c933" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们计划中的下一个里程碑是将HNSW发布到我们的实时流集群(秒级索引延迟)。大规模实时服务HNSW并不是一项简单的任务，部分原因是我们正在开拓新的领域，而不能依赖任何开源实现。</p><p id="a6bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博客中，我们将分享我们实时服务HNSW的旅程——我们解决这个问题的方法，我们面临的挑战，以及我们为生产该系统所做的一些优化。</p><h1 id="3b22" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">玛纳斯实时报</h1><p id="35ab" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">该项目的本质是为HNSW构建实时组件，并将它们集成到Manas Realtime中。为了更好地理解这些组件如何融入更大的画面，让我们简要地看一下Manas Realtime的高层架构。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/1a1a7662645c7b89b0c8a59c6777e61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/0*JDLWm5igIFGIaNBn"/></div></figure><p id="b122" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Manas Realtime本质上是一个<a class="ae jc" href="https://en.wikipedia.org/wiki/Log-structured_merge-tree" rel="noopener ugc nofollow" target="_blank"> LSM </a>引擎，它将随机IO写入转换为顺序IO写入。不是公开写端点，而是从Kafka中摄取写，允许我们简化系统并依赖Kafka作为WAL。有三种类型的写入，下面是它们的处理方式:</p><ol class=""><li id="7231" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb kt ku kv kw bi translated">新文档被写入内存实时段，最终被密封并刷新到磁盘上的静态段</li><li id="3720" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">删除使用内存中的标记应用，并在服务期间过滤掉</li><li id="af6c" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">通过删除旧文档并添加新文档来完成更新</li></ol><p id="465b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">后台压缩过程偶尔会组合各种静态段，以减少拥有过多段的服务开销。我们还依赖压缩过程通过从索引中删除文档来执行实际的删除。</p><p id="85f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从服务的角度来看，Manas Realtime与Manas Static没有太大的不同。我们对索引进行了抽象，因此存储层对整个检索过程是透明的。因此，随着HNSW已经为Manas Static发布，大多数服务组件已经存在。我们的工作主要是与Manas实时LSM索引组件集成。我们需要构建和优化两个核心组件，我们将在下面的小节中详细讨论:</p><ol class=""><li id="764e" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb kt ku kv kw bi translated">实时HNSW图</li><li id="aace" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">HNSW图形压缩</li></ol><h2 id="558c" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">实时HNSW图</h2><p id="2cfb" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">实时段是系统中唯一可变的组件，因此这方面的优化对于确保良好的并发读写性能至关重要。</p><p id="fedb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">HNSW索引本质上是一个多层稀疏图。我们选择了一个邻接表来表示这个图，其中的键是节点id，值是邻居id列表。我们从基于锁的版本开始，每个节点拥有一个锁，在更新邻居列表之前，这个锁由读取器和写入器持有。它很容易实现和推理。然而，由于锁争用，高系统CPU使用率使我们别无选择，只能使用<a class="ae jc" href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" rel="noopener ugc nofollow" target="_blank">无锁</a>技术。</p><h2 id="a57e" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">无锁实现</h2><p id="1a3a" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">让我们剖析一下我们如何以直观的方式处理写操作。HNSW的想法源于众所周知的<a class="ae jc" href="https://en.wikipedia.org/wiki/Skip_list" rel="noopener ugc nofollow" target="_blank">跳表</a>结构。因此，HNSW的无锁实现也类似于无锁跳转列表。一般来说，为了向图中添加新节点，每一层都涉及两个步骤，如下图所示。</p><ol class=""><li id="1df9" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb kt ku kv kw bi translated">在图层中查找新节点的邻居，并将新节点连接到所选邻居</li><li id="ec64" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">更新所选邻居以连接到新节点。</li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lq"><img src="../Images/e6b6c31b579b59c5d08b2b88684eb109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SAEZnNWjBUKq01Th"/></div></div></figure><p id="64fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，我们在HNSW图中从基础层到上层添加新节点，以避免新节点被选为上层中的入口点，但在下层中实际上没有为其建立连接，从而导致没有结果问题。</p><p id="73ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于删除，我们避免了将它们应用到图中的成本和复杂性。相反，我们用内存中的删除标记在图外处理它们，依靠过滤器在服务期间过滤掉删除的节点。</p><p id="4f12" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一些详细的优化值得简单提一下:</p><ul class=""><li id="dc31" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb lv ku kv kw bi translated"><strong class="ig hi">单写多读:</strong>为了简单起见，我们延续了使用单写多读并发模式的传统，使得代码简洁且易于推理。</li><li id="48cb" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb lv ku kv kw bi translated"><strong class="ig hi">预分配图形:</strong>由于实时图形通常很小，大小固定，我们为图形预分配内存，以避免调整大小带来的复杂性。</li><li id="5223" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb lv ku kv kw bi translated"><strong class="ig hi">定制邻居选择算法:</strong>利用标准邻居选择算法，对于更新邻居列表，有三种可能性:添加一个新邻居、减少邻居和替换一个邻居。当谈到无锁实现时，通过回填最近邻居来消除“减少邻居”的情况实际上简化了逻辑，使我们能够只使用原子运算符。</li><li id="405f" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb lv ku kv kw bi translated"><strong class="ig hi">`原子'变量:</strong> c++ std::原子变量实际上是昂贵的，即使使用发布-获取排序。相反，我们使用对齐内存来保证原子性，并使用一个全局原子变量作为内存屏障，使我们能够只显式地提交一个节点的所有更改一次。仍然有可能一些部分更新泄漏到读取线程，在短时间内损害全局连接。由于观察到没有明显的召回率下降，我们将其视为性能和质量之间的合理权衡。</li></ul><h1 id="61f9" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">HNSW图形压缩</h1><p id="2cbc" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们需要解决的主要压实问题是压实速度。如前所述，压缩是我们减少同时服务的数据段总数的方法。在最好的情况下，较长的压缩时间会导致较高的CPU使用率；最坏的情况是，系统停止接收，导致新的更新没有被反映和提供。</p><h2 id="e859" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">全新的合并</h2><p id="8715" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们对hnsw的压缩算法的第一次尝试是我们称之为干净的石板；本质上，该算法从所有输入段的未删除嵌入中构建一个全新的图。这个方法对于我们的一些用例来说太慢了，所以我们需要优化算法。</p><h2 id="4081" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">附加合并</h2><p id="2d12" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们的下一个策略是尽可能多地重用索引；我们从所有要压缩的段中选择最大的段，并将索引转换成我们可以重用的内存结构。然后，来自其他片段的剩余嵌入被添加到重用的图上。</p><p id="c618" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">剩下的问题是如何处理从重用片段中删除的嵌入。我们尝试了两种不同的方法:1)持续删除和重新选择邻居，以及2)将删除的嵌入与附近的活嵌入分组。虽然这两个选项都适合客户端，但是第一个选项在某些场景中太慢了。</p><h2 id="dc1c" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">持续删除</h2><p id="f65c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们需要维护图的小世界属性，简单地删除已删除的节点和它们的入/出边可能会破坏图中的连通性。为了解决这个问题，我们使用一个称为邻居重选的过程，其中节点可能连接到已删除节点的邻居以保持连接。</p><p id="549a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们发现，如果有大量被删除的节点，压缩时间实际上会比clean slate算法慢，这并不理想。</p><h2 id="c873" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">将已删除的节点与其最近的活动节点分组</h2><p id="29bb" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">有两个原因可以解释为什么持久化删除比使用清除算法要慢。</p><ul class=""><li id="720f" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb lv ku kv kw bi translated">我们在重复使用的段中回填节点及其邻居之间的距离，导致大量昂贵的距离计算。</li><li id="0405" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb lv ku kv kw bi translated">邻居重选过程可能非常昂贵，尤其是如果删除了许多节点。这是因为如果被删除节点的邻居也被删除，则需要更多的重选迭代。</li></ul><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="er es lw"><img src="../Images/83bfc94d04a8a462e9ae42b6490bc034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bl_z0pmnWeKsZPp4"/></div></div></figure><p id="d1af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的第二个优化是将删除的节点与附近的活动节点分组，从而避免昂贵的重选过程。原来的图和以前一样，但是现在多个节点映射到同一个嵌入。因为图没有改变，所以保持了连通性。此外，我们延迟计算节点与其邻居之间的距离，而不是主动回填它们，从而避免了不必要的距离计算。我们还需要在算法中添加一个去重复步骤，因为多个节点可以对应于同一个嵌入。</p><h1 id="62c1" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">在线召回监控</h1><p id="bdf4" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">到目前为止，我们一直关注如何构建和优化系统中的组件。但是生产一个系统还有一个非常重要的方面——质量验证。对于HNSW，召回率是我们用来验证索引质量的指标。它是通过将近似最近邻(ANN)搜索的结果与精确最近邻(KNN)搜索返回的理想结果进行比较来计算的。</p><p id="ca61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">监控召回也是特别重要的，因为一些优化可能涉及到更好的系统性能的质量折衷。我们需要跟踪这些质量下降，以确保我们仍然为我们的客户提供良好的结果。</p><p id="d52d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有了一组不可变的嵌入，计算给定查询的召回率就相对容易了。我们可以使用离线批处理作业预先计算KNN，并通过生成索引和向其发出查询来计算ANN。由于嵌入集是恒定的，KNN结果永远不会改变，我们可以调整索引构建参数来优化召回。</p><p id="b5d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在实时场景中，嵌入被不断地添加和删除，使得预先计算的KNN集不可用。为了解决这个问题，我们开发了一个在线召回工具；我们在服务集群中添加了计算人工神经网络和KNN结果的功能，这使我们能够计算给定时间点的召回率。</p><h1 id="05ea" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">下一步是什么</h1><p id="909f" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">对我们来说，在批量索引集群上启动HNSW，并通过实现HNSW的实时服务来拓展我们的能力，这是一段激动人心的旅程。但是HNSW只是我们基于嵌入的检索系统的第一步。</p><h2 id="9e79" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">效率和实验</h2><p id="412b" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们已经建立了一个系统，为生产基于嵌入的检索做繁重的工作，允许我们的ML工程师尝试新的嵌入或新的算法，而不必从头开始建立一个新的生产系统。我们将继续对系统进行迭代，改善服务性能、漏斗效率和简化实验。</p><h2 id="9699" class="lc je hh bd jf ld le lf jj lg lh li jn ip lj lk jr it ll lm jv ix ln lo jz lp bi translated">流式过滤</h2><p id="0cd3" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">当前的过滤方法是从HNSW图中预取K个ann，然后应用过滤器来获得我们的最终候选集。这不是非常有效的漏斗，并且很难计算出K的值会给我们提供我们需要的最终候选人的数量。我们计划以流式方式实现HNSW算法，其中可以在提取期间应用过滤器，并且流式提取仅在我们已经检索到我们需要的候选数量时终止。</p><p id="3f3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">敬请期待！</p><p id="23f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lx">鸣谢:作者感谢以下人员的贡献:、Roger Wang、谢海滨、盛诚、Fu、、Pihui Wei、Pong Eksombatchai、Andrew Zhai、和Vijai Mohan。</em></p></div></div>    
</body>
</html>