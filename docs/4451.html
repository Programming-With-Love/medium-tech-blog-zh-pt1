<html>
<head>
<title>Do-BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多伯特</h1>
<blockquote>原文：<a href="https://medium.com/google-developer-experts/do-bert-a846d7e4853c?source=collection_archive---------1-----------------------#2022-12-05">https://medium.com/google-developer-experts/do-bert-a846d7e4853c?source=collection_archive---------1-----------------------#2022-12-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/23685ffd480aad3ab9692c4fe5c37e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zb5BUfCo6qgWZEh7oii5eA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">(Image source: <a class="ae it" href="https://pixabay.com/illustrations/typewriter-words-write-meaning-6760585/" rel="noopener ugc nofollow" target="_blank">Pixabay</a>)</figcaption></figure><p id="0b9e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">BERT(来自变压器的双向编码器表示)已经席卷了NLP(自然语言处理)的世界。</p><p id="e48a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">语言-文本本质上是一系列单词。因此，像RNNs(递归神经网络)和LSTMs(长短期记忆)这样的传统方法曾经在语言建模(预测下一个单词)中无处不在。还记得，打短信？).但是他们不会记得稍远的以前的单词。然后出现了“注意力是你所需要的”，它的架构被称为“变压器”。</p><p id="4f1a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">BERT是一种基于变压器的机器学习技术，用于NLP预训练，由Jacob Devlin和他来自谷歌的同事在2018年开发。</p><p id="1465" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以下草图给出了BERT的概述:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/419a81721ffbece1b01471c5088e16b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtEzUKE4ZjBM3QcyxN0iwg.png"/></div></div></figure><h1 id="ba1b" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">参考</h1><ul class=""><li id="02df" class="kv kw hh iw b ix kx jb ky jf kz jj la jn lb jr lc ld le lf bi translated">“变压器:一种用于语言理解的新型神经网络架构”——谷歌人工智能博客(<a class="ae it" href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener ugc nofollow" target="_blank">链接</a>)</li><li id="21f3" class="kv kw hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">“第一次使用BERT的视觉指南”——杰伊·阿拉玛(<a class="ae it" href="https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/" rel="noopener ugc nofollow" target="_blank">链接</a>)</li><li id="2b89" class="kv kw hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">“插图中的伯特、埃尔莫等人(NLP如何破解迁移学习)”—杰伊·阿拉玛(<a class="ae it" href="https://jalammar.github.io/illustrated-bert/" rel="noopener ugc nofollow" target="_blank">链接</a>)</li><li id="5368" class="kv kw hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">“图解变形金刚”——杰伊·阿拉玛(<a class="ae it" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">链接</a>)</li><li id="2ed5" class="kv kw hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">“用草图简单地解释伯特”——Rahul Agarwal(<a class="ae it" href="https://mlwhiz.medium.com/explaining-bert-simply-using-sketches-ba30f6f0c8cb" rel="noopener">link</a>)</li><li id="ecd3" class="kv kw hh iw b ix lg jb lh jf li jj lj jn lk jr lc ld le lf bi translated">“注意力是你所需要的”——Ashish vas Wani等人</li></ul><p id="9620" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ll">最初发布于</em><a class="ae it" href="https://www.linkedin.com/pulse/do-bert-yogesh-kulkarni/" rel="noopener ugc nofollow" target="_blank"><em class="ll">LinkedIn</em></a></p></div></div>    
</body>
</html>