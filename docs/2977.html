<html>
<head>
<title>A Step By Step Guide To Implement Naive Bayes In R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在R中实现朴素贝叶斯的逐步指南</h1>
<blockquote>原文：<a href="https://medium.com/edureka/naive-bayes-in-r-37ca73f3e85c?source=collection_archive---------2-----------------------#2019-04-22">https://medium.com/edureka/naive-bayes-in-r-37ca73f3e85c?source=collection_archive---------2-----------------------#2019-04-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/b14fc7ba3a36aa18bff7b6093aafe4f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*tzsOWYCsIsQfSWHH-dleyQ.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Naive Bayes in R -Edureka</figcaption></figure><p id="a94b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">机器学习已经成为市场上最受欢迎的技能。了解各种机器学习算法及其工作原理是非常重要的。在这篇关于R中的朴素贝叶斯的文章中，我打算帮助您了解朴素贝叶斯是如何工作的，以及如何使用R语言实现它。</p><p id="335b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本文涵盖了以下主题:</p><ol class=""><li id="4e37" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">什么是朴素贝叶斯？</li><li id="43db" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">朴素贝叶斯背后的数学</li><li id="6351" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">朴素贝叶斯算法的贝叶斯定理</li><li id="2a14" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">朴素贝叶斯是如何工作的？</li><li id="ecb1" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">朴素贝叶斯在R中的实际实现</li></ol><h1 id="c81b" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">什么是朴素贝叶斯？</h1><p id="f0d9" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated"><em class="le">朴素贝叶斯是一种基于贝叶斯定理的监督机器学习算法，用于通过遵循概率方法来解决分类问题。它基于这样的想法，即在一个</em> <a class="ae lf" href="https://www.edureka.co/blog/what-is-machine-learning?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=naive-bayes-in-r" rel="noopener ugc nofollow" target="_blank"> <em class="le">机器学习</em> </a> <em class="le">模型中的预测变量是相互独立的。这意味着模型的结果取决于一组彼此无关的独立变量。</em></p><h2 id="f079" class="lg kc hh bd kd lh li lj kh lk ll lm kl ja ln lo kp je lp lq kt ji lr ls kx lt bi translated">但是为什么朴素贝叶斯被称为‘朴素’呢？</h2><p id="4d70" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">在现实世界的问题中，预测变量并不总是相互独立的，它们之间总是存在一些相关性。因为朴素贝叶斯认为每个预测变量都独立于模型中的任何其他变量，所以它被称为“朴素”。</p><p id="9dec" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们来理解朴素贝叶斯算法背后的逻辑。</p><h1 id="d5c6" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">朴素贝叶斯背后的数学</h1><p id="0f30" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">朴素贝叶斯背后的原理是贝叶斯定理，也称为贝叶斯规则。贝叶斯定理用于计算条件概率，条件概率只不过是基于过去事件信息的事件发生的概率。数学上，贝叶斯定理表示为:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/7f31d941f4d816451eb2e101b5ea2173.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*dwmrQWPyDUPszyV4.png"/></div></figure><p id="a6fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">上式中:</em> </strong></p><ul class=""><li id="7e9a" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">P(A|B):给定事件B，事件A发生的条件概率</li><li id="8713" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(A):事件A发生的概率</li><li id="f322" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(B):事件B发生的概率</li><li id="cac1" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(B|A):给定事件A，事件B发生的条件概率</li></ul><p id="5c60" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">形式上，贝叶斯定理的术语如下:</em> </strong></p><ul class=""><li id="f4ba" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">a被称为命题，B是证据</li><li id="ac56" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(A)代表命题的先验概率</li><li id="6250" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(B)代表证据的先验概率</li><li id="b8c1" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(A|B)称为后验概率</li><li id="5d9b" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">P(B|A)是可能性</li></ul><p id="dae0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，贝叶斯定理可以概括为:</p><p id="af19" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">后验=(可能性)。(命题先验概率)/证据先验概率</em> </strong></p><p id="06d0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">也可以按以下方式考虑:</p><p id="512f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给定一个假设H和证据E，贝叶斯定理说明，得到证据P(H)之前假设的概率和得到证据P(H|E)之后假设的概率之间的关系是:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/5fea9db577556ae8e0277bc9e34fbdc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*CFub2zettdIFdtfG99Z2Dg.png"/></div></figure><p id="3601" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你知道贝叶斯定理是什么了，让我们看看它是如何推导出来的。</p><h1 id="dde0" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">贝叶斯定理的推导</h1><p id="fc51" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">贝叶斯定理的主要目的是计算条件概率。贝叶斯规则可以从以下两个等式中导出:</p><p id="db34" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给定B，下面的等式表示A的条件概率:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/339d09f1b16587c2f00ceee9e4472ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*U8kdS2garTBvBXDc23SrYA.png"/></div></figure><p id="f9f7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给定A，下面的等式表示B的条件概率:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/f2fa7088656226d0eab763a568e83c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*3e3GkZYO4ywpFDq9oxoXPA.png"/></div></figure><p id="558d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，结合上述两个方程，我们得到贝叶斯定理:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/30605303e8d56396809f5501978f849d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*jeB7mVh7wsdAXN-3w1L10w.png"/></div></figure><h1 id="bbf4" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">朴素贝叶斯算法的贝叶斯定理</h1><p id="59ee" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">上述等式适用于单个预测变量，但是在现实应用中，存在多个预测变量，对于分类问题，存在多个输出类。类别可以表示为C1，C2，…，Ck，预测变量可以表示为向量x1，x2，…，xn。</p><p id="a7f0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">朴素贝叶斯算法的目标是用属于特定类别Ci的特征向量x1，x2，…，xn来测量事件的条件概率，</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/4814c75160ecdcbbb8a6d67501ab5e76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BWOua-acExlICLn3N3qH_w.png"/></div></div></figure><p id="c0ca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在计算上述等式时，我们得到:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/15d7d0fa275d681a474dd3b5cf87c111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQxEiNiCyORnb5aUUvJrTw.png"/></div></div></figure><p id="6b1b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，条件概率，即P(xj|xj+1，…，xn，Ci)总计为P(xj|Ci)，因为每个预测变量在朴素贝叶斯中是独立的。</p><p id="6f2e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后的等式归结为:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mf"><img src="../Images/93ff2582315d0e2688b09de3c74c563b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*07hUQrteTZ9Uttpu.png"/></div></div></figure><p id="ad8f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，<em class="le"> P(x1，x2，…，xn) </em>对于所有的类都是常数，因此我们得到:</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/6711e7922aed23351182f69c37ef6e0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTI7FDqcU-0_Xtly2wyNSQ.png"/></div></div></figure><h1 id="4e87" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">朴素贝叶斯是如何工作的？</h1><p id="abc4" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">为了更好地理解朴素贝叶斯的工作原理，我们来看一个例子。</p><p id="d6d4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑一个具有1500个观察值和以下输出类的数据集:</p><ul class=""><li id="d62d" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">猫</li><li id="d70e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">鹦鹉</li><li id="19b4" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">龟</li></ul><p id="cb7e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">预测变量本质上是分类的，即它们存储两个值，真或假:</p><ul class=""><li id="d79e" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">游泳</li><li id="84fc" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">翅膀</li><li id="c43b" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">绿色</li><li id="c230" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">锋利的牙齿</li></ul><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/b3836ee2e8f372c86946560326a0c68a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*agrdEcNFY6woWhJk9ZhEPQ.png"/></div></div></figure><p id="058a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从上表中，我们可以总结出:</p><p id="4047" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">类猫显示:</em> </strong></p><ul class=""><li id="53e3" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">500只猫中，有450只(90%)会游泳</li><li id="f884" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">0数量的猫有翅膀</li><li id="d98c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">0只猫是绿色的</li><li id="6749" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">所有500只猫都有锋利的牙齿</li></ul><p id="4495" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">类鹦鹉显示:</em> </strong></p><ul class=""><li id="073c" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">50只(10%)鹦鹉具有游泳的真正价值</li><li id="79c4" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">所有500只鹦鹉都有翅膀</li><li id="27e8" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">500只鹦鹉中有400只(80%)是绿色的</li><li id="5511" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">没有鹦鹉有锋利的牙齿</li></ul><p id="6177" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="le">甲鱼类显示:</em> </strong></p><ul class=""><li id="6182" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">所有的500只海龟都会游泳</li><li id="d1b2" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">0数量的乌龟有翅膀</li><li id="0956" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">500只海龟中，有100只(20%)是绿色的</li><li id="243f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">500只海龟中有50只(10%)有锋利的牙齿</li></ul><p id="735b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，有了可用的数据，让我们使用朴素贝叶斯分类器将下面的观察结果分类到其中一个输出类(猫、鹦鹉或海龟)中。</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/4897d8e70be787a0fa8eccde01a8ef96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgwI5beaPk6DuErd_Or6Uw.png"/></div></div></figure><p id="c3e7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里的目标是根据定义的预测变量(游泳、翅膀、绿色、锋利的牙齿)预测动物是猫、鹦鹉还是乌龟。</p><p id="e907" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">为了解决这个问题，我们将使用朴素贝叶斯方法，<br/><em class="le">P(H |多重证据)= P(C1 | H)* P(C2 | H)……* P(Cn | H)* P(H)/P(多重证据)</em> </strong></p><p id="a0b0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在观察中，变量Swim和Green为真，结果可以是任何一种动物(猫、鹦鹉、乌龟)。</p><p id="f997" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">检查动物是否为猫:</strong> <br/> <em class="le"> P(猫|游，绿色)= P(游|猫)* P(绿色|猫)* P(猫)/ P(游，绿色)</em><br/><em class="le">= 0.9 * 0.333/P(游，绿色)</em> <br/> <em class="le"> = 0 </em></p><p id="dacf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">检查动物是否为鹦鹉:</strong> <br/> <em class="le"> P(鹦鹉|游，绿)= P(游|鹦鹉)* P(绿|鹦鹉)* P(鹦鹉)/ P(游，绿)</em><br/><em class="le">= 0.1 * 0.80 * 0.333/P(游，绿)</em> <br/> <em class="le"> = 0.0264/ P(游，绿)</em></p><p id="0cac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">检查动物是否为龟:</strong> <br/> <em class="le"> P(龟|游，绿)= P(游|龟)* P(绿|龟)* P(龟)/ P(游，绿)</em> <br/> <em class="le"> = 1 * 0.2 * 0.333 / P(游，绿)</em> <br/> <em class="le"> = 0.0666/ P(游，绿)</em></p><p id="4561" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于上述所有计算，分母是相同的，即P(游泳，绿色)。P(Turtle| Swim，Green)的值大于P(Parrot| Swim，Green)，因此我们可以正确预测动物的类别为乌龟。</p><p id="e6d2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们看看如何使用R语言实现朴素贝叶斯。</p><h1 id="573a" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">朴素贝叶斯在R中的实际实现</h1><p id="9309" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated"><strong class="ir hi">问题陈述:</strong>研究一个糖尿病数据集，建立一个预测一个人是否患有糖尿病的机器学习模型。</p><p id="5a2b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">数据集描述:</strong>给定的数据集包含100个患者的观察结果以及他们的健康细节。这里有一个预测变量列表，可以帮助我们将患者分为糖尿病患者或正常患者:</p><ul class=""><li id="5501" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">怀孕:迄今为止的怀孕次数</li><li id="3f40" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">葡萄糖:血浆葡萄糖浓度</li><li id="810b" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">血压:舒张压(毫米汞柱)</li><li id="4f91" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">皮肤厚度:三头肌皮褶厚度(毫米)</li><li id="8d94" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">胰岛素:2小时血清胰岛素(μU/ml)</li><li id="508d" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">身体质量指数:体重指数(体重公斤/(身高米) )</li><li id="895e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">糖尿病谱系功能:糖尿病谱系功能</li><li id="63ff" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">年龄:年龄(岁)</li></ul><p id="bea0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">响应变量或输出变量为:</p><ul class=""><li id="d7b1" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">结果:类变量(0或1)</li></ul><p id="1bb7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">逻辑:</strong>构建朴素贝叶斯模型，通过研究患者的医疗记录(如血糖水平、年龄、身体质量指数等)将患者分类为糖尿病患者或正常患者。</p><p id="0827" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你知道了这个演示的目的，让我们开动脑筋，开始编码吧。对于这个演示，我将使用R语言来构建模型。</p><p id="600e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们开始吧。</p><p id="36cc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第一步:</strong> <em class="le">安装并加载所需的包</em></p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="74a6" class="lg kc hh mi b fi mm mn l mo mp">#Loading required packages<br/>install.packages('tidyverse')<br/>library(tidyverse)<br/>install.packages('ggplot2')<br/>library(ggplot2)<br/>install.packages('caret')<br/>library(caret)<br/>install.packages('caretEnsemble')<br/>library(caretEnsemble)<br/>install.packages('psych')<br/>library(psych)<br/>install.packages('Amelia')<br/>library(Amelia)<br/>install.packages('mice')<br/>library(mice)<br/>install.packages('GGally')<br/>library(GGally)<br/>install.packages('rpart')<br/>library(rpart)<br/>install.packages('randomForest')<br/>library(randomForest)</span></pre><p id="646e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第二步:</strong> <em class="le">导入数据集</em></p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="0200" class="lg kc hh mi b fi mm mn l mo mp">#Reading data into R<br/>data&lt;- read.csv("/Users/Zulaikha_Geer/Desktop/NaiveBayesData/diabetes.csv")</span></pre><p id="b624" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我们研究数据集之前，让我们将输出变量(“结果”)转换成分类变量。这是必要的，因为我们的输出将是两个类的形式，真或假。其中true表示患者患有糖尿病，false表示患者没有糖尿病。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="780a" class="lg kc hh mi b fi mm mn l mo mp">#Setting outcome variables as categorical data$Outcome &lt;- factor(data$Outcome, levels = c(0,1), labels = c("False", "True"))</span></pre><p id="e8d0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第三步:</strong> <em class="le">学习数据集</em></p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="88f9" class="lg kc hh mi b fi mm mn l mo mp">#Studying the structure of the data <br/>str(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mq"><img src="../Images/7f1796a4f59df71cec9a9cd73abec910.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8U3xTx0JFZGtBsWWpv6Jg.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="085b" class="lg kc hh mi b fi mm mn l mo mp">head(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/9c83598a44f3aa6c688e9eef9d2052b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QZHlLLYduA4KvDpEMXKiZg.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="a6c0" class="lg kc hh mi b fi mm mn l mo mp">describe(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/ec032c27031db4afb96632f87b86ba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pu3pbtS-gomSsNJdl_1LCg.png"/></div></div></figure><p id="e9e5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第四步:</strong> <em class="le">数据清理</em></p><p id="1067" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在分析数据集的结构时，我们可以看到葡萄糖、血压、皮肤厚度、胰岛素和身体质量指数的最小值都为零。这并不理想，因为没有人的葡萄糖、血压等的值为零。因此，这些值被视为缺失的观察值。</p><p id="3539" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在下面的代码片段中，我们将零值设置为NA:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="8923" class="lg kc hh mi b fi mm mn l mo mp">#Convert '0' values into NA<br/>data[, 2:7][data[, 2:7] == 0] &lt;- NA</span></pre><p id="6f3e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了检查我们现在有多少缺失的值，让我们将数据可视化:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="0884" class="lg kc hh mi b fi mm mn l mo mp">#visualize the missing data<br/>missmap(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/ca5cf7201088bdf59f9e9201dce452fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDrw7-w9p-rEn3EMUAGlyg.png"/></div></div></figure><p id="aff9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上图显示我们的数据集有大量缺失值，移除所有缺失值会使我们的数据集更小，因此，我们可以在r中使用<em class="le"> mice </em>包进行插补。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="4fc8" class="lg kc hh mi b fi mm mn l mo mp">#Use mice package to predict missing values<br/>mice_mod &lt;- mice(data[, c("Glucose","BloodPressure","SkinThickness","Insulin","BMI")], method='rf')<br/>mice_complete &lt;- complete(mice_mod)<br/> <br/>iter imp variable<br/>1 1 Glucose BloodPressure SkinThickness Insulin BMI<br/>1 2 Glucose BloodPressure SkinThickness Insulin BMI<br/>1 3 Glucose BloodPressure SkinThickness Insulin BMI<br/>1 4 Glucose BloodPressure SkinThickness Insulin BMI<br/>1 5 Glucose BloodPressure SkinThickness Insulin BMI<br/>2 1 Glucose BloodPressure SkinThickness Insulin BMI<br/>2 2 Glucose BloodPressure SkinThickness Insulin BMI<br/>2 3 Glucose BloodPressure SkinThickness Insulin BMI<br/>2 4 Glucose BloodPressure SkinThickness Insulin BMI<br/>2 5 Glucose BloodPressure SkinThickness Insulin BMI<br/> <br/>#Transfer the predicted missing values into the main data set<br/>data$Glucose &lt;- mice_complete$Glucose<br/>data$BloodPressure &lt;- mice_complete$BloodPressure<br/>data$SkinThickness &lt;- mice_complete$SkinThickness<br/>data$Insulin&lt;- mice_complete$Insulin<br/>data$BMI &lt;- mice_complete$BMI</span></pre><p id="7004" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了检查是否还有任何缺失值，让我们使用missmap图:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="7b42" class="lg kc hh mi b fi mm mn l mo mp">missmap(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mr"><img src="../Images/03021426ffe8cd79d464b12184ffad34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2fqy2LZEAIjI_jgMtbO5Ag.png"/></div></div></figure><p id="4e7f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">输出看起来不错，没有丢失数据。</p><p id="f38c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第五步:</strong> <em class="le">探索性数据分析</em></p><p id="9a10" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们进行一些可视化，以更好地了解每个变量，这一阶段对于理解每个预测变量的意义至关重要。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="2f1b" class="lg kc hh mi b fi mm mn l mo mp">#Data Visualization<br/>#Visual 1<br/>ggplot(data, aes(Age, colour = Outcome)) +<br/>geom_freqpoly(binwidth = 1) + labs(title=”Age Distribution by Outcome”)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/93877868132b647d9bc5aac0bf2b9edc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYem0H7yF-R_KbxaiE-y0Q.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="cf0b" class="lg kc hh mi b fi mm mn l mo mp">#visual 2<br/>c &lt;- ggplot(data, aes(x=Pregnancies, fill=Outcome, color=Outcome)) +<br/>geom_histogram(binwidth = 1) + labs(title="Pregnancy Distribution by Outcome")<br/>c + theme_bw()</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/04dac8709c5c5c358910fbf856061312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fpqWu35jAQUw-TAET7-5rg.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="69b9" class="lg kc hh mi b fi mm mn l mo mp">#visual 3<br/>P &lt;- ggplot(data, aes(x=BMI, fill=Outcome, color=Outcome)) +<br/>geom_histogram(binwidth = 1) + labs(title="BMI Distribution by Outcome")<br/>P + theme_bw()</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/cbc3dff551e2888f486e757ee4e65e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wTQZ8OVQCNpq4k-p04FFZg.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="4217" class="lg kc hh mi b fi mm mn l mo mp">#visual 4<br/>ggplot(data, aes(Glucose, colour = Outcome)) +<br/>geom_freqpoly(binwidth = 1) + labs(title="Glucose Distribution by Outcome")</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/c123c6db1963fbfc6a08e72fa4c67695.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jG5cf85sulOtG-6xiZ2hYw.png"/></div></div></figure><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="0a74" class="lg kc hh mi b fi mm mn l mo mp">#visual 5</span><span id="8572" class="lg kc hh mi b fi ms mn l mo mp">ggpairs(data)</span></pre><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mg"><img src="../Images/a781b3c8b9095a3d26b524e63816f71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3M5am3-rdHY3RGF7rCQ2SA.png"/></div></div></figure><p id="4a7b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第六步:</strong> <em class="le">数据建模</em></p><ul class=""><li id="da77" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lz jt ju jv bi translated">这个阶段从一个称为数据拼接的过程开始，其中数据集被分成两部分:</li><li id="d518" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">训练集:这部分数据集用于建立和训练机器学习模型。</li><li id="1a78" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lz jt ju jv bi translated">测试集:这部分数据集用于评估模型的效率。</li></ul><p id="5f9f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个阶段从一个称为数据拼接的过程开始，其中数据集被分成两部分:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="437f" class="lg kc hh mi b fi mm mn l mo mp">#Building a model<br/>#split data into training and test data sets<br/>indxTrain &lt;- createDataPartition(y = data$Outcome,p = 0.75,list = FALSE)<br/>training &lt;- data[indxTrain,]<br/>testing &lt;- data[-indxTrain,]<br/> <br/>#Check dimensions of the split<br/> <br/>&gt; prop.table(table(data$Outcome)) * 100<br/> <br/>False True<br/>65.10417 34.89583<br/> <br/>&gt; prop.table(table(training$Outcome)) * 100<br/> <br/>False True<br/>65.10417 34.89583<br/> <br/>&gt; prop.table(table(testing$Outcome)) * 100<br/> <br/>False True<br/>65.10417 34.89583</span></pre><p id="4d48" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了比较培训和测试阶段的结果，让我们创建单独的变量来存储响应变量的值:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="67fb" class="lg kc hh mi b fi mm mn l mo mp">#create objects x which holds the predictor variables and y which holds the response variables<br/>x = training[,-9]<br/>y = training$Outcome</span></pre><p id="4050" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在是时候加载包含朴素贝叶斯函数的e1071包了。这是r提供的内置函数。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="8f55" class="lg kc hh mi b fi mm mn l mo mp">library(e1071)</span></pre><p id="9a25" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">加载包后，以下代码片段将使用训练数据集创建朴素贝叶斯模型:</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="5331" class="lg kc hh mi b fi mm mn l mo mp">model = train(x,y,'nb',trControl=trainControl(method='cv',number=10))<br/> <br/>&gt; model<br/>Naive Bayes<br/> <br/>576 samples<br/>8 predictor<br/>2 classes: 'False', 'True'<br/> <br/>No pre-processing<br/>Resampling: Cross-Validated (10 fold)<br/>Summary of sample sizes: 518, 518, 519, 518, 519, 518, ...<br/>Resampling results across tuning parameters:<br/> <br/>usekernel Accuracy Kappa<br/>FALSE 0.7413793 0.4224519<br/>TRUE 0.7622505 0.4749285<br/> <br/>Tuning parameter 'fL' was held constant at a value of 0<br/>Tuning parameter 'adjust' was held<br/>constant at a value of 1<br/>Accuracy was used to select the optimal model using the largest value.<br/>The final values used for the model were fL = 0, usekernel = TRUE and adjust = 1.</span></pre><p id="6f33" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们通过使用朴素贝叶斯分类器创建了一个预测模型。</p><p id="7f64" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">第七步:</strong> <em class="le">模型评估</em></p><p id="479f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了检查模型的效率，我们现在将对模型运行测试数据集，之后我们将使用混淆矩阵来评估模型的准确性。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="6e00" class="lg kc hh mi b fi mm mn l mo mp">#Model Evaluation<br/>#Predict testing set<br/>Predict &lt;- predict(model,newdata = testing )<br/>#Get the confusion matrix to see accuracy value and other parameter values<br/> <br/>&gt; confusionMatrix(Predict, testing$Outcome )<br/>Confusion Matrix and Statistics<br/> <br/>Reference<br/>Prediction False True<br/>False 91 18<br/>True 34 49<br/> <br/>Accuracy : 0.7292<br/>95% CI : (0.6605, 0.7906)<br/>No Information Rate : 0.651<br/>P-Value [Acc &gt; NIR] : 0.01287<br/> <br/>Kappa : 0.4352<br/> <br/>Mcnemar's Test P-Value : 0.03751<br/> <br/>Sensitivity : 0.7280<br/>Specificity : 0.7313<br/>Pos Pred Value : 0.8349<br/>Neg Pred Value : 0.5904<br/>Prevalence : 0.6510<br/>Detection Rate : 0.4740<br/>Detection Prevalence : 0.5677<br/>Balanced Accuracy : 0.7297<br/> <br/>'Positive' Class : False</span></pre><p id="3bd6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最终输出显示，我们构建了一个朴素贝叶斯分类器，它可以预测一个人是否患有糖尿病，准确率约为73%。</p><pre class="lv lw lx ly fd mh mi mj mk aw ml bi"><span id="1920" class="lg kc hh mi b fi mm mn l mo mp">#Plot Variable performance<br/>X &lt;- varImp(model)<br/>plot(X)</span></pre><p id="b20e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了对演示进行总结，让我们绘制一个图表，显示每个预测变量是如何独立负责预测结果的。</p><figure class="lv lw lx ly fd ii er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mf"><img src="../Images/eacbc57f114c15ddd22c4957707bfc57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Af5mRjiQdxbrF8de.png"/></div></div></figure><p id="09eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从上图可以清楚地看出,“葡萄糖”是预测结果的最重要的变量。到此，我们来结束这篇文章。</p><p id="c7f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于Python、DevOps、Ethical Hacking等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="6e85" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释数据科学的各个方面。</p><blockquote class="mt mu mv"><p id="d397" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 1。</em> <a class="ae lf" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="f80e" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 2。</em> <a class="ae lf" rel="noopener" href="/edureka/math-and-statistics-for-data-science-1152e30cee73"> <em class="hh">数据科学的数学与统计</em> </a></p><p id="3dfe" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 3。</em><a class="ae lf" rel="noopener" href="/edureka/linear-regression-in-r-da3e42f16dd3"><em class="hh">R中的线性回归</em> </a></p><p id="10a3" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 4。</em> <a class="ae lf" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="4e72" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 5。</em><a class="ae lf" rel="noopener" href="/edureka/logistic-regression-in-r-2d08ac51cd4f"><em class="hh">R中的逻辑回归</em> </a></p><p id="c9ca" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 6。</em> <a class="ae lf" rel="noopener" href="/edureka/classification-algorithms-ba27044f28f1"> <em class="hh">分类算法</em> </a></p><p id="2fd6" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 7。</em> <a class="ae lf" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="54ae" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 8。</em> <a class="ae lf" rel="noopener" href="/edureka/a-complete-guide-on-decision-tree-algorithm-3245e269ece"> <em class="hh">决策树中的R </em> </a></p><p id="551f" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 9。</em><a class="ae lf" rel="noopener" href="/edureka/machine-learning-algorithms-29eea8b69a54"><em class="hh">5大机器学习算法</em> </a></p><p id="f85c" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 10。</em> <a class="ae lf" rel="noopener" href="/edureka/introduction-to-machine-learning-97973c43e776"> <em class="hh">机器学习入门</em> </a></p><p id="8fe6" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 11。</em> <a class="ae lf" rel="noopener" href="/edureka/statistics-and-probability-cf736d703703"> <em class="hh">统计与概率</em> </a></p><p id="5c9a" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 12。</em> <a class="ae lf" rel="noopener" href="/edureka/decision-trees-b00348e0ac89"> <em class="hh">如何创建一个完美的决策树？</em>T73】</a></p><p id="ff4a" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 13。</em> <a class="ae lf" rel="noopener" href="/edureka/data-scientists-myths-14acade1f6f7"> <em class="hh">关于数据科学家角色的10大误区</em> </a></p><p id="cf00" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 14。</em> <a class="ae lf" rel="noopener" href="/edureka/data-science-projects-b32f1328eed8"> <em class="hh">顶级数据科学项目</em> </a></p><p id="e310" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated">15。 <a class="ae lf" rel="noopener" href="/edureka/data-analyst-vs-data-engineer-vs-data-scientist-27aacdcaffa5"> <em class="hh">数据分析师vs数据工程师vs数据科学家</em> </a></p><p id="4c38" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated">16。 <a class="ae lf" rel="noopener" href="/edureka/types-of-artificial-intelligence-4c40a35f784"> <em class="hh">人工智能的种类</em> </a></p><p id="215c" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 17。</em><a class="ae lf" rel="noopener" href="/edureka/r-vs-python-48eb86b7b40f"><em class="hh">R vs Python</em></a></p><p id="a702" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 18。</em> <a class="ae lf" rel="noopener" href="/edureka/ai-vs-machine-learning-vs-deep-learning-1725e8b30b2e"> <em class="hh">人工智能vs机器学习vs深度学习</em> </a></p><p id="6baa" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated">19。 <a class="ae lf" rel="noopener" href="/edureka/machine-learning-projects-cb0130d0606f"> <em class="hh">机器学习项目</em> </a></p><p id="9f8d" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated">20。 <a class="ae lf" rel="noopener" href="/edureka/data-analyst-interview-questions-867756f37e3d"> <em class="hh">数据分析师面试问答</em> </a></p><p id="1444" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 21。</em> <a class="ae lf" rel="noopener" href="/edureka/data-science-and-machine-learning-for-non-programmers-c9366f4ac3fb"> <em class="hh">面向非程序员的数据科学和机器学习工具</em> </a></p><p id="f368" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 22。</em> <a class="ae lf" rel="noopener" href="/edureka/top-10-machine-learning-frameworks-72459e902ebb"> <em class="hh">十大机器学习框架</em> </a></p><p id="01aa" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 23。</em> <a class="ae lf" rel="noopener" href="/edureka/statistics-for-machine-learning-c8bc158bb3c8"> <em class="hh">用于机器学习的统计</em> </a></p><p id="25b5" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 24。</em> <a class="ae lf" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="ff5a" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 25。</em> <a class="ae lf" rel="noopener" href="/edureka/breadth-first-search-algorithm-17d2c72f0eaa"> <em class="hh">广度优先搜索算法</em> </a></p><p id="f46b" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 26。</em><a class="ae lf" rel="noopener" href="/edureka/linear-discriminant-analysis-88fa8ad59d0f"><em class="hh">R中的线性判别分析</em> </a></p><p id="2836" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 27。</em> <a class="ae lf" rel="noopener" href="/edureka/prerequisites-for-machine-learning-68430f467427"> <em class="hh">机器学习的先决条件</em> </a></p><p id="38d2" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 28。</em> <a class="ae lf" rel="noopener" href="/edureka/r-shiny-tutorial-47b050927bd2"> <em class="hh">互动WebApps使用R闪亮</em> </a></p><p id="ad0c" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 29。</em> <a class="ae lf" rel="noopener" href="/edureka/top-10-machine-learning-books-541f011d824e"> <em class="hh">机器学习十大书籍</em> </a></p><p id="9dfe" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh">三十。</em> <a class="ae lf" rel="noopener" href="/edureka/unsupervised-learning-40a82b0bac64"> <em class="hh">无监督学习</em> </a></p><p id="7f7e" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated"><em class="hh"> 31.1 </em> <a class="ae lf" rel="noopener" href="/edureka/10-best-books-data-science-9161f8e82aca"> <em class="hh"> 0最佳数据科学书籍</em> </a></p><p id="1539" class="ip iq le ir b is it iu iv iw ix iy iz mw jb jc jd mx jf jg jh my jj jk jl jm ha bi translated">32。 <a class="ae lf" rel="noopener" href="/edureka/supervised-learning-5a72987484d0"> <em class="hh">监督学习</em> </a></p></blockquote></div><div class="ab cl mz na go nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ha hb hc hd he"><p id="3769" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="le">原载于2019年4月22日</em><a class="ae lf" href="https://www.edureka.co/blog/naive-bayes-in-r/" rel="noopener ugc nofollow" target="_blank"><em class="le">https://www.edureka.co</em></a><em class="le">。</em></p></div></div>    
</body>
</html>