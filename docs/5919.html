<html>
<head>
<title>Benchmarking TensorFlow on OCI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OCI张量流基准测试</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/benchmarking-tensorflow-on-oci-70c781287b7d?source=collection_archive---------1-----------------------#2022-05-31">https://medium.com/oracledevs/benchmarking-tensorflow-on-oci-70c781287b7d?source=collection_archive---------1-----------------------#2022-05-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="5531" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="a70f" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">欢迎阅读本系列的第五篇也是最后一篇文章！我们将讨论TensorFlow相对于PyTorch的效率，这一点我们已经在上一篇文章中讨论过了。</p><h1 id="66e2" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">性能零点</h1><p id="6fbf" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由于我们上次已经使用了<strong class="je hi"> pytorch基准</strong>库，我们将使用我提到的另一个开源库，名为<strong class="je hi"> PerfZero </strong>。主要目的是执行TensorFlow测试来调试回归/分类性能。</p><p id="f882" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">PerfZero使得执行预定义的测试变得非常容易。理想情况下，我们希望使用以下三种方法之一:</p><ul class=""><li id="8883" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">在专用基础设施计算实例中使用PerfZero(使用Docker)</li><li id="832c" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">在任何计算机上本地使用PerfZero(带Docker)</li><li id="fc25" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">使用不带Docker的PerfZero</li></ul><p id="acd9" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">第一个选项具有最高的抽象性(因为我们将程序容器化，所有资源都被虚拟化了)，而最新的选项具有最低的抽象性。我们需要考虑在代码执行期间尽量避免中断、阻塞调用和其他类型的异常/中断，以获得尽可能低中断的准确基准。使用哪种方法由你决定。在本指南中，我将着重于重用我们在以前的文章(我们的DS笔记本会话)中已经使用过的资源来执行这些测试。我们将逐步安装PerfZero、Python、一个初始虚拟环境和必要的软件包，以开始在OCI上对TensorFlow进行基准测试。</p><h1 id="eedc" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">在OCI上创建实例和设置</h1><p id="5ce9" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在这里，我们可以选择做两件事:</p><ul class=""><li id="c579" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">从头开始使用计算实例，并安装我们开始所需的一切。</li><li id="2e17" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">使用数据科学笔记本会话，这将对我们有所帮助。幸运的是，数据科学笔记本会议的部署方式与计算实例类似。这意味着，通过使用像Terraform这样的CI/CD语言，计算实例(以及其中的一些东西)的部署已经自动化；因此，每次我们创建DS笔记本会话时，我们基本上都是在创建一个“超级英雄计算实例”。</li></ul><p id="1a28" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这导致底层计算实例安装了许多东西。这包括我们可以通过终端访问的默认conda环境:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/a40cbc28eee4af616de1b05e88453fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lqoiTbZ_BdNfPWtZ"/></div></div></figure><p id="9740" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">由AnaConda创建的conda允许我们互换使用几个Python环境，因此我们可以轻松地在TensorFlow和PyTorch环境之间切换(如上图所示)。</p><p id="d667" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">因为我们在本文中使用TensorFlow，所以让我们切换到那个环境:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="b1f8" class="ll if hh lh b fi lm ln l lo lp">conda activate /home/datascience/conda/tensorflow27_p37_cpu_v1</span></pre><p id="0b16" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">现在，让我们检查安装的Python版本，以及我们的TensorFlow版本:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="c3a3" class="ll if hh lh b fi lm ln l lo lp">python --version<br/>&gt;&gt;&gt; Python 3.7.12</span><span id="a4eb" class="ll if hh lh b fi lq ln l lo lp">pip freeze | grep tensor<br/>&gt;&gt;&gt; tensorboard==2.7.0<br/>&gt;&gt;&gt; tensorboard-data-server==0.6.1<br/>&gt;&gt;&gt; tensorboard-plugin-wit==1.8.0<br/>&gt;&gt;&gt; tensorflow==2.7.0<br/>&gt;&gt;&gt; tensorflow-estimator==2.7.0<br/>&gt;&gt;&gt; tensorflow-io-gcs-filesystem==0.22.0</span></pre><p id="6852" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">看起来我们需要的一切都是最新的。现在，让我们继续安装PerfZero。如果你在运行TensorFlow时遇到麻烦，请参考本文中的<a class="ae ka" href="https://github.com/jasperan/pytorch-tensorflow/blob/main/3_working_with_data_in_tensorflow.md" rel="noopener ugc nofollow" target="_blank">部分，了解OCI tensor flow的介绍以及如何开始。</a></p><p id="4f5e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们将存储库克隆到我们的机器中:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="671b" class="ll if hh lh b fi lm ln l lo lp">git clone <a class="ae ka" href="https://github.com/tensorflow/benchmarks.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/benchmarks.git</a></span></pre><p id="89ed" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们可以构建Docker映像，以便随时执行。但在此之前，我们需要在我们的机器上安装Docker。我使用了<a class="ae ka" href="https://github.com/docker/docker-install" rel="noopener ugc nofollow" target="_blank">这个非常方便的</a>库，它有一个根/非根用户脚本来自动安装和设置我们机器内部的Docker守护进程:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="86f6" class="ll if hh lh b fi lm ln l lo lp">curl -O https://github.com/docker/docker-install/blob/master/install.sh<br/># or<br/>curl -O https://github.com/docker/docker-install/blob/master/rootless-install.sh<br/># execute whichever script you decided, depends on your machine permissions<br/># NOTE: if using DS notebook session from OCI, you'll need the rootless install<br/># then execute the Docker image build<br/>python3 benchmarks/perfzero/lib/setup.py</span></pre><p id="6e72" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在建立我们的映像之后，我们可以通过将虚拟卷附加到数据目录中，以交互模式运行映像(我们附加到shell进程，可以像访问我们自己的操作系统一样访问机器)。</p><p id="fe7b" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">注意<a class="ae ka" href="https://github.com/tensorflow/models/tree/master/official" rel="noopener ugc nofollow" target="_blank">我们可以使用TensorFlow </a>的任何预训练模型(就像我们在上一篇文章中使用<a class="ae ka" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNet </a>一样)，以及第三方社区模型。当使用PerfZero时，所有这些模型都会产生一个结果。</p><p id="34b0" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">下面是需要遵循的命令:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="69c2" class="ll if hh lh b fi lm ln l lo lp">nvidia-docker run -it --rm -v $(pwd):/workspace -v /data:/data perfzero/tensorflow \<br/>python3 /workspace/benchmarks/perfzero/lib/benchmark.py --gcloud_key_file_url="" --git_repos="https://github.com/tensorflow/models.git;benchmark" --python_path=models --benchmark_methods=official.r1.resnet.estimator_benchmark.Resnet50EstimatorBenchmarkSynth.benchmark_graph_1_gpu --root_data_dir=/data</span></pre><p id="b358" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">请注意，您可能会在使用谷歌图书馆时遇到一些麻烦。我所做的是修改原始代码，忽略运行时抛出错误的<strong class="je hi"> gsutils </strong>和其他库。请注意，这些问题的根源是该库是由TensorFlow团队开发的，因此他们进行了集成，以自动部署在谷歌云实例中，而不是OCI。如果你想避免这些问题，你可以在文档中找到解决方案。不需要访问Google Cloud来获取任何数据的例子在任何情况下都适用。</p><p id="ec1e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们可以观察我们的模型性能，在本例中是一个CIFAR-10回归器，以及一些模型指标。这里有一个例子:</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="a590" class="ll if hh lh b fi lm ln l lo lp">{<br/>  "ml_framework_info": {                         # Summary of the machine learning framework<br/>    "version": "1.13.0-dev20190206",             # Short version. It is tf.__version__ for TensorFlow<br/>    "name": "tensorflow",                        # Machine learning framework name such as PyTorch<br/>    "build_label": "ml_framework_build_label",   # Specified by the flag --ml_framework_build_label<br/>    "build_version": "v1.12.0-7504-g9b32b5742b"  # Long version. It is tf.__git_version__ for TensorFlow<br/>  },<br/>  "execution_timestamp": 1550040322.8991697,     # Timestamp when the benchmark is executed<br/>  "execution_id": "2022-05-25-02-41-42-133155",  # A string that uniquely identify this benchmark execution</span><span id="844b" class="ll if hh lh b fi lq ln l lo lp">  "benchmark_info": {                            # Summary of the benchmark framework setup<br/>    "output_url": "gs://tf-performance/test-results/2022-05-25-02-41-42-133155/",     # Google storage url that contains the log file from this benchmark execution<br/>    "has_exception": false,<br/>    "site_package_info": {<br/>      "models": {<br/>        "branch": "benchmark",<br/>        "url": "https://github.com/tensorflow/models.git",<br/>        "hash": "f788046ca876a8820e05b0b48c1fc2e16b0955bc"<br/>      },<br/>      "benchmarks": {<br/>        "branch": "master",<br/>        "url": "https://github.com/tensorflow/benchmarks.git",<br/>        "hash": "af9e0ef36fc6867d9b63ebccc11f229375cd6a31"<br/>      }<br/>    },<br/>    "harness_name": "perfzero",<br/>    "harness_info": {<br/>      "url": "https://github.com/tensorflow/benchmarks.git",<br/>      "branch": "master",<br/>      "hash": "75d2991b88630dde10ef65aad8082a6d5cd8b5fc"<br/>    },<br/>    "execution_label": "execution_label"      # Specified by the flag --execution_label<br/>  },</span><span id="eeed" class="ll if hh lh b fi lq ln l lo lp">  "system_info": {                            # Summary of the resources in the system that is used to execute the benchmark<br/>    "system_name": "system_name",             # Specified by the flag --system_name<br/>    "accelerator_count": 2,                   # Number of GPUs in the system<br/>    "physical_cpu_count": 8,                  # Number of physical cpu cores in the system. Hyper thread CPUs are excluded.<br/>    "logical_cpu_count": 16,                  # Number of logical cpu cores in the system. Hyper thread CPUs are included.<br/>    "cpu_socket_count": 1,                    # Number of cpu socket in the system.<br/>    "platform_name": "platform_name",         # Specified by the flag --platform_name<br/>    "accelerator_model": "Tesla V100-SXM2-16GB",<br/>    "accelerator_driver_version": "410.48",<br/>    "cpu_model": "Intel(R) Xeon(R) CPU @ 2.20GHz"<br/>  },</span><span id="d4a5" class="ll if hh lh b fi lq ln l lo lp">  "process_info": {                           # Summary of the resources used by the process to execute the benchmark<br/>    "max_rss": 4269047808,                    # maximum physical memory in bytes used by the process<br/>    "max_vms": 39894450176,                   # maximum virtual memory in bytes used by the process<br/>    "max_cpu_percent": 771.1                  # CPU utilization as a percentage. See psutil.Process.cpu_percent() for more information<br/>  },</span><span id="4bc3" class="ll if hh lh b fi lq ln l lo lp">  "benchmark_result": {                       # Summary of the benchmark execution results. This is pretty much the same data structure defined in test_log.proto.<br/>                                              # Most values are read from test_log.proto which is written by tf.test.Benchmark.report_benchmark() defined in TensorFlow library.</span><span id="8ddf" class="ll if hh lh b fi lq ln l lo lp">    "metrics": [                              # This is derived from `extras` [test_log.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/test_log.proto)<br/>                                              # which is written by report_benchmark().<br/>                                              # If the EntryValue is double, then name is the extra's key and value is extra's double value.<br/>                                              # If the EntryValue is string, then name is the extra's key. The string value will be a json formated string whose keys<br/>                                              # include `value`, `succeeded` and `description`. Benchmark method can provide arbitrary metric key/value pairs here.<br/>      {<br/>        "name": "accuracy_top_5",<br/>        "value": 0.7558000087738037<br/>      },<br/>      {<br/>        "name": "accuracy_top_1",<br/>        "value": 0.2639999985694885<br/>      }<br/>    ],<br/>    "name": "official.resnet.estimator_cifar_benchmark.EstimatorCifar10BenchmarkTests.unit_test",    # Full path to the benchmark method, i.e. module_path.class_name.method_name<br/>    "succeeded": true,                        # True iff benchmark method execution finishes without exception and no metric in metrics show succeeded = false<br/>    "wall_time": 14.552583694458008           # The value is determined by tf.test.Benchmark.report_benchmark() called by the benchmark method. It is -1 if report_benchmark() is not called.<br/>  }<br/>}</span></pre><h1 id="9b38" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">测量OCI性能</h1><p id="a8df" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">既然我们已经评估了TensorFlow和PyTorch在OCI上的工作情况，我们应该把注意力集中在为什么OCI是开发您自己的NN项目(或AI/ML)的更好的解决方案上。</p><h1 id="840b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">虚拟CPU与OCPUs</h1><p id="a22d" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">每个云供应商经常将他们的处理单元称为虚拟CPU，因为从客户的角度来看，硬件是虚拟化的，我们可以“虚拟地”访问机器和相应的资源。此外，一些云供应商将vCPUs作为他们的性能衡量标准。一个vCPU相当于一个<a class="ae ka" href="https://www.geeksforgeeks.org/difference-between-process-and-thread/" rel="noopener ugc nofollow" target="_blank">线程</a>，它实际上运行我们的代码(不管是否是Python)并顺序执行它。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lr"><img src="../Images/9f7b684927212e135b98ca97bbfc4f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/0*8UZkipbBNH0sySHP"/></div></div></figure><p id="f7e6" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">问题是，许多云供应商并不谈论线程，而是谈论vCPUs。这对于理解OCI的优势是必不可少的:OCPU相当于CPU单元中的一个物理核心，但它有<strong class="je hi"> 2个线程</strong>而不是1个(这是由于英特尔开发的超线程技术才可能实现的，而且这很难实现，因为你必须在同一处理单元中协调两个线程的操作而不发生冲突)。因此，默认情况下，我们机器中收缩的线程数量将是其他厂商中可用线程数量的两倍<strong class="je hi">。这导致:</strong></p><ul class=""><li id="6cc5" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">更高的并行化机会</li><li id="7cc7" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">CPU负载降低</li><li id="2080" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">CPU调度程序工作得更多，但是根本没有达到导致瓶颈的程度。(如果发生这种情况，我们可以随时动态增加OCI的资源！)</li></ul><p id="3a09" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">如果代码不能并行化<a class="ae ka" href="https://github.com/jasperan/pytorch-tensorflow/blob/main/1_getting_started_with_pytorch_on_oci.md#why-we-need-pytorch" rel="noopener ugc nofollow" target="_blank">(阅读我们之前提到的关于GIL的内容)</a>，拥有额外的线程并不一定有益；然而，TensorFlow和PyTorch是考虑到并行化而实现的库，这对于我们、我们的基准和我们的模型来说实际上是很重要的。</p><p id="f01e" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">当然，这适用于其他云提供商网站中的非裸机实例，其中线程数可能高于1；可以推断，由于超线程是由英特尔创建和设计的，因此在我们的计算实例中使用非英特尔处理单元不会产生本节所述的结果。</p><h1 id="10de" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">成本和性能</h1><p id="4531" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">如果我们将OCI成本与AWS(可以说是当今最受欢迎的云提供商)进行比较，我们会发现不同领域存在巨大差异:</p><ul class=""><li id="c8f0" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">网络:在AWS每收取1美元，Oracle就收取0.26美元。</li><li id="0891" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">高性能计算(HPC):甲骨文便宜约44%</li><li id="878d" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">存储:Oracle本地固态硬盘的价格是其一半</li><li id="795e" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">RAM: Oracle的价格只有一半</li><li id="9342" class="kg kh hh je b jf kp jj kq jn kr jr ks jv kt jz kl km kn ko bi translated">冷藏(块存储):在IOPS的2000%的改进，成本的一半。</li></ul><p id="f86c" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这意味着我们之前在本系列文章中创建的模型，以及它们的度量标准，只能在OCI使用。</p><p id="1835" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">如果我们要在AWS中为我们的项目部署类似的硬件基础设施，我已经用<a class="ae ka" href="https://www.oracle.com/webfolder/workload-estimator/index.html" rel="noopener ugc nofollow" target="_blank">这个在线工具</a>生成了一个成本节约器，看看我们节省了多少(更不用说上面提到的其他原因了)。如果我们回想一下，最后两篇文章是以这些特征部署的:</p><ul class=""><li id="2da2" class="kg kh hh je b jf kb jj kc jn ki jr kj jv kk jz kl km kn ko bi translated">英特尔至强白金8167m @ 2.00 GHz ocpu(x16)</li></ul><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ls"><img src="../Images/920c0e8ea207dbea3ff58718eb2de242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9pcuqm2gVWjIxfcE"/></div></div></figure><p id="56a6" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这在OCI要花掉我们588美元，在T2每月要花掉1153美元(进入OCI时节省49%)。</p><p id="7360" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我希望这个系列文章对你来说和我写它时一样有趣。考虑订阅我们的社交媒体，关注未来的文章/酷项目、黑客马拉松和有丰厚福利的比赛！</p><p id="ef73" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">敬请关注…</p><h1 id="33ee" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">我如何开始学习OCI？</h1><p id="7244" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">请记住，你可以随时免费注册OCI！您的Oracle Cloud帐户提供多项始终免费的服务和300美元免费积分的免费试用，可用于所有符合条件的OCI服务，最长30天。这些永远免费的服务在<strong class="je hi">无限期</strong>内有效。免费试用服务可能会一直使用到您的300美元免费点数用完或30天到期，以先到者为准。你可以<a class="ae ka" href="https://signup.cloud.oracle.com/?language=en&amp;sourceType=:ow:de:te::::&amp;intcmp=:ow:de:te::::" rel="noopener ugc nofollow" target="_blank">在这里免费注册</a>。</p><h1 id="5ebc" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">加入对话！</h1><p id="8ab6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">如果你对Oracle开发人员在他们的自然环境中发生的事情感到好奇，请加入我们的公共休闲频道！我们不介意成为你的鱼缸🐠</p><h1 id="6d95" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">许可证</h1><p id="ea0e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由<a class="ae ka" href="https://www.linkedin.com/in/ignacio-g-martinez/" rel="noopener ugc nofollow" target="_blank">伊格纳西奥·吉尔勒莫·马丁内兹</a><a class="ae ka" href="https://github.com/jasperan" rel="noopener ugc nofollow" target="_blank">@贾斯珀兰</a>撰写，由<a class="ae ka" href="https://www.linkedin.com/in/dawsontech/" rel="noopener ugc nofollow" target="_blank">艾琳·道森</a>编辑</p><p id="4f2a" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">版权所有2022 Oracle和/或其附属公司。</p><p id="31f0" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">根据通用许可许可证(UPL)1.0版进行许可。</p><p id="6154" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">详见<a class="ae ka" href="https://github.com/oracle-devrel/leagueoflegends-optimizer/blob/main/LICENSE" rel="noopener ugc nofollow" target="_blank">许可证</a>。</p></div></div>    
</body>
</html>