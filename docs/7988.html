<html>
<head>
<title>Using Context to Improve Intent Classification in Walmart’s Shopping Assistant</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用上下文改进沃尔玛购物助手中的意图分类</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/using-context-to-improve-intent-classification-in-walmarts-shopping-assistant-28f62d40fd17?source=collection_archive---------4-----------------------#2021-03-30">https://medium.com/walmartglobaltech/using-context-to-improve-intent-classification-in-walmarts-shopping-assistant-28f62d40fd17?source=collection_archive---------4-----------------------#2021-03-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a995b1affd79c552acd45962851a5ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxesml8vh1yEP7bPHkdoFw.png"/></div></div></figure><p id="7b4d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi jn translated">最近，语音助手领域有了显著的<a class="ae jw" href="https://voicebot.ai/2019/02/14/juniper-estimates-3-25-billion-voice-assistants-are-in-use-today-google-has-about-30-of-them/" rel="noopener ugc nofollow" target="_blank">进步。因此，2019年，我们在</a><a class="ae jw" href="https://www.walmart.com/ideas/discover-online-grocery/google-assistant-voice-ordering-for-walmart-grocery-pickup-delivery/354497" rel="noopener ugc nofollow" target="_blank">谷歌助手</a>和<a class="ae jw" href="https://corporate.walmart.com/newsroom/2019/11/11/hey-siri-add-to-walmart-introducing-a-new-shortcut-for-online-grocery" rel="noopener ugc nofollow" target="_blank">苹果Siri </a>上为沃尔玛顾客推出了我们的语音购物助手。在沃尔玛，我们的使命是打造世界上最好的购物助手，帮助顾客节省时间和金钱。我们的愿景是通过访问商店和网站来帮助客户完成购买物品的繁琐任务。在当今快节奏的生活中，实现愿景变得更加重要。</p><p id="4e44" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">建立一个基于语音的助手是具有挑战性的。在零售/购物等领域，产品分类既广泛(有各种不同的产品类别)又深入(在一个类别中有各种不同类型的产品)，这尤其困难。构建基于语音的购物助手的另一个主要挑战是在不提供太多上下文的情况下准确理解对话中的话语。举个例子，</p><blockquote class="jx jy jz"><p id="3442" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">如果用户说<strong class="ir hi"> ' </strong> <strong class="ir hi">添加香蕉'</strong>，接着说<strong class="ir hi">'五个'</strong>，那么她打算将<strong class="ir hi">五个香蕉</strong>添加到她的购物车中。</p><p id="ad14" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">如果用户在与购物助理的对话开始时说<strong class="ir hi">‘five’</strong>，那么她的意图是<strong class="ir hi">未知的</strong>(即，在对话开始时它不代表任何电子商务动作)。</p><p id="0a66" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">如果用户说<strong class="ir hi">'</strong>'<strong class="ir hi">设置收件时间段'</strong>，然后说<strong class="ir hi">'五'</strong>，那么她打算设置上午5点或下午5点的收件时间段，这可能是最接近请求时间的时间段。</p></blockquote><p id="db6f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">处理这样的场景需要助手中的自然语言理解(NLU)组件在预测与话语相关联的意图时利用上下文(<em class="ka">先前在对话中发生了什么</em>)。在这项工作中，我们在沃尔玛的语音购物助手的NLU组件中集成了话语间上下文特征，以改进其意图分类。</p><h1 id="a7ac" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">语音助手的基本组成和NLU的作用</h1><p id="5464" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">语音助手有四个主要方面，即语音到文本、NLU、对话管理(DM)和文本到语音。<a class="ae jw" rel="noopener" href="/walmartglobaltech/joint-intent-classification-and-entity-recognition-for-conversational-commerce-35bf69195176"> NLU组件</a>识别用户话语中的意图和实体。对话管理器使用NLU组件的输出为用户准备合适的响应。</p><p id="e34b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当前可用的支持语音的购物助手中的NLU系统不关注话语间的上下文，因此上下文消歧的责任落在对话管理器身上。尽管可以在对话管理器中捕获少量这样的情况，但是对于大量依赖于上下文的话语来说，它变得难以扩展。例如，让我们再次考虑用户话语<strong class="ir hi">‘五’</strong>，在话语<strong class="ir hi">之后添加东西到购物车</strong>。那么对话管理器可以通过使用以下规则来预测其意图:</p><blockquote class="jx jy jz"><p id="c52e" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated"><strong class="ir hi">如果</strong>先前的意图是“<strong class="ir hi">添加到购物车”并且</strong>当前查询是一个<strong class="ir hi">整数</strong></p><p id="c32d" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated"><strong class="ir hi">然后</strong>当前意图是<strong class="ir hi">‘添加到购物车’</strong></p><p id="3e89" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated"><strong class="ir hi">否则</strong>当前意图为<strong class="ir hi">‘未知’</strong></p></blockquote><p id="9c24" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，如果不过度适应对话中使用的实际单词，就不能为许多其他查询创建这样的一般规则。举个例子，</p><blockquote class="jx jy jz"><p id="42fe" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">“有机请”(其中<strong class="ir hi">先前意图</strong>是<strong class="ir hi">“添加到购物车”</strong>，而<strong class="ir hi">当前意图</strong>是<strong class="ir hi">“过滤搜索结果”</strong>)以及</p><p id="cd70" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">请停止’(其中<strong class="ir hi">先前意图</strong>为<strong class="ir hi">‘加入购物车’</strong>，而<strong class="ir hi">当前意图</strong>为<strong class="ir hi">‘停止对话’</strong>)。</p></blockquote><p id="dad5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这项工作中，我们处理了NLU组件中的上下文，减少了对话管理器的上下文歧义消除负担。</p><h1 id="e32d" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">我们如何使用上下文？</h1><p id="edf8" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">我们使用两种不同的基于深度神经网络的架构来实现我们的方法。以下是体系结构的详细信息。</p><h2 id="123c" class="lh kf hh bd kg li lj lk kk ll lm ln ko ja lo lp ks je lq lr kw ji ls lt la lu bi translated">双LSTM和GRU</h2><p id="92ae" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">第一个架构的灵感来自于<a class="ae jw" href="http://giusepperizzo.github.io/publications/Mensio_Rizzo-HQA2018.pdf" rel="noopener ugc nofollow" target="_blank">基于RNN的多回合QA方法</a>中的工作。它有两个主要组成部分。首先，<a class="ae jw" rel="noopener" href="/@raghavaggarwal0089/bi-lstm-bc3d68da8bd0">双LSTM </a>编码器，其生成输入话语的矢量编码。向量表示用户话语的概括版本。它是从话语中单词的嵌入中产生的。第二个组件是一个<a class="ae jw" href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be" rel="noopener" target="_blank"> GRU </a>层，其输入由一个<a class="ae jw" rel="noopener" href="/@b.terryjack/introduction-to-deep-learning-feed-forward-neural-networks-ffnns-a-k-a-c688d83a309d">前馈层</a>关于由双LSTM编码器生成的嵌入的输出组成，连同先前话语意图的<a class="ae jw" rel="noopener" href="/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179">独热编码</a>。这一层的输出(在最后还包括一个<a class="ae jw" href="https://towardsdatascience.com/softmax-function-simplified-714068bf8156" rel="noopener" target="_blank"> Softmax </a>步骤)是当前输入话语的意图。下面的图1用图解法展示了该架构。</p><figure class="lw lx ly lz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/886c4769964e5831dbe342f525ce6521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJKpyrBJ_AoFl9afDOIxjQ.png"/></div></div><figcaption class="ma mb et er es mc md bd b be z dx">Figure 1: Deep Learning Architectures of Bi-LSTM and GRU Approach</figcaption></figure><p id="3a50" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面图1中的编码层是生成输入用户话语中单词的矢量表示的模块。有各种现成的选项可用于插入该层，包括<a class="ae jw" rel="noopener" href="/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1"> Word2Vec </a>、<a class="ae jw" rel="noopener" href="/analytics-vidhya/word-vectorization-using-glove-76919685ee0b"> Glove </a>、<a class="ae jw" href="https://allennlp.org/elmo" rel="noopener ugc nofollow" target="_blank"> Elmo </a>和<a class="ae jw" href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270" rel="noopener" target="_blank"> BERT </a>。在这项工作中，我们实验了BERT和Glove来检索最初的单词嵌入。</p><h2 id="0732" class="lh kf hh bd kg li lj lk kk ll lm ln ko ja lo lp ks je lq lr kw ji ls lt la lu bi translated"><strong class="ak">双LSTM和前馈层</strong></h2><p id="790c" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">类似于上面提到的双LSTM和GRU架构，第二种架构也有两个组件，双LSTM层，后面是前馈层。双LSTM层的输出与用户辅助对话中先前用户话语的<em class="ka">意图</em>的一键编码连接，并作为输入输入到前馈层，该前馈层在末端包括<a class="ae jw" href="https://towardsdatascience.com/softmax-function-simplified-714068bf8156" rel="noopener" target="_blank"> Softmax层</a>。前馈层的输出是输入话语最可能的意图。</p><figure class="lw lx ly lz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/3b9595ff9e44c821381133f826cc7e2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q8mO6UiN_PEZHuMCslrOEg.png"/></div></div><figcaption class="ma mb et er es mc md bd b be z dx">Deep Learning Architectures of Bi-LSTM and Feed-Forward Layer Approach</figcaption></figure><p id="a228" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与第一种架构一样，在这项工作中，我们使用BERT和Glove来检索嵌入编码层的初始单词。</p><h1 id="ec5a" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">效果如何？</h1><p id="8ba2" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">这项工作的主要目标是通过使用话语间上下文来改进沃尔玛购物助手的NLU组件中的意图分类。因此，我们在沃尔玛的语音购物助手的真实用户日志上测试了我们的方法。我们发现大约<strong class="ir hi"> 40%的用户助理交互需要上下文意图分类</strong>。我们还发现，<strong class="ir hi"> <em class="ka">添加商品到购物车</em> </strong>和<strong class="ir hi"> <em class="ka">在沃尔玛搜索商品</em> </strong>是两种最流行的用户辅助交互方式。大约98%的上下文交互都与这些意图有关。我们观察到<strong class="ir hi">在<strong class="ir hi">添加到购物车</strong>和<strong class="ir hi">搜索</strong>相关用户查询上，我们的性能最佳的上下文意图分类方法(基于双LSTM和GRU的实现，使用BERT语言模型)表现出色(上下文90%和总体87.68%)。</strong></p><blockquote class="jx jy jz"><p id="1ab3" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">在这项工作中，我们提高了语音助手对<strong class="ir hi"> <em class="hh">添加到购物车</em> </strong>查询的理解。它导致了一个改进的<a class="ae jw" href="https://databox.com/improve-add-to-cart-conversion-rate#head1" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="hh">添加到购物车</em> </strong> <strong class="ir hi">成功率</strong> </a>，一个决定一个电子商务应用程序性能的重要标准。</p></blockquote><p id="64c8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面的表1给出了我们的方法的两个实现的实验结果(插入了不同的语言模型)。关于实验和结果的更多细节可以在我们的标题为<a class="ae jw" href="https://www.aclweb.org/anthology/2020.ecnlp-1.6/" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="ka">的文章<a class="ae jw" href="https://sites.google.com/view/ecnlp/past-workshops/acl-2020?authuser=0" rel="noopener ugc nofollow" target="_blank"> ECNLP 3 </a>中获得</em></strong></a></p><figure class="lw lx ly lz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mf"><img src="../Images/0101e7dcabc0dc7719d73cc42abc3b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FBesF5V1yKVk56KjR_6LyQ.png"/></div></div></figure><h1 id="fdde" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">我们得出什么结论？</h1><p id="667f" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">正如假设的那样，实验结果表明</p><blockquote class="jx jy jz"><p id="e716" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">NLU模块中的上下文更新改进了意向分类。</p></blockquote><p id="ae8e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它还减轻了对话管理器基于意图的上下文歧义消除的负担。我们实验了我们方法的两种不同的实现，并通过使用真实的用户日志来比较它们。</p><h1 id="a789" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">下一步是什么？</h1><p id="0517" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">尽管在这项工作中，我们的主要焦点是意图的上下文消歧，但是实体也是依赖于上下文的。举个例子，</p><blockquote class="jx jy jz"><p id="db73" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated">在“添加香蕉”之后说出的“五”可以指数量五，而如果在“选择交货时间”之后说出，则可以指第五天的时间(上午/下午)。</p></blockquote><p id="ab46" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们目前正致力于使用上下文特征来消除实体之间的歧义，并改善实体标记。</p><h1 id="e282" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">参考资料和进一步阅读</h1><p id="8b6e" class="pw-post-body-paragraph ip iq hh ir b is lc iu iv iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm ha bi translated">我们的工作发表在第三届电子商务和自然语言处理研讨会(ECNLP) 的<a class="ae jw" href="https://www.aclweb.org/anthology/2020.ecnlp-1.6.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ka">会议录上。2020 </em></a>标题<strong class="ir hi"> <em class="ka">利用跨话语语境</em> </strong>改进电子商务语音助手中的意图分类</p><p id="bddd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jw" rel="noopener" href="/walmartglobaltech/joint-intent-classification-and-entity-recognition-for-conversational-commerce-35bf69195176">我们之前在联合意向-实体培训方面的工作</a></p><p id="5ad2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jw" rel="noopener" href="/walmartglobaltech/building-a-conversational-assistant-platform-for-voice-enabled-shopping-6d174cdc4131">我们购物助手之旅的开始</a></p><p id="8acf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jw" href="http://giusepperizzo.github.io/publications/Mensio_Rizzo-HQA2018.pdf" rel="noopener ugc nofollow" target="_blank">多轮问答:面向目标系统意图分类的RNN上下文方法</a></p></div></div>    
</body>
</html>