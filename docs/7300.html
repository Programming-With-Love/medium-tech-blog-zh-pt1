<html>
<head>
<title>Making AI Interpretable with Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用生成对抗网络使人工智能可解释</h1>
<blockquote>原文：<a href="https://medium.com/square-corner-blog/making-ai-interpretable-with-generative-adversarial-networks-766abc953edf?source=collection_archive---------0-----------------------#2018-04-04">https://medium.com/square-corner-blog/making-ai-interpretable-with-generative-adversarial-networks-766abc953edf?source=collection_archive---------0-----------------------#2018-04-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie"><p id="da95" class="if ig hh bd ih ii ij ik il im in io dx translated">注意，我们已经行动了！如果您想继续了解Square的最新技术内容，请访问我们的新家<a class="ae ip" href="https://developer.squareup.com/blog" rel="noopener ugc nofollow" target="_blank">https://developer.squareup.com/blog</a></p></blockquote><p id="6818" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm io ha bi translated"><em class="jn">作者:</em> <a class="jo jp ge" href="https://medium.com/u/7f4824c1a72d?source=post_page-----766abc953edf--------------------------------" rel="noopener" target="_blank"> <em class="jn">胡安</em> </a> | <a class="ae ip" href="http://twitter.com/damienrj" rel="noopener ugc nofollow" target="_blank"> @damienrj </a></p><p id="7e2d" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">在过去的几十年里，人工智能在技术、商业和科学方面取得了巨大的进步，并且这种进步今天仍在加速。我们日常生活中的很多体验都受到了AI和机器学习的影响。例如，音乐是由人工智能系统推荐给我们的。我们获得金融服务的资格是由信用评分机器学习模型驱动的。汽车正在迅速走向完全自主，许多量产车现在都配备了基于人工智能的驾驶辅助。甚至医疗诊断也依赖于复杂的统计算法来识别患者的医疗状况。刑事法院在量刑时也使用统计模型来估计累犯的风险。</p><p id="ec71" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">然而，一些表现最好的模型很难解释。这通常与算法的复杂性有关。虽然更简单的算法更容易解释，但与更不透明和复杂的算法相比，它们的性能有所欠缺。由于我们作为数据科学家，希望使用这些性能更好的复杂模型，因此我们有责任使这些模型决策更具可解释性，以便我们可以向合作伙伴和消费者解释模型预测，在我们得到错误预测的情况下诊断出了什么问题，并让消费者了解自动化决策背后的基本原理。</p><p id="e952" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">在Square，我们为我们的欺诈预防系统感到自豪，该系统严重依赖于机器学习模型来检测高风险和潜在的欺诈行为，以帮助我们防患于未然。在这篇文章中，我们分享了一个用于扩展复杂机器学习模型可解释性的框架。</p><h1 id="9aae" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">关于原因代码的更多信息</h1><p id="6ccc" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">如上所述，相对简单的模型往往有易于理解的解释。有标准的实践来检查模型决策并生成“原因代码”，即描述模型决策原因的语句。例如，线性模型的系数的值告诉我们每个因素在决策中的相对重要性。这种方法的缺点之一是，它假设了一个简单的模型架构，并假设能够从该模型架构中分离出一个因素的重要性。然而，当试图为更复杂的模型(例如随机森林)生成原因代码时，这些假设很少得到满足，在随机森林中，我们无法隔离某个特性在单个决策中的重要性。</p><p id="ed93" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">幸运的是，有一些方法已经被设计用来从更复杂的模型中产生个体预测的原因。其中一种方法包括<a class="ae ip" href="https://arxiv.org/abs/1602.04938" rel="noopener ugc nofollow" target="_blank">将局部简单模型拟合到模型决策边界</a>的近似区域，然后将标准解释技术应用于这些简单模型。然而，围绕单个决策拟合本地模型是一种相对昂贵的方法，尤其是当一个组织每天生成数百万或更多的决策时。</p><p id="617f" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">如果原因代码被认为是“需要改变以产生替代决策的事物”，那么处理原因代码的另一种方法是找到产生这些替代决策的输入的最小变化。例如，如果一个卖家的账户在一个模型确定他们的活动看起来非常可疑后被暂停，那么问题就变成了，“为了使<em class="jn">而不是</em>被暂停，同一个卖家看起来(关于模型输入信号)应该是什么样的？”如果我们能够做到这一点，那么我们就可以生成清晰的模型决策，甚至可以提供前瞻性的建议。</p><p id="7d6f" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">一个简单的方法是置换输入值，直到模型产生一个替代决策。然而，彼此独立地随机置换信号会产生不现实的、不可能的、甚至矛盾的结果。例如，如果两个信号实际上是相关的，那么独立地置换一个信号并在此基础上形成原因代码是没有意义的。简单地说，我们希望能够产生真实的扰动。</p><p id="0b94" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">为什么输入数据的扰动是真实的很重要？这里详细概述了<a class="ae ip" href="https://arxiv.org/abs/1412.6572" rel="noopener ugc nofollow" target="_blank">和</a>。本质上，攻击者或恶意用户可以非常容易地创建“对立的例子”来欺骗机器学习模型。例如，这是一张熊猫图像上像素值的随机扰动。在第一种情况下，模型正确地将图像识别为熊猫的图像。在第二种情况下，噪声被添加到像素中。我们人类可以分辨出它仍然是一张熊猫的照片，但是模型现在确信它是一只长臂猿。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ky"><img src="../Images/c201f22623514159c68293a3edbf77a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/0*wB6gMZ403StIacrJ."/></div><figcaption class="lg lh et er es li lj bd b be z dx">Example of how a seemingly random permutation can produce a false prediction with very high confidence</figcaption></figure><p id="9da1" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">那么，一个模型如何能够抵抗这类错误呢？特别是如果我们想要使用基于特征排列的原因代码模型，我们的模型如何能够评估合成最近邻的“合理性”？我们想尝试的一个现有框架是生成对抗网络(GAN)。</p><h1 id="e0ac" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">为什么甘斯可能有用</h1><p id="81b7" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">有了GANs，我们应该能够生成看起来像是来自真实的方形卖家分布的合成卖家。这个框架如下操作:生成器模型从随机噪声中创建假数据。训练鉴别器以确定该示例是生成的还是真实的。并且反馈周期允许通过鉴别器的训练来更新发生器权重。换句话说，鉴别器对虚假数据变得越来越健壮，因为生成器被更新以产生越来越多的真实例子。最终，你拥有训练有素的模型来区分真实数据和虚假数据，并生成真实的新数据。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/895375dd61fe01a0582bad12db566193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lhYEmrsW9kqgB8nfIb9GJQ.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Generative Adversarial Network Framework</figcaption></figure><p id="cc75" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">【甘框架】。生成器试图从随机噪声中创建数据。鉴别器试图区分生成的数据和真实的数据。两个网络的权重通过该过程被更新，使得生成器在欺骗鉴别器方面变得更好，并且鉴别器在识别虚假数据方面变得更好。</p><p id="4035" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">在训练我们的模型时，我们发现演员-评论家框架最适合从我们的训练集中生成合成数据。起初，我们使用二进制生成器-鉴别器方法进行训练，但发现我们的GAN遭受了<a class="ae ip" href="https://www.toptal.com/machine-learning/generative-adversarial-networks" rel="noopener ugc nofollow" target="_blank">、【模式崩溃】</a>，这是一种生成器学习在小范围的可能值内生成数据的现象，特别是在鉴别器无法准确地将数据分类为真实或合成的值范围内。行动者-批评家框架通过评估真实数据和合成数据之间的瓦瑟斯坦距离而不是评估二元交叉熵来解决这个问题。</p><h1 id="26be" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">方法</h1><h2 id="6e23" class="lp jw hh bd jx lq lr ls kb lt lu lv kf jb lw lx kj jf ly lz kn jj ma mb kr mc bi translated">数据收集/人口</h2><p id="e3b3" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">我们将我们的框架应用于与欺诈风险相关的建模人群。具体来说，我们想看看我们是否可以使用GANs为模型决策提供理由，以审查被标记为潜在欺诈的帐户。</p><h2 id="3111" class="lp jw hh bd jx lq lr ls kb lt lu lv kf jb lw lx kj jf ly lz kn jj ma mb kr mc bi translated">建模/原因代码框架</h2><p id="ba7b" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">框架:</p><ol class=""><li id="7b79" class="md me hh is b it jq ix jr jb mf jf mg jj mh io mi mj mk ml bi translated">开发一个<em class="jn">生成器</em>函数，从随机噪声中创建“合成”卖家。</li><li id="e69f" class="md me hh is b it mm ix mn jb mo jf mp jj mq io mi mj mk ml bi translated">训练一个<em class="jn">鉴别器</em>来区分合成卖家和真实卖家。</li><li id="e7ae" class="md me hh is b it mm ix mn jb mo jf mp jj mq io mi mj mk ml bi translated">使用<em class="jn">鉴别器</em>的鉴别学习来迭代改进<em class="jn">发生器</em>，同时也改进鉴别器，该鉴别器学习对越来越困难的观察值进行分类。最终，这产生了一个训练有素的生成器，能够生成“现实”的合成卖家。</li><li id="8ccf" class="md me hh is b it mm ix mn jb mo jf mp jj mq io mi mj mk ml bi translated">使用训练有素的发电机创造一个合成卖家的大商店。为了生成原因代码，与合成卖家进行比较:对于一个阈值，<em class="jn"> t </em>，和一个卖家<strong class="is hi"> <em class="jn"> m </em> </strong>，如果<strong class="is hi"> <em class="jn"> m </em> </strong>的模型分数&gt; = <em class="jn"> t </em>，那么哪个合成卖家，<strong class="is hi"> <em class="jn"> s </em> </strong>，其模型分数&lt; <em class="jn"> t </em>是与<strong class="is hi"> <em class="jn"> m最近的邻居<strong class="is hi"> <em class="jn"> s </em> </strong>和<strong class="is hi"> <em class="jn"> m </em> </strong>的区别是模型决策的原因码集合。</em></strong></li></ol><p id="81e9" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">这种方法的优点之一是相对容易实现。由于GAN模型训练和合成销售者的生成都是离线进行的，所以合成销售者可以存储在可从生产环境访问的数据库中。</p><h1 id="b35b" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">评估合成卖家</h1><p id="b458" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">不同的监督模型通常有明确的评估指标。对于GAN来说，仅仅基于分类器性能进行评估有点棘手，因为我们正在训练两个具有竞争目标的耦合模型。我们选择评估模型的一种方法是将合成数据的相关矩阵与真实数据的相关矩阵进行比较。作为参考，这是真实数据的相关矩阵。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mr"><img src="../Images/f0da4ca8f9d50fe3d9f9a54d778b4b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*lVwbJb7gZLjIJfwsCVK83Q.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation Matrix of Real Data</strong></figcaption></figure><p id="027b" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">由于发生器首先通过产生基本上随机的数据开始，这种随机性通过相关矩阵表现出来。这是在训练开始之前生成的一些数据的相关性。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ms"><img src="../Images/b4cbdc931dc3982d4066f4e2f9dad0b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*8Q5unUat05-4pJ3qclngLw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 0 epochs</strong></figcaption></figure><p id="ab96" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">随着模型的训练，相关矩阵开始采用非随机形式。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mt"><img src="../Images/3516af5c4f064df3483f3edec4afaa73.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*L41I0hPVgw1jLdpTElPQ8Q.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 400 epochs</strong></figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mr"><img src="../Images/e217c4e58469d4397582d2c4633c3a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*cbVsfcw3ljo4nVABzMhI6Q.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 500 epochs</strong></figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mr"><img src="../Images/aad728fb935c8e111d20ee21e7e652bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*PD8IMVfenCxSrbycBvF5iw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 800 epochs</strong></figcaption></figure><p id="d116" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">在某一点上，模型超调并开始产生相关性太强的输出。如果我们将此图表与原始数据的相关矩阵进行比较，我们会发现生成的数据比真实数据具有更多更强的相关性。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ms"><img src="../Images/c951465881df2e8dcec218ef4af32de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*_Q84fSn1aG3ZwsVlwQHitw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 1000 epochs</strong></figcaption></figure><p id="4f17" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">最终，我们会得到一个与真实数据非常相似的相关矩阵，读者可以通过与真实数据的原始相关矩阵进行比较来查看。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ms"><img src="../Images/ade52b63dd81b467942b24ef784acd60.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*Qgtpt-59WS6iQf7CEqHM0g.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Correlation matrix at 2000 epochs</strong></figcaption></figure><p id="e9f3" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">大约2000个时期后，我们发现我们的模型性能稳定下来，这意味着合成数据的相关矩阵从一个时期到下一个时期没有太大变化。</p><p id="da77" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">当并排比较真实数据和生成数据的单变量分布时，我们看到生成器的输出值始终落在合理的范围内。这通过并排绘制真实和合成卖家的分布(使用核密度估计)来显示。读者可以看到，合成数据没有将<em class="jn">精确地映射到真实数据，但它做得很好。不出所料，合成数据遵循更平滑、更高斯的分布，但有更多的异常值。值得注意的一件有趣的事情是，我们降低了模式崩溃的幅度，这是一种导致在狭窄的集中带内生成合成数据的现象。这是因为我们使用了演员-评论家框架。</em></p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mu"><img src="../Images/bb75f28fed9a29476ea9b8e210214088.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/0*L2bE6kj5kX87DVql."/></div></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mv"><img src="../Images/4cc4a6a7abb3a754e0c6f4a35c67ff44.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/0*ZT7ww-W1uRDy8nFa."/></div></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mu"><img src="../Images/e29be200ee9c9d201d0b51f67afb616d.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/0*wySLky_pUM--XdB0."/></div></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mu"><img src="../Images/8ebfae4008a1b9ea1eb8ea0c887ee1fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/0*I2saj-iwQFAqcSPf."/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">A subset of signal histograms comparing generated seller distribution to real sellers.</strong></figcaption></figure><h1 id="29a3" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">查找邻居和计算原因代码</h1><p id="5d9c" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">一旦模型被训练，我们就用它来生成一个任意大的合成卖家数据库。给定这些合成卖家，我们现在可以比较“坏的”真实卖家(例如，被模型暂停的卖家)和“好的”合成卖家(模型已经清除的卖家)。为了进行比较，我们专门将他们与<em class="jn"> K </em>最相似的“好”合成卖家进行比较。使用<em class="jn">K</em>-最近邻居的原因是通过平均那些<em class="jn"> K </em>邻居的值并将真实卖家与那些K值的平均值进行比较来减少比较中可能的噪声。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mw"><img src="../Images/6bfec0574163707d9e82e70cc7d234b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/0*jYl08W7R3U5TctsX."/></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd jx">Comparative Framework.</strong> A real seller whom the model has classified as “bad” is compared to the population of synthetic sellers classified by the model as “good.” Among those synthetic sellers, the <em class="mx">K</em> most similar to the input seller are returned as its neighbors and used to generate reasons based on their differences from the input seller.</figcaption></figure><p id="daa0" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">计算<a class="ae ip" href="https://numerics.mathdotnet.com/distance.html" rel="noopener ugc nofollow" target="_blank">成对相似度</a>的方法有很多。我们选择使用归一化信号的余弦相似性，但根据数据类型，也可以使用其他度量。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es my"><img src="../Images/f6a3e74dbea44317d71040f09a451595.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/0*igYIRjQLo447UL21."/></div></figure><h1 id="6cd5" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">生成原因代码</h1><p id="1d45" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">一旦找到卖家的K个邻居，计算原因代码就很简单了:我们确定哪些信号与卖家的邻居相似，哪些信号与卖家的邻居不同。<strong class="is hi">卖方<em class="jn">与其邻居</em>最大的不同之处构成了做出该决定的最可能的原因。</strong></p><p id="d44d" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">我们发现，在审查被模型怀疑有欺诈行为的卖家时，情况就是如此。例如，对于我们的一个高风险卖家，最重要的信号与他们的交易行为和与其他已知的不良行为者的联系有关。对于其他卖家，我们能够生成类似的直观原因代码。值得注意的是，通过这种方法创建的原因代码不仅仅告诉我们一个销售者如何不同于整个群体，而且这些原因代码能够明确地告诉我们一个销售者的突出之处，也就是说，是什么使他们看起来不同于其他类似的销售者。</p><h1 id="bb6d" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">结论</h1><p id="3742" class="pw-post-body-paragraph iq ir hh is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm io ha bi translated">在我们的示例中，我们将这种技术应用于单个领域，即欺诈，以根据输入特征来解释单个模型决策和预测。在这个例子中，我们能够生成代码，用于向卖家解释他们看起来可疑的确切原因。这在自动化应用中非常有用，因为它会给其他领域的客户带来不利的决策。</p><p id="6eb8" class="pw-post-body-paragraph iq ir hh is b it jq iv iw ix jr iz ja jb js jd je jf jt jh ji jj ju jl jm io ha bi translated">Square的宗旨是经济赋能。我们认为人工智能有机会帮助创造一个公平和可持续的环境，让卖家和客户建立联系。向机器学习模型的可解释性迈出这一大步有助于实现更大的公平性和透明度。</p></div></div>    
</body>
</html>