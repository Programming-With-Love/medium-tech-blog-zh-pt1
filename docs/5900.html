<html>
<head>
<title>Getting Started with PyTorch on OCI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OCI py torch入门</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/getting-started-with-pytorch-on-oci-dbaa5e7a40ef?source=collection_archive---------0-----------------------#2022-05-02">https://medium.com/oracledevs/getting-started-with-pytorch-on-oci-dbaa5e7a40ef?source=collection_archive---------0-----------------------#2022-05-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ea9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">欢迎阅读本系列的第一篇文章，在这里我们将探索诸如PyTorch和TensorFlow之类的AI/ML库。通常，人们对PyTorch和它有多棒有一种积极的情绪，而对TensorFlow有一种更消极的社会情绪。然而，这两个库都有独特的功能，我希望，通过这一系列文章，我将能够打破成见，展示这两个库都很棒，同时展示其中的一些功能。</p><p id="2f4c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将学习如何设置OCI来处理PyTorch的一个问题，如何将这个问题发展成一个具有健壮架构的解决方案，最后测试两个库的性能，看看哪个库最适合这个特定的问题。</p><h1 id="952f" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">ML简史</h1><p id="9143" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在设置环境和所有“技术”东西之前，有一些关于这些库和Python本身的事情需要注意:</p><ul class=""><li id="381a" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">Python是在30年前创建的，这是大多数人都不会相信的，因为这种编程语言在不久前“爆发”了流行。</li><li id="3c55" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">TensorFlow是谷歌在2015年创建的</li><li id="1ff3" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">PyTorch是一年后由FAIR(脸书人工智能研究实验室)创造的</li></ul><p id="0015" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为Tensorflow比PyTorch早一年创建，所以它在数据科学界很快受到欢迎，这种增长可以在这些库的普遍情绪中观察到，也可以通过比较两个开源存储库中的提交数量来观察，其中<a class="ae kt" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>在GitHub中的星级数大约是<a class="ae kt" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch的</a>的三倍。</p><p id="3dd9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">很明显，如今数据科学发展非常迅速，因为我们有越来越多的非结构化(和结构化！)我们可以得到的数据。我们的工作是理解这些数据并使其有意义。20世纪下半叶，我们今天所知的人工智能(AI)诞生了。这使得人类可以“放松”他们复杂的计算，同时将这项工作委托给机器。从那以后，机器学习已经成为日常生活的一个重要部分，尽管它并不明显:</p><ul class=""><li id="5c7b" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">垃圾邮件过滤器基于ML模型</li><li id="983d" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">先进的视频游戏反作弊系统(防止黑客)基于ML模型，该模型将合法玩家的数据与作弊玩家的数据进行比较，并分析差异以确定不公平游戏，</li><li id="75f1" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">网飞和亚马逊Prime对观看内容的建议基于一个ML模型，该模型分析你的口味并做出类似的建议</li><li id="20b6" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">特斯拉的autopilot驾驶软件基于计算机视觉和ML模型，对社会中的驾驶进行实时决策</li></ul><h1 id="d339" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">为什么我们需要PyTorch</h1><p id="d82c" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">PyTorch是一个很棒的库，可以很好地与Python协同工作。当使用Python执行数据分析时，我们需要理解Python的解释器仅限于在一个处理器上执行。这被称为GIL或全局解释器锁，一个只允许一个线程执行解释器的互斥锁(这可以通过用<strong class="ig hi">多处理</strong>模块实现代码来避免)。然而，大多数家用电脑和非专业设备很少配备超过16/32核心，这意味着我们理论上最多可以将代码优化提高16/32倍，除非我们使用GPU来帮助我们。</p><p id="8594" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">幸运的是，PyTorch对GPU很友好:我们可以在CPU、GPU甚至TPUs(张量处理单元)中执行我们的代码，这是由Google开发的一个特定的硬件单元，主要用于AI/ML目的。</p><p id="15bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从数学的角度来看，张量是一组数据。一个数相当于一个秩为0的张量；一维数组(向量)是秩为1的张量，矩阵是秩为2的张量。这在更多的维度上继续下去，直到我们得到一个秩为n的张量。</p><p id="f10b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">张量允许我们将数据分组为优化的子集，这些子集将在我们的硬件中高效运行。</p><h1 id="4e40" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">入门指南</h1><p id="3aaf" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">首先，我们需要一个运行PyTorch代码的环境。为此，我们前往Oracle云基础架构控制台。</p><p id="65f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们有两个选择:</p><ul class=""><li id="b52c" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">创建一个计算实例，启动它，安装Jupyter Notebook或其他运行Python代码的笔记本软件，并安装PyTorch。这比第二个选项花费的时间要长一些，因为我们必须自己完成所有的配置，但是从长远来看，我们会节省一些钱，因为创建一个计算实例比第二个选项要便宜一些。</li><li id="a3fd" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">创建一个OCI数据科学笔记本并安装PyTorch。这非常简单，不需要太多的IT知识；我们将拥有笔记本的实时可视化，以及在浏览器中修改它们的界面。</li></ul><p id="df58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这一小节中，我将展示如何遵循第二个选项(OCI数据科学)。</p><h1 id="736a" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">创建一个OCI数据科学笔记本并安装PyTorch</h1><p id="a946" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">首先，我前往OCI控制台，导航到OCI数据科学:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/4ef3c71fd41b625d7c95d81cdb356ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*adwSMsR5--kV1_5N"/></div></div></figure><p id="69e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其次，我创建了一个新项目:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/13a083e74823740685e83992311990b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AbN4YTQ-uEUlTVAF"/></div></div></figure><p id="206a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个项目中，我们可以有几个笔记本会议；并且这些会话将各自具有自己的存储。此外，笔记本会话可以由多个OCI用户同时协作和编辑。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/e38f634e6655cd0a104248d3a38fbffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cqi1UgZgyjZJ8dHp"/></div></div></figure><p id="feb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们在笔记本中，我们可以控制机器(我们可以通过终端访问它，就像我们通过ssh进入机器一样)或者我们可以通过环境浏览器控制Python环境。对于新用户，我强烈推荐environment explorer，因为它有几个现成的预构建环境。我们可以很容易地在环境浏览器中找到PyTorch，并安装它。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/baef6e6be0cf12a8d8c9e7c585e48b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*c49oHWdYiPQ-myJJ"/></div></div></figure><p id="b549" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要安装它，我们在终端中运行带有预建标识符的命令:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/aa85671ef78ae10ca659196b4e903f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ahy9eo-r7vo64NMb"/></div></div></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lg"><img src="../Images/68d03e62e277fdaa68495ffc71d9e3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7OzKfUtzp1iscBSd"/></div></div></figure><p id="e13b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无论你决定去哪个部门，我们都必须安装PyTorch。为此，让我们跟随<a class="ae kt" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">的这些步骤</a>。我个人推荐<strong class="ig hi">康达</strong>作为包管理器，因为它简化了虚拟环境的操作:</p><p id="6ae0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lh li lj lk b">bash conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</code></p><p id="491a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或带pip的同等产品:</p><p id="4eb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lh li lj lk b">bash pip3 install torch torchvision torchaudio</code></p><p id="dcf7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们安装了PyTorch，我们就可以检查测试笔记本在我们的笔记本上运行是否顺畅。为此，我们可以运行预定义的笔记本示例列表(从环境资源管理器中与PyTorch环境一起自动安装)或者自己运行一个示例。我们将混合使用两者来测试PyTorch的功能，使用<a class="ae kt" href="https://gist.github.com/curran/a08a1080b88344b0c8a7" rel="noopener ugc nofollow" target="_blank">非常著名的iris数据集</a>。</p><p id="9461" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们加载虹膜数据集:</p><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="e7b8" class="lp jd hh lk b fi lq lr l ls lt">from sklearn import datasets</span><span id="cfdd" class="lp jd hh lk b fi lu lr l ls lt">from sklearn.model_selection import train_test_split</span><span id="d07a" class="lp jd hh lk b fi lu lr l ls lt">from sklearn.preprocessing import StandardScaler</span><span id="3ee2" class="lp jd hh lk b fi lu lr l ls lt">import numpy as np</span><span id="269d" class="lp jd hh lk b fi lu lr l ls lt">import pandas</span><span id="1858" class="lp jd hh lk b fi lu lr l ls lt">import torch</span><span id="e463" class="lp jd hh lk b fi lu lr l ls lt">import torch.nn as nn</span><span id="c07f" class="lp jd hh lk b fi lu lr l ls lt">import torch.nn.functional as F</span><span id="5803" class="lp jd hh lk b fi lu lr l ls lt">iris = datasets.load_iris()</span><span id="838c" class="lp jd hh lk b fi lu lr l ls lt">X = iris['data'] # dependent variables or features</span><span id="8231" class="lp jd hh lk b fi lu lr l ls lt">y = iris['target'] # independent variable or target</span><span id="dbaf" class="lp jd hh lk b fi lu lr l ls lt">scaler = StandardScaler() # we scale our data for normalization purposes as features don't follow a normal distribution (e.g. the sepal length is about 10-20 times bigger than the petal width, both of them being features of the model)</span><span id="462d" class="lp jd hh lk b fi lu lr l ls lt">X_scaled = scaler.fit_transform(X)</span><span id="336a" class="lp jd hh lk b fi lu lr l ls lt">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=2) # we split our data 80/20%</span></pre><p id="9cb1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用三个线性层和<a class="ae kt" href="https://towardsdatascience.com/complete-guide-to-adam-optimization-1e5f29532c3d" rel="noopener" target="_blank"> Adam优化</a>配置了一个非常简单的神经网络模型。如果您对这些概念不熟悉，不要担心，我们将在本系列的后续文章中深入探讨这些东西的含义。现在，只需要知道Adam是一个优化算法，有一个复杂的数学公式(见下图)，但是要开始，我们不需要关注这个。你只需要知道关于Adam优化的以下内容(一般而言):-它易于实施-它的内存效率很高-它适用于数据密集型问题，这就是Adam优化在大数据中众所周知的原因-超参数化(模型调整)被模型产生的准确结果所掩盖，这意味着，我们通常会节省一些时间。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lv"><img src="../Images/0877dd7ea6eebea8cf1ecd0e255e7b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5fPepPLISABPXOAb"/></div></div></figure><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="1668" class="lp jd hh lk b fi lq lr l ls lt">class Model(nn.Module):</span><span id="7b5f" class="lp jd hh lk b fi lu lr l ls lt">def __init__(self, input_dim):</span><span id="5ebf" class="lp jd hh lk b fi lu lr l ls lt">super(Model, self).__init__()</span><span id="b4dc" class="lp jd hh lk b fi lu lr l ls lt"># with 3 linear layers</span><span id="1fb9" class="lp jd hh lk b fi lu lr l ls lt">self.layer1 = nn.Linear(input_dim, 50)</span><span id="b80e" class="lp jd hh lk b fi lu lr l ls lt">self.layer2 = nn.Linear(50, 50)</span><span id="6788" class="lp jd hh lk b fi lu lr l ls lt">self.layer3 = nn.Linear(50, 3)</span><span id="15c7" class="lp jd hh lk b fi lu lr l ls lt"># it is compulsory to define the forward function.</span><span id="8928" class="lp jd hh lk b fi lu lr l ls lt"># this function will pass data into the computation graph of the NN</span><span id="ab2b" class="lp jd hh lk b fi lu lr l ls lt"># and will represent the algorithm.</span><span id="20fb" class="lp jd hh lk b fi lu lr l ls lt"># we can use any of the tensor operations inside the forward function, like relu and softmax.</span><span id="1838" class="lp jd hh lk b fi lu lr l ls lt">def forward(self, x):</span><span id="cc24" class="lp jd hh lk b fi lu lr l ls lt"># ReLU is the activation function that makes the Neural Network non-linear.</span><span id="a673" class="lp jd hh lk b fi lu lr l ls lt">x = F.relu(self.layer1(x))</span><span id="22cb" class="lp jd hh lk b fi lu lr l ls lt">x = F.relu(self.layer2(x))</span><span id="d3f0" class="lp jd hh lk b fi lu lr l ls lt">x = F.softmax(self.layer3(x), dim=1) # our output layer will be a softmax layer</span><span id="5ef3" class="lp jd hh lk b fi lu lr l ls lt"># otherwise we wouldn't be able to interpret the result as easily</span><span id="6c3b" class="lp jd hh lk b fi lu lr l ls lt">return x</span><span id="f8cf" class="lp jd hh lk b fi lu lr l ls lt">model = Model(X_train.shape[1])</span><span id="19fd" class="lp jd hh lk b fi lu lr l ls lt">optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</span><span id="105d" class="lp jd hh lk b fi lu lr l ls lt">loss_fn = nn.CrossEntropyLoss()</span></pre><p id="f45d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基本上，我们将有三个输入，神经网络的结果将是这样的:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lw"><img src="../Images/eba36ecd1eb188807728f90438d56a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I9vPsp1W9vkO7QD3"/></div></div></figure><p id="7378" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们运行代码100个时期。一个纪元意味着我们在以前的文章中所做的“训练”过程要重复n次，其中n是大于0的整数。</p><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="a994" class="lp jd hh lk b fi lq lr l ls lt">EPOCHS = 100</span><span id="4db3" class="lp jd hh lk b fi lu lr l ls lt">X_train = Variable(torch.from_numpy(X_train)).float()</span><span id="dc3d" class="lp jd hh lk b fi lu lr l ls lt">y_train = Variable(torch.from_numpy(y_train)).long()</span><span id="f7ff" class="lp jd hh lk b fi lu lr l ls lt">X_test = Variable(torch.from_numpy(X_test)).float()</span><span id="c943" class="lp jd hh lk b fi lu lr l ls lt">y_test = Variable(torch.from_numpy(y_test)).long()</span><span id="88f2" class="lp jd hh lk b fi lu lr l ls lt">loss_list = np.zeros((EPOCHS,))</span><span id="8ce7" class="lp jd hh lk b fi lu lr l ls lt">accuracy_list = np.zeros((EPOCHS,))</span><span id="ff40" class="lp jd hh lk b fi lu lr l ls lt">for epoch in tqdm.trange(EPOCHS):</span><span id="4ca8" class="lp jd hh lk b fi lu lr l ls lt">y_pred = model(X_train)</span><span id="1e1f" class="lp jd hh lk b fi lu lr l ls lt">loss = loss_fn(y_pred, y_train)</span><span id="d7fe" class="lp jd hh lk b fi lu lr l ls lt">loss_list[epoch] = loss.item()</span><span id="c411" class="lp jd hh lk b fi lu lr l ls lt"># Zero gradients</span><span id="b30b" class="lp jd hh lk b fi lu lr l ls lt">optimizer.zero_grad()</span><span id="97b7" class="lp jd hh lk b fi lu lr l ls lt">loss.backward()</span><span id="a956" class="lp jd hh lk b fi lu lr l ls lt">optimizer.step()</span><span id="46c1" class="lp jd hh lk b fi lu lr l ls lt">with torch.no_grad():</span><span id="8e72" class="lp jd hh lk b fi lu lr l ls lt">y_pred = model(X_test)</span><span id="b878" class="lp jd hh lk b fi lu lr l ls lt">correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)</span><span id="c911" class="lp jd hh lk b fi lu lr l ls lt">accuracy_list[epoch] = correct.mean()</span></pre><p id="2282" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以创建一个<a class="ae kt" href="https://docs.oracle.com/en-us/iaas/data-science/using/manage-models.htm" rel="noopener ugc nofollow" target="_blank">模型工件</a>。这在使用Oracle Data Science笔记本开发代码时尤其有用，因为它与Oracle ADS(加速数据科学)集成在一起，简化了模型的保存和在未来使用简单命令的重用。</p><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="6733" class="lp jd hh lk b fi lq lr l ls lt"># we create the artifact in a temporary directory and store it in a pickle file, like in previous articles</span><span id="151b" class="lp jd hh lk b fi lu lr l ls lt"># Local path where the artifact will be stored.</span><span id="2b7f" class="lp jd hh lk b fi lu lr l ls lt">model_artifact_path = mkdtemp()</span><span id="7e5f" class="lp jd hh lk b fi lu lr l ls lt"># preparing the model artifact in a local directory:</span><span id="9460" class="lp jd hh lk b fi lu lr l ls lt">model_artifact = prepare_generic_model(model_artifact_path,</span><span id="5344" class="lp jd hh lk b fi lu lr l ls lt">data_science_env=True,</span><span id="ea8b" class="lp jd hh lk b fi lu lr l ls lt">force_overwrite=True)</span><span id="4fe9" class="lp jd hh lk b fi lu lr l ls lt"># saving the PyTorch model in the same model artifact directory:</span><span id="e905" class="lp jd hh lk b fi lu lr l ls lt">torch.save(model,</span><span id="f85b" class="lp jd hh lk b fi lu lr l ls lt">os.path.join(model_artifact_path,</span><span id="c47d" class="lp jd hh lk b fi lu lr l ls lt">'torch_lr.pkl'))</span><span id="39c0" class="lp jd hh lk b fi lu lr l ls lt">print(f"The model artifact is stored in: {model_artifact_path}")</span></pre><p id="7991" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这将返回:</p><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="ebc5" class="lp jd hh lk b fi lq lr l ls lt">&gt;&gt;&gt; {‘prediction’: [[0.9936151504516602,</span><span id="4fc3" class="lp jd hh lk b fi lu lr l ls lt">0.0057501643896102905,</span><span id="a1ae" class="lp jd hh lk b fi lu lr l ls lt">0.0006346192094497383]]}</span></pre><p id="1472" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以访问保存在临时目录中的模型工件，并进行测试预测:</p><p id="6488" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lh li lj lk b">python test_data = torch.tensor(X_test[:10].tolist()) model_artifact.predict(test_data)</code></p><pre class="kv kw kx ky fd ll lk lm ln aw lo bi"><span id="2331" class="lp jd hh lk b fi lq lr l ls lt">&gt;&gt;&gt; {'prediction': [[0.9936151504516602,</span><span id="6207" class="lp jd hh lk b fi lu lr l ls lt">0.0057501643896102905,</span><span id="2d50" class="lp jd hh lk b fi lu lr l ls lt">0.0006346192094497383]]}</span></pre><p id="a0b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为我们先前预先定义了秩1张量(向量)，所以我们返回了三个不同的数字。如果我们将它们相加，得出1；每一个代表每个样本成为给定物种的概率。</p><p id="33da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于概率的一个注意事项:它实际上是由神经网络通过激活函数执行的分类的权重，这在技术上不是被返回的概率；但这基本上意味着，向量中的数字越大，神经网络就越有可能决定它的类别是数组中那个位置的类别。</p><p id="20dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我真的希望您喜欢阅读和学习如何在OCI上开始使用PyTorch。</p><h1 id="d6fd" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">我如何开始学习OCI？</h1><p id="407e" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">记住，你可以随时免费注册OCI！您的Oracle Cloud帐户提供多项始终免费的服务和300美元免费积分的免费试用，可用于所有符合条件的OCI服务，最长30天。这些永远免费的服务可以在一段时间内无限制地在T2使用。免费试用服务可能会一直使用到您的300美元免费点数用完或30天到期，以先到者为准。你可以在这里<a class="ae kt" href="https://signup.cloud.oracle.com/?language=en&amp;sourceType=:ow:de:te::::&amp;intcmp=:ow:de:te::::" rel="noopener ugc nofollow" target="_blank">免费报名</a>！</p><h1 id="0d05" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">加入对话！</h1><p id="bf98" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">如果你对Oracle开发人员在他们的自然环境中发生的事情感到好奇，来<a class="ae kt" href="https://join.slack.com/t/oracledevrel/shared_invite/zt-uffjmwh3-ksmv2ii9YxSkc6IpbokL1g?customTrackingParam=:ow:de:te::::RC_WWMK220210P00062:Medium_nachoLoL5" rel="noopener ugc nofollow" target="_blank">加入我们的公共休闲频道</a>！我们不介意成为你的鱼缸🐠</p><h1 id="d7ee" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">许可证</h1><p id="c1d9" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">由伊格纳西奥·吉尔勒莫·马丁内兹撰写，艾琳·道森编辑。</p><p id="1ae6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">版权所有2022 Oracle和/或其附属公司。</p><p id="31c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据通用许可许可证(UPL)1.0版进行许可。</p><p id="a008" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">详见<a class="ae kt" href="https://github.com/oracle-devrel/leagueoflegends-optimizer/blob/main/LICENSE" rel="noopener ugc nofollow" target="_blank">许可证</a>。</p></div></div>    
</body>
</html>