<html>
<head>
<title>How to solve the “large number of small files” problem in Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解决Spark中的“大量小文件”问题</h1>
<blockquote>原文：<a href="https://medium.com/globant/how-to-solve-a-large-number-of-small-files-problem-in-spark-21f819eb36d3?source=collection_archive---------0-----------------------#2022-11-25">https://medium.com/globant/how-to-solve-a-large-number-of-small-files-problem-in-spark-21f819eb36d3?source=collection_archive---------0-----------------------#2022-11-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="716c" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">“大量小文件”问题的解决方案</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/92dc6f6083f49684b591a429cf46fdfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0z9tCV33G377k8wd"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Photo by <a class="ae jm" href="https://unsplash.com/@timwildsmith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Tim Wildsmith</a> on <a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a324" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi kj translated"><span class="l kk kl km bm kn ko kp kq kr di"> B </span> <a class="ae jm" href="https://en.wikipedia.org/wiki/Big_data" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> ig数据</strong> </a>不再是流行语，因为每个人都知道数据的力量和它能做什么。<a class="ae jm" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> Spark </strong> </a> <strong class="jp hi"> </strong>是处理大数据的健壮框架。与传统的数据处理框架相比，它有许多优点，但也有一些局限性。一个最大的限制是，当使用像HDFS、AWS S3等对象存储系统时，它将输出存储在许多小文件中。这是因为Spark是一个并行处理框架，当并行任务处理数据时，它们将输出存储在跨分区的多个文件中。所以假设你的Spark应用有200个并行任务<em class="ks"> </em>和10个分区；然后Spark应用程序可能会将结果存储到<em class="ks"> 200 * 10 = 2000 </em>文件中。每天多次运行此作业将在对象存储中创建更多文件。这就是Spark中所谓的<strong class="jp hi">大量小文件</strong>问题。</p><p id="c951" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这篇文章中，我将解释解决这个问题的不同方法。本文将帮助数据工程师优化Spark应用程序的输出存储。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="5d2c" class="la lb hh bd lc ld le lf lg lh li lj lk in ll io lm iq ln ir lo it lp iu lq lr bi translated">为什么我们认为<strong class="ak">【大量小文件】</strong>是个问题？</h1><p id="066b" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">以下是我们认为“大量小文件”是一个问题的一些原因。</p><ul class=""><li id="1b22" class="lx ly hh jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated"><a class="ae jm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#NameNode+and+DataNodes" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">名称节点</strong> </a> <strong class="jp hi">开销</strong> <br/>在<a class="ae jm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"> HDFS </a>中，文件被拆分成块存储并复制在<a class="ae jm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#NameNode+and+DataNodes" rel="noopener ugc nofollow" target="_blank">数据节点</a>上。每个块的大小为128 MB，并且每个块都有与之相关联的元数据。HDFS命名空间树和相关的元数据作为对象保存在NameNode的主内存中，每个对象大约占用150个字节。因此，名称节点必须管理这些对象，并为读/写请求提供服务。大量的小块增加了名称节点的开销。当Spark应用程序从HDFS读取数据时，它必须为更多的块读取请求提供服务。见下图，它很好地说明了HDFS建筑。</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mg"><img src="../Images/cdae757985728a03855efdf7b313f240.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dD1nikt4r0RbiKNdMHf2Zg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">HDFS Architecture</figcaption></figure><ul class=""><li id="74de" class="lx ly hh jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated"><strong class="jp hi">增加查询执行的元数据开销</strong> <br/>将小文件写入对象存储非常简单，但是对它们的查询会运行得非常慢或者无法完成。查询许多小文件会导致读取元数据、执行非连续磁盘寻道、打开文件、关闭文件并重复的开销。每个文件的开销只有几毫秒，但是当您查询数百万个文件时，这些毫秒会累积起来。<a class="ae jm" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"> Hive </a>是查询存储在<a class="ae jm" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"> HDFS </a>中文件的优秀工具。它是建立在HDFS之上的数据仓库解决方案。它支持写模式、分区和索引数据来加速查询，但是当我们在HDFS有大量小文件时，这些都不起作用。</li><li id="3e05" class="lx ly hh jp b jq mh jt mi jw mj ka mk ke ml ki mc md me mf bi translated"><strong class="jp hi">查询性能不足是因为</strong> <a class="ae jm" href="https://www.unraveldata.com/common-failures-slowdowns-part-ii/#:~:text=the%20application%20increases.-,What%20is%20Data%20Skew%3F,-In%20an%20ideal" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">数据偏斜</strong> </a> <br/>数据偏斜会妨碍查询性能。当执行一个查询时，Spark试图将相等的工作负载分配给所有任务。当Spark执行一个查询时，特定的任务可能会得到许多小文件，而其余的任务可能会得到大文件。例如，200个任务处理3到4个大文件，2个任务处理1000个小文件。这两个任务比其他200个任务需要更多的时间来完成处理。这就是查询性能受到影响的原因。</li></ul></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="37da" class="la lb hh bd lc ld le lf lg lh li lj lk in ll io lm iq ln ir lo it lp iu lq lr bi translated">“大量小文件”问题的解决方案</h1><p id="a07f" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">我们讨论了大量小文件如何影响应用程序的集群和性能。解决这个问题有不同的方法。</p><ul class=""><li id="d3a7" class="lx ly hh jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated">我们可以降低应用程序的并行性，以减少小文件的数量。</li><li id="44bb" class="lx ly hh jp b jq mh jt mi jw mj ka mk ke ml ki mc md me mf bi translated">此外，我们可以在将数据帧写入对象存储之前对其进行优化。</li></ul><p id="6974" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们看看如何实施这些解决方案…</p><h2 id="f665" class="mm lb hh bd lc mn mo mp lg mq mr ms lk jw mt mu lm ka mv mw lo ke mx my lq mz bi translated"><strong class="ak">减少并行度</strong></h2><p id="022f" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">当执行Spark应用程序时，它会创建一个<a class="ae jm" href="https://www.projectpro.io/recipes/what-is-dag-apache-spark" rel="noopener ugc nofollow" target="_blank"> DAG </a>。然后<a class="ae jm" href="https://books.japila.pl/apache-spark-internals/scheduler/DAGScheduler/" rel="noopener ugc nofollow" target="_blank"> DAG调度器</a>创建阶段，这些阶段被进一步分成几个任务。任务是发送给执行者的工作单元。<a class="ae jm" href="https://books.japila.pl/apache-spark-internals/scheduler/TaskScheduler/" rel="noopener ugc nofollow" target="_blank">任务调度器</a>在执行器上调度任务执行。每个阶段都有一些任务，每个<a class="ae jm" href="https://sparkbyexamples.com/spark/spark-shuffle-partitions/#:~:text=What%20is%20Spark%20Shuffle%3F" rel="noopener ugc nofollow" target="_blank">混洗分区</a>有一个任务。同样的任务在RDD的不同分区完成。每个任务处理每个混洗分区。</p><p id="cd59" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">随机分区的数量取决于两个属性。</p><ul class=""><li id="3072" class="lx ly hh jp b jq jr jt ju jw lz ka ma ke mb ki mc md me mf bi translated"><code class="du na nb nc nd b">spark.default.parallelism</code></li><li id="8222" class="lx ly hh jp b jq mh jt mi jw mj ka mk ke ml ki mc md me mf bi translated"><code class="du na nb nc nd b">spark.sql.shuffle.partitions</code></li></ul><p id="b64c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><code class="du na nb nc nd b">spark.default.parallelism</code>房产是用<code class="du na nb nc nd b"><a class="ae jm" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" rel="noopener ugc nofollow" target="_blank">RDD</a></code>引进的，因此该房产只适用于RDD。此属性定义创建RDD时创建的分区的初始数量。此配置的默认值设置为集群中所有节点上所有核心的数量。如果您在本地运行Spark，它将被设置为系统上的内核数量。您可以按如下方式设置该属性:</p><p id="4157" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><code class="du na nb nc nd b">spark.default.parallelism = &lt;&lt;integer value&gt;&gt;</code></p><p id="e7b3" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">属性<code class="du na nb nc nd b"><a class="ae jm" href="https://www.linkedin.com/pulse/always-more-resources-performance-spark-optimization-gaurav-patil" rel="noopener ugc nofollow" target="_blank">spark.sql.shuffle.partitions</a></code>控制在<a class="ae jm" href="https://sparkbyexamples.com/apache-spark-rdd/spark-rdd-transformations/#:~:text=of%20narrow%20transformation-,Wider%20Transformation,-Wider%20transformations%20are" rel="noopener ugc nofollow" target="_blank">宽变换</a>后为RDD和数据帧创建的洗牌分区的数量。每当宽变换如<code class="du na nb nc nd b">join()</code>、<code class="du na nb nc nd b">agg()</code>等。，由Spark应用程序执行，它生成<em class="ks"> N个</em>混洗分区，其中<em class="ks"> N </em>是由<code class="du na nb nc nd b">spark.sql.shuffle.partitions</code>属性设置的值。Spark可能会在输出目录中创建N个文件。如果在分区表中存储数据帧，文件总数将等于输出目录<em class="ks">中的<strong class="jp hi"> <em class="ks"> N * &lt;潜在表分区&gt; </em> </strong> <em class="ks"> </em>。</em>该属性的默认值是200。您应该根据集群的数据大小和可用资源来设置随机分区的数量。分区的数量应该是您拥有的执行器数量的倍数，这样分区就可以在任务之间平均分配。您可以按如下方式设置该属性:</p><p id="8d78" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><code class="du na nb nc nd b">spark.sql.shuffle.partitions = &lt;&lt;integer value&gt;&gt;</code></p><p id="48f7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">减少shuffle partitions值会减少小文件，因为在减少shuffle partitions后，相同大小的数据会分布在可用的shuffle partitions中。</p><h2 id="3e69" class="mm lb hh bd lc mn mo mp lg mq mr ms lk jw mt mu lm ka mv mw lo ke mx my lq mz bi translated"><strong class="ak">在写入数据帧之前减少混洗分区</strong></h2><p id="407b" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">最简单和最常用的技术是在将数据帧保存到表中之前减少数据帧的混洗分区。对于重新分区，Spark有两个功能— <code class="du na nb nc nd b"><a class="ae jm" href="https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce" rel="noopener ugc nofollow" target="_blank">repartition()</a></code>和<code class="du na nb nc nd b"><a class="ae jm" href="https://sparkbyexamples.com/spark/spark-repartition-vs-coalesce" rel="noopener ugc nofollow" target="_blank">coalesce()</a></code>。我们可以应用上述任何一个函数来减少分区。当您减少分区<strong class="jp hi"> </strong>的数量时，<code class="du na nb nc nd b">coalesce()</code>功能会工作得更快，因为它将输入分区粘在一起，但<code class="du na nb nc nd b">coalesce()</code>不能保证均匀的数据分布。<code class="du na nb nc nd b">repartition()</code>函数在混洗分区之间重新混洗数据，提供了更好的数据分布，但是与<code class="du na nb nc nd b">coalesce()</code>相比，使用<code class="du na nb nc nd b">repartition()</code>时会涉及很多混洗。向<code class="du na nb nc nd b">repartition()</code>函数提供一个列名和分区计数保证了基于所提供的列值的数据分布。</p><p id="9573" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们来看看PySpark <code class="du na nb nc nd b">repartition()</code>和<code class="du na nb nc nd b">coalesce()</code>的区别。</p><p id="26e9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们将首先创建一个有20个整数值的RDD。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="9d9e" class="ni lb hh nd b be nj nk l nl nm">rdd = spark.sparkContext.parallelize(range(0,20))<br/>rdd.collect() #show records in RDD</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nn"><img src="../Images/c75ed5d2df569b4f91757b71fb3adb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0UvMR0M5dD29qLqPb7X74g.png"/></div></div></figure><p id="363f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们使用<code class="du na nb nc nd b">getNumPartitions()</code>函数来检查RDD的分区数量。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="b70d" class="ni lb hh nd b be nj nk l nl nm">print("Initial number of partitions: " + str(rdd.getNumPartitions()))</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es no"><img src="../Images/77ce6c473b72de3538fb674bb22ee179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIKa9PZ8U7iz-yiScpqlsQ.png"/></div></div></figure><p id="9661" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我们将打印每个分区中的数据。我们可以使用<code class="du na nb nc nd b">glom()</code>函数来检查每个分区中的数据。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/64be399fae89dc948175a51139049ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NSnNYqgsr-vZFRzOTTg47g.png"/></div></div></figure><p id="d2b5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在上面的输出中，您可以看到RDD的数据是如何分布在不同的分区上的。</p><p id="3df6" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们在刚刚创建的第一个RDD上使用<code class="du na nb nc nd b">repartition()</code>函数。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="202d" class="ni lb hh nd b be nj nk l nl nm">rdd2 = rdd.repartition(4)<br/>print("Number of partitions after repartition: " + str(rdd2.getNumPartitions()))</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nq"><img src="../Images/92330713eb3ada938629e5f745a96682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7eIoog451hRqvoYgsIkfw.png"/></div></div></figure><p id="33c9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我们将打印每个分区中的数据。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nr"><img src="../Images/bc48c28817f0817093e7994fd79541f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0VIGO5w07qcWVz6N7pdPwg.png"/></div></div></figure><p id="138c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们在我们创建的第一个RDD上使用<code class="du na nb nc nd b">coalesce()</code>函数。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="6e33" class="ni lb hh nd b be nj nk l nl nm">rdd3 = rdd.coalesce(4)<br/>print("Number of partitions after coalesce: " + str(rdd3.getNumPartitions()))</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/815d85fbb67b61144162dfe7bc096107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G5GDDykmgiJ3qa2GyTkcnQ.png"/></div></div></figure><p id="e959" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们打印每个分区中的数据。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nt"><img src="../Images/ee98e5a632bd21192f8c368cfb635901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EOGLDI3UVUUkWA3tNLgWZg.png"/></div></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nu"><img src="../Images/11977e18a0d5b99583f1f038f31dbe30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PklMQvk5xISVMg6qB51gVw.png"/></div></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nv"><img src="../Images/a4cf4f128d3105b4fa0eacf6c7da06ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WWwFXUJaOVWjIRseVE27HA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx">Visualization of the output</figcaption></figure><p id="b0bb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">使用<code class="du na nb nc nd b">repartition()</code>和<code class="du na nb nc nd b">coalesce()</code>函数后，可以看到分区中记录的区别。当我们使用<code class="du na nb nc nd b">repartition()</code>函数时，数据会更加混乱，而<code class="du na nb nc nd b">coalesce()</code>函数则不那么混乱。(它只是将数据移动到最近的分区。)此外，我们可以看到<code class="du na nb nc nd b">coalesce()</code>函数比<code class="du na nb nc nd b">repartition()</code>函数具有更好的数据分布。</p><h2 id="22f2" class="mm lb hh bd lc mn mo mp lg mq mr ms lk jw mt mu lm ka mv mw lo ke mx my lq mz bi translated"><strong class="ak">对派生列进行重新分区</strong></h2><p id="0864" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">这只是对上述解决方案的改进。在上面的解决方案中，不能保证记录在混洗分区之间的分布。这里，我们将创建一个派生列，并将其传递给repartition函数，以基于该列重新分布数据。这个解决方案适用于我们没有任何数据均匀分布的列的情况。简单地说，我们的数据框架有倾斜的列。</p><p id="2fda" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果您在数据帧上应用<code class="du na nb nc nd b">repartition()</code>函数来减少混洗分区，从而减少小文件的数量，您会发现您的Spark应用程序变慢了。因此，要在不影响性能的情况下解决小文件问题，您需要创建一个值高度分布的派生列。您必须将这个派生列和分区计数一起传递给函数。之后，<code class="du na nb nc nd b">repartition()</code>函数将在shuffle分区之间平均分配记录。那么您的小文件问题将得到解决，而不会影响性能。</p><p id="9826" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在下面给出的PySpark示例<strong class="jp hi"> </strong>中，我正在处理2GB的数据。我有一个数据框架叫做<code class="du na nb nc nd b">df</code>。我想将它重新分区，然后存储在一个表上。这可以通过三个步骤实现，如下所示。</p><ol class=""><li id="112e" class="lx ly hh jp b jq jr jt ju jw lz ka ma ke mb ki nw md me mf bi translated">创建一个变量<code class="du na nb nc nd b">number_of_files</code>并给它分配一个整数值。根据数据的不同，您需要调整这个变量的值。我已经设定了<code class="du na nb nc nd b">number_of_files = 10</code>。创建一个具有唯一值的列，如下所示。我通过使用<code class="du na nb nc nd b">monotonically_increasing_id()</code>函数创建了具有唯一值的<code class="du na nb nc nd b">_unique_id</code>列。</li></ol><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="bbf2" class="ni lb hh nd b be nj nk l nl nm">from pyspark.sql import functions as F<br/>number_of_files = 10<br/>df = df.withColumn('_unique_id', F.monotonically_increasing_id())</span></pre><p id="6a67" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">2.之后，应用<a class="ae jm" href="https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8#:~:text=join%20cost%20itself.-,Key%20Salting" rel="noopener ugc nofollow" target="_blank">加盐技术</a>使用一个随机值跨分区分布记录。在Spark中，salting是一种添加随机值来均匀分布Spark分区数据的技术。为此，我们需要通过取上面创建的<code class="du na nb nc nd b">_unique_id</code>列的模数值来创建一个派生列；不是一个真正的随机数，但它工作得很好。在这个例子中，我创建了一个名为<code class="du na nb nc nd b">_salted_key</code>的列。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="75a8" class="ni lb hh nd b be nj nk l nl nm">df = df.withColumn('_salted_key', \<br/>                           F.col('_unique_id') % number_of_files)</span></pre><p id="8382" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">3.基于<code class="du na nb nc nd b">_salted_key</code>列重新划分数据帧。</p><pre class="ix iy iz ja fd ne nd nf bn ng nh bi"><span id="09e6" class="ni lb hh nd b be nj nk l nl nm">df = df.repartition(number_of_files, '_salted_key') \                  <br/>                           .drop('_unique_id', '_salted_key')</span></pre><p id="b87f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">完成上述三个步骤后，我们将对数据帧进行重新分区。我们可以将这个数据帧保存到目标表中，或者保存为一个文件。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="e461" class="la lb hh bd lc ld le lf lg lh li lj lk in ll io lm iq ln ir lo it lp iu lq lr bi translated">结论</h1><p id="b08b" class="pw-post-body-paragraph jn jo hh jp b jq ls ii js jt lt il jv jw lu jy jz ka lv kc kd ke lw kg kh ki ha bi translated">在本文中，我介绍了解决Spark中“大量小文件”问题的不同技术。在配置Spark参数以优化存储或应用性能方面，没有什么灵丹妙药<strong class="jp hi"> </strong>。这完全取决于您的数据和代码。建议事先对源数据进行一些分析，以便更好地理解数据，从而可以尝试不同的技术来优化Spark应用程序的存储和性能。</p><p id="701f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">快乐学习！</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="7d3b" class="la lb hh bd lc ld le lf lg lh li lj lk in ll io lm iq ln ir lo it lp iu lq lr bi translated">参考</h1><ul class=""><li id="2674" class="lx ly hh jp b jq ls jt lt jw nx ka ny ke nz ki mc md me mf bi translated"><a class="ae jm" href="https://blog.cloudera.com/the-small-files-problem/" rel="noopener ugc nofollow" target="_blank">小文件问题</a></li><li id="db7f" class="lx ly hh jp b jq mh jt mi jw mj ka mk ke ml ki mc md me mf bi translated"><a class="ae jm" href="https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8" rel="noopener ugc nofollow" target="_blank">在Apache Spark中处理数据偏斜</a></li><li id="9248" class="lx ly hh jp b jq mh jt mi jw mj ka mk ke ml ki mc md me mf bi translated"><a class="ae jm" href="https://blog.rockthejvm.com/repartition-coalesce/" rel="noopener ugc nofollow" target="_blank">重新划分与合并</a></li></ul></div></div>    
</body>
</html>