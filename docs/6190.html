<html>
<head>
<title>Building a dynamic and responsive Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建动态响应的Pinterest</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/building-a-dynamic-and-responsive-pinterest-7d410e99f0a9?source=collection_archive---------1-----------------------#2018-09-20">https://medium.com/pinterest-engineering/building-a-dynamic-and-responsive-pinterest-7d410e99f0a9?source=collection_archive---------1-----------------------#2018-09-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1ffa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">刘波|工程经理，服务系统团队</p><p id="3a48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2015年，Pinterest上的大部分内容都是在用户登录之前预先生成的。它被静态地存储在HBase中，并在进入服务时被直接服务。(更多细节可以在博客文章<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/building-a-smarter-home-feed-ad1918fdfbe3">构建更智能的家庭饲料</a>中找到。)</p><p id="a605" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然我们早期的架构帮助我们在2015年前将月活跃用户增加到1亿，但它有几个弱点，阻碍了我们构建更具动态性和响应性的产品。例如，很难在系统的不同组件上试验不同的想法和模型。由于内容是预先生成的，用于对候选人进行排名的功能可能是几周前的，我们无法利用最新的Pin/Board/用户数据，更不用说实时用户操作了。我们还必须为每个用户预先生成和存储内容，包括那些从未返回的用户。此外，我们一直在运行大量的并发实验，并且需要为每个实验预先生成和存储内容。存储成本巨大。</p><p id="df68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管一个动态且响应迅速的Pinterest对Pinners更有吸引力，但它对我们的后端系统提出了苛刻的要求。</p><p id="7c09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决技术问题，我们构建了九个不同的系统，共同为当今完全动态且响应迅速的Pinterest产品提供动力。虽然这些系统是为Pinterest构建的，但它们解决了许多面向消费者的网络内容分发应用程序的常见问题。在这里，我们将讨论这些系统以及它们如何改变驱动主要Pinterest产品的后端架构，包括Following Feed、Interest Feed和Picked For You(推荐)。</p><h1 id="342e" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">挑战</h1><p id="22cc" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">首先，需要实时存储和更新下图、所有者到电路板的映射和电路板到引脚的映射。尽管我们的MySQL和HBase集群中有这些信息，但从这些数据存储中查询这些信息以用于在线应用程序需要太长时间(每个请求不止一次往返、大扇出和大数据扫描)。</p><p id="16f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一个巨大的挑战是缺乏高性能的机器学习排名系统，以对每个请求的数千条内容进行排名，P99延迟为几十毫秒。为了向该ML排名系统提供特征数据，需要一些具有批处理和实时更新支持的有状态服务。这些有状态服务不仅必须提供KV数据模型，还必须提供更复杂的数据模型，如计数、列表等。这些有状态服务必须以个位数P99延迟来回答查询，给定依赖于它们的ML排名系统的延迟要求。</p><p id="9bb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们需要一个候选生成系统来为内容推荐实时提供高质量的候选集。</p><h1 id="0120" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">跟随馈送</h1><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/68de6a683421314c157b529c7c6571a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xD779rH71W5kgb0FBJfz7g.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 1: Former Following Feed</figcaption></figure><p id="5a66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图1描绘了大约2015年的以下馈送。每当保存一个Pin，一个异步任务就被排队到<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/pinlater-an-asynchronous-job-execution-system-b8664cb8aa7d"> Pinlater </a>，一个异步作业执行系统。该任务将首先通过follower服务从MySQL检索Pin的所有(直接和间接)追随者，然后将(追随者列表，Pin)发送给智能feed worker。智能feed工作器将利用<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/pinnability-machine-learning-in-the-home-feed-64be2074bf60">Pin ability</a>为每个追随者打分，然后将(追随者、分数、Pin)列表插入HBase。当用户访问Pinterest时，我们以用户id为前缀扫描HBase，提取该用户得分最高的pin。这种实现消耗了不必要的大量存储空间，并且使得利用新信号和试验新想法变得困难。此外，获取关注者列表(步骤2和3)和排名(步骤5)的长等待时间阻止了我们进行在线实验。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kw"><img src="../Images/ee912f365488aa17c496cac946d9296c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHQwzRAlMGT7rFv2d7DcuQ.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 2: Current Following Feed</figcaption></figure><p id="d555" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在图2所示的当前版本的feed中，绿色的组件是新构建的系统，而数据库形状表示有状态服务(在本文中我们使用相同的术语)。从用户到直接和间接跟踪的电路板的映射在Apiary中存储并实时更新，这支持适用于在线应用的低延迟查询。在Polaris中存储并实时更新板到引脚映射和一些轻量级引脚数据，Polaris不仅支持基于板的引脚检索，还支持通过传入的bloom filter进行过滤，以及轻量级评分来选择高质量引脚。</p><p id="320e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当向Feed Generator发送请求以获取用户的后续Feed时，它会同时获取用户的实时信号、用户跟踪的电路板以及用户最近分别从RealPin、Apiary和Aperture看到的引脚。</p><p id="ad57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">RealPin是一个高度可定制的对象检索系统，为对象存储和时间维度上的数据聚合提供了丰富的数据模型。我们定制了RealPin来跟踪和服务实时用户信号。Aperture最初是为内容重复数据删除而设计的；它存储所有用户事件，包括后端和前端Pin印象，并返回任何用户长达几个月的印象历史，所有这些都有个位数的P99延迟。Aperture后来被改编为广告用户行为计数用例，如博客文章<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/building-a-real-time-user-action-counting-system-for-ads-88a60d9c9a">中所述，为广告构建实时用户行为计数系统</a>。</p><p id="8899" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，Feed Generator向Polaris发送由用户印象历史组成的公告板列表和bloom过滤器。在检索、过滤和应用轻量级评分之后，Polaris向Feed Generator返回一个pin列表。最后，这个pin列表和实时用户信号被发送到Scorpion进行第二次全面评分。Scorpion是一个统一的ML在线排名平台，为生产中的大多数Pinterest ML模型提供支持。我们有Counter service和Rockstore底层Scorpion来提供计数信号和用户数据、pin数据等。请注意，Scorpion积极地在本地内存中缓存静态特征数据，这是ML模型所需的所有特征数据的较大部分。Scorpion被分片以实现超过90%的缓存命中率。</p><h1 id="4fc5" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">利息馈送</h1><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kx"><img src="../Images/0fec37af124783bf848adffb221bb3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9cEAx0mtJu8YG88rZQTcA.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 3: Former Interest Feed</figcaption></figure><p id="b7c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图3描绘了兴趣馈送架构的2015版本，其类似于图1中描述的以下馈送。主要区别是内容生成由日常工作触发，源数据存储在HBase而不是MySQL中。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ky"><img src="../Images/f4771cecf651f80cc60b107e2bf52c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TZjzD9QH0FHqupcIAdwNg.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 4: Current Interest Feed</figcaption></figure><h1 id="a754" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">为您挑选(推荐)</h1><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kz"><img src="../Images/dce07a0de38e1d270d1b8d7678d6137f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0NhIL8Dl8b6qBgljq1xAw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 5: Former Picked For You (recommendations)</figcaption></figure><p id="8864" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图5描绘了2015年的“为您挑选”架构。它的内容生成也是由日常工作引发的。定期的离线作业为每个用户生成一个电路板列表，作为Pin建议的种子。这些种子板被批量上传到<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/open-sourcing-terrapin-a-serving-system-for-batch-generated-data-7aa2f38c4472">水龟</a>上桌。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es la"><img src="../Images/88fc7be9e1be10de2770ba9ed88a737e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BziKCR7Mf8USNH7NDUwX5g.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx">Fig. 6: Current Picked For You (recommendations)</figcaption></figure><p id="4194" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图6描述了当前的“为你挑选”架构。Pixie是一个为实时董事会推荐而构建的新服务。它会定期将离线生成的由电路板和引脚组成的图形加载到内存中。当用户请求推荐的板时，通过使用用户使用的引脚作为起点，在Pixie图中模拟随机行走。(更多信息请见博客文章<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/introducing-pixie-an-advanced-graph-based-recommendation-system-e7b4229b664b">介绍Pixie，一个先进的基于图形的推荐系统</a>。)其余系统类似于跟进给。</p><h1 id="34b9" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">简短的技术讨论</h1><p id="efa7" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">在从头构建系统以实现完全动态和响应的Pinterest产品的整个过程中，我们需要做出合理权衡的设计决策，解决技术问题，并优化系统以满足在线应用的延迟要求。</p><p id="f088" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">回到2015年，Pinterest的大多数后端系统都是用Java实现的，我们还没有用C++构建任何系统。正如我们在前面几节中看到的，新系统必须通过大扇出(有时是所有分片扇出)实现低长尾延迟，并且一些系统是CPU密集型的(例如Scorpion、Pixie和RealPin)。我们选择采用C++11，FBThrift，Folly，RocksDB来构建这些系统。一开始很慢，因为我们必须安装所有的依赖项，构建几个基本的工具库(比如统计报告、请求路由等等。)，并设置我们的构建和发布环境。它最终得到了回报，因为我们使用我们的新基础在整个公司范围内建立了越来越高效和有效的系统。</p><p id="fee5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">RocksDB是一个嵌入式存储引擎。为了在其上构建分片和复制的分布式系统，数据复制是我们需要解决的第一个问题。我们从写入所有副本的方法开始，后来转向主从复制。我们的系统运行在AWS上，AWS将其网络建模为区域、可用性区域和放置组。值得注意的是，跨AZ网络流量的费用很高。我们构建了一个基于前缀的AZ感知流量路由库，最大限度地减少跨AZ流量，并支持所有可能的路由模式(例如，单分片、多分片和全分片扇出)。该库还监视TCP连接的健康状况，并在副本之间适度地对请求进行故障转移。需要注意的一点是，当远程对等体上的操作系统崩溃时，我们需要利用TCP_USER_TIMEOUT套接字选项来快速失败。由于各种原因，在不关闭TCP连接的情况下，VM实例在AWS上变得不可达是很常见的。如果没有设置TCP_USER_TIMEOUT，典型的TCP实现可能需要超过10分钟来向用户空间应用程序报告问题。(关于数据复制和流量路由的更多细节可以在<a class="ae jc" href="https://github.com/pinterest/rocksplicator" rel="noopener ugc nofollow" target="_blank"> Rocksplicator Github repo </a>和博客文章<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/open-sourcing-rocksplicator-a-real-time-rocksdb-data-replicator-558cd3847a9d">开源Rocksplicator，一个实时RocksDB数据复制器</a>中找到。)</p><p id="53ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinterest超过10%的AWS实例运行我们的系统。为了减少运营开销和服务停机时间，我们将Apache Helix(Linkedin开源的集群管理框架)与Rocksplicator进行了集成。(更多细节可以在博客文章<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/automated-cluster-management-and-recovery-for-rocksplicator-f1f8fd35c833">中找到。)</a></p><p id="83b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在实施和生产这些系统时，我们做了大量的优化和调整。例如，我们需要调整RocksDB压缩线程数，并将L0和L1设置为相同的大小，以减少写入放大并提高写入吞吐量。</p><p id="96c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中一个计数器服务集群必须支持为P99延迟小于20毫秒的单个请求返回数万个计数。为了实现这一点，我们切换到RocksDB普通表，并将其配置为本质上类似于内存哈希表的东西。我们还必须切换到float16以减少数据大小，并手动将返回计数列表编码为二进制字符串以节省序列化和反序列化开销。对于大的请求，计数器服务也可以利用多个线程来处理单个请求。</p><p id="55f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然RealPin是作为一个对象检索系统设计的，但我们对它进行了定制，将其作为一个在线评分系统运行了几个月。然而，我们注意到，考虑到计算和存储在同一位置，操作该系统是一个挑战。随着我们开始使用更多类型的特征数据，这个问题变得更加严重。最终，我们开发了新的Scorpion系统，它将计算与存储分离，并将特征数据缓存在计算节点上。</p><p id="4d02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于Scorpion是CPU密集型的，并且运行在大型集群上，我们需要在优化它上投入大量资金。我们仔细地调优了Scorpion线程模型，以在高并发处理和低上下文切换或同步开销之间取得良好的平衡。最佳点不是固定的，因为它取决于许多因素，例如数据是从内存、本地磁盘还是RPC获取。我们优化了内存中的LRU缓存模块，实现了零拷贝；也就是说，缓存的数据在没有任何数据复制的情况下被提供给ML模型。实施批量评分是为了让GCC更好地利用SIMD指令。GBDT模型中的决策树在内存中被压缩并仔细布局，以实现更好的CPU缓存命中率。对象级同步避免了高速缓存未命中的大爆发。</p><p id="5696" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">储存在Aperture中的数据沿时间维度存储。我们对旧数据使用冻结数据格式，它是不可变的，适合快速读取访问。更新的数据以可变格式存储，这对于更新是有效的。利用max_successive_merges RocksDB选项来限制mem-table中来自同一个键的合并操作数的数量。此设置对于Aperture实现低读取延迟至关重要，因为它可能需要读取具有大量合并操作数的RocksDB键，这在读取时处理起来非常昂贵。为了节省存储空间，RocksDB被配置为对不同级别使用不同的压缩策略和乘数因子。</p><p id="5223" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你对这些挑战感兴趣，<a class="ae jc" href="https://careers.pinterest.com/careers/engineering" rel="noopener ugc nofollow" target="_blank">加入我们的团队</a>！请关注这个博客，了解更多关于我们一些系统开源的文章和信息。</p><p id="a1c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lb">鸣谢:除了服务系统团队之外，我们还要感谢我们的客户团队提供了有用的反馈，帮助构建和采用这些系统——主页反馈、相关pin、广告、兴趣、应用科学、视觉搜索、垃圾邮件等。</em></p></div></div>    
</body>
</html>