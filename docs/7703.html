<html>
<head>
<title>Getting started with the Kafka Connect Cassandra Source</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kafka Connect Cassandra源代码入门</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/getting-started-with-the-kafka-connect-cassandra-source-e6e06ec72e97?source=collection_archive---------0-----------------------#2018-03-13">https://medium.com/walmartglobaltech/getting-started-with-the-kafka-connect-cassandra-source-e6e06ec72e97?source=collection_archive---------0-----------------------#2018-03-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ebf2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章将着眼于如何设置和调整<a class="ae jc" href="http://lenses.stream/connectors/source/cassandra.html" rel="noopener ugc nofollow" target="_blank">卡珊德拉源连接器</a>，可从<a class="ae jc" href="http://www.landoop.com/" rel="noopener ugc nofollow" target="_blank"> Landoop </a>获得。Cassandra Source连接器用于从Cassandra表中读取数据，仅使用一个配置文件将内容写入Kafka主题。这使得已经保存的数据可以很容易地转换成事件流。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/016e04d4e47ac5f18c27ddb62091711b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Fi0Zp7l0lbj-y9QT.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx">all logos are trademark of Apache Foundation</figcaption></figure><p id="85be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的示例中，我们将捕获代表一包(即一个大箱子)正在运输的物品的数据。每个包都以JSON格式推送给消费者，主题是Kafka。</p><h1 id="d7da" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">Cassandra数据模型和Cassandra源连接器</h1><p id="10c8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Cassandra中的数据建模必须围绕访问数据所需的查询来完成(详见本文<a class="ae jc" href="https://www.datastax.com/dev/blog/basic-rules-of-cassandra-data-modeling" rel="noopener ugc nofollow" target="_blank"/>)。通常，这意味着每个查询都有一个表，数据(在我们的例子中是关于包的)将跨多个表重复。</p><p id="afac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不考虑产品使用的其他表，Cassandra Source连接器需要一个允许我们使用时间范围查询数据的表。连接器是围绕其基于配置生成CQL查询的能力而设计的。它使用该查询从表中检索在可配置的时间范围内可用的数据。所有这些数据发布后，Kafka Connect会将时间范围的上限标记为偏移量。然后，连接器将使用从偏移量中存储的日期/时间开始的下一个时间范围来查询表中的更多数据。我们将在后面研究如何配置它。现在，我们想把重点放在表的约束上。因为Cassandra不支持连接，所以我们从中提取数据的表必须包含我们想要放入Kafka主题的所有数据。Kafka Connect将无法使用其他表中的数据。</p><p id="361f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最简单的形式是，Cassandra源连接器使用的表格可能如下所示:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="e45f" class="lb ju hh kx b fi lc ld l le lf">CREATE TABLE IF NOT EXISTS “pack_events” (<br/>    event_id TEXT, <br/>    event_ts TIMESTAMP, <br/>    event_data TEXT, <br/>PRIMARY KEY ((event_id),event_ts));</span></pre><p id="8ca8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lg lh li kx b">event_id</code>是分区键。Cassandra使用它来确定集群中的哪些节点将存储数据。<code class="du lg lh li kx b">event_ts</code>是集群密钥的一部分。它决定了分区内数据的顺序(详见本文)。Cassandra源连接器也使用该列来管理时间范围。在这个例子中，<code class="du lg lh li kx b">event_data</code>列存储了包的JSON表示。</p><p id="92bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这不是唯一可行的表结构。Cassandra源连接器查询的表可以使用许多列来表示分区键和数据。然而，<strong class="ig hi">为了正确工作，连接器需要一个基于时间的列</strong>(或者<code class="du lg lh li kx b">TIMESTAMP</code>或者<code class="du lg lh li kx b">TIMEUUID</code>)。</p><p id="10c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于Cassandra源连接器，这将是一个同样有效的表。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="3608" class="lb ju hh kx b fi lc ld l le lf">CREATE TABLE IF NOT EXISTS “kc_events” (<br/>    event_id1 TEXT, <br/>    event_id2 TEXT, <br/>    event_ts TIMEUUID, <br/>    event_data1 TEXT, <br/>    event_data2 TEXT, <br/>PRIMARY KEY ((event_id1, event_id2)));</span></pre><p id="6eb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">访问该表中数据的最有效方法是使用分区键查询数据。这将允许Cassandra快速识别包含我们感兴趣的数据的节点。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="1c5f" class="lb ju hh kx b fi lc ld l le lf">SELECT * FROM pack_events WHERE event_id = “1234”;</span></pre><p id="9ca8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，Cassandra Source连接器无法知道它将需要发布到Kafka主题的数据的id。这就是它使用时间范围的原因。</p><p id="89b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们不能使用<code class="du lg lh li kx b">event_ts</code>作为分区键的原因是因为Cassandra在查询时不支持分区键上的这些运算符(&gt;、&gt; =、&lt; =、&lt;)。如果没有这些，我们将无法跨日期/时间范围进行查询(详见本文的<a class="ae jc" href="https://www.datastax.com/dev/blog/a-deep-look-to-the-cql-where-clause" rel="noopener ugc nofollow" target="_blank"/>)。</p><p id="88ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还有一件事。如果我们尝试运行以下查询，它将会失败。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="a243" class="lb ju hh kx b fi lc ld l le lf">SELECT * FROM pack_events <br/>WHERE event_ts &gt; ‘2018–01–22T20:28:20.869Z’ <br/>AND event_ts &lt;= '2018-01-22T20:28:50.869Z';</span></pre><p id="25fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">连接器必须在查询结束时提供<code class="du lg lh li kx b">ALLOW FILTERING</code>选项，这样它才能工作。这一增加允许Cassandra在集群中的所有节点上搜索指定时间范围内的数据(参见本文的<a class="ae jc" href="https://www.datastax.com/dev/blog/allow-filtering-explained-2" rel="noopener ugc nofollow" target="_blank">了解详细信息</a>)。</p><h1 id="3efd" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">配置连接器:KCQL基础知识</h1><p id="0b92" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Landoop连接器是使用Kafka连接查询语言(KCQL)配置的。这提供了一种简洁和一致的方式来配置连接器(至少是Landoop的连接器)。KCQL和其他基本属性是通过JSON格式的属性文件提供的。</p><p id="f64d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了这篇文章，让我们创建一个名为<code class="du lg lh li kx b">connect-cassandra-source.json</code>的文件。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="a5e0" class="lb ju hh kx b fi lc ld l le lf">{ <br/>  “name”: “packs”, <br/>  “config”: { <br/>   “tasks.max”: “1”, <br/>   “connector.class”: … </span></pre><p id="46c8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">连接器的<code class="du lg lh li kx b">name</code>需要在Kafka Connect中安装的所有连接器中是唯一的。</p><p id="bad2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lg lh li kx b">connector.class</code>用于指定正在使用的连接器。​​</p><ul class=""><li id="036c" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><code class="du lg lh li kx b">com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</code></li></ul><p id="ebc5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一组配置(如下所示)用于指定连接到Cassandra集群所需的信息以及要使用的键空间。</p><ul class=""><li id="f802" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated"><code class="du lg lh li kx b">​connect.cassandra.contact.points</code></li><li id="a421" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><code class="du lg lh li kx b">connect.cassandra.port</code></li><li id="1a09" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><code class="du lg lh li kx b">connect.cassandra.username</code></li><li id="978e" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><code class="du lg lh li kx b">connect.cassandra.password</code></li><li id="a2b0" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><code class="du lg lh li kx b">connect.cassandra.consistency.level</code></li><li id="f3e5" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated"><code class="du lg lh li kx b">connect.cassandra.key.space</code></li></ul><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="86de" class="lb ju hh kx b fi lc ld l le lf">{ <br/>  “name”: “packs”, <br/>  “config”: { <br/>    “tasks.max”: “1”, <br/>    “connector.class”: “com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector”, <br/>    “connect.cassandra.contact.points”: “localhost”,    <br/>    “connect.cassandra.port”: 9042, <br/>    “connect.cassandra.username”: “cassandra”,   <br/>    “connect.cassandra.password”: “cassandra”,<br/>    “connect.cassandra.consistency.level”: “LOCAL_ONE”,<br/>    “connect.cassandra.key.space”: “blog”, <br/>    <br/>    “connect.cassandra.import.mode”: “incremental”, <br/>    “connect.cassandra.kcql”: “INSERT INTO test_topic SELECT event_data, event_ts FROM pack_events IGNORE event_ts PK event_ts WITHUNWRAP INCREMENTALMODE=TIMESTAMP”, <br/>     <br/>     … <br/>  } <br/>}</span></pre><p id="682e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lg lh li kx b">connect.cassandra.import.mode</code>有两个值。那些是<code class="du lg lh li kx b">bulk</code>和<code class="du lg lh li kx b">incremental</code>。每次Kafka Connect轮询发生时，<code class="du lg lh li kx b">bulk</code>选项将查询表<em class="lx">中的所有内容。我们将把它设置为<code class="du lg lh li kx b">incremental</code>。</em></p><p id="7bdb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">配置中有趣的部分是<code class="du lg lh li kx b">connect.cassandra.kcql</code>属性(如上所示)。KCQL语句告诉连接器使用Cassandra集群中的哪个表，如何使用表上的列，以及在哪里发布数据。</p><p id="0cb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">KCQL语句的第一部分告诉连接器将发布数据的Kafka主题的名称。在我们的例子中，这就是名为<code class="du lg lh li kx b">test_topic</code>的主题。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="7d9c" class="lb ju hh kx b fi lc ld l le lf">INSERT INTO test_topic</span></pre><p id="4e45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">KCQL语句的下一部分告诉连接器如何处理这个表。<code class="du lg lh li kx b">SELECT/FROM</code>指定用查询轮询的表。它还指定应该检索其值的列。跟踪日期/时间的列必须是<code class="du lg lh li kx b">SELECT</code>语句的一部分。然而，如果我们不希望这些数据成为我们发布到Kafka主题的一部分，我们可以使用<code class="du lg lh li kx b">IGNORE.</code></p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="a537" class="lb ju hh kx b fi lc ld l le lf">SELECT event_data, event_ts FROM pack_events IGNORE event_ts</span></pre><p id="af45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">语句的下一部分<code class="du lg lh li kx b">PK</code>告诉连接器哪个列用于管理日期/时间。这被认为是连接器的主键。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="ba12" class="lb ju hh kx b fi lc ld l le lf">PK event_ts WITHUNWRAP INCREMENTALMODE=”TIMESTAMP”</span></pre><p id="3009" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lg lh li kx b">INCREMENTALMODE</code>告诉连接器<code class="du lg lh li kx b">PK</code>列的数据类型。那将是<code class="du lg lh li kx b">TIMESTAMP</code>或者<code class="du lg lh li kx b">TIMEUUID</code>。</p><p id="43cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，<code class="du lg lh li kx b">WITHUNWRAP</code>选项告诉连接器将数据作为字符串而不是JSON对象发布到主题。</p><p id="cf66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果我们在<code class="du lg lh li kx b">event_data</code>列中有以下值:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="69e1" class="lb ju hh kx b fi lc ld l le lf">{ “foo”:”bar” }</span></pre><p id="e638" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们希望发布如上图所示的内容。</p><p id="462c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关闭<code class="du lg lh li kx b">WITHUNWRAP</code>选项将导致以下值发布到主题。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="4821" class="lb ju hh kx b fi lc ld l le lf">{ <br/>  “schema”: {<br/>    “type”: “struct”, <br/>    “fields”: [{ <br/>      “type”: “string”,<br/>      “optional”: true,<br/>      “field”: “event_data” <br/>    }],<br/>    “optional”: false, <br/>    “name”: “blog.pack_events” <br/>  }, <br/>  “payload”: { <br/>    “event_data”: “{\”foo\”:\”bar\”}” <br/>  } <br/>}</span></pre><p id="b0d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们让<code class="du lg lh li kx b">WITHUNWRAP</code>关闭，当使用<code class="du lg lh li kx b">StringConverter</code>(稍后会详细介绍)时，我们会得到以下结果:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="b7c7" class="lb ju hh kx b fi lc ld l le lf">Struct:{event_data={“foo”:”bar"}}</span></pre><p id="8d85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们需要使用<code class="du lg lh li kx b">WITHUNWRAP</code>和<code class="du lg lh li kx b">StringConverter</code>的组合来得到我们想要的结果。</p><h1 id="38f1" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">配置连接器:调整参数</h1><p id="c7f8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们将在另一篇文章中探讨这些问题。但是现在，让我们开始在表中查找今天开始日期/时间的数据。我们还会每秒进行一次投票。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="a759" class="lb ju hh kx b fi lc ld l le lf">{ <br/>  “name”: “packs”, <br/>  “config”: { <br/>    “tasks.max”: “1”,<br/>    … <br/>    “connect.cassandra.initial.offset”: “2018–01–22 00:00:00.0000000Z”, <br/>    “connect.cassandra.import.poll.interval”: 1000 <br/>  } <br/>}</span></pre><h1 id="070d" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">建立基础设施</h1><p id="3e92" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们将使用以下产品:</p><ul class=""><li id="20b6" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated">Apache Cassandra 3.11.1</li><li id="a854" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">阿帕奇卡夫卡和卡夫卡连接1.0</li><li id="0b78" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb lo lp lq lr bi translated">Landoop Cassandra Source 1.0</li></ul><h1 id="cd3f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">安装Cassandra</h1><p id="15df" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Apache Cassandra的安装说明可以在网上找到(<a class="ae jc" href="https://cassandra.apache.org/doc/latest/getting_started/installing.html" rel="noopener ugc nofollow" target="_blank">链接</a>)。安装并启动后，可以使用以下命令验证群集:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="3564" class="lb ju hh kx b fi lc ld l le lf">nodetool -h [IP] status</span></pre><p id="f19b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这将生成如下响应:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="6a27" class="lb ju hh kx b fi lc ld l le lf">Datacenter: dc1<br/>===============<br/>Status=Up/Down<br/>|/ State=Normal/Leaving/Joining/Moving<br/>--  Address   Load       Tokens       Owns (effective)  Host ID   Rack<br/>UN  10.x.x.x  96.13 GiB   64           39.6%            [UUID]    r6<br/>UN  10.x.x.x  148.98 GiB  64           33.6%            [UUID]    r5<br/>UN  10.x.x.x  88.08 GiB   64           36.4%            [UUID]    r5<br/>UN  10.x.x.x  97.96 GiB   64           30.4%            [UUID]    r6<br/>UN  10.x.x.x  146.89 GiB  64           33.2%            [UUID]    r7<br/>UN  10.x.x.x  205.24 GiB  64           36.8%            [UUID]    r7</span></pre><h1 id="b219" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">安装Kafka和Kafka Connect</h1><p id="c5fe" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Kafka Connect是作为Apache Kafka的一部分发货和安装的。这些说明也可以在网上找到(<a class="ae jc" href="https://kafka.apache.org/quickstart" rel="noopener ugc nofollow" target="_blank">链接</a>)。</p><ol class=""><li id="1fbd" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb ly lp lq lr bi translated">下载tar文件(<a class="ae jc" href="https://kafka.apache.org/downloads" rel="noopener ugc nofollow" target="_blank">链接</a>)。</li><li id="85ed" class="lj lk hh ig b ih ls il lt ip lu it lv ix lw jb ly lp lq lr bi translated">安装tar文件</li></ol><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="f250" class="lb ju hh kx b fi lc ld l le lf">tar -xzf kafka_2.11–1.0.0.tgz <br/>cd kafka_2.11–1.0.0</span></pre><h1 id="0bdd" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">开始卡夫卡</h1><p id="ff0d" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">这篇文章不会试图解释Kafka集群背后的架构。然而，一个典型的安装将有几个Kafka代理和Apache Zookeeper。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/facc368310de567048103acfe391adae.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/0*HoKUvzx_Q25-P5Rq.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx">all logos are trademark of Apache Foundation</figcaption></figure><p id="846b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要运行Kafka，首先启动Zookeeper，然后启动Kafka brokers。以下命令假设本地安装只有一个节点。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="eed8" class="lb ju hh kx b fi lc ld l le lf">bin/zookeeper-server-start.sh config/zookeeper.properties</span></pre><p id="77cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">和</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="ded3" class="lb ju hh kx b fi lc ld l le lf">bin/kafka-server-start.sh config/server.properties</span></pre><p id="7528" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们安装并运行了Kafka，我们需要创建四个主题。一个由我们的应用程序用来发布我们的包JSON。另外三个是Kafka Connect要求的。我们将继续假设大多数人最初在笔记本电脑上运行，因此我们将复制因子设置为1。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="541c" class="lb ju hh kx b fi lc ld l le lf">bin/kafka-topics.sh — create — topic test_topic -zookeeper localhost:2181 — replication-factor 1 — partitions 3</span></pre><p id="1251" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">和</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="054b" class="lb ju hh kx b fi lc ld l le lf">bin/kafka-topics.sh — create — zookeeper localhost:2181 — topic connect-configs — replication-factor 1 — partitions 1 — config cleanup.policy=compact </span><span id="43f4" class="lb ju hh kx b fi ma ld l le lf">bin/kafka-topics.sh — create — zookeeper localhost:2181 — topic connect-offsets — replication-factor 1 — partitions 50 — config cleanup.policy=compact </span><span id="ad4c" class="lb ju hh kx b fi ma ld l le lf">bin/kafka-topics.sh — create — zookeeper localhost:2181 — topic connect-status — replication-factor 1 — partitions 10 — config cleanup.policy=compact</span></pre><p id="1461" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了验证已经创建了四个主题，请运行以下命令:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="f0fe" class="lb ju hh kx b fi lc ld l le lf">bin/kafka-topics.sh — list — zookeeper localhost:2181</span></pre><h1 id="e7e9" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">安装Cassandra信号源连接器</h1><p id="9f7c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Landoop为Kafka Connect提供了众多连接器。这些都是开源的。我们需要做的第一件事是下载Cassandra源连接器jar文件(<a class="ae jc" href="https://github.com/Landoop/stream-reactor/releases" rel="noopener ugc nofollow" target="_blank">链接</a>)。</p><ul class=""><li id="9df6" class="lj lk hh ig b ih ii il im ip ll it lm ix ln jb lo lp lq lr bi translated">kafka-connect-cassandra-1.0.0–1.0.0-all.tar.gz</li></ul><p id="c2c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解压缩tar文件，并将jar文件复制到Kafka安装目录下的<code class="du lg lh li kx b">libs</code>文件夹中。</p><h1 id="0a03" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">配置Kafka Connect</h1><p id="f0d8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们需要告诉Kafka Connect Kafka集群在哪里。在安装卡夫卡的<code class="du lg lh li kx b">config</code>文件夹中，我们会找到文件:<code class="du lg lh li kx b">connect-distributed.properties.</code>寻找<code class="du lg lh li kx b">bootstrap.servers</code>键。更新它以指向集群。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="01dd" class="lb ju hh kx b fi lc ld l le lf">bootstrap.servers=localhost:9092</span></pre><h1 id="66ff" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">启动Kafka Connect</h1><p id="18b5" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们现在可以启动分布式Kafka Connect服务了。有关独立模式与分布式模式的更多信息，请参见文档(<a class="ae jc" href="https://docs.confluent.io/current/connect/userguide.html" rel="noopener ugc nofollow" target="_blank">链接</a>)。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="62ce" class="lb ju hh kx b fi lc ld l le lf">bin/connect-distributed.sh config/connect-distributed.properties</span></pre><p id="24bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果一切顺利，您应该会在控制台上看到以下内容:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/4cc75ae0825996c3045f6c969a6c750c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M6D9vzHCNtCScBNN.png"/></div></div></figure><p id="627d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想知道，“数据登山家”，是该公司更名为Landoop之前的名字。</p><h1 id="fb57" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">添加Cassandra源连接器</h1><p id="cfca" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Kafka Connect有一个与连接器交互的REST API(<a class="ae jc" href="https://docs.confluent.io/current/connect/restapi.html" rel="noopener ugc nofollow" target="_blank">查看API上的细节</a>)。我们需要将Cassandra Source连接器添加到Kafka Connect。这是通过REST API向Kafka Connect发送属性文件(<code class="du lg lh li kx b">connect-cassandra-source.json</code>)来完成的。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="bb81" class="lb ju hh kx b fi lc ld l le lf">curl -X POST -H “Content-Type: application/json” -d @connect-cassandra-source.json localhost:8083/connectors</span></pre><p id="47f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们成功地加载了连接器，我们就可以使用这个API来查看已安装的连接器:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="6cc1" class="lb ju hh kx b fi lc ld l le lf">curl localhost:8083/connectors</span></pre><p id="dacd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这应该会返回一个按配置名称排列的连接器列表。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="b394" class="lb ju hh kx b fi lc ld l le lf">[“packs”]</span></pre><h1 id="4ce8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试Cassandra源连接器</h1><p id="2758" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">为了测试所有东西，我们需要在表中插入一些数据。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="3d44" class="lb ju hh kx b fi lc ld l le lf">INSERT INTO pack_events (event_id, event_ts, event_data) <br/>VALUES (‘500’, ‘2018–01–22T20:28:50.869Z’, ‘{“foo”:”bar”}’);</span></pre><p id="5f22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以通过运行以下命令来检查向Kafka主题写入了什么:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="7fa3" class="lb ju hh kx b fi lc ld l le lf">bin/kafka-console-consumer.sh — bootstrap-server localhost:9092 — topic test_topic</span></pre><p id="b4a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此时，我们可能会惊讶地看到这样的内容:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="eaa5" class="lb ju hh kx b fi lc ld l le lf">{ <br/>  “schema”:{ <br/>    “type”:”string”, <br/>    “optional”:false <br/>  }, <br/>  “payload”:”{\”foo\”:\”bar\”}” <br/>}</span></pre><p id="361b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这比我们在没有<code class="du lg lh li kx b">WITHUNWRAP</code>的情况下得到的要好，但并不完全是我们所希望的。为了获得写入表列的JSON值，我们需要更新<code class="du lg lh li kx b">connect-distributed.properties</code>文件。打开这个找<code class="du lg lh li kx b">JsonConverter</code>。用以下内容替换这些行:</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="e984" class="lb ju hh kx b fi lc ld l le lf">key.converter=org.apache.kafka.connect.storage.StringConverter value.converter=org.apache.kafka.connect.storage.StringConverter</span></pre><p id="b8d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">重启Kafka Connect。<br/>在表格中插入另一行。现在我们应该得到我们想要的了。</p><pre class="je jf jg jh fd kw kx ky kz aw la bi"><span id="012c" class="lb ju hh kx b fi lc ld l le lf">{ “foo”:”bar” }</span></pre><p id="08e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码快乐！</p><p id="3cbb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这最初出现在TheAgileJedi的博客上</p></div></div>    
</body>
</html>