<html>
<head>
<title>Understand Machine Learning With An Example In R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用R中的一个例子理解机器学习</h1>
<blockquote>原文：<a href="https://medium.com/edureka/machine-learning-with-r-c7d3edf1f7b?source=collection_archive---------6-----------------------#2018-06-14">https://medium.com/edureka/machine-learning-with-r-c7d3edf1f7b?source=collection_archive---------6-----------------------#2018-06-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/183740fd348ed8bdc3987501ddfffce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*VCleY-n08aSnO6C8Xy7fSw.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Machine Learning with R — Edureka</figcaption></figure><p id="98ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">机器学习是现在，也是未来！从网飞的推荐引擎到谷歌的自动驾驶汽车，都是机器学习。这篇关于用R实现机器学习的文章帮助你理解机器学习的核心概念，以及不同的机器学习算法和用R实现这些机器学习算法。</p><p id="2294" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本文由以下几部分组成:</p><ul class=""><li id="4051" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">理解机器学习</li><li id="fb4f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">机器学习算法的类型</li><li id="10b0" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">用R实现机器学习算法</li></ul><h1 id="6f60" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">理解机器学习</h1><ul class=""><li id="f4ff" class="jn jo hh ir b is kz iw la ja lb je lc ji ld jm js jt ju jv bi translated">机器学习算法的类型</li><li id="0fe4" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">用R实现机器学习算法</li></ul><h1 id="125a" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">理解机器学习</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/29e195a767bf32ca02f36f79d6ecd911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXJi9qxH1ZiFJE0qP4aKRQ.png"/></div></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/be82907d46d107e743764677d8bedc90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fXLVGHHdrdsmr3jBUA0gzA.png"/></div></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/63b1329be731279afd920f16a7fc3736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IAmVAxpoaSNYbX4lchdsSA.png"/></div></div></figure><p id="28b5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你怎么知道这些都是鱼？</p><p id="d1be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">作为一个孩子，你可能会看到一张鱼的照片，你的幼儿园老师或父母会告诉你这是一条鱼，它有一些特定的特征，比如它有鳍，鳃，一双眼睛，一条尾巴等等。现在，每当你的大脑遇到具有这些特征的图像，它会自动将其注册为一条鱼，因为你的大脑<em class="ln">已经</em>知道它是一条鱼。</p><p id="f370" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就是我们大脑的运作方式，但是机器呢？如果把同样的图像输入机器，机器将如何识别它是一条鱼？</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/18f333b2400038d59034ff2bc88d5e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aEoH5Rtrhuf8W9U_tkzJ8w.png"/></div></div></figure><p id="f97f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就是M <em class="ln"> achine Learning </em>的用武之地。我们将继续向带有“鱼”标签的计算机输入鱼的图像，直到<em class="ln">机器学习到与<em class="ln">鱼相关的</em>的所有特征。</em></p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/a48132b14d520243bf3c12d5626a2f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J483RIogoNwjlmMADRF1DQ.png"/></div></div></figure><p id="72eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦机器学习了与鱼相关的所有特征，我们将向它输入新数据，以确定它学习了多少。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/801317df0df876e2622264baaa893441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7he9uMLgvt7KOvUIqDrtKw.png"/></div></div></figure><p id="7322" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">换句话说，<em class="ln">原始数据/训练数据</em>被提供给机器，因此它<em class="ln">学习</em>与<em class="ln">训练数据相关的所有特征。</em>一旦学习完成，它将获得<em class="ln">新数据/测试数据</em>以确定机器学习的程度。</p><p id="d4f6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们在这篇关于机器学习的文章中继续前进，了解机器学习的类型。</p><h1 id="55a8" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">机器学习的类型</h1><h2 id="171b" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">监督学习:</h2><p id="cad9" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">监督学习算法从具有标签的已知数据集(训练数据)中学习，以进行预测。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/20d9d1972aaae803355aa24a556a7dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZW8vmR9RktECzBueijnxyg.png"/></div></div></figure><p id="b62c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回归和分类是监督学习的一些例子。</p><p id="95bd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="ln">分类:</em> </strong></p><p id="0ae7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">分类确定新的观察值属于哪一组类别，即分类算法学习训练数据的所有特征和标签，并且当新的数据被提供给它时，它必须根据它从训练数据中学习到的内容为新的观察值分配标签。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/f01e22877afc8fb4a5c2bc92acc4df78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tcFvp3pzBMo1SgEv2W2K0w.png"/></div></div></figure><p id="e5be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于这个例子，如果第一个观察被赋予标签“男人”,那么它被正确地分类，但是如果它被赋予标签“女人”,那么分类是错误的。类似地，对于第二个观察，如果给定的标签是“女人”，它被正确地分类，否则分类是错误的。</p><p id="d363" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="ln">回归:</em> </strong></p><p id="c0f5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回归是一种监督学习算法，有助于确定一个变量如何影响另一个变量。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/8e0d5a13b9abb4c796a70c682cf3d3ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ZJlyxEpFjyGCH2YrWYA9Q.png"/></div></div></figure><p id="52b2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这里，“居住面积”是自变量，“价格”是因变量，即我们确定“价格”如何随“居住面积”而变化。</p><h2 id="e826" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">无监督学习:</h2><p id="c982" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">无监督学习算法从没有标签的数据中进行推理。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mf"><img src="../Images/3635651cf7900a328b6d98ad677bde52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwFNkeaZbl_2HX3Er_G5Ig.png"/></div></div></figure><p id="3fb2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ln">聚类</em>就是无监督学习的一个例子。“K-均值”、“分层”、“模糊C-均值”是聚类算法的一些例子。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/cf9c90d70f0297c85807c26f0dfcebc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-nlMZz3E_1GXZMEvz6WLCA.png"/></div></div></figure><p id="f1e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这个例子中，观察值集合被分成两个集群。聚类是基于观察值之间的相似性来完成的。存在高的组内相似性和低的组间相似性，即，在所有公共汽车之间存在非常高的相似性，但是在公共汽车和汽车之间存在低的相似性。</p><h2 id="a6d3" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">强化学习:</h2><p id="50d7" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">强化学习是一种机器学习算法，其中在<em class="ln">环境</em>中的<em class="ln">机器/代理</em>学习理想的行为以最大化其性能。代理人需要简单的奖励反馈来学习它的行为，这被称为<em class="ln">强化信号</em>。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/dbad8752285ce43d697d51050129c56c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-TcapTsw1e7mppc7mKGfA.png"/></div></div></figure><p id="6f6f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">就拿<em class="ln">吃豆人</em>来说吧。只要吃豆人继续吃食物，它就能获得积分，但当它撞上怪物时，它就失去了生命。因此，吃豆人知道它需要吃更多的食物，并避免怪物，以提高其性能。</p><h1 id="db00" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">用R实现机器学习；</h1><h2 id="4dca" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">线性回归:</h2><p id="5b2e" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">我们将使用diamonds数据集来实现线性回归算法:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/6a48661a16094979fd77e5272acd9524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*d6YMhKBOhiiMDKpdO1EQew.png"/></div></figure><p id="abee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数据集的描述:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/04e47aed82f978169c70b050b9d7036b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*4EDN8vcfcCMV6Rtpi3ZeGQ.png"/></div></figure><p id="ab17" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在对数据建立任何模型之前，我们应该将数据分成“训练”和“测试”集。该模型将在“列车”装置上建立，其准确性将在“测试”装置上检查。</p><p id="7935" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们需要加载“caTools”包来将数据分成两组。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="41e7" class="lo kc hh mj b fi mn mo l mp mq">library(caTools)</span></pre><p id="04b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“caTools”包提供了一个函数“sample.split()”，有助于拆分数据。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="19a9" class="lo kc hh mj b fi mn mo l mp mq">sample.split(diamonds$price,SplitRatio = 0.65)-&gt;split_index</span></pre><p id="db25" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">价格列中65%的观察值被指定为“真”标签，其余35%被指定为“假”标签。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="3ccd" class="lo kc hh mj b fi mn mo l mp mq">subset(diamonds,split_index==T)-&gt;train subset(diamonds,split_index==F)-&gt;test</span></pre><p id="f720" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所有具有“真”标签的观察值已被存储在“<em class="ln">训练”对象</em>中，而那些具有“假”标签的观察值已被分配给“测试”组。</p><p id="3b8c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，拆分已经完成，我们有了“训练”和“测试”集，是时候在训练集上构建线性回归模型了。</p><p id="4e55" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将使用“lm()”函数来构建“train”数据的线性回归模型。我们根据数据集的所有其他变量来确定钻石的价格。构建的模型存储在对象“mod _ regressive”中。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="7880" class="lo kc hh mj b fi mn mo l mp mq">lm(price~.,data = train)-&gt;mod_regress</span></pre><p id="b546" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们已经建立了模型，我们需要对“测试”集进行预测。“predict()”函数用于获得预测值。它需要两个参数:T2制造的模型T3和T4测试集。预测结果存储在“result _ regressive”对象中。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="763c" class="lo kc hh mj b fi mn mo l mp mq">predict(mod_regress,test)-&gt;result_regress</span></pre><p id="0a6f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们使用“cbind()”函数将“测试”数据集中的实际价格值和预测值绑定到一个数据集中。新的数据帧存储在“最终数据”中</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="c327" class="lo kc hh mj b fi mn mo l mp mq">cbind(Actual=test$price,Predicted=result_regress)-&gt;Final_Data</span><span id="7e60" class="lo kc hh mj b fi mr mo l mp mq">as.data.frame(Final_Data)-&gt;Final_Data</span></pre><p id="553a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">浏览由实际值和预测值组成的“最终数据”:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/c1a9d5780d085a0a2693f7a137fd5693.png" data-original-src="https://miro.medium.com/v2/resize:fit:332/format:webp/1*RzezBtnc-QlQPA0AN8mtdA.png"/></div></figure><p id="ba30" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们通过从实际值中减去预测值来找出误差，并将该误差作为新列添加到“Final_Data”中:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="488d" class="lo kc hh mj b fi mn mo l mp mq">(Final_Data$Actual- Final_Data$Predicted)-&gt;error</span><span id="abf7" class="lo kc hh mj b fi mr mo l mp mq">cbind(Final_Data,error)-&gt;Final_Data</span></pre><p id="a8ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“最终数据”也包括预测误差:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/5cbecc9f09137fb2ce0e19c62c3da550.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*NU2G0PTyNj-_ldjzAt-kRw.png"/></div></figure><p id="b2ee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们将继续计算"<em class="ln">均方根误差"</em>，它给出了所有预测的总误差</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="68b7" class="lo kc hh mj b fi mn mo l mp mq">rmse1&lt;-sqrt(mean(Final_Data$error^2))</span><span id="6c6d" class="lo kc hh mj b fi mr mo l mp mq">rmse1</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/92d40c6c3100933b61e6f508e5c21c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/format:webp/1*Qy1uNxODCFTdwBGKHXpNpQ.png"/></div></figure><p id="ff16" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，让我们建立另一个模型，以便我们可以比较这两个模型的准确性，并确定哪个模型更好。</p><p id="3c94" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将在“train”集合上建立一个新的线性回归模型，但这一次，我们将从独立变量中删除“x”和“y”列，即钻石的“价格”由除“x”和“y”之外的所有列决定。</p><p id="d37d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">建立的模型存储在“mod _ regression 2”中:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="91e0" class="lo kc hh mj b fi mn mo l mp mq">lm(price~.-y-z,data = train)-&gt;mod_regress2</span></pre><p id="4714" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">预测结果存储在“result _ regression 2”中</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="9961" class="lo kc hh mj b fi mn mo l mp mq">predict(mod_regress2,test)-&gt;result_regress2</span></pre><p id="aecc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">实际值和预测值合并存储在“Final_Data2”中:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="34da" class="lo kc hh mj b fi mn mo l mp mq">cbind(Actual=test$price,Predicted=result_regress2)-&gt;Final_Data2</span><span id="81cd" class="lo kc hh mj b fi mr mo l mp mq">as.data.frame(Final_Data2)-&gt;Final_Data2</span></pre><p id="3e66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们也将预测中的误差添加到“Final_Data2”中</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="8a85" class="lo kc hh mj b fi mn mo l mp mq">(Final_Data2$Actual- Final_Data2$Predicted)-&gt;error2</span><span id="81b1" class="lo kc hh mj b fi mr mo l mp mq">cbind(Final_Data2,error2)-&gt;Final_Data2</span></pre><p id="858f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“Final_Data2”一瞥:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/5cbecc9f09137fb2ce0e19c62c3da550.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*NU2G0PTyNj-_ldjzAt-kRw.png"/></div></figure><p id="9847" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">寻找均方根误差以获得总误差:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="17f7" class="lo kc hh mj b fi mn mo l mp mq">rmse2&lt;-sqrt(mean(Final_Data2$error^2))</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/6d87d208a88f552a54a27ace79b0a33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/0*K68z82DHTN7skrfb.png"/></div></figure><p id="342d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们看到“rmse2”略小于“rmse1”，因此第二个模型略好于第一个模型。</p><h2 id="6874" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">分类:</h2><p id="a1ac" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">我们将使用“car_purchase”数据集来实现分类算法<em class="ln">递归分区</em>。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/8232c5173a5b02fbc53327a9f897f5eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*mlQMDFALksOWJzwcKwvIug.png"/></div></figure><p id="ed76" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们使用“caTools”包中的“sample.split()”函数将数据分成“训练”和“测试”组。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="f57e" class="lo kc hh mj b fi mn mo l mp mq">library(caTools)</span></pre><p id="e2d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“已购买”栏中65%的观察值将被指定为“真”标签，其余的将被指定为“假”标签。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="86e8" class="lo kc hh mj b fi mn mo l mp mq">sample.split(car_purchase$Purchased,SplitRatio = 0.65)-&gt;split_values</span></pre><p id="59c1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所有那些具有“真”标签的观察值将被存储到“训练”数据中，而那些具有“假”标签的观察值将被分配给“测试”数据。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="24e6" class="lo kc hh mj b fi mn mo l mp mq">subset(car_purchase,split_values==T)-&gt;train_data</span><span id="a909" class="lo kc hh mj b fi mr mo l mp mq">subset(car_purchase,split_values==F)-&gt;test_data</span></pre><p id="9f45" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">构建递归分区算法的时间:</p><p id="71b5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将从加载“rpart”包开始:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="6b2a" class="lo kc hh mj b fi mn mo l mp mq">library(rpart)</span></pre><p id="9aed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“已购买”列将是因变量，所有其他列都是自变量，即我们将根据所有其他列来确定此人是否购买了汽车。模型建立在“train_data”上，结果存储在“mod1”中。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="4ce1" class="lo kc hh mj b fi mn mo l mp mq">rpart(Purchased~.,data = train_data)-&gt;mod1</span></pre><p id="7411" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们画出结果:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="539c" class="lo kc hh mj b fi mn mo l mp mq">plot(mod1,margin = 0.1)<!-- --> <!-- -->text(mod1,pretty = T,cex=0.8)</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mx"><img src="../Images/fcb8d411450741c33b9846fa383b9dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-eRopZU4pNSktk-lhMkxA.png"/></div></figure><p id="24e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们继续在“test_data”上预测结果。我们将构建的rpart模型“mod1”作为第一个参数，测试集“test_data”作为第二个参数，预测类型作为第三个参数的“class”。结果存储在“result1”对象中。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="2997" class="lo kc hh mj b fi mn mo l mp mq">predict(mod1,test_data,type = "class")-&gt;result1</span></pre><p id="f763" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们使用caret包中的“confusionMatrix()”函数来评估模型的准确性。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="76ab" class="lo kc hh mj b fi mn mo l mp mq">library(caret)<!-- --> <!-- -->confusionMatrix(table(test_data$Purchased,result1))</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es my"><img src="../Images/e7f8ee347d07807a1ed24a0730770337.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*c7DDTb96NGEKnDngL3SJlw.png"/></div></figure><p id="e793" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">混淆矩阵告诉我们，在这个人没有买车的90次观察中，79次观察被正确地归类为“否”，11次被错误地归类为“是”。类似地，在这个人实际购买汽车的50次观察中，47次被正确地分类为“是”，3次被错误地分类为“否”。</p><p id="ec35" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以通过将正确预测除以总预测，即(79+47)/(79+47+11+3)，来确定模型的准确性。</p><h2 id="76fb" class="lo kc hh bd kd lp lq lr kh ls lt lu kl ja lv lw kp je lx ly kt ji lz ma kx mb bi translated">k均值聚类:</h2><p id="e9c8" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja mc jc jd je md jg jh ji me jk jl jm ha bi translated">我们将使用“iris”数据集来实现k-means聚类:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mz"><img src="../Images/dba2eb11d64a9dab1cb1a41236f13fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*zmLqH22k2nkslr3wQy0Hjg.png"/></div></figure><p id="573f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们删除“物种”列，并创建一个新的数据集，该数据集仅包含“iris”数据集的前四列。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="38fa" class="lo kc hh mj b fi mn mo l mp mq">iris[1:4]-&gt;iris_k</span></pre><p id="5031" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们假设集群的数量为3。“Kmeans()”函数接受输入数据和数据将被聚类的聚类数。语法是:kmeans( data，k)其中k是聚类中心的数量。</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="31d8" class="lo kc hh mj b fi mn mo l mp mq">kmeans(iris_k,3)-&gt;k1</span></pre><p id="f525" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">分析聚类:</p><pre class="lf lg lh li fd mi mj mk ml aw mm bi"><span id="d502" class="lo kc hh mj b fi mn mo l mp mq">str(k1)</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es na"><img src="../Images/fdc66ff9c52fcd5b36d07150f6950444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*nRNAnwNPZyDRg4HkwaUS_A.png"/></div></figure><p id="5279" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">str()函数给出了kmeans的结构，其中包括各种参数，如withinss、betweenss等，分析这些参数可以了解kmeans的性能。</p><p id="3d74" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> betweenss : </strong>平方和之间，即聚类内相似性</p><p id="3e16" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">内:</strong>平方和内即簇间相似度</p><p id="0446" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">总相似度:</strong>所有类的所有相似度之和，即总的类内相似度</p><p id="301b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好的聚类将具有较低的“tot.withinss”值和较高的“betweenss”值，这取决于最初选择的聚类数“k”。</p><p id="95ff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">成为机器学习专家的时机已经成熟，可以利用你遇到的新机会。这就把我们带到了这篇“<strong class="ir hi"> <em class="ln">机器学习带R </em> </strong>”文章的结尾。我希望这篇文章是有益的。</p><p id="d802" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于Python、DevOps、Ethical Hacking等市场最热门技术的文章，那么你可以参考<a class="ae nb" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=machine-learning-with-r" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释数据科学的各个方面。</p><blockquote class="nc nd ne"><p id="0461" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 1。</em> <a class="ae nb" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="59a2" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 2。</em> <a class="ae nb" rel="noopener" href="/edureka/math-and-statistics-for-data-science-1152e30cee73"> <em class="hh">数据科学的数学与统计</em> </a></p><p id="f479" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 3。</em><a class="ae nb" rel="noopener" href="/edureka/linear-regression-in-r-da3e42f16dd3"><em class="hh">R中的线性回归</em> </a></p><p id="08e8" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 4。</em> <a class="ae nb" rel="noopener" href="/edureka/machine-learning-algorithms-29eea8b69a54"> <em class="hh">机器学习算法</em> </a></p><p id="5e1a" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 5。</em><a class="ae nb" rel="noopener" href="/edureka/logistic-regression-in-r-2d08ac51cd4f"><em class="hh">R中的逻辑回归</em> </a></p><p id="2632" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 6。</em> <a class="ae nb" rel="noopener" href="/edureka/classification-algorithms-ba27044f28f1"> <em class="hh">分类算法</em> </a></p><p id="3def" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 7。</em> <a class="ae nb" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="5e3d" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 8。</em> <a class="ae nb" rel="noopener" href="/edureka/a-complete-guide-on-decision-tree-algorithm-3245e269ece"> <em class="hh">决策树中的R </em> </a></p><p id="b2b0" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 9。</em> <a class="ae nb" rel="noopener" href="/edureka/introduction-to-machine-learning-97973c43e776"> <em class="hh">机器学习入门</em> </a></p><p id="fee6" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 10。</em> <a class="ae nb" rel="noopener" href="/edureka/naive-bayes-in-r-37ca73f3e85c"> <em class="hh">朴素贝叶斯在R </em> </a></p><p id="e34b" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 11。</em> <a class="ae nb" rel="noopener" href="/edureka/statistics-and-probability-cf736d703703"> <em class="hh">统计与概率</em> </a></p><p id="a01f" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 12。</em> <a class="ae nb" rel="noopener" href="/edureka/decision-trees-b00348e0ac89"> <em class="hh">如何创建一个完美的决策树？</em> </a></p><p id="b85c" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 13。</em> <a class="ae nb" rel="noopener" href="/edureka/data-scientists-myths-14acade1f6f7"> <em class="hh">关于数据科学家角色的10大误区</em> </a></p><p id="7d58" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 14。</em> <a class="ae nb" rel="noopener" href="/edureka/data-science-projects-b32f1328eed8"> <em class="hh">顶级数据科学项目</em> </a></p><p id="0bed" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 15。</em> <a class="ae nb" rel="noopener" href="/edureka/data-analyst-vs-data-engineer-vs-data-scientist-27aacdcaffa5"> <em class="hh">数据分析师vs数据工程师vs数据科学家</em> </a></p><p id="2b59" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 16。</em> <a class="ae nb" rel="noopener" href="/edureka/types-of-artificial-intelligence-4c40a35f784"> <em class="hh">人工智能的种类</em> </a></p><p id="2d04" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 17。</em><a class="ae nb" rel="noopener" href="/edureka/r-vs-python-48eb86b7b40f"><em class="hh">R vs Python</em></a></p><p id="aefc" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 18。</em> <a class="ae nb" rel="noopener" href="/edureka/ai-vs-machine-learning-vs-deep-learning-1725e8b30b2e"> <em class="hh">人工智能vs机器学习vs深度学习</em> </a></p><p id="5811" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 19。</em> <a class="ae nb" rel="noopener" href="/edureka/machine-learning-projects-cb0130d0606f"> <em class="hh">机器学习项目</em> </a></p><p id="6368" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">20。 <a class="ae nb" rel="noopener" href="/edureka/data-analyst-interview-questions-867756f37e3d"> <em class="hh">数据分析师面试问答</em> </a></p><p id="c4c9" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 21。</em> <a class="ae nb" rel="noopener" href="/edureka/data-science-and-machine-learning-for-non-programmers-c9366f4ac3fb"> <em class="hh">面向非程序员的数据科学和机器学习工具</em> </a></p><p id="67c2" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 22。</em> <a class="ae nb" rel="noopener" href="/edureka/top-10-machine-learning-frameworks-72459e902ebb"> <em class="hh">十大机器学习框架</em> </a></p><p id="fa5f" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 23。</em> <a class="ae nb" rel="noopener" href="/edureka/statistics-for-machine-learning-c8bc158bb3c8"> <em class="hh">用于机器学习的统计</em> </a></p><p id="14ec" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 24。</em> <a class="ae nb" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中R </em> </a></p><p id="4bcd" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh">二十五。</em> <a class="ae nb" rel="noopener" href="/edureka/breadth-first-search-algorithm-17d2c72f0eaa"> <em class="hh">广度优先搜索算法</em> </a></p><p id="bd19" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh">二十六。</em><a class="ae nb" rel="noopener" href="/edureka/linear-discriminant-analysis-88fa8ad59d0f"><em class="hh">R中的线性判别分析</em> </a></p><p id="330b" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 27。</em> <a class="ae nb" rel="noopener" href="/edureka/prerequisites-for-machine-learning-68430f467427"> <em class="hh">机器学习的先决条件</em> </a></p><p id="b985" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 28。</em> <a class="ae nb" rel="noopener" href="/edureka/r-shiny-tutorial-47b050927bd2"> <em class="hh">互动WebApps使用R闪亮</em> </a></p><p id="33e6" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 29。</em> <a class="ae nb" rel="noopener" href="/edureka/top-10-machine-learning-books-541f011d824e"> <em class="hh">机器学习十大书籍</em> </a></p><p id="ca89" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 30。</em> <a class="ae nb" rel="noopener" href="/edureka/unsupervised-learning-40a82b0bac64"> <em class="hh">无监督学习</em> </a></p><p id="8c60" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 31。</em> <a class="ae nb" rel="noopener" href="/edureka/10-best-books-data-science-9161f8e82aca"> <em class="hh"> 10本最好的数据科学书籍</em> </a></p><p id="4b70" class="ip iq ln ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated"><em class="hh"> 32。</em> <a class="ae nb" rel="noopener" href="/edureka/supervised-learning-5a72987484d0"> <em class="hh">监督学习</em> </a></p></blockquote></div><div class="ab cl ni nj go nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ha hb hc hd he"><p id="afab" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ln">原载于2018年6月14日</em><a class="ae nb" href="https://www.edureka.co/blog/machine-learning-with-r" rel="noopener ugc nofollow" target="_blank"><em class="ln">www.edureka.co</em></a><em class="ln">。</em></p></div></div>    
</body>
</html>