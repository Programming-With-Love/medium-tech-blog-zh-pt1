<html>
<head>
<title>Tracker: Ingesting MySQL data at scale — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">追踪器:大规模获取MySQL数据—第2部分</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/tracker-ingesting-mysql-data-at-scale-part-2-9c5249e9332a?source=collection_archive---------3-----------------------#2016-08-16">https://medium.com/pinterest-engineering/tracker-ingesting-mysql-data-at-scale-part-2-9c5249e9332a?source=collection_archive---------3-----------------------#2016-08-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d48f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Robert Wultsch | Pinterest工程师</p><p id="3567" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在<a class="ae jc" href="https://engineering.pinterest.com/blog/tracker-ingesting-mysql-data-scale-part-1" rel="noopener ugc nofollow" target="_blank">第1部分</a>中，我们讨论了吸收MySQL的现有架构Tracker，包括它的优势、挑战和新架构的概要，重点是Hadoop方面。这里我们将关注MySQL端的实现细节。上传到S3的数据已经作为<a class="ae jc" href="https://github.com/pinterest/mysql_utils" rel="noopener ugc nofollow" target="_blank"> Pinterest MySQL Utils </a>的一部分被开源。</p><h2 id="5378" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">跟踪器V-0</h2><p id="bc41" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">作为概念验证，我们编写了一个96行的Bash脚本来解除对新数据集的备份的阻塞。这个脚本产生了一群工人，每个工人一次处理一个数据库。对于数据库中的每个表，它将SELECT运行到OUTFILE，然后将数据上传到S3。它起作用了，但是BASH……而且那不是一个长期的解决方案。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es kd"><img src="../Images/1c03b4447d87b5236ebcd3ec282abf21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A0EsQ8Vq9xEow87F.png"/></div></div></figure><h2 id="6dc2" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">跟踪器V-1</h2><p id="6a6d" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">为了我们的可维护实现，我们将Bash脚本重写为一个名为<a class="ae jc" href="https://github.com/pinterest/mysql_utils/blob/master/mysql_backup_csv.py" rel="noopener ugc nofollow" target="_blank"> mysql_backup_csv.py </a>的Python脚本。唯一显著的区别(除了让我们不要自我感觉不好)是我们添加了lzop压缩，以减少S3中的数据量。为什么是lzop？我们认为这将是最轻的压缩工具，带有命令行界面，可以从apt-get安装。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kp"><img src="../Images/006589f947a99a89884390479e3b7456.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*kPPhx4ir4umHT7Zh.png"/></div></figure><p id="12b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在我们庞大的分片MySQL车队上测试了这个，它很慢。非常慢，慢了8个小时。</p><h2 id="4297" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">加快速度</h2><p id="a59a" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">我们现在有了一个可维护的工具，可以将我们的MySQL数据上传到S3。问题是该工具处理所有数据的速度不够快，我们的团队无法满足他们的SLA。我们需要显著提高整体吞吐量，因此我们着手进行了以下工作:</p><ul class=""><li id="567d" class="kq kr hh ig b ih ii il im ip ks it kt ix ku jb kv kw kx ky bi translated">实现锁定，以便多个从模块可以协作地并行转储。锁是通过主服务器上的一个简单的表来维护的。这使我们能够在大约3.5小时内转储所有数据。太慢了！</li><li id="8545" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb kv kw kx ky bi translated">跳过写入磁盘。MySQL的Percona发行版有一个非常有趣的特性，即<a class="ae jc" href="https://www.percona.com/doc/percona-server/5.5/flexibility/extended_select_into_outfile.html#extended-select-into-outfile" rel="noopener ugc nofollow" target="_blank"> SELECT INTO OUTFILE可以写入FIFO </a>。实际上，我们必须转储所有的数据，然后从文件系统中读回这些数据。使用一个<a class="ae jc" href="https://en.wikipedia.org/wiki/Named_pipe" rel="noopener ugc nofollow" target="_blank"> fifo </a>，我们可以构建一个根本不需要写入本地文件系统的管道！这使我们大约1小时，这远远低于我们的要求。</li></ul><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es le"><img src="../Images/a68a1b670349c66aab0b368f8df5e160.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*W7FrmLOgFBGGgE7Z.png"/></div></figure><h2 id="b938" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">慢下来</h2><p id="f5dd" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">根据<a class="ae jc" href="http://dev.mysql.com/doc/refman/5.7/en/select-into.html" rel="noopener ugc nofollow" target="_blank">精细手册</a>(这是在超老的手册里):<br/>“ASCII NUL被转义，以便更容易用一些寻呼机查看。”</p><p id="45eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">！@#()U@！#!！！</p><p id="4a30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们不得不编写一个名为<a class="ae jc" href="http://github.com/pinterest/mysql_utils/blob/master/NullEscape.c" rel="noopener ugc nofollow" target="_blank"> nullescape </a>的C程序来对数据进行转义。&amp; *(@！#!</p><p id="13dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将这一点添加到我们的管道中，导致我们的服务器燃烧了四个内核，只是为了避免NUL字节。这使我们转储所有数据的时间减少到1.5小时。这仍然在我们的要求之内，给我们留下了一点喘息的空间。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es lf"><img src="../Images/037df0b0b8734b1e81dbd4c3292a8d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7J3tQPfwUr1JLaHc.png"/></div></div></figure><h2 id="8b04" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">赢得与EOF的比赛</h2><p id="09e6" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">该系统的一个问题是必须阻止部分上传。如果管道中有任何东西失败，就可能发生部分上传。当一个Linux程序终止时(不管如何或为什么)，它打开的文件句柄将关闭。如果文件句柄指向一个FIFO，FIFO的读取器将接收到一个<a class="ae jc" href="https://en.wikipedia.org/wiki/End-of-file" rel="noopener ugc nofollow" target="_blank"> EOF </a>，而没有任何将数据送入FIFO的过程成功或失败的指示。</p><p id="4b13" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么，这有什么关系呢？嗯，转储查询有时会被终止，nullescape的早期版本偶尔会出现segfault。当任何一种情况发生时，管道的其余部分将认为不再有数据到来。捕捉非零返回状态并删除上传的数据是可能的，但这有点太过了，最终比赛会失败。</p><p id="76e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们讨论了很多次，我们得出的最佳解决方案是一个位于管道中s3gof3r之前的程序。这个程序将从stdin到stdout重复它的输入，但是只有当管道中的所有程序都成功时才传输一个EOF。这个程序叫做<a class="ae jc" href="https://github.com/pinterest/mysql_utils/blob/master/safe_uploader.py" rel="noopener ugc nofollow" target="_blank"> safe_uploader </a>，最终非常轻便。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="er es lg"><img src="../Images/6a77ce9953e2dbe408b5f842e45fb0d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cyzICvbYeBP1Ea2c.png"/></div></div></figure><p id="63c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">起初，safe_uploader中有一些微妙的错误，导致了<a class="ae jc" href="https://en.wikipedia.org/wiki/Zombie_process" rel="noopener ugc nofollow" target="_blank">僵尸</a>和<a class="ae jc" href="https://en.wikipedia.org/wiki/Orphan_process" rel="noopener ugc nofollow" target="_blank">孤儿</a>进程，但是一旦我们修复了这些错误，它们就不再出现在数据库服务器上了。</p><h2 id="4059" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">系统性改进</h2><p id="17b0" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">与之前的系统相比，该项目显著提高了所得数据的可用性，并减少了操作问题:</p><ol class=""><li id="5f55" class="kq kr hh ig b ih ii il im ip ks it kt ix ku jb lh kw kx ky bi translated">我们增加了对MySQL二进制类型的支持。在备份过程中，我们没有对二进制列使用十六进制编码(这会使备份文件的大小加倍)，而是选择对一些特殊字符使用转义(例如，\n，\t，\ r)；</li></ol><ul class=""><li id="f49b" class="kq kr hh ig b ih ii il im ip ks it kt ix ku jb kv kw kx ky bi translated">Hadoop内置的TextInputFormat无法读取换行符转义的备份，所以我们为Hadoop/HIVE编写了自己的EscapedTextInputFormat</li><li id="dd40" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb kv kw kx ky bi translated">我们在Hadoop流端为这个特殊的TextInputFormat做了一个修复</li><li id="1b39" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb kv kw kx ky bi translated">我们为Python客户机重写了CSV解析器，以读取新的备份文件</li></ul><ol class=""><li id="855d" class="kq kr hh ig b ih ii il im ip ks it kt ix ku jb lh kw kx ky bi translated">我们为所有备份文件添加了一致的数据保留策略，并对HIVE表进行了自动调整，以确保其模式始终与MySQL模式保持同步。</li><li id="c372" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb lh kw kx ky bi translated">由于所有的数据都被导入到MySQL中而没有进行重大修改，我们现在有了一个辅助备份系统。这对于少量的数据丢失很有用。恢复xtrabackup需要几个小时，但是从Hive中提取一行或一个小表非常快，而且更好的是，不需要DBA的帮助！</li><li id="921a" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb lh kw kx ky bi translated">当发生故障转移时，cron运行的一个<a class="ae jc" href="https://github.com/pinterest/mysql_utils/blob/master/kill_backups.py" rel="noopener ugc nofollow" target="_blank">小脚本</a>会终止正在运行的备份。在过去，这需要为dumper框架删除MySQL用户。通常，这也会导致DBA团队和Data-Eng在凌晨时分互相呼叫。</li><li id="18f1" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb lh kw kx ky bi translated">我们的备份现在在模式级别上完全一致，并且通常在几秒钟内在副本集上一致。对于跨片数据一致性检查来说，这是一个很大的改进。</li><li id="c5c0" class="kq kr hh ig b ih kz il la ip lb it lc ix ld jb lh kw kx ky bi translated">tracker将从属服务器推得非常非常紧的一个意想不到的好处是，我们每天晚上都在有效地运行一个基准测试，这对我们的从属服务器造成了很大的压力。我们会不时地从生产中移除速度较慢的服务器。</li></ol><p id="7f5c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tracker现已全面投产，能够在两小时内将我们所有的MySQL数据转移到S3。</p><h2 id="17ef" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">未来的工作</h2><p id="c5bc" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">我们不会停在这里。我们意识到，对于某些表，每日变化实际上不足以保证完整的快照拉取，因此我们正在构建一个增量拉取管道，将MySQL二进制日志转换为Kafka流。然后，这将被增量推送至S3，并随后与之前的快照进行压缩，以获得持续更新的快照。敬请期待！</p><p id="655d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="li">鸣谢:感谢Henry Cai、Krishna Gade、Vamsi Ponnekanti、叶茂和Ernie Souhrada对Tracker项目做出的宝贵贡献。</em></p><p id="325c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有关Pinterest工程新闻和更新，请关注我们的工程<a class="ae jc" href="https://www.pinterest.com/malorie/pinterest-engineering-news/" rel="noopener ugc nofollow" target="_blank"> Pinterest </a>、<a class="ae jc" href="https://www.facebook.com/pinterestengineering" rel="noopener ugc nofollow" target="_blank">脸书</a>和<a class="ae jc" href="https://twitter.com/PinterestEng" rel="noopener ugc nofollow" target="_blank"> Twitter </a>。有兴趣加入团队吗？查看我们的<a class="ae jc" href="https://careers.pinterest.com/careers" rel="noopener ugc nofollow" target="_blank">职业网站</a>。</p></div></div>    
</body>
</html>