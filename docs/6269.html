<html>
<head>
<title>Scaling Cache Infrastructure at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">扩展Pinterest的缓存基础设施</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/scaling-cache-infrastructure-at-pinterest-422d6d294ece?source=collection_archive---------0-----------------------#2020-12-10">https://medium.com/pinterest-engineering/scaling-cache-infrastructure-at-pinterest-422d6d294ece?source=collection_archive---------0-----------------------#2020-12-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0bc1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">林义杰|软件工程师，存储和缓存</p><p id="3e1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着越来越多的Pinterest用户到Pinterest寻找灵感，对Pinterest核心基础设施系统的需求正以前所未有的速度增长。面向许多服务和数据库的分布式缓存层是我们的核心存储系统之一，位于Pinterest基础设施堆栈的底部，负责吸收这一增长所驱动的绝大多数后端流量。</p><p id="b2ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinterest的分布式缓存车队跨越由数千台机器组成的EC2实例足迹，缓存数百TB的数据，峰值时每秒超过1.5亿次请求。该缓存层通过降低整个后端堆栈的延迟来优化顶级性能，并通过减少昂贵的后端所需的容量来提供显著的成本效益。我们将对支持Pinterest大规模缓存车队的基础设施进行深入的技术探讨。</p><h1 id="e924" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">应用程序数据缓存</h1><p id="ef53" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">每个传入Pinterest内部的API请求都会通过堆栈扇出到一个复杂的RPC树，在完成其关键路径之前会触及数十个服务。这可以包括查询核心数据(如电路板和引脚)的服务、提供相关引脚的推荐系统以及垃圾邮件检测系统。在这些层中的许多层，只要输入数据可以用唯一的键描述，离散工作单元的结果可以缓存在临时存储中以供将来重用。</p><p id="bede" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Pinterest，分布式缓存层最常见的用途是存储带有后备语义的中间计算结果。这使得缓存层能够吸收大量流量，否则这些流量将流向计算成本高或存储成本高的服务和数据库。凭借个位数毫秒级尾部延迟和极低的每请求基础设施成本，分布式缓存层提供了一种高性能且经济高效的机制来扩展各种后端，以满足不断增长的Pinterest需求。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/69380c92375f65793aa5cae622f32a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OxwhPh9_Z4Q4KgyY"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx"><em class="kv">Figure 1: Highly simplified lifecycle of an API request through Pinterest’s main API service, its dependency service backends, and the distributed cache layer.</em></figcaption></figure><p id="035f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将分布式缓存层作为服务提供，使应用程序开发人员能够专注于实现业务逻辑，而不必担心分布式数据一致性、高可用性或内存容量。缓存客户端使用通用路由抽象层，确保应用程序具有容错和一致的数据视图。此外，服务器群可以独立于应用层进行横向扩展，从而透明地调整内存或吞吐量，以适应资源使用情况的变化。</p><h1 id="547f" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">分布式缓存的支柱:Memcached和Mcrouter</h1><p id="3309" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Memcached和mcrouter构成了Pinterest分布式缓存基础设施的主干，在Pinterest的存储基础设施堆栈中发挥着关键作用。M <a class="ae kw" href="https://github.com/memcached/memcached" rel="noopener ugc nofollow" target="_blank"> emcached </a>是一个用纯c语言编写的开源、高效、内存中的键值存储。M <a class="ae kw" href="https://github.com/facebook/mcrouter" rel="noopener ugc nofollow" target="_blank"> crouter </a>是一个<a class="ae kw" href="https://en.wikipedia.org/wiki/OSI_model#Layer_7:_Application_Layer" rel="noopener ugc nofollow" target="_blank">第7层</a> memcached协议代理，位于memcached车队的前面，提供强大的高可用性和路由功能。</p><p id="69c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Memcached作为缓存解决方案是一个有吸引力的选择:</p><ul class=""><li id="3f06" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">部分由于其异步事件驱动架构和多线程处理模型，memcached非常高效，并且易于进行水平扩展以满足容量需求。</li><li id="cd63" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><a class="ae kw" href="https://github.com/memcached/memcached/wiki/Extstore" rel="noopener ugc nofollow" target="_blank"> Extstore </a>通过位于实例的NVMe闪存磁盘上的二级热存储层，帮助实现令人难以置信的存储效率优势。</li><li id="59d4" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">Memcached刻意简化的体系结构提供了在其上构建抽象的灵活性，并提供了简单的水平可伸缩性来满足不断增长的需求。单个memcached进程本身就是一个简单的键值存储，并且故意不知道它的对等体，甚至不知道memcached集群的概念。</li><li id="31a9" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">Memcached在过去几十年的发展中已经在准确性和性能方面经受了考验，并被一个活跃的开源社区所包围(该社区也接受了上游的几个Pinterest补丁)。</li><li id="a38b" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">Memcached附带了对TLS终止的本机支持，允许我们通过相互TLS认证的流量来保护整个车队(内部构建了额外的基于<a class="ae kw" href="https://spiffe.io/" rel="noopener ugc nofollow" target="_blank"> SPIFFE </a>的授权访问控制)。</li></ul><p id="0561" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Mcrouter是脸书在2014年开源的，并且<a class="ae kw" href="https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf" rel="noopener ugc nofollow" target="_blank">在扩展他们的memcached部署</a>中发挥了至关重要的作用。出于类似的原因，它非常适合Pinterest的架构:</p><ul class=""><li id="7982" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">Mcrouter作为整个memcached服务器群的有效抽象，为应用程序开发人员提供了与整个缓存群交互的单一端点。此外，使用mcrouter作为系统的单一接口可确保Pinterest上所有服务和机器的通用、全球一致的流量行为。</li><li id="041d" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">Mcrouter提供了一个解耦的控制平面和数据平面:memcached服务器群的整个拓扑被组织成“池”(逻辑集群)，而所有请求路由策略和指示客户端与服务器池之间交互的行为都是独立管理的。</li><li id="ffcf" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">Mcrouter的配置API为复杂的路由行为提供了强大的<a class="ae kw" href="https://github.com/facebook/mcrouter/wiki/List-of-Route-Handles" rel="noopener ugc nofollow" target="_blank">构建模块，包括区域关联路由、数据冗余复制、多级缓存层和影子流量。</a></li><li id="fcda" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">作为使用<a class="ae kw" href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt" rel="noopener ugc nofollow" target="_blank"> memcached的ASCII协议</a>的第7层代理，mcrouter公开了智能协议特定的功能，如请求操作(TTL修改、动态压缩等)。</li><li id="acde" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">丰富的可观察性特性是免费提供给客户端应用程序的，提供了对我们所有基础设施上的memcached流量的详细可见性。对我们来说最重要的是百分比请求延迟、沿单个客户端和服务器维度划分的吞吐量、按关键前缀和关键模式划分的请求趋势，以及检测行为不当的服务器的错误率。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/673e513759205e07bcc9b4a52a0bc567.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mI1oM7q3nW84kFoz"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx"><em class="kv">Figure 2: Overview of request routing from mcrouter to memcached. Every key prefix is associated with a routing policy; two examples are shown.</em></figcaption></figure><p id="1e3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在实践中，mcrouter被部署为服务托管的进程外代理sidecar。如图2所示，应用程序(用任何语言编写)在回环上向mcrouter发送memcached协议请求，mcrouter将这些请求代理到数千个上游memcached服务器。这种架构允许我们在<em class="ll">完全管理的</em>缓存服务器群中构建健壮的功能，对消费服务完全透明。</p><p id="0047" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ll">虽然memcached从早期就已经是Pinterest基础设施堆栈的一部分，但我们围绕扩展其客户端对等物的策略已经在这些年里发生了显著的变化。具体来说，路由和发现首先是在客户端库中完成的(客户端库很脆弱，需要二进制部署)，然后是内部构建的路由代理(它不提供可扩展的构建块来实现高可用性)，最后是mcrouter。</em></p><h1 id="556b" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">计算和存储效率</h1><p id="b43e" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Memcached非常高效:单个r5.2xlarge EC2实例能够支持每秒超过10万个请求和数万个并发TCP连接，而没有明显的客户端延迟下降，这使得memcached Pinterest成为吞吐量效率最高的生产服务。这部分是由于编写良好的C及其架构，它利用多个工作线程独立运行一个“libevent”驱动的事件循环来服务传入的连接。</p><p id="bbcb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Pinterest，memcached的extstore在存储效率方面取得了巨大的胜利，从视觉搜索到个性化搜索推荐引擎。除了DRAM之外，Extstore还将缓存数据容量扩展到本地装载的NVMe闪存盘，从而将每个实例的可用存储容量从大约55 GB (r5.2xlarge)增加到近1.7 TB (i3.2xlarge)，而实例成本只是其一小部分。在实践中，尽管DRAM和SSD响应时间相差几个数量级，但extstore在不牺牲端到端延迟的情况下，使数据容量受限的用例受益。Extstore的内置调优旋钮使我们能够找到一个平衡点，平衡磁盘I/O、磁盘到内存的重新缓存率、压缩频率和积极性以及客户端尾部响应时间。</p><h1 id="8ba6" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">高可用性</h1><p id="93dd" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinterest的所有基础设施系统都是高度可用的，我们的缓存系统也不例外。利用mcrouter中丰富的路由功能，我们的memcached车队具有广泛的容错功能:</p><ul class=""><li id="8fe2" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated"><strong class="ig hi">部分降级或完全脱机的服务器的自动故障转移。</strong>网络本来就脆弱且有损耗；整个缓存堆栈都认为这是一个不可否认的事实，并且旨在当服务器不可用或速度慢时保持可用性。幸运的是，缓存数据本质上是短暂的，这降低了对数据持久性的要求，否则像数据库这样的持久性存储就需要数据持久性。在Pinterest中，当单个服务器离线或对请求的响应太慢时，mcrouter会自动将请求故障转移到全局共享集群，并通过主动健康检查自动将服务器带回服务池。结合针对单个服务器故障的丰富代理层工具，这使得运营商能够在最短的生产停机时间内识别和更换行为不当的服务器。</li><li id="34fa" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">通过透明的跨区域复制实现数据冗余。</strong>跨不同AWS可用性区域(AZs)的多个集群复制关键用例。这允许在零宕机的情况下完全丢失AZ:所有请求都自动重定向到位于单独AZ中的健康副本，在该副本中有完整的数据冗余副本可用。</li><li id="cdee" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">针对真实生产流量的隔离阴影测试。【mcrouter中的流量路由功能使我们能够针对实际生产请求执行各种弹性练习，包括集群到集群的暗流量以及人为延迟和停机时间注入，而不会影响生产。</strong></li></ul><h1 id="1bc0" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">负载平衡和数据分片</h1><p id="f658" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">分布式系统的关键特征之一是水平可伸缩性——横向扩展<em class="ll">而不是纵向扩展<em class="ll">以适应额外流量增长的能力。在Pinterest，我们的绝大多数缓存工作负载都受到吞吐量的限制，这就要求集群中的实例数量与入站请求量大致成线性比例。然而，memcached本身是一个非常简单的键值存储，它本身并不知道集群中的其他对等点。每秒数以亿计的请求实际上是如何通过网络路由到正确的服务器的？</em></em></p><p id="dac1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Mcrouter对每个传入请求的缓存关键字应用哈希算法，以确定性地将请求分割到池中的一台主机。这对于在服务器之间均匀分布流量非常有效，但memcached有一个独特的要求，即其集群需要<em class="ll">可任意扩展</em>——运营商需要能够自由调整集群容量以响应不断变化的流量需求，同时最大限度地减少对客户端的影响。</p><p id="62fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一致的散列确保即使合格碎片的总数增加或减少，大多数键空间分区也映射到同一个服务器。由于高度本地化和可预测的命中率影响，这使得系统可以对客户端层透明地进行横向扩展，从而降低了容量的微小变化导致群集范围命中率灾难性下降的可能性。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/a901bcb8343c70d2aa58625f6e2fb215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bDf1MrLc0qzseDqM"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx"><em class="kv">Figure 3: Consistent hashing keeps most of the keyspace server allocation intact when one node is added to an existing pool.</em></figcaption></figure><p id="9ed6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">客户端路由层将单个密钥前缀映射到若干路由策略之一背后的一个或多个这样的一致散列池，包括用于跨AZ复制集群的AZ-affinity首选路由、用于由基于闪存的故障转移容量集群支持的内存集群的L1L2路由等等。这允许隔离流量，从而按客户端用例分配容量，并确保Pinterest机群中任何客户端机器的缓存路由行为一致。</p><h1 id="08aa" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">权衡和考虑</h1><p id="8016" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">所有足够复杂的基础设施系统都有一个特点，那就是(通常是非常细微的)权衡。在构建和扩展我们的缓存系统的过程中，我们权衡了许多权衡的成本和收益。下面重点介绍几个例子:</p><ul class=""><li id="fda1" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">中间代理层会带来额外的计算和I/O开销，尤其是对于具有严格延迟SLO的性能关键型系统。然而，mcrouter提供的高可用性抽象、灵活的路由行为和许多其他功能远远超过了性能损失。</li><li id="0351" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">全球共享的代理配置在变更部署中存在风险，因为所有控制平面变更都在Pinterest部署的数万台机器上应用。然而，这也确保了对memcached车队拓扑和相关路由策略的全局一致了解，而不管客户端在Pinterest中的部署位置或部署方式。</li><li id="f45e" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">我们运营着大约100个不同的memcached集群，其中许多具有不同的租用特征(专用与共享)、硬件实例类型和路由策略。虽然这给团队带来了相当大的维护负担，但它也允许对每个用例进行有效的性能和可用性隔离，同时还通过选择最适合特定工作负载使用情况的参数和实例类型来提供效率优化的机会。</li><li id="6aa4" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">在大多数情况下，利用一致的哈希方案在上游服务器池中进行负载分配非常有效，即使密钥空间的特征是前缀相似的密钥集群。但是，这并不能解决热键的问题——对于一组特定的键，请求量的异常增加仍然会导致服务器集群中的热碎片造成的负载不平衡。</li></ul><h1 id="189a" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">未来的工作</h1><p id="dac9" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">展望未来，我们希望继续提高Pinterest缓存基础设施的效率、可靠性和性能。这包括实验项目，如将memcached核心直接嵌入到主机应用程序进程中，用于性能关键的用例(允许memcached与服务进程共享内存空间，并消除网络和I/O开销)，以及可靠性项目，如为多区域冗余设计可靠的解决方案。</p><p id="06a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢Pinterest的整个存储和缓存团队对这项工作的支持，特别是Ankita Girish Wagh和Xu。</p></div></div>    
</body>
</html>