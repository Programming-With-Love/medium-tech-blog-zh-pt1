<html>
<head>
<title>Confluent cloud integration with Logz.io.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">融合云与Logz.io的集成。</h1>
<blockquote>原文：<a href="https://medium.com/globant/confluent-cloud-integration-with-logz-io-8c0b26af94c0?source=collection_archive---------2-----------------------#2022-05-04">https://medium.com/globant/confluent-cloud-integration-with-logz-io-8c0b26af94c0?source=collection_archive---------2-----------------------#2022-05-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="1be8" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">简介</strong></h1><p id="6434" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">Apache Kafka是一个实时流平台，它在系统或应用程序之间传输数据。融合云是围绕Apache Kafka构建的针对动态数据的云原生服务，Apache Kafka是一种简单、可扩展、弹性和安全的事件流。</p><p id="3a97" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最初用于解决该问题的融合云是从应用程序实时事件处理系统低延迟摄取大量事件数据。</p><p id="e552" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">关键是“实时”处理。Kafka充当日志收集框架和ELK堆栈之间的缓冲。它能够像ELK和SEIM工具一样将日志多汇到不同的汇。</p><p id="c096" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">Logz.io基本上是日志管理解决方案的ELK堆栈，用于历史时序分析的扩展保留。可观察性观点监控实时融合云kafka资源日志非常重要，以便对情况做出快速反应，从而改变结果或防止糟糕的结果。</p><p id="730d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">S3汇连接器只不过是一个由融合云提供的插件，允许我们将Apache Kafka与其他应用程序和数据系统集成在一起，在我们的情况下，将融合审计和事件日志导出到s3 bucket等外部系统供以后使用。默认情况下，融合云仅在其内部独立审计日志集群中存储日志7天。</p><h1 id="5e23" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">问题陈述</strong></h1><p id="570a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">融合云将客户kafka集群的审计日志和事件日志存储在其内部独立审计日志集群中，由于安全原因，融合云或logz.io之间没有直接集成来直接捕获融合云审计日志。但是融合云会公开一些API/rest端点来使用这些客户帐户审计日志，以进行安全审计和合规性管理。</p><p id="5cb0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">融合云提供了受管s3 sink连接器，但由于安全原因，我们不能在融合云内部独立审计日志集群上实施它，如前所述。</p><p id="3a69" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">为了解决这个问题，我们正在实现一个自我管理的s3接收器连接器。并使用融合云事件日志和审计日志。</p><p id="d70c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">本文主要讨论如何将融合云(SAAS)审计日志和事件日志导出到Logz.io。</p><p id="7589" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">高层概述</strong></p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/0c3130f3b0889f8792a0229c932521c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*moyJnMcmj4u0Izr2"/></div></div></figure><h1 id="4c1a" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">本文涵盖的要点</strong></h1><p id="b55e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">1.先决条件</p><p id="51d7" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">2.自我管理的S3接收器连接器配置/实施。</p><p id="3f0e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">3.将审计和事件日志从融合云内部审计日志集群转移到AWS S3存储桶。</p><p id="a1ff" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">4.将审计日志从亚马逊S3存储桶导出到logz.io等外部日志记录系统</p><p id="686e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">5.摘要</p><p id="db4e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">6.参考</p><h1 id="60ad" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">先决条件</strong></h1><p id="cbdd" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">1.1融合云帐户和审计日志集群详细信息。</p><p id="f7c9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">1.2使用令牌导入日志的Logz.io帐户。</p><p id="1565" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">1.3 Linux虚拟机实例，融合平台安装和Java-1.8.0，虚拟机对互联网的访问。</p><p id="ed25" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">按照步骤安装合流平台最新版本和Java-1.8.0。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="bd4f" class="kw if hh ks b fi kx ky l kz la">wget -qO — <a class="ae lb" href="https://packages.confluent.io/deb/4.0/archive.key" rel="noopener ugc nofollow" target="_blank">https://packages.confluent.io/deb/4.0/archive.key</a> | sudo apt-key add -<br/>sudo apt-get update &amp;&amp; sudo apt-get install -y confluent-platform <br/>sudo apt-get install -y openjdk-8-jdk</span></pre><p id="361b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">4.AWS访问:IAM用户、IAM用户策略、s3时段。融合云内部审计日志集群和s3存储桶必须位于同一区域。</p><p id="18de" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">以下附有IAM政策应附于合流用户。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="8fc9" class="kw if hh ks b fi kx ky l kz la">{ <br/> “Version”:”2012–10–17", <br/> “Statement”:[ <br/> { <br/> “Effect”:”Allow”, <br/> “Action”:[ <br/> “s3:ListAllMyBuckets” <br/> ], <br/> “Resource”:”arn:aws:s3:::*” <br/> }, <br/> { <br/> “Effect”:”Allow”, <br/> “Action”:[ <br/> “s3:ListBucket”, <br/> “s3:GetBucketLocation” <br/> ], <br/> “Resource”:”arn:aws:s3:::logexporter-ccloud” <br/> }, <br/> { <br/> “Effect”:”Allow”, <br/> “Action”:[ <br/> “s3:PutObject”, <br/> “s3:GetObject”, <br/> “s3:AbortMultipartUpload”, <br/> “s3:ListMultipartUpload”, <br/> “s3:ListMultipartUploadParts”, <br/> “s3:ListBucketMultipartUploads” <br/> ], <br/> “Resource”:”arn:aws:s3:::logexporter-ccloud/*” <br/> } <br/> ] <br/>}</span></pre><h1 id="26b3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">自管理S3接收器连接器配置</strong></h1><p id="06ac" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">运行工作线程有两种模式:独立模式和分布式模式</p><p id="8e91" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">模式。独立模式用于通常使用单个代理的环境。</p><p id="3cf2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">2.1 <strong class="je hi">单机模式配置:</strong></p><p id="a701" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">对于我们的例子，我们实现的是独立模式。</p><p id="b27c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在一个汇合虚拟机上打开/ <strong class="je hi"> <em class="lc"> etc/kafka/ </em> </strong>下的<strong class="je hi"><em class="lc">connect-standalone . properties</em></strong>文件，并在下面添加配置和<strong class="je hi"> <em class="lc">保存</em> </strong>。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="6d5f" class="kw if hh ks b fi kx ky l kz la">vim /etc/kafka/connect-standalone.properties</span><span id="fea7" class="kw if hh ks b fi ld ky l kz la">bootstrap.servers=&lt;audit-log-cluster-endpoint&gt;<br/>security.protocol=SASL_SSL<br/>sasl.mechanism=PLAIN<br/>sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=”&lt;AUDITLOG_CLUSTER_API_KEY&gt;” <br/>password=”&lt;AUDITLOG_CLUSTER_SECRET_KEY&gt;”;<br/>key.converter=org.apache.kafka.connect.json.JsonConverter<br/>value.converter=org.apache.kafka.connect.json.JsonConverter<br/>key.converter.schemas.enable=false<br/>value.converter.schemas.enable=false<br/>internal.key.converter=org.apache.kafka.connect.json.JsonConverter<br/>internal.value.converter=org.apache.kafka.connect.json.JsonConverter<br/>internal.key.converter.schemas.enable=false<br/>internal.value.converter.schemas.enable=false<br/>offset.storage.file.filename=/tmp/connect.offsets<br/>offset.flush.interval.ms=10000<br/>plugin.path=/usr/share/java,/etc/kafka-connect-s3<br/>consumer.bootstrap.servers=&lt;audit-log-cluster-endpoint&gt;<br/>consumer.security.protocol=SASL_SSL<br/>consumer.sasl.mechanism=PLAIN<br/>consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username=”&lt;AUDITLOG_CLUSTER_API_KEY&gt;” password=”&lt;AUDITLOG_CLUSTER_SECRET_KEY&gt;”;</span></pre><p id="62dd" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这里在上图中配置<strong class="je hi"><em class="lc">bootstrap . server</em></strong>是一个合流云独立审计日志集群端点。并且用于<strong class="je hi"><em class="lc">connect-standalone . properties</em></strong>的API密钥/秘密必须是我们的合流云独立审计日志集群。</p><h1 id="2a69" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">使用来自融合云的审计和事件日志</strong></h1><p id="f6a8" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">内部审计日志集群到AWS S3时段。</strong></p><p id="7075" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在，在/etc/kafka-connect-s3/位置下配置S3接收器连接器。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="dc3b" class="kw if hh ks b fi kx ky l kz la">vim /etc/kafka-connect-s3/s3-sink-connector.properties</span><span id="96ab" class="kw if hh ks b fi ld ky l kz la">name=auditlog-connector-s3-sink<br/>connector.class=io.confluent.connect.s3.S3SinkConnector<br/>tasks.max=1<br/>topics=confluent-audit-log-events<br/>s3.region=us-west-2<br/>s3.bucket.name=logexporter-ccloud<br/>s3.part.size=5242880<br/>flush.size=3<br/>storage.class=io.confluent.connect.s3.storage.S3Storage<br/>format.class=io.confluent.connect.s3.format.json.JsonFormat<br/>partitioner.class=io.confluent.connect.storage.partitioner.DefaultPartitioner<br/>schema.compatibility=NONE</span></pre><p id="f0f6" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi"> <em class="lc">保存</em> </strong> <em class="lc">所有配置并执行</em><strong class="je hi"><em class="lc">connect-standalone</em></strong><em class="lc">命令开始s3-sink connector执行。</em></p><p id="1ffd" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">启用对s3-sink连接器<em class="lc">c</em>hange<strong class="je hi"><em class="lc">log4j . root logger</em><em class="lc">INFO</em></strong>到<strong class="je hi"> <em class="lc"> DEBUG </em> </strong>的调试，在<strong class="je hi"><em class="lc">/etc/Kafka/connect-log4j . properties</em></strong><em class="lc">文件</em>中查看运行连接器时的错误。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="8182" class="kw if hh ks b fi kx ky l kz la">vim /etc/kafka/connect-log4j.properties</span><span id="232d" class="kw if hh ks b fi ld ky l kz la">log4j.rootLogger=DEBUG, stdout</span></pre><p id="1a63" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><em class="lc">然后运行以下命令，在独立模式下执行连接器。</em></p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="ac4c" class="kw if hh ks b fi kx ky l kz la"><em class="lc">connect-standalone -daemon /etc/kafka/connect-standalone.properties /etc/kafka-connect-s3/s3-sink-connector-properties</em></span></pre><p id="943b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><em class="lc">一旦命令没有任何错误地运行，我们就能够看到上传到我们的</em> logexporter-ccloud <em class="lc"> s3存储桶的日志。</em></p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es le"><img src="../Images/10f7415d63c2ab8cfca676ff6e2076c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ipDz4dAl_ppO6g6C"/></div></div></figure><h1 id="86a7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">将审计日志从亚马逊S3存储桶导出到外部</strong></h1><p id="098c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi">logz . io等日志系统</strong></p><p id="1528" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在第三步是将日志转移到logz.io首先登录到您想要导出这些日志的帐户。</p><p id="705f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在Kibana仪表板上，选择日志图标，然后选择管理数据部分:</p><p id="50d0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在“管理数据”下，点击“发送您的日志”,选择日志源亚马逊S3桶。</p><p id="6c52" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">按照以下步骤设置从s3到logz.io的日志转移。</p><ol class=""><li id="662c" class="lf lg hh je b jf ka jj kb jn lh jr li jv lj jz lk ll lm ln bi translated">使用专用的Logz.io配置向导添加新的S3存储桶。</li></ol><p id="2ab0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">单击+添加存储桶</p><p id="287f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">2.提供S3时段名称</p><p id="d4d9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">3.从下拉列表中选择托管区域</p><p id="397c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">4.选择首选的身份验证方法—配置向导将打开的IAM角色或访问密钥。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="1571" class="kw if hh ks b fi kx ky l kz la">S3 bucket name : log exporter-ccloud<br/>Region: &lt;bucket region&gt;<br/>AWS Access key:&lt;access key&gt; <br/>AWS Access key: &lt;secret key&gt;</span></pre><p id="5bea" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">保存您的信息。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lo"><img src="../Images/22a3ddfd06d1a143fe7b68fdab664b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GFFZ_QCRUT14j-L-"/></div></div></figure><p id="22b5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">5.给你的日志一些时间从你的系统到logz.io，然后打开<a class="ae lb" href="https://app.logz.io/#/dashboard/kibana" rel="noopener ugc nofollow" target="_blank"> Kibana </a>。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lp"><img src="../Images/5b1ba464bc6f6ce0710f081660489871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rfJn3yU87TZTvAOs"/></div></div></figure><p id="f6ec" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">s3接收器连接器的定制服务。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="ebd4" class="kw if hh ks b fi kx ky l kz la">vim /etc/systemd/system/s3-auditlog-sink.service</span><span id="ed40" class="kw if hh ks b fi ld ky l kz la">[Unit]<br/>Description=s3-sink-connector for exporting confluent cloud auditlog from internal audit log cluster to logz.io service<br/>After=network.target<br/>StartLimitIntervalSec=0<br/>[Service]<br/>Type=simple<br/>Restart=always<br/>RestartSec=1<br/>User=centos<br/>ExecStart=connect-standalone -daemon /etc/kafka/connect-standalone.properties /etc/kafka-connect-s3/s3-sink-connector.properties <br/>[Install]<br/>WantedBy=multi-user.target</span></pre><p id="0cbb" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">保存服务配置。</p><pre class="kg kh ki kj fd kr ks kt ku aw kv bi"><span id="133a" class="kw if hh ks b fi kx ky l kz la">systemctl start s3-sink-connector.service<br/>systemctl enable s3-sink-connector.service<br/>systemctl status s3-sink-connector.service</span></pre><h1 id="0430" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">总结</strong></h1><p id="39c1" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">通过本文，我们能够从融合云内部独立审计日志集群中消费融合审计日志，并可视化这些日志的可观察性。</p><h1 id="2eae" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">参考文献</strong></h1><p id="03d4" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><a class="ae lb" href="https://docs.confluent.io/cloud/current/connectors/cc-s3-sink.html#cc-s3-connect-sink" rel="noopener ugc nofollow" target="_blank">https://docs . confluent . io/cloud/current/connectors/cc-S3-sink . html # cc-S3-connect-sink</a></p><p id="c958" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><a class="ae lb" href="https://docs.logz.io/shipping/log-sources/s3-bucket.html" rel="noopener ugc nofollow" target="_blank">https://docs.logz.io/shipping/log-sources/s3-bucket.html</a></p></div></div>    
</body>
</html>