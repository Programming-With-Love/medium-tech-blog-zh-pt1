<html>
<head>
<title>Top 50 Hadoop Interview Questions You Must Prepare In 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年你必须准备的50个Hadoop面试问题</h1>
<blockquote>原文：<a href="https://medium.com/edureka/hadoop-interview-questions-55b8e547dd5c?source=collection_archive---------0-----------------------#2019-12-03">https://medium.com/edureka/hadoop-interview-questions-55b8e547dd5c?source=collection_archive---------0-----------------------#2019-12-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/9e4b107875583eab7d4f795d7ed7f10a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*NRS1y3xHg3YOjRjtGiCEEg.png"/></div></figure><p id="a046" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这个Hadoop面试问题博客中，我们将涵盖所有常见问题，这些问题将帮助您以最佳解决方案赢得面试。但在此之前，让我告诉你对大数据和Hadoop专家的需求是如何持续增长的。</p><p id="6bcf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">以下几个统计数据非常准确地反映了对Hadoop需求的增长:</p><ul class=""><li id="8143" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><em class="js">到2019年，大数据将推动486亿美元的年度支出——IDC。</em></li><li id="bec6" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">【Indeed.com T2】美国大数据Hadoop开发人员的平均工资是135万美元</li><li id="2972" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">【itjobswatch.co.uk】英国平均年薪66250—66750英镑</li></ul><p id="de98" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我想提请大家注意大数据革命。更早的时候，组织只关注运营数据，运营数据不到整个数据的20%。后来，他们意识到分析整个数据会给他们带来更好的商业洞察力和决策能力。那是雅虎、脸书、谷歌等巨头。开始采用Hadoop和大数据相关技术。事实上，如今五分之一的公司正在转向大数据分析。因此，对大数据Hadoop工作的需求像任何事情一样在上升。所以，如果你想助推自己的事业，Hadoop和Spark正是你需要的技术。这将永远给你一个好的开始，无论是作为一个新人还是有经验的人。</p><p id="95f9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">准备好这些顶级Hadoop面试问题，在蓬勃发展的大数据市场中获得优势，全球和本地企业，无论大小，都在寻找高质量的大数据和Hadoop专家。这份权威的Hadoop面试问题列表将带您浏览围绕<strong class="in hi"> Hadoop集群</strong>、<strong class="in hi"> HDFS、MapReduce </strong>、<strong class="in hi"> Pig </strong>、<strong class="in hi"> Hive、HBase </strong>的问答。这个博客是你下一份Hadoop工作的入口。</p><p id="61b8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果您在Hadoop面试中遇到了一些难题，但仍然不知道最佳答案，请将这些问题放在下面的评论部分。我们将很乐意回答这些问题。</p><p id="fe85" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">与此同时，通过参加Edureka的Hadoop在线培训，您可以最大限度地利用大数据分析职业机会。点击下方了解更多信息。</p><p id="606b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">1.关系数据库和HDFS的基本区别是什么？</p><p id="cbf2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">以下是HDFS和关系数据库之间的主要区别:</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es jy"><img src="../Images/971d73f58b6ef971cce96bcf640195f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXDQ2T5-pyvu26-8OzjgZA.png"/></div></div></figure><h2 id="b8b0" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">2.解释“大数据”以及大数据的五个V是什么？</h2><p id="71f6" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“大数据”是指大型复杂数据集的集合，这使得使用关系数据库管理工具或传统数据处理应用程序很难处理。捕获、管理、存储、搜索、共享、传输、分析和可视化大数据非常困难。大数据已经成为企业的机遇。现在，他们可以成功地从数据中获取价值，并且凭借增强的业务决策制定能力，比竞争对手拥有明显的优势。</p><p id="404d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">♣提示:在这类问题中谈论5v是个好主意，不管它是否被特别问到！</p><ul class=""><li id="b4bd" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi">卷</strong>:卷代表以指数速度增长的数据量，即以Pb和EB为单位。</li><li id="b3c3" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">速度</strong>:速度是指数据增长的速率，非常快。今天，昨天的数据被认为是旧数据。如今，社交媒体是数据增长速度的主要贡献者。</li><li id="30eb" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">多样性</strong>:多样性是指数据类型的异构性。换句话说，收集的数据有多种格式，如视频、音频、csv等。所以，这些不同的格式代表了数据的多样性。</li><li id="90b2" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">准确性</strong>:准确性是指由于数据的不一致和不完整而对现有数据产生怀疑或不确定的数据。可用的数据有时会变得混乱，可能难以信任。对于多种形式的大数据，质量和准确性很难控制。数量往往是数据缺乏质量和准确性的原因。</li><li id="c88c" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">价值</strong>:获得大数据固然很好，但除非我们能将其转化为价值，否则毫无用处。我说的将它转化为价值是指，它增加了组织的利益吗？从事大数据工作的组织是否实现了高ROI(投资回报)？除非它通过处理大数据来增加他们的利润，否则它是无用的。</li></ul><h2 id="81d2" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">3.什么是Hadoop及其组件。</h2><p id="8c9b" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">当“大数据”作为一个问题出现时，Apache Hadoop作为一个解决方案应运而生。Apache Hadoop是一个框架，为我们提供各种服务或工具来存储和处理大数据。它有助于分析大数据并从中做出业务决策，而使用传统系统无法高效地完成这些工作。</p><p id="da3f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="js"> ♣提示:现在，在解释Hadoop的同时，你还应该解释Hadoop的主要组件，</em>即:</p><ul class=""><li id="e4eb" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js">存储单元</em></strong>–HDFS(NameNode，DataNode)</li><li id="014e" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js">处理框架</em></strong>–纱线(ResourceManager，NodeManager)</li></ul><h2 id="5e22" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">4.什么是HDFS和纱？</h2><p id="ed59" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated"><strong class="in hi"> HDFS </strong> (Hadoop分布式文件系统)是Hadoop的存储单元。它负责在分布式环境中将不同种类的数据存储为块。它遵循主从拓扑结构。</p><p id="2ac2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="js"> ♣提示:建议也解释一下HDFS组件，即</em></p><ul class=""><li id="0665" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"><em class="js">NameNode</em>:</strong>NameNode是分布式环境中的主节点，它维护存储在HDFS的数据块的元数据信息，如块位置、复制因子等。</li><li id="7f4d" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"><em class="js">DataNode</em>:</strong>DataNode是从节点，负责在HDFS中存储数据。NameNode管理所有的DataNodes。</li></ul><p id="b58c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> YARN </strong>(又一个资源协商者)是Hadoop中的处理框架，它管理资源并为进程提供执行环境。</p><p id="8ec3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="js"> ♣提示:同样，正如我们在HDFS中所做的，我们也应该解释纱线的两种成分:</em></p><ul class=""><li id="9247" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"><em class="js">resource manager</em>:</strong>它接收处理请求，然后相应地将部分请求传递给相应的节点管理器，在那里进行实际的处理。它根据需求为应用程序分配资源。</li><li id="b632" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js">节点管理器</em> : </strong>节点管理器安装在每一个数据节点上，它负责每一个数据节点上任务的执行。</li></ul><h2 id="e453" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">5.告诉我各种Hadoop守护进程及其在Hadoop集群中的角色。</h2><p id="476f" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">通常，解决这个问题的方法是首先解释HDFS守护进程，即NameNode、DataNode和辅助NameNode，然后继续解释YARN守护进程，即ResorceManager和NodeManager，最后解释JobHistoryServer。</p><ul class=""><li id="57f8" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"> NameNode: </strong>主节点，负责存储所有文件和目录的元数据。它包含有关组成文件的数据块的信息，以及这些数据块在群集中的位置。</li><li id="bd2a" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> Datanode: </strong>它是包含实际数据的从节点。</li><li id="027d" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">辅助NameNode: </strong>它定期将更改(编辑日志)与命名节点中的FsImage(文件系统映像)合并。它将修改后的FsImage存储到持久存储中，可以在NameNode出现故障时使用。</li><li id="0416" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">ResourceManager: 它是管理资源和调度运行在YARN上的应用程序的中心机构。</li><li id="d83a" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi">节点管理器:</strong>它运行在从机上，负责启动应用程序的容器(应用程序在其中执行它们的部分)，监控它们的资源使用情况(CPU、内存、磁盘、网络)并将这些报告给资源管理器。</li><li id="ebd7" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> JobHistoryServer: </strong>它在应用程序主机终止后维护有关MapReduce作业的信息。</li></ul><h1 id="beb6" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Hadoop HDFS面试问题</h1><h2 id="3ee2" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">6.将HDFS与网络连接存储(NAS)进行比较。</h2><p id="2ccc" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">在此问题中，首先解释NAS和HDFS，然后按如下方式比较它们的功能:</p><ul class=""><li id="8221" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">网络连接存储(NAS)是连接到计算机网络的文件级计算机数据存储服务器，为不同种类的客户端组提供数据访问。NAS可以是为存储和访问文件提供服务的硬件或软件。而Hadoop分布式文件系统(HDFS)是一个使用商用硬件存储数据的分布式文件系统。</li><li id="937e" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">在HDFS中，数据块分布在集群中的所有机器上。而在NAS中，数据存储在专用硬件上。</li><li id="4eff" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">HDFS被设计为使用MapReduce范式，将计算转移到数据上。NAS不适合MapReduce，因为数据是与计算分开存储的。</li><li id="8dc9" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">HDFS使用经济高效的商用硬件，而NAS是一种高成本的高端存储设备。</li></ul><h2 id="9fba" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">7.列出Hadoop 1和Hadoop 2的区别。</h2><p id="58f9" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这是一个重要的问题，在回答这个问题时，我们必须主要关注两点，即被动NameNode和YARN架构。</p><ul class=""><li id="39c8" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">在Hadoop 1.x中，“NameNode”是单点故障。在Hadoop 2.x中，我们有主动和被动的“命名节点”。如果主动“NameNode”失败，被动“NameNode”将接管。正因为如此，在Hadoop 2.x中可以实现高可用性。</li><li id="36e3" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">此外，在Hadoop 2.x中，YARN提供了一个中央资源管理器。使用YARN，您现在可以在Hadoop中运行多个应用程序，所有应用程序共享一个公共资源。MRV2是一种特殊类型的分布式应用程序，它在YARN之上运行MapReduce框架。其他工具也可以通过YARN执行数据处理，这在Hadoop 1.x中是个问题。</li></ul><figure class="jz ka kb kc fd ii er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es ly"><img src="../Images/fb20fd032af78b30858e052a11fdb192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODFeO7wwhz3gWZ4pX-jkeQ.png"/></div></div></figure><h2 id="b87e" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">8.什么是主动和被动的“命名节点”？</h2><p id="0a0c" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">在HA(高可用性)架构中，我们有两个NameNode—主动“NameNode”和被动“NameNode”。</p><ul class=""><li id="8d02" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">主动“NameNode”是在集群中工作和运行的“NameNode”。</li><li id="12d8" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">被动“NameNode”是一个备用“NameNode”，它具有与主动“NameNode”相似的数据。</li></ul><p id="d0e7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当主动“NameNode”出现故障时，被动“NameNode”会替换群集中的主动“NameNode”。因此，集群永远不会没有“NameNode ”,因此它永远不会失败。</p><h2 id="bd83" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">9.为什么要频繁地在Hadoop集群中删除或添加节点？</h2><p id="3e07" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Hadoop框架最吸引人的特性之一是它对商用硬件的<em class="js">利用。然而，这导致Hadoop集群中频繁出现“DataNode”崩溃。Hadoop框架的另一个显著特征是<em class="js">根据数据量的快速增长进行扩展的简易性</em>。由于这两个原因，Hadoop管理员最常见的任务之一就是在Hadoop集群中调试(添加)和停用(移除)“数据节点”。</em></p><h2 id="6a93" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">10.当两个客户端试图访问HDFS中的同一个文件时会发生什么？</h2><p id="f648" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">HDFS仅支持独占写入。</p><p id="830b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当第一个客户端联系“NameNode”以打开文件进行写入时，“NameNode”授予客户端创建该文件的租约。当第二个客户端尝试打开同一文件进行写入时，“NameNode”会注意到该文件的租约已经授予了另一个客户端，并将拒绝第二个客户端的打开请求。</p><h2 id="5f63" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">11.NameNode如何处理DataNode故障？</h2><p id="b8c1" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">NameNode定期从集群中的每个DataNode接收心跳(信号),这意味着DataNode运行正常。</p><p id="7c05" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">块报告包含DataNode上所有块的列表。如果某个DataNode未能发送心跳消息，经过一段特定的时间后，它将被标记为失效。</p><p id="c6c9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">NameNode使用之前创建的副本将失效节点的数据块复制到另一个DataNode。</p><h2 id="60e6" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">12.当NameNode关闭时，您会怎么做？</h2><p id="8bde" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">NameNode恢复过程包括以下步骤来启动和运行Hadoop集群:</p><ol class=""><li id="cfe3" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lz jp jq jr bi translated">使用文件系统元数据副本(FsImage)启动新的NameNode。</li><li id="ce60" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">然后，配置DataNodes和客户机，以便它们可以确认这个新的NameNode，这是启动的。</li><li id="e7e4" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">现在，新的NameNode将在加载完最后一个检查点FsImage(用于元数据信息)并从DataNodes接收到足够多的块报告后开始为客户端提供服务。</li></ol><p id="c71a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，在大型Hadoop集群上，这种NameNode恢复过程可能会消耗大量时间，这在日常维护的情况下甚至会成为更大的挑战。</p><h2 id="95c3" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">13.什么是检查点？</h2><p id="7660" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">简而言之，“检查点”是一个获取文件系统映像、编辑日志并将其压缩成新文件系统映像的过程。因此，NameNode可以直接从FsImage加载最终的内存状态，而不是重放编辑日志。这是一个非常有效的操作，减少了NameNode的启动时间。检查点由辅助NameNode执行。</p><h2 id="869f" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">14.HDFS是如何容错的？</h2><p id="0915" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">当数据存储在HDFS上时，NameNode将数据复制到几个DataNode。默认的复制因子是3。您可以根据需要更改配置因子。如果一个DataNode出现故障，NameNode会自动将数据从副本复制到另一个节点，并使数据可用。这在HDFS中提供了容错。</p><h2 id="2704" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">15.NameNode和DataNode可以做商品硬件吗？</h2><p id="ae0a" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这个问题的聪明答案是，DataNodes是像个人电脑和笔记本电脑一样的商品硬件，因为它存储数据，并且需要大量的数据。但是根据您的经验，您可以知道，NameNode是主节点，它存储有关存储在HDFS的所有块的元数据。它需要很高的内存(RAM)空间，所以NameNode需要是一个内存空间很好的高端机器。</p><h2 id="9de4" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">16.为什么我们对有大数据集的应用程序使用HDFS，而不是在有很多小文件的时候？</h2><p id="ddff" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">与分布在多个文件中的少量数据相比，HDFS更适合单个文件中的大量数据集。如您所知，NameNode将关于文件系统的元数据信息存储在RAM中。因此，内存量限制了我的HDFS文件系统中的文件数量。换句话说，太多的文件会导致产生太多的元数据。而且，在RAM中存储这些元数据将成为一个挑战。根据经验，文件、数据块或目录的元数据需要150字节。</p><h2 id="961d" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">17.你如何定义HDFS的“街区”？Hadoop 1和Hadoop 2中的默认块大小是多少？能改吗？</h2><p id="743c" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">块是硬盘上存储数据的最小连续位置。HDFS将每个存储为块，并在Hadoop集群中分发。HDFS的文件被分解成块大小的块，作为独立的单元存储。</p><ul class=""><li id="8431" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">Hadoop 1默认块大小:64 MB</li><li id="6176" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">Hadoop 2默认块大小:128 MB</li></ul><p id="8c88" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">是的，可以配置块。可以在hdfs-site.xml文件中使用dfs.block.size参数来设置Hadoop环境中的块大小。</p><h2 id="773a" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">18.“jps”命令是做什么的？</h2><p id="d7fc" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“jps”命令帮助我们检查Hadoop守护进程是否正在运行。它显示了所有Hadoop守护进程，即namenode、datanode、resourcemanager、nodemanager等。在机器上运行。</p><h2 id="f502" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">19.在Hadoop中如何定义“机架感知”？</h2><p id="6fe7" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated"><strong class="in hi">机架感知</strong>是一种算法，其中“NameNode”根据机架定义决定如何放置数据块及其副本，以最大限度地减少同一机架内“DataNodes”之间的网络流量。假设我们考虑复制因子3(默认)，策略是“对于每个数据块，两个拷贝将存在于一个机架中，第三个拷贝存在于不同的机架中”。该规则被称为“副本放置策略”。</p><h2 id="9bc8" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">20.Hadoop中的“推测执行”是什么？</h2><p id="0a1d" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">如果一个节点看起来执行任务较慢，主节点可以在另一个节点上冗余地执行同一任务的另一个实例。然后，最先完成的任务将被接受，另一个将被杀死。这个过程被称为“推测执行”。</p><h2 id="838f" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">21.如何重启Hadoop中的“NameNode”或所有守护进程？</h2><p id="f677" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这个问题可以有两个答案，我们将讨论这两个答案。我们可以通过以下方法重启NameNode:</p><ol class=""><li id="1018" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lz jp jq jr bi translated">您可以使用<strong class="in hi"><em class="js">/sbin/Hadoop-daemon . sh stop namenode</em></strong>命令单独停止NameNode，然后使用<em class="js">启动NameNode。</em><strong class="in hi"><em class="js">/sbin/Hadoop-daemon . sh启动namenode </em> </strong>命令。</li><li id="adfa" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">要停止和启动所有守护程序，请使用<strong class="in hi">。</strong> <strong class="in hi"> <em class="js"> /sbin/stop-all。</em> </strong>然后使用。<strong class="in hi"><em class="js">/sbin/start-all . sh</em></strong>命令，该命令将首先停止所有守护进程，然后启动所有守护进程。</li></ol><p id="50a2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这些脚本文件位于Hadoop目录下的sbin目录中。</p><h2 id="ab82" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">22.“HDFS块”和“输入分离”之间有什么区别？</h2><p id="f657" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“HDFS块”是数据的物理划分，而“输入拆分”是数据的逻辑划分。HDFS将数据划分为块，以便将块存储在一起，而为了处理，MapReduce将数据划分为输入拆分，并将其分配给映射器函数。</p><h2 id="8312" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">23.说出Hadoop可以运行的三种模式。</h2><p id="57fa" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Hadoop可以运行的三种模式如下:</p><ol class=""><li id="eb22" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lz jp jq jr bi translated"><strong class="in hi"> <em class="js">单机(本地)模式</em> </strong>:如果我们不做任何配置，这是默认模式。在这种模式下，Hadoop的所有组件，如NameNode、DataNode、ResourceManager和NodeManager，都作为一个Java进程运行。这使用本地文件系统。</li><li id="df4f" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated"><strong class="in hi"> <em class="js">伪分布式模式</em> </strong>:单节点Hadoop部署被认为是在伪分布式模式下运行Hadoop系统。在这种模式下，所有Hadoop服务，包括主服务和从服务，都在单个计算节点上执行。</li><li id="51d9" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated"><strong class="in hi"> <em class="js">全分布式模式</em></strong>:Hadoop主服务和从服务在不同节点上运行的Hadoop部署称为全分布式模式。</li></ol><h1 id="a40e" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Hadoop MapReduce面试问题</h1><h2 id="7bc3" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">24.什么是“MapReduce”？运行“MapReduce”程序的语法是什么？</h2><p id="938f" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">它是一个框架/编程模型，用于在使用并行编程的计算机集群上处理大型数据集。运行MapReduce程序的语法是<strong class="in hi">Hadoop _ jar _ file . jar/input _ path/output _ path</strong>。</p><h2 id="04a5" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">25.“MapReduce”程序的主要配置参数是什么？</h2><p id="3a75" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">用户需要在“MapReduce”框架中指定的主要配置参数有:</p><ul class=""><li id="bd7b" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">分布式文件系统中作业的输入位置</li><li id="3988" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">分布式文件系统中作业的输出位置</li><li id="7e9b" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">数据的输入格式</li><li id="1187" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">数据输出格式</li><li id="11ce" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">包含地图函数的类</li><li id="906e" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">包含reduce函数的类</li><li id="6be1" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">包含映射器、缩减器和驱动程序类的JAR文件</li></ul><h2 id="bf9e" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">26.陈述我们无法在mapper中执行“聚合”(加法)的原因？为什么我们需要这个“减速器”呢？</h2><p id="c6ee" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这个答案包含了许多要点，所以我们将按顺序逐一介绍。</p><ul class=""><li id="c49c" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">我们无法在mapper中执行“聚合”(添加)，因为在“mapper”函数中不会进行排序。排序仅发生在缩减器端，没有排序就无法进行聚合。</li><li id="b40d" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">在“聚合”期间，我们需要所有映射器函数的输出，这可能无法在映射阶段收集，因为映射器可能运行在存储数据块的不同机器上。</li><li id="c183" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">最后，如果我们尝试在mapper上聚合数据，则需要在可能运行于不同机器上的所有mapper函数之间进行通信。因此，它将消耗很高的网络带宽，并可能导致网络瓶颈。</li></ul><h2 id="825a" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">27.Hadoop中“RecordReader”的用途是什么？</h2><p id="4316" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“InputSplit”定义了一个工作片段，但没有描述如何访问它。“RecordReader”类从数据源加载数据，并将其转换为适合“Mapper”任务读取的(键，值)对。“RecordReader”实例由“输入格式”定义。</p><h2 id="2f71" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">28.解释“MapReduce框架”中的“分布式缓存”。</h2><p id="e45b" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">分布式缓存可以解释为，MapReduce框架提供的一种工具，用于缓存应用程序所需的文件。一旦你为你的工作缓存了一个文件，Hadoop框架将使它在你映射/减少任务运行的每一个数据节点上可用。然后，您可以在映射器或缩减器作业中将缓存文件作为本地文件进行访问。</p><h2 id="b694" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">29.「还原者」之间是如何沟通的？</h2><p id="7140" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这是一个棘手的问题。“MapReduce”编程模型不允许“reducers”相互通信。“减速器”孤立运行。</p><h2 id="62e4" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">三十岁。“MapReduce分区器”是做什么的？</h2><p id="ded5" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“MapReduce Partitioner”确保一个键的所有值都进入同一个“reducer ”,从而允许在“reducer”上均匀分布地图输出。它通过确定哪个“缩减器”负责特定的键，将“映射器”的输出重定向到“缩减器”。</p><h2 id="901c" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">31.你将如何编写一个自定义的分区？</h2><p id="fc12" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">按照以下步骤，可以轻松编写Hadoop作业的自定义分区程序:</p><ul class=""><li id="787b" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">创建一个扩展分区器类的新类</li><li id="a4e5" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">覆盖方法— getPartition，在MapReduce中运行的包装器中。</li><li id="5180" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">使用set Partitioner方法将自定义分区程序添加到作业中，或者将自定义分区程序作为配置文件添加到作业中。</li></ul><h2 id="3a48" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">32.什么是“合并器”？</h2><p id="35f7" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“组合器”是一个小型的“缩减器”,执行本地的“缩减”任务。它从特定“节点”上的“映射器”接收输入，并将输出发送到“缩减器”。“合并器”通过减少需要发送给“缩减器”的数据量来帮助提高“MapReduce”的效率。</p><h2 id="31a0" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">33.你对“SequenceFileInputFormat”了解多少？</h2><p id="6c40" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“SequenceFileInputFormat”是一种用于在序列文件中读取的输入格式。它是一种特定的压缩二进制文件格式，针对在一个“MapReduce”作业的输出到另一个“MapReduce”作业的输入之间传递数据进行了优化。</p><p id="2134" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">序列文件可以作为其他MapReduce任务的输出生成，并且是从一个MapReduce作业传递到另一个作业的数据的有效中间表示。</p><h1 id="1100" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">阿帕奇猪面试问题</h1><h2 id="570f" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">34.Apache Pig比MapReduce有什么好处？</h2><p id="55c3" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Apache Pig是一个平台，用于分析大型数据集，将它们表示为雅虎开发的数据流。它旨在提供MapReduce的抽象，降低编写MapReduce程序的复杂性。</p><ul class=""><li id="1701" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">Pig Latin是一种高级数据流语言，而MapReduce是一种低级数据处理范式。</li><li id="6142" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">不用在MapReduce中编写复杂的Java实现，程序员可以使用Pig Latin非常容易地实现相同的实现。</li><li id="e420" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">Apache Pig将代码长度减少了大约20倍(据雅虎称)。因此，这将开发周期缩短了近16倍。</li><li id="17f7" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">Pig提供了许多内置的操作符来支持数据操作，如连接、过滤、排序、分类等。而在MapReduce中执行相同的功能是一项巨大的任务。</li><li id="b63c" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">在Apache Pig中执行连接操作很简单。而在MapReduce中很难执行数据集之间的连接操作，因为它需要顺序执行多个MapReduce任务来完成工作。</li><li id="9d9a" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated">此外，pig还提供了MapReduce中没有的嵌套数据类型，如元组、包和地图。</li></ul><h2 id="7c40" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">35.猪拉丁有哪些不同的数据类型？</h2><p id="36ca" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Pig Latin可以处理两种原子数据类型，如int、float、long、double等。以及复杂的数据类型，如tuple、bag和map。</p><p id="f02f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">原子数据类型:原子或标量数据类型是所有语言中使用的基本数据类型，如string、int、float、long、double、char[]、byte[]。</p><p id="fb3f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">复杂数据类型:复杂数据类型有Tuple、Map、Bag。</p><h2 id="d952" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">36.你合作过的《猪拉丁》中有哪些不同的关系运算？</h2><p id="ef32" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">不同的关系运算符有:</p><ol class=""><li id="34c4" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lz jp jq jr bi translated">对于每个</li><li id="a3e0" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">以...排序</li><li id="982b" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">过滤</li><li id="db57" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">组</li><li id="9dcb" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">明显的</li><li id="bedb" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">加入</li><li id="cbeb" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji lz jp jq jr bi translated">限制</li></ol><p id="1bfb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果一些函数在内置操作符中不可用，我们可以通过编程创建用户定义的函数(UDF ),使用其他语言如Java、Python、Ruby等来实现这些功能。并将其嵌入脚本文件中。</p><h2 id="2b75" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">37.什么是UDF？</h2><p id="5cbc" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">如果一些函数在内置操作符中不可用，我们可以通过编程创建用户定义的函数(UDF ),使用其他语言如Java、Python、Ruby等来实现这些功能。并将其嵌入脚本文件中。</p><h1 id="49ea" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Apache Hive面试问题</h1><h2 id="b6ab" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">38.《蜂巢》中的“SerDe”是什么？</h2><p id="d90d" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Apache Hive是一个建立在Hadoop之上的数据仓库系统，用于分析脸书开发的结构化和半结构化数据。Hive抽象了Hadoop MapReduce的复杂性。</p><p id="e1fc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">“SerDe”接口允许您指示“Hive”应该如何处理记录。“SerDe”是“串行器”和“解串器”的组合。“Hive”使用“SerDe”(和“FileFormat”)来读写表的行。</p><h2 id="a0dc" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">39.默认的“Hive Metastore”可以同时被多个用户(进程)使用吗？</h2><p id="8b85" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“Derby数据库”是默认的“Hive Metastore”。多个用户(进程)不能同时访问它。它主要用于执行单元测试。</p><h2 id="a876" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">40.“Hive”存储表数据的默认位置是什么？</h2><p id="8041" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Hive存储表数据的默认位置是/user/hive/warehouse中的HDFS内部。</p><h1 id="4226" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Apache HBase面试问题</h1><h2 id="d8b3" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">41.什么是Apache HBase？</h2><p id="0a71" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">HBase是一个开源的、多维的、分布式的、可扩展的、用Java编写的NoSQL数据库。HBase运行在HDFS (Hadoop分布式文件系统)之上，为Hadoop提供类似BigTable (Google)的功能。它旨在提供一种存储大量稀疏数据集的容错方式。HBase通过在大型数据集上提供更快的读/写访问来实现高吞吐量和低延迟。</p><h2 id="909c" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">42.Apache HBase有哪些组件？</h2><p id="fb36" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">HBase有三大组件，分别是HMaster Server、HBase RegionServer和Zookeeper。</p><ul class=""><li id="3484" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js">区域服务器</em> </strong>:一张桌子可以分成几个区域。一组区域由区域服务器提供给客户。</li><li id="9134" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> HMaster </em> </strong>:协调管理区域服务器(类似HDFS的NameNode管理DataNode)。</li><li id="cb84" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"><em class="js">ZooKeeper</em></strong>:ZooKeeper在HBase分布式环境中充当协调者的角色。它通过会话通信来帮助维护集群内部的服务器状态。</li></ul><h2 id="ce5a" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">43.区域服务器的组件有哪些？</h2><p id="fb0b" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">区域服务器的组件包括:</p><ul class=""><li id="95c0" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> WAL </em> </strong>:预写日志(WAL)是附着在分布式环境中每个区域服务器上的文件。WAL存储尚未持久化或提交到永久存储器的新数据。</li><li id="d5b0" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js">块缓存</em> </strong>:块缓存驻留在区域服务器的顶层。它将经常读取的数据存储在存储器中。</li><li id="b7e5" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> MemStore </em> </strong>:就是写缓存。它在将所有传入的数据提交到磁盘或永久内存之前存储这些数据。区域中的每个列族都有一个MemStore。</li><li id="5902" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> HFile </em> </strong> : HFile存放在HDFS。它在磁盘上存储实际的细胞。</li></ul><h2 id="fb0e" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">44.解释HBase中的“WAL”？</h2><p id="6c3d" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">预写日志(WAL)是附加到分布式环境中每个区域服务器的文件。WAL存储尚未持久化或提交到永久存储器的新数据。它用于恢复数据集失败的情况。</p><h2 id="c650" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">45.提及“HBase”和“关系数据库”的区别？</h2><p id="2328" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">HBase是一个开源的、多维的、分布式的、可扩展的和用Java编写的<em class="js"> NoSQL数据库</em>。HBase运行在HDFS之上，为Hadoop提供类似BigTable的功能。让我们看看HBase和关系数据库的区别。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es ma"><img src="../Images/e4b5718b90294546a433951bddfc4ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9UOzG6KK8DYGvILzO2_zMw.png"/></div></div></figure><h1 id="e67e" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Apache Spark面试问题</h1><h2 id="890b" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">46.什么是阿帕奇火花？</h2><p id="0cca" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">这个问题的答案是，Apache Spark是一个用于分布式计算环境中实时数据分析的框架。它执行内存中的计算来提高数据处理的速度。</p><p id="946b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通过利用内存中的计算和其他优化，它在大规模数据处理方面比MapReduce快100倍。</p><h2 id="eb15" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">47.你能用任何特定的Hadoop版本构建“Spark”吗？</h2><p id="a329" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">是的，人们可以为特定的Hadoop版本构建“Spark”。</p><h2 id="63eb" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">48.定义RDD。</h2><p id="791b" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">RDD是弹性分布数据集的首字母缩写，它是并行运行的操作元素的容错集合。RDD中的分区数据是不可变的和分布式的，这是Apache Spark的一个关键组件。</p><h1 id="b2b6" class="lh ki hh bd kj li lj lk kn ll lm ln kr lo lp lq ku lr ls lt kx lu lv lw la lx bi translated">Oozie和动物园管理员面试问题</h1><h2 id="a0ac" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">49.什么是Apache ZooKeeper和Apache Oozie？</h2><p id="d1f1" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">Apache ZooKeeper在分布式环境中协调各种服务。它通过执行同步、配置维护、分组和命名节省了大量时间。</p><p id="dcff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Apache Oozie是一个调度程序，它调度Hadoop作业并将它们绑定在一起作为一个逻辑工作。有两种工作:</p><ul class=""><li id="7fa6" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> Oozie工作流</em> </strong>:这些是要执行的一系列动作。你可以假设它是一场接力赛。每个运动员等待最后一个人完成他的部分。</li><li id="f3a3" class="jj jk hh in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><strong class="in hi"> <em class="js"> Oozie协调器</em> </strong>:这些是当数据对其可用时触发的Oozie作业。把这想象成我们身体中的反应-刺激系统。同样，当我们对外部刺激做出反应时，Oozie协调器会对数据的可用性做出反应，否则它就会停止工作。</li></ul><h2 id="51d8" class="kh ki hh bd kj kk kl km kn ko kp kq kr iw ks kt ku ja kv kw kx je ky kz la lb bi translated">50.如何在Hadoop中配置一个“Oozie”作业？</h2><p id="35c1" class="pw-post-body-paragraph il im hh in b io lc iq ir is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji ha bi translated">“Oozie”与Hadoop堆栈的其余部分集成，支持几种类型的Hadoop作业，如“Java MapReduce”、“流MapReduce”、“Pig”、“Hive”和“Sqoop”。</p><p id="7126" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我希望这篇文章能给你带来信息和附加值。</p><p id="83e2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你想查看更多关于人工智能、Python、道德黑客等市场最热门技术的文章，那么你可以参考<a class="ae mb" href="https://www.edureka.co/blog?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=bigdata_interview_questions" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="9c6d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请留意本系列中解释大数据其他各方面的其他文章。</p><blockquote class="mc md me"><p id="11f1" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">1.<a class="ae mb" rel="noopener" href="/edureka/hadoop-tutorial-24c48fbf62f6"> Hadoop教程</a></p><p id="3ed5" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">2.<a class="ae mb" rel="noopener" href="/edureka/hive-tutorial-b980dfaae765">蜂巢教程</a></p><p id="8a8f" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">3.<a class="ae mb" rel="noopener" href="/edureka/pig-tutorial-2baab2f0a5b0">养猪教程</a></p><p id="b54e" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">4.<a class="ae mb" rel="noopener" href="/edureka/mapreduce-tutorial-3d9535ddbe7c">地图缩小教程</a></p><p id="697f" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">5.<a class="ae mb" rel="noopener" href="/edureka/hbase-tutorial-bdc36ab32dc0">h基础教程</a></p><p id="b1db" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">6.<a class="ae mb" rel="noopener" href="/edureka/hdfs-tutorial-f8c4af1c8fde"> HDFS教程</a></p><p id="3eac" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">7.<a class="ae mb" rel="noopener" href="/edureka/hadoop-3-35e7fec607a"> Hadoop 3 </a></p><p id="fac7" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">8.<a class="ae mb" rel="noopener" href="/edureka/apache-sqoop-tutorial-431ed0af69ee"> Sqoop教程</a></p><p id="a802" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">9.<a class="ae mb" rel="noopener" href="/edureka/apache-flume-tutorial-6f7150210c76">水槽教程</a></p><p id="6596" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">10.<a class="ae mb" rel="noopener" href="/edureka/apache-oozie-tutorial-d8f7bbbe1591"> Oozie教程</a></p><p id="c00f" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">11.<a class="ae mb" rel="noopener" href="/edureka/hadoop-ecosystem-2a5fb6740177"> Hadoop生态系统</a></p><p id="64df" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">12.<a class="ae mb" rel="noopener" href="/edureka/hive-commands-b70045a5693a">HQL顶级蜂巢命令示例</a></p><p id="3f3a" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">13.<a class="ae mb" rel="noopener" href="/edureka/create-hadoop-cluster-with-amazon-emr-f4ce8de30fd"> Hadoop集群搭配亚马逊EMR？</a></p><p id="ac6f" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">14.<a class="ae mb" rel="noopener" href="/edureka/big-data-engineer-resume-7bc165fc8d9d">大数据工程师简历</a></p><p id="3b7f" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">15.<a class="ae mb" rel="noopener" href="/edureka/hadoop-developer-cc3afc54962c"> Hadoop开发人员-工作趋势和工资</a></p><p id="30d9" class="il im js in b io ip iq ir is it iu iv mf ix iy iz mg jb jc jd mh jf jg jh ji ha bi translated">16.<a class="ae mb" rel="noopener" href="/edureka/big-data-tutorial-b664da0bb0c8">大数据教程</a></p></blockquote></div><div class="ab cl mi mj go mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="ha hb hc hd he"><p id="5b4c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="js">原载于</em><a class="ae mb" href="https://www.edureka.co/blog/interview-questions/top-50-hadoop-interview-questions-2016/" rel="noopener ugc nofollow" target="_blank"><em class="js">https://www.edureka.co</em></a><em class="js">。</em></p></div></div>    
</body>
</html>