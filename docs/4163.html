<html>
<head>
<title>Building an Iris classifier with eager execution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建一个具有快速执行能力的虹膜分类器</h1>
<blockquote>原文：<a href="https://medium.com/google-developer-experts/building-an-iris-classifier-with-eager-execution-3d77ef2c024?source=collection_archive---------1-----------------------#2018-04-13">https://medium.com/google-developer-experts/building-an-iris-classifier-with-eager-execution-3d77ef2c024?source=collection_archive---------1-----------------------#2018-04-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="bf66" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">(转自<a class="ae iw" rel="noopener" href="/tensorflow/building-an-iris-classifier-with-eager-execution-13c00a32adb0"> TensorFlow博客</a>)</h2></div><p id="7c2d" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">近几个月来，TensorFlow的新增功能之一是<a class="ae iw" href="https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html" rel="noopener ugc nofollow" target="_blank">渴望执行</a>，这是一个额外的底层接口，有望使开发变得更加简单和易于调试。只要启用了急切执行，操作就会立即执行，而不必经过单独的执行步骤。简而言之，这意味着编写TF代码可以(潜在地)<strong class="iz hi">像编写纯NumPy代码</strong>一样简单！</p><p id="f7fa" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">作为一个长期要求的功能，我期待着测试它。在玩了一会儿新的界面后，我可以说新的工作流程感觉更加简单和直观，所有的方法都与TF的其余部分完美地集成在一起，尽管处于试验阶段，但大多数功能已经稳定地实现了。</p><p id="597e" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">与此同时，渴望执行是对许多新来者来说已经很复杂的框架的进一步补充。这就是这篇文章的原因:通过展示在<a class="ae iw" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>上从头开始构建一个简单分类模型所需的所有步骤，导航到这个新界面的指导教程。在本文结束时，您将已经在热切的执行中实现了一个完全工作的模型，您可以继续从中进行试验。</p><p id="02d8" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这篇文章也是对热切执行的自我介绍:如果你是TensorFlow低级编程的新手，你将学习如何实现你自己的算法，并使用这个新的接口运行它们。但是如果你已经认为自己是TF方面的专家，这篇文章也将强调启用急切执行<em class="jt"> </em>与标准图构造的区别。</p><p id="9833" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">大家准备好了吗？我们走吧！</p><p id="e361" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated"><em class="jt">注:如果你想尝试急切执行，我还写了一个</em> <a class="ae iw" href="https://github.com/tensorflow/workshops/blob/master/extras/eager/eager-tutorial-simone.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> Jupyter笔记本</em> </a> <em class="jt">作为这个帖子的扩展伴侣。如果你没有可用的TensorFlow设备呢？记得你可以使用</em> <a class="ae iw" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> <em class="jt">谷歌合作服务</em> </a> <em class="jt">在云端运行笔记本！</em></p><h1 id="cc56" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">为什么我们需要急切的执行力？</h1><p id="2d7d" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">如今TF包括几个高级API，比如<a class="ae iw" href="https://www.tensorflow.org/programmers_guide/estimators" rel="noopener ugc nofollow" target="_blank">估算器</a>和<a class="ae iw" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>。但是很多时候，您还想探索和运行一些底层代码，或者更深入地研究框架。在这一点上，您可能想开始编写或运行一些简单的东西。</p><p id="8346" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">为了了解急切执行是如何工作的，让我们从一些数字的加法和乘法开始，看看没有急切执行的代码看起来会是什么样子<strong class="iz hi">:</strong></p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Just adding and multiplying… simple enough!</figcaption></figure><p id="bfbf" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">如果你(像我一样)从早期的<a class="ae iw" href="http://deeplearning.net/software/theano/" rel="noopener ugc nofollow" target="_blank">开始就已经在这里了，如果你不习惯的话，很难记得<strong class="iz hi">这段代码感觉有多奇怪:为什么你甚至需要一个外部对象来打印一个数字？还有为什么在任何地方都找不到b <em class="jt">的值</em>？原因是，在内部，TensorFlow正在构建一个描述所有操作的计算图，然后在幕后进行编译和优化——在TF的最初开发中，优化应该只在模型的完整规范之后发生。</strong></a></p><p id="4c5a" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">现在比较同一个示例，但是在启用了急切执行之后:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Adding and multiplying, this time with eager execution enabled.</figcaption></figure><p id="10b5" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这是相当多的NumPy代码！用编程术语来说，TF的默认API是<strong class="iz hi">声明性的</strong>:只有当我们请求特定节点的输出时才会执行，并且它只返回特定的结果。相反，新的急切执行是<strong class="iz hi">命令式的</strong>:执行立即遵循定义，有其所有的好处，例如立即的可视化调试。让我们看看这对优化我们的模型意味着什么——但是首先，让我们绕一个小弯路，看看如何安装和启用热切执行。</p><h1 id="fd8c" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">在代码中启用急切执行</h1><p id="ef81" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">从TF v1.5开始，急切执行就已经作为一个实验性的特性被包含进来了，为了这篇文章的目的，我将使用最新的v1.7rc0版本(提到为了向后兼容可能需要修改代码的地方)。</p><p id="9b96" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">如果你想玩最新版本，推荐的方法是建立一个单独的虚拟环境(你可以在笔记本和<a class="ae iw" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank">官方指南</a>上找到详细的说明)并从控制台安装TF的每夜版本:</p><blockquote class="lc ld le"><p id="b755" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">pip安装tf-nightly[-gpu]</p></blockquote><p id="89e6" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">可以通过一行代码实现急切执行:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Importing and enabling eager.</figcaption></figure><blockquote class="lc ld le"><p id="3a7b" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">如果您正在使用1.5版或1.6版，请用<code class="du li lj lk ll b"><em class="hh">tfe.enable_eager_execution()</em></code>更改<code class="du li lj lk ll b"><em class="hh">tf.enable_eager_execution()</em></code>。</p></blockquote><p id="44e1" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">重要的是，你需要在程序的开头运行命令<strong class="iz hi">，否则命令会抛出错误并拒绝执行。原因是，通过启用渴望执行，您正在改变前面描述的TF的默认内部机制，这意味着几个低级命令将只在文档中描述的两种模态(图构造或渴望执行)之一中可用。</strong></p><h1 id="7b3f" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">我们将在本教程中做什么</h1><p id="1e66" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">在本教程的剩余部分中，我们将为Iris数据集构建一个分类模型(启用了渴望执行)，这是一个简单的分类数据集，您在遵循TF 的<a class="ae iw" href="https://www.tensorflow.org/get_started/premade_estimators" rel="noopener ugc nofollow" target="_blank">入门指南时应该已经遇到过。任务是根据描述其几何形状的四个数字特征将一组虹膜分为三个不同的类别:</a></p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/29be41fe4fde3561b65b3cc96b52a713.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xOxhDM-2Cz8RL16rkRBPKQ.jpeg"/></div><figcaption class="ky kz et er es la lb bd b be z dx">The three classes of Irises we want to classify (<a class="ae iw" href="https://www.tensorflow.org/get_started/premade_estimators" rel="noopener ugc nofollow" target="_blank">taken from Getting Started with TensorFlow</a>). From left to right, original copyright by by <a class="ae iw" href="https://commons.wikimedia.org/wiki/User:Radomil" rel="noopener ugc nofollow" target="_blank">Radomil</a>, CC BY-SA 3.0, <a class="ae iw" href="https://commons.wikimedia.org/wiki/User:Dlanglois" rel="noopener ugc nofollow" target="_blank">Dlanglois</a>, CC BY-SA 3.0, and <a class="ae iw" href="https://www.flickr.com/photos/33397993@N05" rel="noopener ugc nofollow" target="_blank">Frank Mayfield</a>, CC BY-SA 2.0.</figcaption></figure><p id="3807" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">出于本文的目的，我只是从<a class="ae iw" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit-learn库</a>加载数据集的版本，规范化其输入，并将其一分为二用于训练和测试。如果您有兴趣，以下是加载数据集的完整代码:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Sample code for loading the Iris dataset.</figcaption></figure><p id="f6e6" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">我们将分五步进行。第一部分只是熟悉一些基本的eager对象，比如变量和函数，以及它们如何与NumPy数组进行互操作。然后，我们将学习如何构建分类模型(第2部分)、优化分类模型(第3部分)、将数据加载到TF中(第4部分)以及调试整个过程(第5部分)。</p><h1 id="3dd7" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">构建分类器(1/5):函数、梯度和变量</h1><p id="6631" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">eager execution提供的基本操作是<strong class="iz hi">自动微分</strong>:给定一些在张量上操作的函数，我们可以自动计算关于这些张量中的一个或多个的梯度(并且，不用说，是高效的)。</p><p id="3c69" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">如果你正在构建一个TF图，函数和梯度被定义为计算图中的节点。启用急切执行后，<strong class="iz hi">这两个函数都是标准的Python函数</strong>。例如，下面是一些定义简单平方函数并计算其梯度的代码:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Automatic gradient computation in eager.</figcaption></figure><p id="6e74" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">所有操作都内部保存在“磁带”中，对用户透明，而不是必须构建图形。<code class="du li lj lk ll b">tfe.gradients_function</code>就是神奇之处:您可以将任何Python函数(至少有一个张量作为输入)作为参数传递，它将返回<strong class="iz hi">另一个Python函数</strong>来计算关于它的任何参数的梯度。</p><blockquote class="lc ld le"><p id="f0bf" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">您可能已经注意到，在上面的第6行中，我们使用了<code class="du li lj lk ll b"><em class="hh">tf.constant</em></code>来构建一个常量张量:这一步是可选的，因为传递一个NumPy数组或一个float值会触发一个自动转换操作。</p></blockquote><p id="1bdb" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">您还可以将调用链接起来以获得高阶导数:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Higher-order derivatives with eager execution.</figcaption></figure><p id="1d5a" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">TF的一个基本构件是<a class="ae iw" href="https://www.tensorflow.org/programmers_guide/variables" rel="noopener ugc nofollow" target="_blank">变量</a>:组成我们模型的有状态数组，我们需要在训练阶段对其进行优化。Eager有一个自定义的变量实现:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Variables in eager execution and casting to/from NumPy objects.</figcaption></figure><p id="ff2c" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">正如您所看到的，eager中的变量<strong class="iz hi">完全可以与NumPy数组</strong>互操作，它们的值一旦被请求就会被自动初始化(而对于图形构造，您需要显式调用一个初始化例程)。使用<code class="du li lj lk ll b">tfe.implicit_gradients</code>，你也可以自动计算一个函数相对于<em class="jt">它使用的所有</em>变量的梯度。例如，这等同于上面的梯度计算，但是使用变量和隐式梯度:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Computing implicit gradients with respect to all variables.</figcaption></figure><p id="97dc" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">现在我们已经有了所有的构建模块，我们可以进入更高的抽象层次，从神经网络的定义开始。</p><h1 id="8ea2" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">构建分类器(2/5):层和网络</h1><p id="6671" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">理论上，我们已经拥有了优化模型所需的一切:我们可以实例化一堆变量(模型的参数)，并将模型本身的逻辑封装在一个函数中。例如，这是一个一维逻辑回归模型:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">A simple logistic regression model (without using high-level methods).</figcaption></figure><p id="9d7e" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">然而，一旦我们开始添加更多的操作(例如，新的隐藏层、dropout等等)，这种方法就无法扩展。构建更复杂模型的一个简单方法是使用<a class="ae iw" href="https://www.tensorflow.org/tutorials/layers" rel="noopener ugc nofollow" target="_blank">层</a>，这对于使用TF高级接口的人来说应该很熟悉:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Defining a neural network model with Layers.</figcaption></figure><p id="8a05" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">在上面的例子中，我们正在构建一个只有一个隐藏层的模型，中间有一个dropout操作:变量的<strong class="iz hi">定义在每一层</strong>中处理，我们可以通过在一个简单的(再次，Python)函数中将各层链接在一起来定义我们的模型。这个模型很容易解释，即使你不习惯TF，我们可以通过向函数传递另一个布尔标志来实现dropout逻辑，增加可读性。</p><blockquote class="lc ld le"><p id="4451" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated"><code class="du li lj lk ll b"><em class="hh">tf.layers</em></code>模块是<code class="du li lj lk ll b"><em class="hh">tf.keras.layers</em></code>的实现，它包含一组在<a class="ae iw" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers" rel="noopener ugc nofollow" target="_blank"> Keras库</a>中定义的高层。目前的实现只是部分的，新的层在不断的增加:同时，你也可以直接使用<code class="du li lj lk ll b"><em class="hh">tf.keras.layers</em></code>中定义的层。</p></blockquote><p id="a0b5" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">由于以这种方式构建网络是一个常见的工作流，TF还提供了一个更高层次的抽象，即<code class="du li lj lk ll b">Model</code>对象，一个封装了模型逻辑的定制类，提供了一些用于调试和检查训练的高级工具:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Defining a neural network model with the Network object.</figcaption></figure><blockquote class="lc ld le"><p id="b99c" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">如果你使用的是v1.5或者v1.6，你需要使用<code class="du li lj lk ll b"><em class="hh">tfe.Network</em></code>而不是<code class="du li lj lk ll b"><em class="hh">tf.keras.Model</em></code>，你需要为初始化中添加的每一层显式调用<code class="du li lj lk ll b"><em class="hh">self.track_layer()</em></code>。</p></blockquote><p id="af48" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">网络的一个主要好处是它们封装了与模型变量相关的所有逻辑。为了理解它，让我们稍微摆弄一下我们的模型:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Using a network to compute predictions and get its variables.</figcaption></figure><p id="88c3" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">第2行只是模型的初始化。第五行显示了模型中变量的<strong class="iz hi">惰性</strong>:即使eager执行有一个动态工作流，变量也只在模型第一次运行时被初始化，因为在此之前，eager对其输入张量的形状没有任何指示。预测可以通过简单地用一些数据调用对象来获得(第8行):在这之后，变量被正确地初始化，如第11行所示。</p><h1 id="71b5" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">构建分类器(3/5):损失和优化器</h1><p id="5416" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">由于我们将使用我们的模型来做一些分类，我们需要定义一个适当的成本函数来训练它。与之前类似，我们可以使用TF的标准组件，通过<strong class="iz hi">将它们封装在Python函数</strong>中:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Cross-entropy definition with eager execution enabled.</figcaption></figure><blockquote class="lc ld le"><p id="e582" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">作为一个小提示，我们正在使用<code class="du li lj lk ll b"><em class="hh">softmax_cross_entropy_with_logits_v2</em></code>，因为旧的<code class="du li lj lk ll b"><em class="hh">softmax_cross_entropy_with_logits</em></code>将很快被废弃！两者在这里完全相同，不同之处在于新版本允许对标签进行梯度计算(这个简单的例子不需要)。通过去除一键编码，我们也可以等效地使用<code class="du li lj lk ll b"><em class="hh">sparse_softmax_cross_entropy</em></code>。</p></blockquote><p id="69a7" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">为了优化，我们可以定义自己的定制逻辑，或者(更有可能)使用TF 中已经定义的<a class="ae iw" href="https://www.tensorflow.org/api_guides/python/train" rel="noopener ugc nofollow" target="_blank">优化器之一。此时，您可能会猜到我们的代码会是什么样子:</a></p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Building and calling optimizers in TF.</figcaption></figure><p id="33ed" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这里唯一的语法上的好处是使用一个没有参数的匿名函数来调用最小化例程:这是必需的，因为优化器是为图形构造而设计的，并且已经被定制为支持新的eager接口。另一种可能性是显式计算我们模型的梯度，并使用优化器的<code class="du li lj lk ll b">apply_gradients</code>函数:如果你感兴趣，我在笔记本中描述了这种替代方式。</p><h1 id="dcee" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">构建分类器(4/5):加载数据和迭代器</h1><p id="4a7f" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">如果您了解TF的最新信息，您会知道向我们的模型提供数据的首选方式是通过<a class="ae iw" href="https://www.tensorflow.org/programmers_guide/datasets" rel="noopener ugc nofollow" target="_blank">高级数据集API </a>，它可用于从多个来源加载数据，并与所有高级API连接。急切执行的一个很好的特性是，您可以将数据集封装在Pythonesque迭代器中，并像使用任何其他迭代器一样使用迭代器<strong class="iz hi">循环遍历它。</strong></p><p id="bf3c" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">在使用迭代器之前，让我们遍历一下我们加载的Iris数据集的训练部分:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Building datasets and iterating over it using the tfe.Iterator object.</figcaption></figure><p id="8ad8" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">在上面的代码中，我们将数据加载到<code class="du li lj lk ll b">Dataset</code>对象中(第2行)，然后使用迭代器遍历32个元素的小批，计算每批的阳性标签的平均数，例如:</p><blockquote class="lc ld le"><p id="d78c" class="ix iy jt iz b ja jb ii jc jd je il jf lf jh ji jj lg jl jm jn lh jp jq jr js ha bi translated">第[0]类百分比:31.25 % <br/>第[0]类百分比:34.375 % <br/>第[0]类百分比:37.5 % <br/>第[0]类百分比:25.0 %</p></blockquote><h1 id="6d58" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">构建分类器(5/5):调试工具</h1><p id="e828" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">我们的任务最不需要的是一些调试和可视化结果的工具。因为在标准的图结构中，执行被隐藏在会话的动态之下，所以调试一直是TF新手的难点，也是开发<a class="ae iw" href="https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>的主要原因。然而，在急切执行中，一切都是动态运行的，你可以使用Python工具箱中的任何工具来完成它:从Matplotlib的绘图到控制台的输出，你可以命名它。</p><p id="3384" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">Eager也有一些实用程序来简化调试。例如，<a class="ae iw" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/eager/metrics" rel="noopener ugc nofollow" target="_blank">度量</a>可用于计算和累加每个时期的值:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Accumulating the accuracy for an entire epoch using a tfe.metrics.Metric object.</figcaption></figure><p id="0f82" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">上面的代码循环遍历一个时期，并为每一批计算模型的准确性。由于我们还没有训练它，准确率可能会达到33%左右，或者说是随机的。</p><p id="6dde" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">如果您喜欢好的ol' TensorBoard，您可以使用摘要的<a class="ae iw" href="https://www.tensorflow.org/versions/master/api_docs/python/tf/contrib/summary" rel="noopener ugc nofollow" target="_blank">实验实现</a>在仪表板上保存可视化值:</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Saving the accuracy on disk using a summary.</figcaption></figure><p id="59b9" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这里的语法稍微复杂一些:在创建一个writer之后，我们需要将它设置为默认的writer<em class="jt">和</em>选择一个在磁盘上保存值的时间间隔(基于TF的全局步长，它将随着我们每次优化步长而增加)。</p><p id="8c5e" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这只是粗略地看了一下一些启用了急切执行的调试工具:查看笔记本，了解其他可视化和调试技术的描述。</p><h1 id="0705" class="ju jv hh bd jw jx jy jz ka kb kc kd ke in kf io kg iq kh ir ki it kj iu kk kl bi translated">把所有的放在一起</h1><p id="d60c" class="pw-post-body-paragraph ix iy hh iz b ja km ii jc jd kn il jf jg ko ji jj jk kp jm jn jo kq jq jr js ha bi translated">我们终于准备好把所有的东西放在一起了！我们将对我们的网络进行几个时期的训练，使用一个度量来计算准确性并将其存储在一个NumPy数组中，并通过将它保存在磁盘上来跟踪损失。最后，我们使用Matplotlib绘制所有时期的精确度。</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="kw kx l"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Training procedure for our Iris classifier.</figcaption></figure><p id="d7f3" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">网络很容易达到100%的准确性，这是一个简单的基准:</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/42e4b1168f34184a761e0be84a2eb725.png" data-original-src="https://miro.medium.com/v2/format:webp/1*iKa1eJxRTSdOgnWquUHSPQ.png"/></div></figure><p id="7449" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">如果你打开TensorBoard，你可以查看损失进度:</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="ab fe cl lm"><img src="../Images/e9d808d037b3a81f2bf22151888b7250.png" data-original-src="https://miro.medium.com/v2/format:webp/1*IyozhqraW1-VSCuWen0cSg.png"/></div></figure><p id="d7f7" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">你已经到了我的急切执行教程的结尾。到目前为止，我希望您相信使用eager可以非常快速地构建原型，同时使调试更加简单。再一次，如果你想了解我们在本教程中使用的所有方法的更多细节，你可以查看<a class="ae iw" href="https://github.com/tensorflow/workshops/blob/master/extras/eager/eager-tutorial-simone.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>，本教程只是对界面的简明介绍。</p><p id="2cb1" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated">这里有很多我们没有看到的东西，比如如何启用GPU支持，或者如何在模型内部使用控制流操作。尽管如此，我希望这是足够的样板代码，可以帮助您踏上TF的低级编程之旅！</p></div><div class="ab cl lp lq go lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ha hb hc hd he"><p id="29dc" class="pw-post-body-paragraph ix iy hh iz b ja jb ii jc jd je il jf jg jh ji jj jk jl jm jn jo jp jq jr js ha bi translated"><em class="jt">原载于2018年4月13日</em><a class="ae iw" rel="noopener" href="/tensorflow/building-an-iris-classifier-with-eager-execution-13c00a32adb0"><em class="jt">medium.com</em></a><em class="jt">。</em></p></div></div>    
</body>
</html>