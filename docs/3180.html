<html>
<head>
<title>Scrapy Tutorial: How To Make A Web-Crawler Using Scrapy?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scrapy教程:如何使用Scrapy制作网络爬虫？</h1>
<blockquote>原文：<a href="https://medium.com/edureka/scrapy-tutorial-5584517658fb?source=collection_archive---------2-----------------------#2019-09-06">https://medium.com/edureka/scrapy-tutorial-5584517658fb?source=collection_archive---------2-----------------------#2019-09-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/ac4b9128e02a9bb6168f94da9b28b03c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*dvIQL6ORCLyBWeZ8k2tZBA.png"/></div><figcaption class="il im et er es in io bd b be z dx">Scrapy Tutorial — Edureka</figcaption></figure><p id="2ea6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Web抓取是从网页中收集数据的一种有效方式，已经成为数据科学中的一种有效工具。有了beautifulsoup等各种用于web抓取的python库，数据科学家的工作就变得最佳了。Scrapy是一个强大的网络框架，用于提取、处理和存储数据。在这篇文章中，我们将学习如何使用scrapy制作一个网络爬虫，以下是这篇博客中讨论的主题:</p><ul class=""><li id="42bd" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">什么是Scrapy？</li><li id="9500" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">什么是网络爬虫？</li><li id="e5b8" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">Scrapy怎么安装？</li><li id="3119" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">开始你的第一个Scrapy项目</li><li id="520f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">制作你的第一只蜘蛛</li><li id="c7a7" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">提取数据</li><li id="69d1" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">存储提取的数据</li></ul><h1 id="ea69" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">什么是Scrapy？</h1><p id="0989" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">Scrapy是一个用python编写的免费开源网络爬行框架。它最初是为执行web抓取而设计的，但也可以用于使用API提取数据。它由Scrapinghub有限公司维护。</p><p id="0b1f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Scrapy是一个完整的软件包，可以下载网页，处理和存储数据库中的数据。</p><p id="4b27" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它就像一个发电站，有多种方式来抓取网站。Scrapy可以轻松处理更大的任务，在不到一分钟的时间内抓取多个页面或一组URL。它使用异步工作的twister来实现并发性。</p><p id="3cbc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它提供了蜘蛛契约，允许我们创建通用和深度爬虫。Scrapy还提供了项目管道来创建spider中的函数，这些函数可以执行各种操作，如替换数据中的值等。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/704fdafd07c2404591b1de0b3dd04950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KlIBmZXVvzoAHWy0eAtKfQ.png"/></div></div></figure><h1 id="83c7" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">什么是网络爬虫？</h1><p id="e52e" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">网络爬虫是一种自动在网上搜索文件的程序。它们主要是为自动浏览的重复动作而设计的。</p><h2 id="fdab" class="ln kc hh bd kd lo lp lq kh lr ls lt kl ja lu lv kp je lw lx kt ji ly lz kx ma bi translated">它是如何工作的？</h2><p id="009f" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">网络爬虫很像图书管理员。它在web上查找信息，对信息进行分类，然后对信息进行索引和编目，以便相应地检索和存储爬取的信息。</p><p id="fd83" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">爬虫要执行的操作是预先创建的，然后爬虫自动执行所有那些将创建索引的操作。输出软件可以访问这些索引。</p><p id="c935" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们来看看网络爬虫的各种应用:</p><ul class=""><li id="5ee3" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">价格比较门户使用网络爬虫搜索特定的产品细节，以便对不同平台上的价格进行比较。</li><li id="38fa" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">网络爬虫在数据挖掘领域的信息检索中起着非常重要的作用。</li><li id="c9d5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">数据分析工具使用网络爬虫来计算页面视图、入站和出站链接的数据。</li><li id="b9d8" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">爬虫也服务于信息中心，收集数据，例如新闻门户。</li></ul><h1 id="b3b4" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">Scrapy怎么安装？</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/3427a00064a791b6a784fcfebd231e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*qoRBl4WykVikoAtd7FX04g.png"/></div></figure><p id="da82" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要在你的系统上安装scrapy，建议安装在专用的virtualenv上。安装工作与python中的任何其他包非常相似，如果您使用的是<a class="ae mc" href="https://www.edureka.co/blog/python-anaconda-tutorial/" rel="noopener ugc nofollow" target="_blank"> conda </a>环境，请使用以下命令安装scrapy:</p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="ad15" class="ln kc hh me b fi mi mj l mk ml">conda install -c conda-forge scrapy</span></pre><p id="2736" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您也可以使用pip环境来安装scrapy，</p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="4e18" class="ln kc hh me b fi mi mj l mk ml">pip install scrapy</span></pre><p id="df27" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">根据您的操作系统，可能会有一些编译依赖关系。Scrapy是用纯python编写的，可能依赖于一些python包，如:</p><ul class=""><li id="a8e4" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">lxml——它是一个高效的xml和HTML解析器。</li><li id="07b3" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">parcel——基于lxml编写的HTML/XML提取库</li><li id="4097" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">w3lib——它是处理URL和网页编码的多用途助手</li><li id="dddf" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">twisted——一个异步网络框架</li><li id="8c8e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">加密技术—它有助于满足各种网络级别的安全需求</li></ul><h1 id="4bbc" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">开始你的第一个Scrapy项目</h1><p id="a691" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">要启动您的第一个scrapy项目，请转到您想要保存文件的目录或位置，并执行以下命令</p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="d8e1" class="ln kc hh me b fi mi mj l mk ml">scrapy startproject projectname</span></pre><p id="1680" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">执行该命令后，您将在该位置创建以下目录。</p><ul class=""><li id="ed38" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">项目名称/</li></ul><p id="0e6c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">scrapy.cfg:它部署配置文件</p><ul class=""><li id="048c" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">项目名称/</li></ul><p id="aa20" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">__init__。py:项目的python模块</p><p id="8303" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">items.py:项目项定义文件</p><p id="da97" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">py:项目中间件文件</p><p id="c590" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">项目管道文件</p><p id="d111" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">settings.py:项目设置文件</p><ul class=""><li id="4087" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">蜘蛛/</li></ul><p id="c22f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">__init__。py:一个目录，稍后你会把你的蜘蛛放在那里</p><h1 id="f574" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">制作你的第一只蜘蛛</h1><p id="4639" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">蜘蛛是我们定义的类，scrapy用它从网络上收集信息。你必须子类化scrapy。Spider并定义要发出的初始请求。</p><p id="379c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您在一个单独的python文件中为您的蜘蛛编写代码，并将其保存在项目的projectname/spiders目录中。</p><p id="4689" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> quotes_spider.py </strong></p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="3579" class="ln kc hh me b fi mi mj l mk ml">import scrapy<br/> <br/>class QuotesSpider(scrapy.Spider):<br/>    name = "quotes"<br/>    def start_request(self):<br/>          urls = [ '&lt;a href="<a class="ae mc" href="http://quotes.toscrape.com/page/1/" rel="noopener ugc nofollow" target="_blank">http://quotes.toscrape.com/page/1/</a>"&gt;<a class="ae mc" href="http://quotes.toscrape.com/page/1/" rel="noopener ugc nofollow" target="_blank">http://quotes.toscrape.com/page/1/</a>&lt;/a&gt;',<br/>                       <a class="ae mc" href="http://quotes.toscrape.com/page/2/" rel="noopener ugc nofollow" target="_blank">http://quotes.toscrape.com/page/2/</a>,<br/>                     ]<br/>          for url in urls:<br/>              yield scrapy.Request(url=url , callback= self.parse)<br/> <br/>def parse(self, response):<br/>     page = response.url.split("/")[-2]<br/>     filename = 'quotes-%s.html' % page<br/>     with open(filename, 'wb') as f:<br/>           f.write(response.body)<br/>     self.log('saved file %s' % filename)</span></pre><p id="11a7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如你所见，我们在蜘蛛中定义了各种功能，</p><ul class=""><li id="e612" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">名称:它识别蜘蛛，它必须在整个项目中是唯一的。</li><li id="0816" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">start_requests():必须返回蜘蛛开始爬行的请求的iterable。</li><li id="bc6f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">parse():这个方法将被调用来处理每个请求下载的响应。</li></ul><h1 id="3bf3" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">提取数据</h1><p id="1465" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">直到现在蜘蛛没有提取任何数据，它只是保存了整个HTML文件。scrapy spider通常会生成许多包含从页面中提取的数据的字典。我们在回调中使用python中的yield关键字来提取数据。</p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="9d7f" class="ln kc hh me b fi mi mj l mk ml">import scrapy<br/> <br/>class QuotesSpider(scrapy.Spider):<br/> <br/>       name = "quotes"<br/>       start_urls = [ <a class="ae mc" href="http://quotes.toscrape.com/page/1/'" rel="noopener ugc nofollow" target="_blank">http://quotes.toscrape.com/page/1/'</a>,<br/>                             <a class="ae mc" href="http://quotes.toscrape.com/page/2/" rel="noopener ugc nofollow" target="_blank">http://quotes.toscrape.com/page/2/</a>,<br/>                           ]<br/> <br/>       def parse(self, response):<br/>            for quote in response.css('div.quote'):<br/>                  yield {<br/>                              'text': quote.css(span.text::text').get(),<br/>                              'author': quote.css(small.author::text')get(),<br/>                              'tags': quote.css(div.tags a.tag::text').getall()<br/>                             }</span></pre><p id="788a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当您运行这个蜘蛛时，它将输出提取的数据和日志。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/f4c422ced2ad7699c96437eeae675a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fylT_L6cDsR3u1UOhSnI-A.png"/></div></div></figure><h1 id="e5fe" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">存储数据</h1><p id="d298" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">存储提取数据的最简单方法是使用feed exports，使用以下命令来存储数据。</p><pre class="lf lg lh li fd md me mf mg aw mh bi"><span id="25a4" class="ln kc hh me b fi mi mj l mk ml">scrapy crawl quotes -o quotes.json</span></pre><p id="ebd9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个命令将生成一个quotes.json文件，包含所有抓取的项目，以json序列化。</p><p id="ee02" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就把我们带到了本文的结尾，在这里我们学习了如何使用python中的scrapy制作一个网络爬虫来抓取网站并将数据提取到一个JSON文件中。我希望你清楚本教程中与你分享的所有内容。</p><p id="9d90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="d95a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释Python和数据科学的各个方面。</p><blockquote class="mn mo mp"><p id="ec78" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated"><em class="hh"> 1 </em>。<a class="ae mc" rel="noopener" href="/edureka/machine-learning-classifier-c02fbd8400c9">Python中的机器学习分类器</a></p><p id="ca54" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">2.<a class="ae mc" rel="noopener" href="/edureka/python-scikit-learn-cheat-sheet-9786382be9f5"> Python Scikit-Learn备忘单</a></p><p id="484e" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">3.<a class="ae mc" rel="noopener" href="/edureka/python-libraries-for-data-science-and-machine-learning-1c502744f277">机器学习工具</a></p><p id="824a" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">4.<a class="ae mc" rel="noopener" href="/edureka/python-libraries-for-data-science-and-machine-learning-1c502744f277">用于数据科学和机器学习的Python库</a></p><p id="2980" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">5.<a class="ae mc" rel="noopener" href="/edureka/how-to-make-a-chatbot-in-python-b68fd390b219">Python中的聊天机器人</a></p><p id="9cd9" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">6.<a class="ae mc" rel="noopener" href="/edureka/collections-in-python-d0bc0ed8d938"> Python集合</a></p><p id="ef50" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">7.<a class="ae mc" rel="noopener" href="/edureka/python-modules-abb0145a5963"> Python模块</a></p><p id="985c" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">8.<a class="ae mc" rel="noopener" href="/edureka/python-developer-skills-371583a69be1"> Python开发者技能</a></p><p id="b881" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">9.<a class="ae mc" rel="noopener" href="/edureka/oops-interview-questions-621fc922cdf4">哎呀面试问答</a></p><p id="de6c" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">10.<a class="ae mc" rel="noopener" href="/edureka/python-developer-resume-ded7799b4389">Python开发者简历</a></p><p id="4794" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">11.<a class="ae mc" rel="noopener" href="/edureka/exploratory-data-analysis-in-python-3ee69362a46e">Python中的探索性数据分析</a></p><p id="f298" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">12.<a class="ae mc" rel="noopener" href="/edureka/python-turtle-module-361816449390">带Python的乌龟模块的贪吃蛇游戏</a></p><p id="470c" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">13.<a class="ae mc" rel="noopener" href="/edureka/python-developer-salary-ba2eff6a502e"> Python开发者工资</a></p><p id="8c57" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">14.<a class="ae mc" rel="noopener" href="/edureka/principal-component-analysis-69d7a4babc96">主成分分析</a></p><p id="9642" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">15.<a class="ae mc" rel="noopener" href="/edureka/python-vs-cpp-c3ffbea01eec"> Python vs C++ </a></p><p id="05f8" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">16.<a class="ae mc" rel="noopener" href="/edureka/web-scraping-with-python-d9e6506007bf">用Python进行网页抓取</a></p><p id="7987" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">17.<a class="ae mc" rel="noopener" href="/edureka/scipy-tutorial-38723361ba4b"> Python SciPy </a></p><p id="c1fc" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">18.<a class="ae mc" rel="noopener" href="/edureka/least-square-regression-40b59cca8ea7">最小二乘回归法</a></p><p id="9ce0" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">19.<a class="ae mc" rel="noopener" href="/edureka/jupyter-notebook-cheat-sheet-88f60d1aca7"> Jupyter笔记本小抄</a></p><p id="9ae5" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">20.<a class="ae mc" rel="noopener" href="/edureka/python-basics-f371d7fc0054"> Python基础知识</a></p><p id="6ac2" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">21.<a class="ae mc" rel="noopener" href="/edureka/python-pattern-programs-75e1e764a42f"> Python模式程序</a></p><p id="0345" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">22.<a class="ae mc" rel="noopener" href="/edureka/generators-in-python-258f21e3d3ff">Python中的发电机</a></p><p id="abe3" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">23.<a class="ae mc" rel="noopener" href="/edureka/python-decorator-tutorial-bf7b21278564"> Python装饰师</a></p><p id="e7d3" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">24.<a class="ae mc" rel="noopener" href="/edureka/spyder-ide-2a91caac4e46"> Python Spyder IDE </a></p><p id="7295" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">25.<a class="ae mc" rel="noopener" href="/edureka/kivy-tutorial-9a0f02fe53f5">在Python中使用Kivy的移动应用</a></p><p id="bc88" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">26.<a class="ae mc" rel="noopener" href="/edureka/best-books-for-python-11137561beb7">十大最佳学习书籍&amp;练习Python </a></p><p id="0591" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">27.<a class="ae mc" rel="noopener" href="/edureka/robot-framework-tutorial-f8a75ab23cfd">使用Python的机器人框架</a></p><p id="ca4a" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">28.<a class="ae mc" rel="noopener" href="/edureka/snake-game-with-pygame-497f1683eeaa">使用PyGame的Python中的贪吃蛇游戏</a></p><p id="ca77" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">29.<a class="ae mc" rel="noopener" href="/edureka/django-interview-questions-a4df7bfeb7e8"> Django面试问答</a></p><p id="9dc1" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">30.<a class="ae mc" rel="noopener" href="/edureka/python-applications-18b780d64f3b">十大Python应用</a></p><p id="c5bb" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">31.<a class="ae mc" rel="noopener" href="/edureka/hash-tables-and-hashmaps-in-python-3bd7fc1b00b4">Python中的哈希表和哈希表</a></p><p id="588a" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">32.<a class="ae mc" rel="noopener" href="/edureka/whats-new-python-3-8-7d52cda747b"> Python 3.8 </a></p><p id="7de9" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">33.<a class="ae mc" rel="noopener" href="/edureka/support-vector-machine-in-python-539dca55c26a">支持向量机</a></p><p id="c318" class="ip iq mq ir b is it iu iv iw ix iy iz mr jb jc jd ms jf jg jh mt jj jk jl jm ha bi translated">34.<a class="ae mc" rel="noopener" href="/edureka/python-tutorial-be1b3d015745"> Python教程</a></p></blockquote><p id="667b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="mq">原载于2019年9月6日</em><a class="ae mc" href="https://www.edureka.co/blog/scrapy-tutorial/" rel="noopener ugc nofollow" target="_blank"><em class="mq">https://www.edureka.co</em></a><em class="mq">。</em></p></div></div>    
</body>
</html>