# Hadoop 3.0 有什么新功能？Apache Hadoop 3 的增强功能

> 原文：<https://medium.com/edureka/hadoop-3-35e7fec607a?source=collection_archive---------0----------------------->

![](img/3806d9faa790bc3794f2d399af8e6cdb.png)

What’s new in Hadoop 3 - Edureka

这篇“***Hadoop 3.0 中的新特性*** ”文章关注 Hadoop 3 中预期的变化，因为它仍处于 alpha 阶段。Apache 社区已经整合了许多变化，并且仍在对其中一些进行改进。因此，我们将从更广泛的角度来看待预期的变化。

我们将讨论的主要变化是:

*   Hadoop 3 中要求的最低 Java 版本是 8
*   HDFS 对擦除编码的支持
*   纱线时间线服务 v.2
*   外壳脚本重写
*   阴影客户端 jar
*   支持机会容器
*   MapReduce 任务级本机优化
*   支持 2 个以上的 NameNodes
*   多个服务的默认端口已更改
*   支持文件系统连接器
*   DataNode 内部平衡器
*   返工守护进程和任务堆管理

Apache Hadoop 3 将在 Hadoop-2.x 的基础上整合多项增强功能。因此，让我们向前看一下每项增强功能。

# 1.Hadoop 3 中所需的最低 Java 版本从 7 增加到 8

在 Hadoop 3 中，所有 Hadoop JARs 都是针对 Java 8 的运行时版本编译的。所以，仍在使用 Java 7 或更低版本的用户在开始使用 Hadoop 3 时，必须升级到 Java 8。

![](img/90b639bd0edfa3f17080bc629778f672.png)

现在让我们讨论 Hadoop 3 的重要增强之一，即擦除编码，它将减少存储开销，同时提供与之前相同的容错级别。

# 2.HDFS 对擦除编码的支持

现在让我们先来了解一下什么是擦除编码。

![](img/35b73efdffc2bbbb0fac7f99b294c530.png)

一般在存储系统中，擦除编码多用于 ***廉价磁盘冗余阵列(RAID)*** 。

如上图所示，RAID 通过 ***条带化*** 实现 EC，其中逻辑上连续的数据(如文件)被分成更小的单元(如位、字节或块)，并将连续的单元存储在不同的磁盘上。

然后，对于原始数据单元的每个条带，计算并存储一定数量的 ***奇偶校验单元*** 。这个过程叫做 ***编码*** 。*任何条带单元上的错误都可以通过基于幸存数据单元和奇偶校验单元的解码计算来恢复*。

既然我们有了擦除编码的概念，现在让我们先来看看 Hadoop 2.x 中的早期复制场景。

![](img/fb26da8953a87543a2d87241ccc30a05.png)

***HDFS*** 中的默认复制因子是 3，其中一个是原始数据块，另外两个是副本，每个副本都需要 100%的存储开销。因此，这使得 ***的存储开销为*** 的 200%,并且会消耗网络带宽等其他资源。

但是，具有低 I/O 活动的冷数据集的副本在正常操作期间很少被访问，但仍然会消耗与原始数据集相同数量的资源。

与 HDFS 复制相比，擦除编码以更少的空间开销存储数据并提供容错。擦除编码(EC)可用于替代复制，这将提供相同级别的容错，而存储开销更少。

![](img/5ed886050581a1071fd0a20a12447ba1.png)

将 EC 与 HDFS 集成可以保持相同的容错能力，同时提高存储效率。例如，具有 6 个数据块的 3x 复制文件将消耗 6*3 = 18 个数据块的磁盘空间。但采用 EC (6 数据，3 奇偶)部署，只会消耗 9 块(6 数据块+ 3 奇偶块)的磁盘空间。这只需要高达 50%的存储开销。

由于执行远程读取，擦除编码在数据重建中需要额外的开销，因此它通常用于存储不太频繁访问的数据。在部署擦除代码之前，用户应该考虑擦除编码的所有开销，如存储、网络和 CPU 开销。

现在，为了在 HDFS 有效地支持擦除编码，他们在体系结构上做了一些改变。让我们来看看架构的变化。

## HDFS 擦除编码:架构

*   **NameNode 扩展**–HDFS 文件被分成块组，这些块组具有一定数量的内部块。现在，为了减少这些额外块的 NameNode 内存消耗，引入了新的分层 ***块命名协议*** 。块组的 ID 可以从其任何内部块的 ID 中推导出来。这允许在块组级别而不是块级别进行管理。
*   **客户端扩展**–在 HDFS 实施擦除编码后，NameNode 在块组级别工作&客户端读写路径得到增强，可在*并行*的块组中的多个内部块上工作。

1.  在输出/写入路径上， *DFSStripedOutputStream* 管理一组数据流，每个数据流对应一个在当前块组中存储内部块的 DataNode。协调器负责整个块组的操作，包括结束当前块组、分配新的块组等。
2.  在输入/读取路径上， *DFSStripedInputStream* 将请求的数据逻辑字节范围转换为存储在 DataNodes 上的内部块。然后，它并行发出读取请求。失败时，它会发出额外的解码读取请求。

*   **DataNode 扩展****–**DataNode 运行一个额外的 ErasureCodingWorker (ECWorker)任务，用于失败的擦除编码块的后台恢复。NameNode 检测到失败的 EC 块，然后选择一个 DataNode 来执行恢复工作。重建执行三项关键任务:

1.  从源节点读取数据，并只读取最少数量的输入块和奇偶校验块进行重建。
2.  从输入数据中解码出新的数据和奇偶校验块。所有丢失的数据和奇偶校验块一起被解码。
3.  解码完成后，恢复的块将被传输到目标数据节点。

*   **擦除编码策略**–为了适应异构工作负载，我们允许 HDFS 集群中的文件和目录采用不同的复制和 EC 策略。关于编码&解码文件的信息封装在 ErasureCodingPolicy 类中。它包含两条信息，即 *ECSchema &剥离单元的大小。*

Hadoop 3 中第二个最重要的增强是来自 YARN 版本 1 的 YARN Timeline 服务版本 2(在 Hadoop 2.x 中)。他们正试图在第二版《YARN》中做出许多乐观的改变。

# 3.纱线时间线服务 v.2

Hadoop 推出了纱线时间轴服务的主要版本，即版本 2 .纱线时间轴服务。它的开发是为了解决两个主要挑战:

1.  *提高时间轴服务的可扩展性和可靠性*
2.  *通过引入流和聚合增强可用性*

开发人员可以测试 YARN Timeline Service v.2，以提供反馈和建议。它应该只在测试容量中使用。YARN Timeline Service v.2 中没有启用安全性。

因此，让我们首先讨论可伸缩性，然后我们将讨论流和聚合。

## 纱线时间线服务 v.2:可扩展性

YARN 版本 1 仅限于单个写/读实例，并且不能很好地扩展到小型集群之外。版本 2 使用了更具可伸缩性的分布式编写器架构和可伸缩的后端存储。它将数据的收集(写入)与数据的服务(读取)分开。它使用分布式收集器，基本上每个纱线应用一个收集器。读取器是独立的实例，专门用于通过 REST API 提供查询服务。

YARN Timeline Service v.2 选择 Apache HBase 作为主要后备存储，因为 Apache HBase 可以很好地扩展到大规模，同时保持良好的读写响应时间。

## 纱线时间线服务 v.2:可用性改进

现在来谈谈可用性的改进，在很多情况下，用户感兴趣的是“流”级别的信息或者 YARN 应用程序的逻辑组。更常见的是启动一组或一系列的纱线应用程序来完成一个逻辑应用程序。时间轴服务 v.2 明确支持流的概念。此外，它支持在流程级别聚合指标，如下图所示。

![](img/5562e3eca7971c1ba58ba96818a2b518.png)

现在让我们看看架构层面，YARN 版本 2 是如何工作的。

## 纱线时间轴服务 v.2:架构

YARN Timeline Service v.2 使用一组收集器(写入器)将数据写入后端存储。收集器是分布式的，并与它们所服务的应用程序主机位于同一位置，如下图所示。属于该应用程序的所有数据都被发送到应用程序级时间线收集器，但资源管理器时间线收集器除外。

![](img/13ea68746c370bee7d7c47e59f1954aa.png)

对于给定的应用，应用主机可以将该应用的数据写入协同定位的时间线收集器。此外，运行应用程序容器的其他节点的节点管理器也将数据写入运行应用程序主程序的节点上的时间轴收集器。

资源管理器还维护自己的时间线收集器。它只发出普通的生命周期事件，以保持合理的写入量。

时间轴读取器是独立于时间轴收集器的守护进程，它们专门用于通过 REST API 提供查询服务。

# 4.外壳脚本重写

Hadoop shell 脚本已经过重新编写，修复了许多错误，解决了兼容性问题，并对一些现有安装进行了更改。它还包含了一些新功能。所以我会列举一些重要的例子:

*   所有的 Hadoop shell 脚本子系统现在执行 ***hadoop-env.sh，*** ，这允许所有的环境变量在一个位置。
*   通过***–daemon***选项，守护进程已经从 ****-daemon.sh*** 移动到 bin 命令中。在 Hadoop 3 中，我们可以简单地使用–daemon start 来启动一个守护进程，使用–daemon stop 来停止一个守护进程，使用–daemon status 来设置$？守护进程的状态。例如，“HDFS–守护程序启动 namenode”。
*   如果安装了 pdsh，触发 ssh 连接的操作现在可以使用 pdsh。
*   ${HADOOP\_CONF\_DIR} 现在在任何地方都可以正常使用，不需要符号链接和其他类似的技巧。
*   脚本现在可以在守护程序启动时测试和报告日志和 pid 目录的各种状态的更好的错误消息。以前，未受保护的 shell 错误会显示给用户。

当 Hadoop 3 处于测试阶段时，你会知道更多的功能。现在让我们讨论一下阴影客户端 jar 并了解它们的好处。

# 5.阴影客户端 jar

hadoop 2.x 版本中可用的***Hadoop-client***将 Hadoop 的可传递依赖项拉到 Hadoop 应用程序的类路径中。如果这些可传递依赖项的版本与应用程序使用的版本冲突，这可能会产生问题。

因此，在 Hadoop 3 中，我们有了新的 hadoop-client-api 和 hadoop-client-runtime 构件，它们将 Hadoop 的依赖关系隐藏在单个 jar 中。 *hadoop-client-api* 是编译作用域&*Hadoop-client-runtime*是运行时作用域，包含从 *hadoop-client* 重新定位的第三方依赖。因此，您可以将依赖项捆绑到一个 jar 中，并测试整个 jar 的版本冲突。这避免了将 Hadoop 的依赖性泄漏到应用程序的类路径中。例如，HBase 可以使用与 Hadoop 集群对话，而无需查看任何实施依赖关系。

现在，让我们继续了解 Hadoop 3 中引入的另一个新特性，即机会容器。

# 6.支持机会容器和分布式调度

引入了一种新的执行类型，即 ***机会容器*** ，即使在调度时没有可用的资源，也可以被调度到节点管理器上执行。在这种情况下，这些容器将在 NM 处排队，等待资源可供它启动。机会容器的优先级低于默认的保证容器，因此如果需要的话，会被抢占，以便为保证容器腾出空间。这应该会提高集群的利用率。

![](img/e346bec46ba4b2dd1215b44fc99c6cd8.png)

**保证容器**对应现有纱线容器。它们是由容量调度程序分配的，一旦被分派到一个节点，就保证有可用的资源供它们立即开始执行。此外，只要没有故障，这些容器就会运行到完成。

默认情况下，机会容器由中央 RM 分配，但也添加了支持，以允许机会容器由分布式调度程序分配，该调度程序实现为 AMRMProtocol 拦截器。

现在，让我们来看看 MapReduce 的性能是如何优化的。

# 7.MapReduce 任务级本机优化

在 Hadoop 3 中，MapReduce 为地图输出收集器添加了一个本地 Java 实现。对于随机密集型作业，这可以将性能提高 30%或更多。

他们添加了地图输出收集器的本地实现。对于洗牌密集型工作，这可能提供 30%或更多的速度提升。他们正致力于基于 JNI 的地图任务的原生优化。基本思想是添加一个 NativeMapOutputCollector 来处理映射器发出的键值对，因此排序、溢出、IFile 序列化都可以在本机代码中完成。他们仍在研究合并代码。

现在让我们来看看，Apache 社区是如何努力使 Hadoop 3 更具容错性的。

# 8.支持 2 个以上的 NameNodes

在 Hadoop 2.x 中，HDFS 命名节点高可用性架构有一个活动命名节点和一个备用命名节点。通过将编辑内容复制到三个 JournalNodes 的仲裁中，这种体系结构能够容忍任何一个 NameNode 的失败。

但是，业务关键型部署需要更高程度的容错能力。所以，在 Hadoop 3 中允许用户运行多个备用 NameNodes。例如，通过配置三个 NameNodes 个主动，2 个被动)和五个 JournalNodes，集群可以容忍两个节点的故障。

![](img/42aac7a2627f2fa143a50ad550fad87b.png)

接下来，我们将了解 Hadoop 3 中已更改的 Hadoop 服务的默认端口。

# 9.多个服务的默认端口已更改

此前，多个 Hadoop 服务的默认端口都在 Linux *的短暂端口范围* (32768-61000)内。除非客户端程序明确请求特定的端口号，否则所使用的端口号是一个 ***短暂的*** 端口号。因此，在启动时，服务有时会由于与另一个应用程序的冲突而无法绑定到端口。

因此，具有短暂范围的冲突端口已被移出该范围，影响多个服务的端口号，即 NameNode、二级 NameNode、DataNode 等。其中一些重要的是:

![](img/3f6b49c6833fb08af1a0f0ead7ff372b.png)

还有几个是可以期待的。现在继续，让我们知道什么是新的 Hadoop 3 文件系统连接器。

# 10.支持文件系统连接器

Hadoop 现在支持与微软 Azure 数据湖和阿里云对象存储系统的集成。它可以用作替代的 Hadoop 兼容文件系统。首先添加了微软 Azure 数据湖，然后他们也添加了阿里云对象存储系统。你可能会期待更多。

让我们了解一下 ***平衡器*** 在一个数据节点的多个磁盘中是如何改进的。

# 11.DataNode 内部平衡器

![](img/8018ea94b858f2087007d75cada821f3.png)

单个 DataNode 管理多个磁盘。在正常的写操作期间，数据被平均划分，因此，磁盘被平均填满。但是添加或更换磁盘会导致 DataNode 中的不对称。这种情况以前没有被现有的 HDFS 平衡器处理。这涉及到 DataNode 内部的不对称。

![](img/b4ac23b041474fd31fefd30863f1d45e.png)

现在，Hadoop 3 通过新的 DataNode 内平衡功能来处理这种情况，该功能通过 hdfs 磁盘平衡器 CLI 调用。

现在让我们看看各种内存管理是如何发生的。

# 12.返工守护进程和任务堆管理

对 Hadoop 守护进程和 MapReduce 任务的堆管理进行了一系列更改。

*   配置守护进程堆大小的新方法。值得注意的是，现在可以根据主机的内存大小进行自动调优，HADOOP_HEAPSIZE 变量已被弃用。取而代之的是， **HADOOP\_HEAPSIZE\_MAX 和 HADOOP\_HEAPSIZE\_MIN** 分别用于设置 Xmx 和 Xms。所有全局和守护进程特定的堆大小变量现在都支持单位。如果变量只是一个数字，则大小假定为兆字节。
*   简化 map 的配置并减少任务堆大小，因此不再需要在任务配置中和作为 Java 选项指定所需的堆大小。已经指定两者的现有配置不受此更改的影响。

我希望这篇文章能给你带来信息和附加值。Apache 社区仍在致力于多项增强功能，这些功能可能会持续到测试阶段。

如果你想查看更多关于人工智能、Python、道德黑客等市场最热门技术的文章，你可以参考 Edureka 的官方网站。

请留意本系列中解释大数据其他各方面的其他文章。

> 1. [Hadoop 教程](/edureka/hadoop-tutorial-24c48fbf62f6)
> 
> 2.[蜂巢教程](/edureka/hive-tutorial-b980dfaae765)
> 
> 3.[养猪教程](/edureka/pig-tutorial-2baab2f0a5b0)
> 
> 4.[地图缩小教程](/edureka/mapreduce-tutorial-3d9535ddbe7c)
> 
> 5. [HBase 教程](/edureka/hbase-tutorial-bdc36ab32dc0)
> 
> 6. [HDFS 教程](/edureka/hdfs-tutorial-f8c4af1c8fde)
> 
> 7.[大数据教程](/edureka/big-data-tutorial-b664da0bb0c8)
> 
> 8. [Sqoop 教程](/edureka/apache-sqoop-tutorial-431ed0af69ee)
> 
> 9.[水槽教程](/edureka/apache-flume-tutorial-6f7150210c76)
> 
> 10. [Oozie 教程](/edureka/apache-oozie-tutorial-d8f7bbbe1591)
> 
> 11. [Hadoop 生态系统](/edureka/hadoop-ecosystem-2a5fb6740177)
> 
> 12.[HQL 顶级配置单元命令及示例](/edureka/hive-commands-b70045a5693a)
> 
> 13. [Hadoop 集群搭配亚马逊 EMR？](/edureka/create-hadoop-cluster-with-amazon-emr-f4ce8de30fd)
> 
> 14.[大数据工程师简历](/edureka/big-data-engineer-resume-7bc165fc8d9d)
> 
> 15. [Hadoop 开发人员-工作趋势和薪水](/edureka/hadoop-developer-cc3afc54962c)
> 
> 16. [Hadoop 面试问题](/edureka/hadoop-interview-questions-55b8e547dd5c)