<html>
<head>
<title>Learn PySpark Dataframes With FIFA World Cup &amp; Superheroes Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过FIFA世界杯和超级英雄数据集学习PySpark数据帧</h1>
<blockquote>原文：<a href="https://medium.com/edureka/pyspark-dataframe-tutorial-9335f3d09b4?source=collection_archive---------5-----------------------#2018-07-12">https://medium.com/edureka/pyspark-dataframe-tutorial-9335f3d09b4?source=collection_archive---------5-----------------------#2018-07-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/fdc9d5179580e9767aadd60ff23ce032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*y-wETBpjKYs57dh-gqtMLg.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">PySpark Dataframes Tutorial — Edureka</figcaption></figure><p id="1120" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Dataframes是当今业界的一个时髦词。人们倾向于将它与用于<a class="ae jn" href="https://www.edureka.co/blog/what-is-data-analytics?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pyspark-dataframe-tutorial" rel="noopener ugc nofollow" target="_blank">数据分析</a>的流行语言一起使用，如Python、Scala和r。那么，为什么每个人都在如此频繁地使用它呢？让我们用文章来理解这一点。在本文中，我将讨论以下主题:</p><ul class=""><li id="8793" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">什么是数据帧？</li><li id="0b0f" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">为什么我们需要数据框架？</li><li id="7f62" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">数据帧的特征</li><li id="d409" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">PySpark数据帧源</li><li id="277a" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">数据帧创建</li><li id="49ea" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">Pyspark数据帧与FIFA世界杯和超级英雄数据集</li></ul><h1 id="5a17" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">什么是数据帧？</h1><p id="676f" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">数据帧通常指本质上是表格的数据结构。它表示行，每一行都由许多观察值组成。行可以有多种数据格式(<strong class="ir hi">异构</strong>，而列可以有相同数据类型的数据(<strong class="ir hi">同构</strong>)。除数据外，数据帧通常还包含一些元数据；例如，列名和行名。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/a7372422a0ddfaf6de0d037064205ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*y0u2-p4TITPVdodujURY9Q.jpeg"/></div></figure><p id="9691" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以说数据帧什么也不是，只是二维数据结构，类似于SQL表或电子表格。现在让我们继续这篇文章，并理解我们到底为什么需要Pyspark Dataframe？</p><h1 id="1000" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">为什么我们需要数据帧？</h1><h2 id="4ab3" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated"><strong class="ak"> 1。处理结构化和半结构化数据</strong></h2><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ly"><img src="../Images/b2b993a213e8f263c0b67d474e5b1549.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*dbGsEW9R3ZHPk76vXeU7ww.jpeg"/></div></figure><p id="ce03" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数据帧被设计用来处理<strong class="ir hi">大量结构化和半结构化数据</strong>。Spark数据帧中的观察结果组织在命名列下，这有助于Apache Spark理解数据帧的模式。这有助于优化这些查询的执行计划。它还可以处理<strong class="ir hi">千兆字节</strong>的数据。</p><h2 id="9978" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated"><strong class="ak"> 2。切片和切块</strong></h2><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ly"><img src="../Images/d7bc712cee8e5c1bfb8c89e69c39f272.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*0fbl_qpz8evHo6slJVB91w.jpeg"/></div></figure><p id="8fd8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数据框架API通常支持精细的数据切片方法。它包括按名称或编号“选择”行、列和单元格，过滤出行等操作。统计数据通常非常混乱，包含大量缺失值、错误值和范围违规。因此，数据帧的一个至关重要的特性是对丢失数据的显式管理。</p><h2 id="e39d" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated"><strong class="ak"> 3。数据来源</strong></h2><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/de0634308a3b2c650c3686ede4c9fd16.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*u3O5QFdn71HGsMXB4vEGRw.jpeg"/></div></figure><p id="7bc5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">DataFrame支持多种数据格式和数据源，我们将在本文后面讨论这一点。他们可以从各种来源获取数据。</p><h2 id="8a91" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated"><strong class="ak"> 4。支持多种语言</strong></h2><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/13e6e9fe84bc15bab2b4c77312265f6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*_1KsnVxPUt1Ety4sfPFvBA.jpeg"/></div></figure><p id="e3eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它有对不同语言的API支持，如Python、R、Scala、Java，这使得它更容易被具有不同编程背景的人使用。</p><h1 id="20e4" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">数据帧的特征</h1><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/3de1ca469951b4186ade8c67a324d22b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*byLfPbYiOvqJKuvZmG1q8A.jpeg"/></div></figure><ul class=""><li id="fcbf" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">数据帧在本质上是分布式的T21，这使得它成为容错和高度可用的数据结构。</li><li id="74db" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">惰性求值</strong>是一种求值策略，它保留表达式的求值，直到需要它的值。避免了重复评估。Spark中的惰性求值意味着直到一个动作被触发，执行才会开始。在Spark中，当Spark转换发生时，就会出现懒惰评估的情况。</li><li id="ee11" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">数据帧在本质上是不可变的<strong class="ir hi"/>。我说的不可变是指它是一个在被创建后其状态<strong class="ir hi">不能被修改</strong>的对象。但是我们可以通过应用某种转换来转换它的值，就像在RDDs中一样。</li></ul><h1 id="e2d4" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">PySpark数据帧源</h1><p id="df6b" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">Pyspark中的数据帧可以通过多种方式创建:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/431e8379ffd484259733c490b28ae382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*P-fhGJBb_zMD4_LLnp2n2g.jpeg"/></div></figure><p id="e149" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数据可以通过<strong class="ir hi"> CSV、JSON、XML </strong>或Parquet文件加载。也可以使用现有的<strong class="ir hi"> RDD </strong>并通过任何其他数据库来创建，如<a class="ae jn" href="https://www.edureka.co/blog/hive-tutorial?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pyspark-dataframe-tutorial" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> Hive </strong> </a>或<strong class="ir hi"> Cassandra </strong>等。它还可以从<a class="ae jn" href="https://www.edureka.co/blog/hdfs-tutorial?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pyspark-dataframe-tutorial" rel="noopener ugc nofollow" target="_blank"> HDFS </a>或本地文件系统接收数据。</p><h1 id="ef49" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">数据帧创建</h1><p id="c554" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">让我们继续阅读本文，了解如何创建数据帧。</p><p id="a166" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将创建雇员和部门实例。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="ef4a" class="lk kd hh mc b fi mg mh l mi mj">from pyspark.sql import *<br/> <br/>Employee = Row("firstName", "lastName", "email", "salary")<br/> <br/>employee1 = Employee('Basher', 'armbrust', '<a class="ae jn" href="mailto:bash@edureka.co" rel="noopener ugc nofollow" target="_blank">bash@edureka.co</a>', 100000)<br/>employee2 = Employee('Daniel', 'meng', '<a class="ae jn" href="mailto:daniel@stanford.edu" rel="noopener ugc nofollow" target="_blank">daniel@stanford.edu</a>', 120000 )<br/>employee3 = Employee('Muriel', None, '<a class="ae jn" href="mailto:muriel@waterloo.edu" rel="noopener ugc nofollow" target="_blank">muriel@waterloo.edu</a>', 140000 )<br/>employee4 = Employee('Rachel', 'wendell', '<a class="ae jn" href="mailto:rach_3@edureka.co" rel="noopener ugc nofollow" target="_blank">rach_3@edureka.co</a>', 160000 )<br/>employee5 = Employee('Zach', 'galifianakis', '<a class="ae jn" href="mailto:zach_g@edureka.co" rel="noopener ugc nofollow" target="_blank">zach_g@edureka.co</a>', 160000 )<br/> <br/>print(Employee[0])<br/> <br/>print(employee3)<br/> <br/>department1 = Row(id='123456', name='HR')<br/>department2 = Row(id='789012', name='OPS')<br/>department3 = Row(id='345678', name='FN')<br/>department4 = Row(id='901234', name='DEV')</span></pre><p id="c326" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，我们将从雇员和部门创建一个DepartmentWithEmployees实例</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="48a3" class="lk kd hh mc b fi mg mh l mi mj">departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2, employee5]) departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4]) departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee3]) departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])</span></pre><p id="9a0a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们从行列表中创建我们的数据帧</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="fecb" class="lk kd hh mc b fi mg mh l mi mj">departmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2, employee5])<br/>departmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])<br/>departmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4, employee3])<br/>departmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])</span></pre><h1 id="9bfe" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">Pyspark数据帧示例1: FIFA世界杯数据集</h1><p id="d03e" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">在这里，我们已经采取了国际足联世界杯球员数据集。我们将把CSV格式的数据加载到数据帧中，然后我们将了解可以在该数据帧上执行的不同转换和操作。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/5135bad58ade1e30c37824ed78f6f482.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*j4qbETuMc05rL9Y6fBNcRw.jpeg"/></div></figure><h2 id="521c" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">从CSV文件中读取数据</h2><p id="49d7" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">让我们从CSV文件加载数据。这里我们将使用<strong class="ir hi"> spark.read.csv </strong>方法将数据加载到数据帧fifa_df中。实际方法是<strong class="ir hi">spark . read . format【CSV/JSON】</strong>。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="e7a2" class="lk kd hh mc b fi mg mh l mi mj">fifa_df = spark.read.csv("path-of-file/fifa_players.csv", inferSchema = True, header = True) <br/>fifa_df.show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es ml"><img src="../Images/a5ae1c0c77f92631172592f05e75f251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ose97nrPbegvwfqI82G3Sg.jpeg"/></div></div></figure><h2 id="36a1" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">数据帧的模式</h2><p id="5840" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">来看看ie的模式。dataframe的结构，我们将使用<strong class="ir hi"> printSchema </strong>方法。这将为我们提供数据帧中的不同列，以及该特定列的数据类型和可空条件。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="1871" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.printSchema()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/a9bc4689931c25244bae3aee7f631123.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*f63hD3bdmsCzHrr3YquQRg.jpeg"/></div></figure><h2 id="da5e" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">列名和计数(行和列)</h2><p id="772d" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">当我们想要查看特定数据帧的名称以及行数和列数时，我们使用以下方法。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="f461" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.columns //Column Names <br/>fifa_df.count() // Row Count <br/>len(fifa_df.columns) //Column Count</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/83eba3c4fed6ce4ecee7e2ba5e0ccb46.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*o5v9YbZ4lszAmiNEf6LcDw.jpeg"/></div></figure><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="254e" class="lk kd hh mc b fi mg mh l mi mj">37784 <br/>8</span></pre><h2 id="5c56" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">描述特定的列</h2><p id="80f0" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">如果我们想要查看数据帧中任何特定列的摘要，我们使用<strong class="ir hi"> describe </strong>方法。这个方法给出给定列的统计摘要，如果没有指定，它提供数据帧的统计摘要。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="aff2" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.describe('Coach Name').show() fifa_df.describe('Position').show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/0d176b18fef0612c8665a31ce7a20103.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*lhwHE-sRVdqoMKSF4xTu5w.jpeg"/></div></figure><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/bd4d4b8405117a46cd190a27973b95c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*x2eroB8PsdH1-CrQCUTfQA.jpeg"/></div></figure><h2 id="69d7" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">选择多列</h2><p id="6ce3" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">如果我们想从数据帧中选择特定的列，我们使用<strong class="ir hi">选择</strong>方法。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="0164" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.select('Player Name','Coach Name').show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es mu"><img src="../Images/26cc5acd2a5d17d9c71122ab278bfe8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*spnKZdeBYR-OL_UAyBVvPw.jpeg"/></div></div></figure><h2 id="2469" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">选择不同的多列</h2><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="007e" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.select('Player Name','Coach Name').distinct().show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/7ff718f012a340d68c2eebad9eabf19a.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*iZdHM6n3rS-eaxDJzCqb5g.jpeg"/></div></figure><h2 id="c71c" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">过滤数据</h2><p id="f645" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">为了过滤数据，根据指定的条件，我们使用<strong class="ir hi">过滤器</strong>命令。这里，我们根据匹配ID必须等于1096的条件过滤数据帧，然后计算过滤后的输出中有多少记录/行。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="aa98" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.filter(fifa_df.MatchID=='1096').show() fifa_df.filter(fifa_df.MatchID=='1096').count() //to get the count</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es mw"><img src="../Images/271c972bc8bce1d169c2084b2d620f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sLdCr8j0n0qy-WNqFj2WSQ.jpeg"/></div></div></figure><h2 id="9115" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">过滤数据(多参数)</h2><p id="3528" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们可以根据多个条件(AND或or)过滤数据</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="738f" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.filter((fifa_df.Position=='C') &amp;&amp; (fifa_df.Event=="G40'")).show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es mx"><img src="../Images/b203154c63321775148b0d62d47a01b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AZOlZ7OfRNf613XBNTmRmQ.jpeg"/></div></div></figure><h2 id="f19c" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">数据排序(排序依据)</h2><p id="ca6c" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">为了对数据进行排序，我们使用了<strong class="ir hi"> OrderBy </strong>方法。默认情况下，它按升序排序，但我们也可以将其更改为降序。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="0efe" class="lk kd hh mc b fi mg mh l mi mj">fifa_df.orderBy(fifa_df.MatchID).show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es my"><img src="../Images/6e88814b523df55c0ad1ffebddecd8b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTEyC9s2xlgiyYqYfbx1tg.jpeg"/></div></div></figure><h1 id="bf72" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">PySpark数据帧示例2:超级英雄数据集</h1><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mz"><img src="../Images/e5c1d951c57ca8bf3e8039b913e4773c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*hDDh6upUXimr9MofPt_fsw.jpeg"/></div></figure><h2 id="7b49" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">加载数据</h2><p id="53b8" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">这里，我们将以与前面相同的方式加载数据。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="3d76" class="lk kd hh mc b fi mg mh l mi mj">Superhero_df = spark.read.csv("path-of file/superheros.csv", inferSchema = True, header = True) <br/>Superhero_df.show(10)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es na"><img src="../Images/6e83ae0a4d02871c1132c36b8ddb1f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NjsTM8PcOWpNYPmS6Yn-Q.jpeg"/></div></div></figure><h2 id="b766" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">过滤数据</h2><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="283a" class="lk kd hh mc b fi mg mh l mi mj">Superhero_df.filter(Superhero_df.Gender == 'Male').count() //Male Heros Count <br/>Superhero_df.filter(Superhero_df.Gender == 'Female').count() //Female Heros Count</span></pre><h2 id="23f6" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">将数据分组</h2><p id="c03e" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated"><strong class="ir hi"> GroupBy </strong>用于根据指定的列对数据帧进行分组。这里，我们根据列竞争对数据帧进行分组，然后使用<strong class="ir hi"> count </strong>函数，我们可以找到特定竞争的计数。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="24fc" class="lk kd hh mc b fi mg mh l mi mj">Race_df = Superhero_df.groupby("Race")\<br/>.count()\<br/>.show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es nb"><img src="../Images/7ff5dcdff6a7c7fca109a07231f32c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*cUzB05OglE1tYzNZSRaE6Q.jpeg"/></div></figure><h2 id="db3b" class="lk kd hh bd ke ll lm ln ki lo lp lq km ja lr ls kq je lt lu ku ji lv lw ky lx bi translated">执行SQL查询</h2><p id="64a7" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们还可以将sql查询直接传递给任何数据帧，因为我们需要使用<strong class="ir hi"> registerTempTable </strong>方法从数据帧创建一个表，然后使用<strong class="ir hi"> sqlContext.sql() </strong>传递SQL查询。</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="f19d" class="lk kd hh mc b fi mg mh l mi mj">Superhero_df.registerTempTable('superhero_table')<br/>sqlContext.sql('select * from superhero_table').show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es na"><img src="../Images/6e83ae0a4d02871c1132c36b8ddb1f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NjsTM8PcOWpNYPmS6Yn-Q.jpeg"/></div></div></figure><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="f0cd" class="lk kd hh mc b fi mg mh l mi mj">sqlContext.sql(‘select distinct(Eye_color) from superhero_table’).show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es nc"><img src="../Images/e1fc5f2ae5eec936e06a9f2475972485.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*FbXHCXye_XEvvnZViHJr5A.jpeg"/></div></figure><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="e926" class="lk kd hh mc b fi mg mh l mi mj">sqlContext.sql('select distinct(Eye_color) from superhero_table').count()</span></pre><p id="740a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi">23</p><pre class="lg lh li lj fd mb mc md me aw mf bi"><span id="3dde" class="lk kd hh mc b fi mg mh l mi mj">sqlContext.sql(‘select max(Weight) from superhero_table’).show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/bc3ae7a099a4ffd804fefe78ee6e9e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*WmJuqSAlJMnCLnpkUpOYwQ.jpeg"/></div></figure><p id="263b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，那么你可以参考<a class="ae jn" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pyspark-dataframe-tutorial" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释PySpark的各个方面。</p><blockquote class="ne nf ng"><p id="60fe" class="ip iq nh ir b is it iu iv iw ix iy iz ni jb jc jd nj jf jg jh nk jj jk jl jm ha bi translated">1.<a class="ae jn" rel="noopener" href="/edureka/pyspark-tutorial-87d41dab9657"> PySpark教程</a></p><p id="b279" class="ip iq nh ir b is it iu iv iw ix iy iz ni jb jc jd nj jf jg jh nk jj jk jl jm ha bi translated">2.PySpark的RDDs</p><p id="7e12" class="ip iq nh ir b is it iu iv iw ix iy iz ni jb jc jd nj jf jg jh nk jj jk jl jm ha bi translated">3.<a class="ae jn" rel="noopener" href="/edureka/pyspark-mllib-tutorial-759391dbb08a"> PySpark MLlib教程</a></p><p id="6411" class="ip iq nh ir b is it iu iv iw ix iy iz ni jb jc jd nj jf jg jh nk jj jk jl jm ha bi translated">4.<a class="ae jn" rel="noopener" href="/edureka/pyspark-programming-e007e68fbccb"> PySpark编程</a></p></blockquote></div></div>    
</body>
</html>