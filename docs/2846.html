<html>
<head>
<title>Convolutional Neural Network (CNN) — Developing An Image Classifier In Python Using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络(CNN) —使用TensorFlow在Python中开发图像分类器</h1>
<blockquote>原文：<a href="https://medium.com/edureka/convolutional-neural-network-3f2c5b9c4778?source=collection_archive---------2-----------------------#2018-11-27">https://medium.com/edureka/convolutional-neural-network-3f2c5b9c4778?source=collection_archive---------2-----------------------#2018-11-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/bc5bc81534caa6c4792830162886420e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*gqR9DEaHtRqbE0s4Tiz1Jg.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Convolutional Neural Network — Edureka</figcaption></figure><p id="15ff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这篇文章中，让我们讨论什么是卷积神经网络(CNN)以及卷积神经网络背后的<strong class="ir hi">架构</strong>——卷积神经网络旨在<strong class="ir hi">解决</strong> <strong class="ir hi">图像识别</strong>系统和<strong class="ir hi">分类</strong>问题。卷积神经网络在图像和视频识别、推荐系统和自然语言处理中有广泛的应用。</p><p id="5dca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将检验以下概念:</p><ul class=""><li id="2d1f" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">计算机如何读取图像？</li><li id="fd72" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">为什么不是完全连接的网络？</li><li id="32cc" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">什么是卷积神经网络？</li><li id="7a14" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">卷积神经网络的起源</li><li id="2056" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">卷积神经网络是如何工作的？</li></ul><ol class=""><li id="f70c" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm kb jt ju jv bi translated">一个示例卷积神经网络</li><li id="5033" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">图像的卷积</li><li id="cb16" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">ReLu层</li><li id="0480" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">汇集层</li><li id="0282" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">堆叠这些层</li><li id="5ae0" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">使用卷积神经网络预测图像</li></ol><ul class=""><li id="ab6e" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">用例:CIFAR10图像分类器</li></ul><h1 id="8629" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">计算机如何读取图像？</h1><p id="ced8" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">考虑一下这张纽约天际线的图片，第一眼你会看到许多建筑和颜色。那么计算机<strong class="ir hi">是如何处理</strong>这张图像的呢？</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/7e717ccca82160edf2f768db18e3f9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*gpEVTW4Wp5o_rfE-tbNiFg.png"/></div></figure><p id="3655" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图像被<strong class="ir hi">分解</strong>成三个颜色通道，分别是<strong class="ir hi">红色、绿色</strong>和<strong class="ir hi">蓝色。</strong>这些颜色通道中的每一个都被<strong class="ir hi">映射</strong>到<strong class="ir hi">图像的像素。</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/6f62311355e370156f6f58369eba986c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v1LM663dEdoPImnefa2zBQ.png"/></div></div></figure><p id="a6ea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，<strong class="ir hi">计算机识别</strong>与每个像素和<strong class="ir hi">相关联的值，确定</strong>图像的<strong class="ir hi">大小</strong>。</p><p id="e08e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然而对于<strong class="ir hi">黑白</strong>图像，只有<strong class="ir hi">一个通道</strong>并且<strong class="ir hi">概念</strong>与<strong class="ir hi">相同。</strong></p><h1 id="b8d4" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">为什么不是完全连接的网络？</h1><p id="ebac" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">我们<strong class="ir hi">不能</strong>利用全连接网络，当谈到<strong class="ir hi">卷积神经网络时，</strong>下面是原因！</p><p id="d267" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑下面的图像:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/70ef8dd324f1094a3a7e32dfd199a90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8ojjCqDlMYZ2CViSglE2Q.png"/></div></div></figure><p id="cbdb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，我们将<strong class="ir hi">视为</strong>一个<strong class="ir hi">输入</strong>大小为<strong class="ir hi"> 28x28x3 </strong>像素的图像。如果我们<strong class="ir hi">输入</strong>这个到我们的卷积神经网络，我们将有大约<strong class="ir hi"> 2352个权重</strong>在<strong class="ir hi">第一个</strong>隐藏层本身。</p><p id="d178" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是这个案例<strong class="ir hi">并不实用</strong>。现在，看看这个:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/29bbf62093793049f30cc9e6e49d79a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WRNLlWvnSAKUxzOljpMBCg.png"/></div></div></figure><p id="54ae" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">任何<strong class="ir hi">普通</strong>输入<strong class="ir hi">图像</strong>将<strong class="ir hi">至少</strong>具有<strong class="ir hi"> 200x200x3像素</strong>大小。第一个隐藏层的大小就变成了一个<strong class="ir hi">哇哇十二万</strong>。如果这只是第一个<strong class="ir hi">隐藏层，想象一下处理一个<strong class="ir hi">完整的</strong>复杂的<strong class="ir hi">图像集需要的<strong class="ir hi">数量的神经元</strong>。</strong></strong></p><p id="ca9f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这导致<strong class="ir hi">过度装配</strong>并且不实用。因此，我们不能利用完全连接的网络。</p><h1 id="8c9d" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">什么是卷积神经网络？</h1><p id="0d4a" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">卷积神经网络和神经网络一样，都是由<strong class="ir hi">个神经元</strong>组成，具有<strong class="ir hi">个可学习的</strong> <strong class="ir hi">个权重</strong>和<strong class="ir hi">个偏差</strong>。每个<strong class="ir hi">神经元</strong>接收几个<strong class="ir hi">输入</strong>，对它们进行加权<strong class="ir hi">求和</strong>，<strong class="ir hi">将其通过<strong class="ir hi">激活</strong> <strong class="ir hi">功能</strong>传递给</strong>，并以<strong class="ir hi">输出</strong>响应。</p><p id="27a6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">整个网络有一个<strong class="ir hi">损失</strong> <strong class="ir hi">函数</strong>，我们为神经网络开发的所有提示和技巧仍然适用于<strong class="ir hi">卷积神经网络。</strong></p><p id="f5cb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">很简单，对吧？</p><p id="4907" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">神经网络</strong>顾名思义，是一种模仿<strong class="ir hi">大脑</strong>结构的<strong class="ir hi">机器学习技术</strong>。它由称为神经元的学习单元网络组成。</p><p id="9296" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些<strong class="ir hi">神经元</strong>学习如何将<strong class="ir hi">输入信号</strong>(例如一只猫的图片)转换成相应的<strong class="ir hi">输出信号</strong>(例如标签“猫”)，形成自动识别的基础。</p><p id="5c5c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们以<strong class="ir hi">自动图像识别为例。</strong>判断一张<strong class="ir hi">图片</strong>是否包含一只<strong class="ir hi">猫</strong>的过程涉及到一个<strong class="ir hi">激活函数</strong>。如果图片类似于神经元之前<strong class="ir hi">见过的先前猫图像，</strong>标签<strong class="ir hi">“猫”</strong>将被<strong class="ir hi">激活。</strong></p><p id="128b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">因此，</strong>神经元接触的<strong class="ir hi">标记的图像</strong>越多<strong class="ir hi">接触的</strong>图像，<strong class="ir hi">越好</strong>它学习如何识别其他未标记的图像。我们称之为<strong class="ir hi">训练</strong>神经元的过程。</p><h1 id="8011" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">卷积神经网络的起源</h1><p id="226d" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">神经网络的智能不可思议。虽然人工神经网络早在<strong class="ir hi">20世纪60年代</strong>就由<strong class="ir hi">Rosenblatt</strong>研究过<strong class="ir hi">，但是使用神经网络<strong class="ir hi">的深度学习只是在2000年代<strong class="ir hi">后期</strong>才开始起步。</strong>关键的<strong class="ir hi">促成因素</strong>是<strong class="ir hi">计算能力</strong>和<strong class="ir hi">数据集</strong>的规模<strong class="ir hi">谷歌</strong>对深度学习的开创性研究。2012年7月，<strong class="ir hi">谷歌</strong>的研究人员将一个<strong class="ir hi">高级神经网络</strong>暴露在一系列<strong class="ir hi">未标记的、</strong>静态<strong class="ir hi">图像</strong>中，这些图像来自<strong class="ir hi"> YouTube </strong>视频。</strong></p><p id="fcff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">令他们【40】惊讶的是，【41】他们发现神经网络<strong class="ir hi">自主学习了【43】一个【44】猫探测【45】神经元，【47】支持了【48】“互联网是由猫组成的”这一流行论断。</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/a464156f68af5d28ec4d594f2f374680.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*rsUSrCxuuIUJhu4bB8kkwA.png"/></div></figure><h1 id="7f25" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">卷积神经网络是如何工作的？</h1><p id="4d10" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">卷积神经网络中有<strong class="ir hi">四个</strong>分层<strong class="ir hi">概念</strong>我们应该了解:</p><ol class=""><li id="e4d1" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm kb jt ju jv bi translated">卷积，</li><li id="65ec" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">雷鲁，</li><li id="0caf" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">共享和</li><li id="18ad" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm kb jt ju jv bi translated">完全连接(完全连接层)。</li></ol><p id="f195" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们从一个简单的例子<strong class="ir hi">开始:</strong></p><h2 id="78b1" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">CNN的例子:</h2><p id="5d1d" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">考虑下图:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/0dc656618567e4edd4b18f2bf5f8eae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9qyPcm_WgAGXvneE7isidg.png"/></div></div></figure><p id="15ba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，有X和O的多种翻译。这使得计算机很难识别。但是目标是，如果<strong class="ir hi">输入信号</strong>看起来像它以前见过的<strong class="ir hi">先前的</strong>图像，那么<strong class="ir hi">“图像”参考</strong>信号将被混合到<strong class="ir hi">输入</strong>信号中，或者<strong class="ir hi">与<strong class="ir hi">输入</strong>信号卷积。产生的<strong class="ir hi">输出</strong>信号然后被传递到下一层<strong class="ir hi">。</strong></strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/320e8ae27e1688861013569e57d6b115.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*aQUI0l7M_cp_F75a0beYwg.png"/></div></figure><p id="da19" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以，<strong class="ir hi">电脑理解</strong>每一个像素。在这种情况下，<strong class="ir hi">白色</strong>像素称为<strong class="ir hi"> -1 </strong>，而<strong class="ir hi">黑色</strong>像素称为<strong class="ir hi"> 1。</strong>这就是我们在基本二进制分类中实现<strong class="ir hi">区分像素</strong>的方式。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/90af5bb8c7c5efcefbc808dd01634bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0eRLz0JthYu0kDaNdyPbRA.png"/></div></div></figure><p id="e480" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，如果我们仅仅<strong class="ir hi">正常搜索</strong>并且<strong class="ir hi">比较</strong>正常图像和另一个<strong class="ir hi">‘x’再现</strong>之间的<strong class="ir hi">值</strong>，我们将得到<strong class="ir hi">缺失像素的<strong class="ir hi">批次</strong>。</strong></p><p id="6fd5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">那么，我们如何解决这个问题呢？</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/fb71756a212348ad33db24b39d2a4792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o92LnwFZm_JDjvaKS6bI7w.png"/></div></div></figure><p id="a657" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们取称为<strong class="ir hi">过滤器</strong>的像素的<strong class="ir hi">小块</strong>并尝试<strong class="ir hi">匹配</strong>它们在附近的相应<strong class="ir hi">位置，看看我们是否得到一个<strong class="ir hi">匹配。</strong>通过这样做，卷积神经网络<strong class="ir hi">在查看<strong class="ir hi">相似度</strong>方面比直接尝试匹配<strong class="ir hi">整个图像要好得多</strong>。</strong></strong></p><h2 id="640f" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">图像的卷积</h2><p id="8fe5" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">卷积具有良好的平移不变性。直观地，这意味着<strong class="ir hi">每个</strong>卷积滤波器代表感兴趣的<strong class="ir hi">特征</strong>(例如字母中的<strong class="ir hi">像素)</strong>，并且卷积神经网络<strong class="ir hi">算法</strong>学习哪些<strong class="ir hi">特征</strong>包括<strong class="ir hi">结果参考</strong>(即字母)。</p><p id="6193" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们有<strong class="ir hi"> 4个步骤</strong>用于卷积:</p><ul class=""><li id="6409" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi">对齐</strong>特征和图像</li><li id="50f8" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">将每个<strong class="ir hi">图像的</strong>像素乘以相应的<strong class="ir hi">特征</strong>像素</strong></li><li id="a676" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">将</strong>的值相加，得到<strong class="ir hi">和</strong></li><li id="24f3" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">用</strong>除以<strong class="ir hi">特征<strong class="ir hi">中的总</strong>像素数</strong></li></ul><p id="732b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑上面的图像——正如你所看到的，我们已经完成了前两个步骤。我们考虑一个<strong class="ir hi">特征图像</strong>和<strong class="ir hi">距离它一个像素</strong>。我们<strong class="ir hi">将</strong>与<strong class="ir hi">现有图像</strong>相乘，结果存储在另一个<strong class="ir hi">缓冲特征图像</strong>中。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/e1f4da6b658ae408944639b695c0ef35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*SYF1XZLtlCmzc-jM7XOYMg.png"/></div></figure><p id="ce9c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有了这张<strong class="ir hi">，</strong>图像，我们完成了l <strong class="ir hi"> ast 2步骤。</strong>我们将<strong class="ir hi">值</strong>相加，得到<strong class="ir hi">和。</strong>然后，<strong class="ir hi">将</strong>这个<strong class="ir hi">数</strong>除以<strong class="ir hi">特征图像中的</strong>总像素数。完成后，得到的<strong class="ir hi">最终值</strong>被放置在<strong class="ir hi">滤波图像</strong>的<strong class="ir hi">中心</strong>，如下图所示:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/84d941551943e365ac2cf95da00f2fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DT32lTmLYhyR2kXk7jwBfA.png"/></div></div></figure><p id="d259" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们可以<strong class="ir hi">移动</strong>这个<strong class="ir hi">滤镜</strong>并对图像中的任意像素做同样的<strong class="ir hi">操作</strong>。为了<strong class="ir hi">更清晰，</strong>让我们考虑<strong class="ir hi">的另一个例子:</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/e1f4da6b658ae408944639b695c0ef35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*SYF1XZLtlCmzc-jM7XOYMg.png"/></div></figure><p id="c4bb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如你所见，在执行了前4步后，我们得到的值是0.55！我们取这个值，并把它放在图像中，如前所述。这是在下图中完成的:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/84d941551943e365ac2cf95da00f2fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DT32lTmLYhyR2kXk7jwBfA.png"/></div></div></figure><p id="86c9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">类似地，我们将该特征移动到图像中的每一个其他位置，并查看该特征如何匹配该区域。这样做之后，我们将得到如下输出:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/86c55f92eeedab5b117bef0c0a14edf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*L8zdZ9kA4TRYI4qPAG-1aQ.png"/></div></figure><p id="20af" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里我们只考虑一个滤波器。同样，我们将对每隔一个滤波器执行相同的卷积，以获得该滤波器的卷积。</p><p id="7f56" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出</strong>信号<strong class="ir hi">强度</strong>不取决于<strong class="ir hi">特征</strong>的位置，而仅仅取决于<strong class="ir hi">特征</strong>是否存在<strong class="ir hi">。</strong>因此，一个字母可以位于<strong class="ir hi">不同的位置</strong>并且<strong class="ir hi">卷积神经网络</strong>算法仍然能够<strong class="ir hi">识别它。</strong></p><h2 id="4a2e" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">ReLU层</h2><p id="1bcc" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">ReLU是一个激活函数。但是，什么是激活函数呢？</p><p id="5ce9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">整流线性单元</strong> (ReLU)变换函数只在输入在一定量以上时才激活一个节点，而输入在零以下时，输出为零，但当输入上升到一定阈值以上时，与因变量成线性关系。</p><p id="3518" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑下面的例子:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mj"><img src="../Images/7d961d040388f5a3e91c6115d5468509.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*KknxxWazEvb-oMkqhq_AFA.png"/></div></figure><p id="5c7e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们已经考虑了一个具有上述值的简单函数。因此，如果该值是由因变量获得的，则该函数只执行一次运算。对于此示例，获得了以下值:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/f27fcd4cc0a9b13c84ee6777b7c5260e.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*Vs8OUHZ5zcn4iI9tsSY4yQ.png"/></div></figure><p id="9e24" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="ml">为什么我们这里要求ReLU？</em>T55】</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/d63e0f455ebc1d520ff35386d288c52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a0PZCQmzmUfylL_BK5dIZg.png"/></div></div></figure><p id="8091" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">主要目的是从卷积中去除所有负值。所有正值保持不变，但所有负值都变为零，如下所示:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/bada77e01550a607ffcd26d5f7fd43dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBcUJS_BzKTTwuMhSNW8tA.png"/></div></div></figure><p id="477c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，在我们处理了这个特定的特性之后，我们得到了以下输出:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/3f063b2dc518b856fedca4122c20e9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5KL_vg29wpSJLT1qoMS1yw.png"/></div></div></figure><p id="a1bd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，类似地，我们对所有其他特征图像也进行相同的处理:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/f558e0d44818e5c4c8bbdc388297d418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V8CsBuXDrwEf9xM06JZ9eg.png"/></div></div></figure><p id="c843" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">来自卷积层的<strong class="ir hi">输入</strong>可以被<strong class="ir hi">【平滑】</strong>到<strong class="ir hi">降低</strong><strong class="ir hi">滤波器的<strong class="ir hi">灵敏度</strong></strong>到<strong class="ir hi">噪声</strong>和<strong class="ir hi">变化。</strong>该平滑过程被称为<strong class="ir hi">子采样</strong>，并且可以通过对信号的<strong class="ir hi">样本</strong>取<strong class="ir hi">平均值</strong>或取<strong class="ir hi">最大值</strong>来<strong class="ir hi">实现。</strong></p><h2 id="5156" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">汇集层</h2><p id="171c" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">在这一层，我们<strong class="ir hi">将<strong class="ir hi">图像</strong>堆栈</strong>缩小为<strong class="ir hi">更小的尺寸。</strong>在通过<strong class="ir hi">激活</strong>层后<strong class="ir hi">完成汇集。我们通过实施以下4个步骤来实现这一点:</strong></p><ul class=""><li id="0f6b" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">选择一个<strong class="ir hi">窗口大小</strong>(通常为2或3)</li><li id="979f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">选择一个<strong class="ir hi">步幅</strong>(通常为2)</li><li id="0122" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">走过</strong>你的窗口<strong class="ir hi">跨过</strong>你的<strong class="ir hi">过滤过的</strong>图像</li><li id="9c4a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">从每个<strong class="ir hi">窗口中，</strong>取<strong class="ir hi">最大值</strong></li></ul><p id="1a6b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们用一个例子来理解这一点。考虑执行窗口大小为2、步幅也为2的池。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/1485e4ad72f5c8429eb23e99e52d593b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-4erZcwmYBnCjHpbcYU8g.png"/></div></div></figure><p id="b14f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，在这种情况下，我们将<strong class="ir hi">窗口大小</strong>设为<strong class="ir hi"> 2 </strong>，并从中选择<strong class="ir hi"> 4 </strong>和<strong class="ir hi">值</strong>。从这4个值中，<strong class="ir hi">最大值</strong>为1，因此我们选择1。此外，请注意，我们<strong class="ir hi">从</strong>开始时使用的是<strong class="ir hi"> 7×7 </strong>矩阵，但现在在<strong class="ir hi">合并</strong>后，相同的矩阵下降到了<strong class="ir hi"> 4×4。</strong></p><p id="b403" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是我们需要<strong class="ir hi">移动</strong>窗口穿过整个图像。这个过程和上面完全一样，我们需要对整个图像重复这个过程。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/ce27efd57b89dc1ccb3f98ad1dd4bd48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*PFGxJqctB_1YZvFG4q0Itg.png"/></div></figure><p id="c4dc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请注意，这是针对<strong class="ir hi">一个过滤器的。</strong>我们还需要对另外两个过滤器进行同样的操作。这样做后，我们得到了以下结果:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/2ba481806b0048023c0478508de2e43f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QCnXkHwM2dmxUg0L2wV4qg.png"/></div></div></figure><p id="4aff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个<strong class="ir hi">过程</strong>的<strong class="ir hi">容易部分</strong>已经<strong class="ir hi">结束了。接下来，我们需要把所有这些层叠加起来！</strong></p><h2 id="213c" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">堆叠这些层</h2><p id="1367" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">因此，为了在一张图片中获得<strong class="ir hi">时间帧</strong>，我们在这里使用了一个来自<strong class="ir hi"> 7×7 </strong>矩阵的<strong class="ir hi"> 4×4 </strong>矩阵，在此之前，输入经过了3层处理，即<strong class="ir hi">卷积、ReLU </strong>和<strong class="ir hi">合并</strong>，如下所示:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/bbfb1ef3047832f7bc8a11030693851a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0s30olNe7nj_BQzzVyIjkA.png"/></div></div></figure><p id="f7cf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是我们能不能进一步把图片从T2的4×4缩小到T4的更小的尺寸呢？</p><p id="7ec4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">是的，我们可以！在第一遍之后，我们需要在迭代中执行3个操作。所以在第二遍之后，我们得到一个2×2的矩阵，如下所示:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/b4347e0454c64815f9d8acd8c502b33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZjTvmkfAHQ6UOi9RGL__g.png"/></div></div></figure><p id="5722" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">网络中的最后几层是<strong class="ir hi">完全连接的，</strong>意味着前几层的神经元是<strong class="ir hi">连接到</strong>到<strong class="ir hi">后续</strong>层中的每个神经元。</p><p id="6adb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该<strong class="ir hi">模仿高级推理</strong>，其中考虑了从<strong class="ir hi">输入</strong>到<strong class="ir hi">输出</strong>的所有可能的<strong class="ir hi">路径</strong>。</p><p id="b235" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此外，全连通层是分类实际发生的最后一层。这里，我们将过滤和缩小后的图像放入一个列表中，如下所示:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/31d5b3a84940d90574ee1ccc00ab256c.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*6oWcir6-VqlChLViQcC3Iw.png"/></div></figure><p id="c24b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以<strong class="ir hi">接下来，</strong>当我们馈入，<strong class="ir hi">‘X’</strong>和<strong class="ir hi">‘O’</strong>矢量中会有<strong class="ir hi">某个元素</strong>会为<strong class="ir hi">高。</strong>考虑下图，如你所见，对于“X”有<strong class="ir hi">不同的元素</strong>为高<strong class="ir hi">和<strong class="ir hi">类似地，</strong>对于<strong class="ir hi">“O”</strong>我们有<strong class="ir hi">不同的元素</strong>为高<strong class="ir hi">:</strong></strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mn"><img src="../Images/1c10a0697c5cc60d0045b7dd9de897b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yXdLYKalxnCNDw-zzyGJ1w.png"/></div></div></figure><p id="1f88" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那么，我们从上面的<strong class="ir hi">图片中<strong class="ir hi">理解了</strong>什么？</strong></p><p id="5b52" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当<strong class="ir hi">第1、第4、第5、第10</strong>和<strong class="ir hi">第11</strong>值为<strong class="ir hi">高时，</strong>我们可以将图像分类为<strong class="ir hi">‘x’。</strong>这个概念对于其他<strong class="ir hi">字母</strong>也是类似的——当某些<strong class="ir hi">值</strong>按照它们的方式排列时，它们可以被<strong class="ir hi">映射</strong>到一个<strong class="ir hi">实际的</strong>字母或者一个我们<strong class="ir hi">需要的<strong class="ir hi">数字</strong>，简单吧？</strong></p><h2 id="4288" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated">用卷积神经网络预测图像——全连接层</h2><p id="5765" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">此时，<strong class="ir hi">我们完成了对</strong>网络的训练，我们可以开始预测和<strong class="ir hi">检查</strong>分类器<strong class="ir hi">的<strong class="ir hi">工作</strong>。让我们看一个简单的例子:</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/efd6020e948ee907415dab73cf0c42f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:194/format:webp/1*y82lJsjRkBJ9v28fsbrg3w.png"/></div></figure><p id="43ab" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在上图中，我们有一个<strong class="ir hi"> 12元素</strong>向量，它是在<strong class="ir hi">通过<strong class="ir hi">网络的所有<strong class="ir hi">层</strong>将一个<strong class="ir hi">随机字母</strong>的<strong class="ir hi">输入</strong>传递给</strong>后获得的。</strong></p><p id="5ddf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，<strong class="ir hi">我们如何</strong>检查以知道我们得到的<strong class="ir hi">是对的还是错的</strong>？</p><p id="6846" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们<strong class="ir hi">根据<strong class="ir hi">输出的</strong>数据，通过将<strong class="ir hi">获得的值</strong>与列表中的‘x’和‘o’进行比较，做出预测</strong>！</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/947f13151a6c9c3581bb46e25786e5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SVyU_WfOO12xtfL87pRPw.png"/></div></div></figure><p id="85a5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">嗯，这真的很简单。我们只是将<strong class="ir hi">从<strong class="ir hi"> X </strong>的<strong class="ir hi">向量表</strong>中找到的最高值(第1、第4、第5、第10和第11)与</strong>相加，我们得到的总和为<strong class="ir hi"> 5。</strong>我们对<strong class="ir hi">输入图像</strong>做了<strong class="ir hi">完全相同的事情</strong>，得到的值<strong class="ir hi">为4.56 </strong>。</p><p id="89f5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们<strong class="ir hi">用</strong>除以<strong class="ir hi">值</strong>时，我们有一个<strong class="ir hi">概率匹配</strong>为<strong class="ir hi"> 0.91！</strong>现在用<strong class="ir hi">【o】</strong>的<strong class="ir hi">向量表</strong>做<strong class="ir hi">同样的</strong>:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/3d2f9327bbc430a8ff5e986417555139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYJB_DiKC-wGiURWgLWvwQ.png"/></div></div></figure><p id="2b3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们用此表将<strong class="ir hi">输出</strong>作为<strong class="ir hi"> 0.51 </strong>。嗯，概率是<strong class="ir hi"> 0.51 </strong>小于<strong class="ir hi"> 0.91 </strong>不是吗？</p><p id="6b34" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以我们可以断定<strong class="ir hi">产生的输入图像</strong>是一个<strong class="ir hi">‘x’！</strong></p><h1 id="ca55" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">用例:使用TensorFlow通过卷积神经网络实现CIFAR10</h1><p id="5212" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">让我们<strong class="ir hi">训练</strong>一个<strong class="ir hi">网络</strong>使用卷积神经网络内置TensorFlow对来自<strong class="ir hi"> CIFAR10数据集</strong>的图像进行分类。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/a0a1f1fca020e82831c9b626f566d792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkLl7D4StsGuzLfmA9drFA.png"/></div></div></figure><p id="4aed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑下面的<strong class="ir hi">流程图</strong>到<strong class="ir hi">来理解用例的</strong>和<strong class="ir hi">工作</strong>:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mp"><img src="../Images/4fee8c8a03df5fe53913f6def38f7257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GyIKmHRoX05QLbSdr5MeUw.png"/></div></div></figure><h2 id="7cdd" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated"><strong class="ak">安装必要的软件包:</strong></h2><pre class="lg lh li lj fd mq mr ms mt aw mu bi"><span id="60f4" class="ls kd hh mr b fi mv mw l mx my">pip3 install numpy tensorflow pickle</span></pre><h2 id="3f19" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated"><strong class="ak">训练网络:</strong></h2><pre class="lg lh li lj fd mq mr ms mt aw mu bi"><span id="8088" class="ls kd hh mr b fi mv mw l mx my">import numpy as np<br/>import tensorflow as tf<br/>from time import time<br/>import math<br/> <br/> <br/>from include.data import get_data_set<br/>from include.model import model, lr<br/> <br/> <br/>train_x, train_y = get_data_set("train")<br/>test_x, test_y = get_data_set("test")<br/>tf.set_random_seed(21)<br/>x, y, output, y_pred_cls, global_step, learning_rate = model()<br/>global_accuracy = 0<br/>epoch_start = 0<br/> <br/> <br/># PARAMS<br/>_BATCH_SIZE = 128<br/>_EPOCH = 60<br/>_SAVE_PATH = "./tensorboard/cifar-10-v1.0.0/"<br/> <br/> <br/># LOSS AND OPTIMIZER<br/>loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))<br/>optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,<br/>                                   beta1=0.9,<br/>                                   beta2=0.999,<br/>                                   epsilon=1e-08).minimize(loss, global_step=global_step)<br/> <br/> <br/># PREDICTION AND ACCURACY CALCULATION<br/>correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))<br/>accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br/> <br/> <br/># SAVER<br/>merged = tf.summary.merge_all()<br/>saver = tf.train.Saver()<br/>sess = tf.Session()<br/>train_writer = tf.summary.FileWriter(_SAVE_PATH, sess.graph)<br/> <br/> <br/>try:<br/>    print("\nTrying to restore last checkpoint ...")<br/>    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)<br/>    saver.restore(sess, save_path=last_chk_path)<br/>    print("Restored checkpoint from:", last_chk_path)<br/>except ValueError:<br/>    print("\nFailed to restore checkpoint. Initializing variables instead.")<br/>    sess.run(tf.global_variables_initializer())<br/> <br/> <br/>def train(epoch):<br/>    global epoch_start<br/>    epoch_start = time()<br/>    batch_size = int(math.ceil(len(train_x) / _BATCH_SIZE))<br/>    i_global = 0<br/> <br/>    for s in range(batch_size):<br/>        batch_xs = train_x[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]<br/>        batch_ys = train_y[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]<br/> <br/>        start_time = time()<br/>        i_global, _, batch_loss, batch_acc = sess.run(<br/>            [global_step, optimizer, loss, accuracy],<br/>            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)})<br/>        duration = time() - start_time<br/> <br/>        if s % 10 == 0:<br/>            percentage = int(round((s/batch_size)*100))<br/> <br/>            bar_len = 29<br/>            filled_len = int((bar_len*int(percentage))/100)<br/>            bar = '=' * filled_len + '&gt;' + '-' * (bar_len - filled_len)<br/> <br/>            msg = "Global step: {:&gt;5} - [{}] {:&gt;3}% - acc: {:.4f} - loss: {:.4f} - {:.1f} sample/sec"<br/>            print(msg.format(i_global, bar, percentage, batch_acc, batch_loss, _BATCH_SIZE / duration))<br/> <br/>    test_and_save(i_global, epoch)<br/> <br/> <br/>def test_and_save(_global_step, epoch):<br/>    global global_accuracy<br/>    global epoch_start<br/> <br/>    i = 0<br/>    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)<br/>    while i &lt; len(test_x): j = min(i + _BATCH_SIZE, len(test_x)) batch_xs = test_x[i:j, :] batch_ys = test_y[i:j, :] predicted_class[i:j] = sess.run( y_pred_cls, feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)} ) i = j correct = (np.argmax(test_y, axis=1) == predicted_class) acc = correct.mean()*100 correct_numbers = correct.sum() hours, rem = divmod(time() - epoch_start, 3600) minutes, seconds = divmod(rem, 60) mes = "\nEpoch {} - accuracy: {:.2f}% ({}/{}) - time: {:0&gt;2}:{:0&gt;2}:{:05.2f}"<br/>    print(mes.format((epoch+1), acc, correct_numbers, len(test_x), int(hours), int(minutes), seconds))<br/> <br/>    if global_accuracy != 0 and global_accuracy &lt; acc: summary = tf.Summary(value=[ tf.Summary.Value(tag="Accuracy/test", simple_value=acc), ]) train_writer.add_summary(summary, _global_step) saver.save(sess, save_path=_SAVE_PATH, global_step=_global_step) mes = "This epoch receive better accuracy: {:.2f} &gt; {:.2f}. Saving session..."<br/>        print(mes.format(acc, global_accuracy))<br/>        global_accuracy = acc<br/> <br/>    elif global_accuracy == 0:<br/>        global_accuracy = acc<br/> <br/>    print("###########################################################################################################")<br/> <br/> <br/>def main():<br/>    train_start = time()<br/> <br/>    for i in range(_EPOCH):<br/>        print("\nEpoch: {}/{}\n".format((i+1), _EPOCH))<br/>        train(i)<br/> <br/>    hours, rem = divmod(time() - train_start, 3600)<br/>    minutes, seconds = divmod(rem, 60)<br/>    mes = "Best accuracy pre session: {:.2f}, time: {:0&gt;2}:{:0&gt;2}:{:05.2f}"<br/>    print(mes.format(global_accuracy, int(hours), int(minutes), seconds))<br/> <br/> <br/>if __name__ == "__main__":<br/>    main()<br/> <br/> <br/>sess.close()</span></pre><p id="898f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lg lh li lj fd mq mr ms mt aw mu bi"><span id="4737" class="ls kd hh mr b fi mv mw l mx my">Epoch: 60/60</span><span id="a8c5" class="ls kd hh mr b fi mz mw l mx my">Global step: 23070 - [&gt;-----------------------------]   0% - acc: 0.9531 - loss: 1.5081 - 7045.4 sample/sec<br/>Global step: 23080 - [&gt;-----------------------------]   3% - acc: 0.9453 - loss: 1.5159 - 7147.6 sample/sec<br/>Global step: 23090 - [=&gt;----------------------------]   5% - acc: 0.9844 - loss: 1.4764 - 7154.6 sample/sec<br/>Global step: 23100 - [==&gt;---------------------------]   8% - acc: 0.9297 - loss: 1.5307 - 7104.4 sample/sec<br/>Global step: 23110 - [==&gt;---------------------------]  10% - acc: 0.9141 - loss: 1.5462 - 7091.4 sample/sec<br/>Global step: 23120 - [===&gt;--------------------------]  13% - acc: 0.9297 - loss: 1.5314 - 7162.9 sample/sec<br/>Global step: 23130 - [====&gt;-------------------------]  15% - acc: 0.9297 - loss: 1.5307 - 7174.8 sample/sec<br/>Global step: 23140 - [=====&gt;------------------------]  18% - acc: 0.9375 - loss: 1.5231 - 7140.0 sample/sec<br/>Global step: 23150 - [=====&gt;------------------------]  20% - acc: 0.9297 - loss: 1.5301 - 7152.8 sample/sec<br/>Global step: 23160 - [======&gt;-----------------------]  23% - acc: 0.9531 - loss: 1.5080 - 7112.3 sample/sec<br/>Global step: 23170 - [=======&gt;----------------------]  26% - acc: 0.9609 - loss: 1.5000 - 7154.0 sample/sec<br/>Global step: 23180 - [========&gt;---------------------]  28% - acc: 0.9531 - loss: 1.5074 - 6862.2 sample/sec<br/>Global step: 23190 - [========&gt;---------------------]  31% - acc: 0.9609 - loss: 1.4993 - 7134.5 sample/sec<br/>Global step: 23200 - [=========&gt;--------------------]  33% - acc: 0.9609 - loss: 1.4995 - 7166.0 sample/sec<br/>Global step: 23210 - [==========&gt;-------------------]  36% - acc: 0.9375 - loss: 1.5231 - 7116.7 sample/sec<br/>Global step: 23220 - [===========&gt;------------------]  38% - acc: 0.9453 - loss: 1.5153 - 7134.1 sample/sec<br/>Global step: 23230 - [===========&gt;------------------]  41% - acc: 0.9375 - loss: 1.5233 - 7074.5 sample/sec<br/>Global step: 23240 - [============&gt;-----------------]  43% - acc: 0.9219 - loss: 1.5387 - 7176.9 sample/sec<br/>Global step: 23250 - [=============&gt;----------------]  46% - acc: 0.8828 - loss: 1.5769 - 7144.1 sample/sec<br/>Global step: 23260 - [==============&gt;---------------]  49% - acc: 0.9219 - loss: 1.5383 - 7059.7 sample/sec<br/>Global step: 23270 - [==============&gt;---------------]  51% - acc: 0.8984 - loss: 1.5618 - 6638.6 sample/sec<br/>Global step: 23280 - [===============&gt;--------------]  54% - acc: 0.9453 - loss: 1.5151 - 7035.7 sample/sec<br/>Global step: 23290 - [================&gt;-------------]  56% - acc: 0.9609 - loss: 1.4996 - 7129.0 sample/sec<br/>Global step: 23300 - [=================&gt;------------]  59% - acc: 0.9609 - loss: 1.4997 - 7075.4 sample/sec<br/>Global step: 23310 - [=================&gt;------------]  61% - acc: 0.8750 - loss: 1.5842 - 7117.8 sample/sec<br/>Global step: 23320 - [==================&gt;-----------]  64% - acc: 0.9141 - loss: 1.5463 - 7157.2 sample/sec<br/>Global step: 23330 - [===================&gt;----------]  66% - acc: 0.9062 - loss: 1.5549 - 7169.3 sample/sec<br/>Global step: 23340 - [====================&gt;---------]  69% - acc: 0.9219 - loss: 1.5389 - 7164.4 sample/sec<br/>Global step: 23350 - [====================&gt;---------]  72% - acc: 0.9609 - loss: 1.5002 - 7135.4 sample/sec<br/>Global step: 23360 - [=====================&gt;--------]  74% - acc: 0.9766 - loss: 1.4842 - 7124.2 sample/sec<br/>Global step: 23370 - [======================&gt;-------]  77% - acc: 0.9375 - loss: 1.5231 - 7168.5 sample/sec<br/>Global step: 23380 - [======================&gt;-------]  79% - acc: 0.8906 - loss: 1.5695 - 7175.2 sample/sec<br/>Global step: 23390 - [=======================&gt;------]  82% - acc: 0.9375 - loss: 1.5225 - 7132.1 sample/sec<br/>Global step: 23400 - [========================&gt;-----]  84% - acc: 0.9844 - loss: 1.4768 - 7100.1 sample/sec<br/>Global step: 23410 - [=========================&gt;----]  87% - acc: 0.9766 - loss: 1.4840 - 7172.0 sample/sec<br/>Global step: 23420 - [==========================&gt;---]  90% - acc: 0.9062 - loss: 1.5542 - 7122.1 sample/sec<br/>Global step: 23430 - [==========================&gt;---]  92% - acc: 0.9297 - loss: 1.5313 - 7145.3 sample/sec<br/>Global step: 23440 - [===========================&gt;--]  95% - acc: 0.9297 - loss: 1.5301 - 7133.3 sample/sec<br/>Global step: 23450 - [============================&gt;-]  97% - acc: 0.9375 - loss: 1.5231 - 7135.7 sample/sec<br/>Global step: 23460 - [=============================&gt;] 100% - acc: 0.9250 - loss: 1.5362 - 10297.5 sample/sec</span><span id="7b1c" class="ls kd hh mr b fi mz mw l mx my">Epoch 60 - accuracy: 78.81% (7881/10000)<br/>This epoch receive better accuracy: 78.81 &gt; 78.78. Saving session...<br/>###########################################################################################################</span></pre><h2 id="c002" class="ls kd hh bd ke lt lu lv ki lw lx ly km ja lz ma kq je mb mc ku ji md me ky mf bi translated"><strong class="ak">对测试数据集运行网络:</strong></h2><pre class="lg lh li lj fd mq mr ms mt aw mu bi"><span id="3892" class="ls kd hh mr b fi mv mw l mx my">import numpy as np<br/>import tensorflow as tf<br/> <br/>from include.data import get_data_set<br/>from include.model import model<br/> <br/> <br/>test_x, test_y = get_data_set("test")<br/>x, y, output, y_pred_cls, global_step, learning_rate = model()<br/> <br/> <br/>_BATCH_SIZE = 128<br/>_CLASS_SIZE = 10<br/>_SAVE_PATH = "./tensorboard/cifar-10-v1.0.0/"<br/> <br/> <br/>saver = tf.train.Saver()<br/>sess = tf.Session()<br/> <br/> <br/>try:<br/>    print("\nTrying to restore last checkpoint ...")<br/>    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)<br/>    saver.restore(sess, save_path=last_chk_path)<br/>    print("Restored checkpoint from:", last_chk_path)<br/>except ValueError:<br/>    print("\nFailed to restore checkpoint. Initializing variables instead.")<br/>    sess.run(tf.global_variables_initializer())<br/> <br/> <br/>def main():<br/>    i = 0<br/>    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)<br/>    while i &lt; len(test_x):<br/>        j = min(i + _BATCH_SIZE, len(test_x))<br/>        batch_xs = test_x[i:j, :]<br/>        batch_ys = test_y[i:j, :]<br/>        predicted_class[i:j] = sess.run(y_pred_cls, feed_dict={x: batch_xs, y: batch_ys})<br/>        i = j<br/> <br/>    correct = (np.argmax(test_y, axis=1) == predicted_class)<br/>    acc = correct.mean() * 100<br/>    correct_numbers = correct.sum()<br/>    print()<br/>    print("Accuracy on Test-Set: {0:.2f}% ({1} / {2})".format(acc, correct_numbers, len(test_x)))<br/> <br/> <br/>if __name__ == "__main__":<br/>    main()<br/> <br/> <br/>sess.close()</span></pre><p id="901b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">简单输出:</strong></p><pre class="lg lh li lj fd mq mr ms mt aw mu bi"><span id="2333" class="ls kd hh mr b fi mv mw l mx my">Trying to restore last checkpoint ...<br/>Restored checkpoint from: ./tensorboard/cifar-10-v1.0.0/-23460</span><span id="743e" class="ls kd hh mr b fi mz mw l mx my">Accuracy on Test-Set: 78.81% (7881 / 10000)</span></pre><p id="517b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">训练时间</strong></p><p id="89ca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这里你可以看到60个纪元需要多少时间:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es na"><img src="../Images/2847f075ec598544e871d5fbd51ebefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b717aenVIUnlXyqMsx8xPw.png"/></div></div></figure><h1 id="b7d7" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结论</h1><p id="3266" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">卷积神经网络是一种<strong class="ir hi">流行的</strong>深度学习技术，用于当前的<strong class="ir hi">视觉识别任务。</strong>像所有深度学习技术一样，卷积神经网络非常依赖于训练数据的<strong class="ir hi">大小</strong>和<strong class="ir hi">质量</strong>。</p><p id="41be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给定一个准备充分的<strong class="ir hi">数据集，</strong>卷积神经网络能够在视觉识别任务中<strong class="ir hi">超越人类</strong>。然而，它们仍然<strong class="ir hi">对诸如眩光和噪声等视觉伪像不够鲁棒</strong>，而人类<strong class="ir hi">能够<strong class="ir hi">应对这些伪像。</strong></strong></p><p id="340a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">卷积神经网络的<strong class="ir hi">理论</strong>仍在<strong class="ir hi">开发中</strong>，研究人员正致力于赋予其属性，如<strong class="ir hi">主动注意</strong>和<strong class="ir hi">在线记忆</strong>，允许卷积神经网络<strong class="ir hi">评估</strong>与它们所接受的训练完全不同的新项目。</p><p id="8e8c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这种更好的<strong class="ir hi">模仿</strong>的<strong class="ir hi">哺乳动物视觉系统，</strong>从而走向<strong class="ir hi">更智能的人工</strong>视觉识别<strong class="ir hi">系统。</strong></p><p id="ebea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ml">这就把我们带到了“卷积神经网络”这篇文章的结尾。我希望这篇文章对你有所帮助，并增加了你的知识价值。</em></p><p id="6864" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，那么你可以参考<a class="ae nb" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=convolutional-neural-network" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释深度学习的各个其他方面。</p><blockquote class="nc nd ne"><p id="1554" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">1.<a class="ae nb" rel="noopener" href="/edureka/tensorflow-tutorial-ba142ae96bca"> TensorFlow教程</a></p><p id="0a8c" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">2.<a class="ae nb" rel="noopener" href="/edureka/pytorch-tutorial-9971d66f6893"> PyTorch教程</a></p><p id="22d9" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">3.<a class="ae nb" rel="noopener" href="/edureka/perceptron-learning-algorithm-d30e8b99b156">感知器学习算法</a></p><p id="2491" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">4.<a class="ae nb" rel="noopener" href="/edureka/neural-network-tutorial-2a46b22394c9">神经网络教程</a></p><p id="030f" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">5.<a class="ae nb" rel="noopener" href="/edureka/backpropagation-bd2cf8fdde81">什么是反向传播？</a></p><p id="0611" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">6.<a class="ae nb" rel="noopener" href="/edureka/tensorflow-object-detection-tutorial-8d6942e73adc">tensor flow中的物体检测</a></p><p id="a939" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">7.<a class="ae nb" rel="noopener" href="/edureka/capsule-networks-d7acd437c9e">胶囊神经网络</a></p><p id="2c32" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">8.<a class="ae nb" rel="noopener" href="/edureka/recurrent-neural-networks-df945afd7441">递归神经网络</a></p><p id="e09a" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">9.<a class="ae nb" rel="noopener" href="/edureka/autoencoders-tutorial-cfdcebdefe37">自动编码器教程</a></p><p id="5a2b" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">10.<a class="ae nb" rel="noopener" href="/edureka/restricted-boltzmann-machine-tutorial-991ae688c154">受限玻尔兹曼机教程</a></p><p id="9923" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">11.<a class="ae nb" rel="noopener" href="/edureka/pytorch-vs-tensorflow-252fc6675dd7"> PyTorch vs TensorFlow </a></p><p id="ba9f" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">12.<a class="ae nb" rel="noopener" href="/edureka/deep-learning-with-python-2adbf6e9437d">用Python进行深度学习</a></p><p id="7076" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">13.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-tutorial-4257c66f5bb1">人工智能教程</a></p><p id="dcdf" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">14.<a class="ae nb" rel="noopener" href="/edureka/tensorflow-image-classification-19b63b7bfd95">张量流图像分类</a></p><p id="d5d5" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">15.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-applications-7b93b91150e3">人工智能应用</a></p><p id="d281" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">16.<a class="ae nb" rel="noopener" href="/edureka/become-artificial-intelligence-engineer-5ac2ede99907">如何成为一名人工智能工程师？</a></p><p id="fabd" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">17.<a class="ae nb" rel="noopener" href="/edureka/q-learning-592524c3ecfc">问学习</a></p><p id="73ae" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">18.<a class="ae nb" rel="noopener" href="/edureka/apriori-algorithm-d7cc648d4f1e"> Apriori算法</a></p><p id="ae04" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">19.<a class="ae nb" rel="noopener" href="/edureka/introduction-to-markov-chains-c6cb4bcd5723">用Python实现马尔可夫链</a></p><p id="4293" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">20.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-algorithms-fad283a0d8e2">人工智能算法</a></p><p id="c0d0" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">21.<a class="ae nb" rel="noopener" href="/edureka/best-laptop-for-machine-learning-a4a5f8ba5b">机器学习的最佳笔记本电脑</a></p><p id="811a" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">22.<a class="ae nb" rel="noopener" href="/edureka/top-artificial-intelligence-tools-36418e47bf2a">12大人工智能工具</a></p><p id="460d" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">23.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-interview-questions-872d85387b19">人工智能(AI)面试问题</a></p><p id="8e0f" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">24.<a class="ae nb" rel="noopener" href="/edureka/theano-vs-tensorflow-15f30216b3bc"> Theano vs TensorFlow </a></p><p id="db4e" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">25.<a class="ae nb" rel="noopener" href="/edureka/what-is-a-neural-network-56ae7338b92d">什么是神经网络？</a></p><p id="ea9e" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">26.<a class="ae nb" rel="noopener" href="/edureka/pattern-recognition-5e2d30ab68b9">模式识别</a></p><p id="930d" class="ip iq ml ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">27.<a class="ae nb" rel="noopener" href="/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a">人工智能中的阿尔法贝塔剪枝</a></p></blockquote></div><div class="ab cl ni nj go nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ha hb hc hd he"><p id="ba7e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最初发表于2018年11月27日<a class="ae nb" href="https://www.edureka.co/blog/convolutional-neural-network/" rel="noopener ugc nofollow" target="_blank">www.edureka.co</a>。</p></div></div>    
</body>
</html>