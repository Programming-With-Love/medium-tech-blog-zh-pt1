<html>
<head>
<title>Mozrt, a Deep Learning Recommendation System Empowering Walmart Store Associates with a Personalized Learning Experience</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Mozrt是一个深度学习推荐系统，为沃尔玛商店员工提供个性化的学习体验</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/mozrt-a-deep-learning-recommendation-system-empowering-walmart-store-associates-with-a-5d42c08d88da?source=collection_archive---------0-----------------------#2021-11-04">https://medium.com/walmartglobaltech/mozrt-a-deep-learning-recommendation-system-empowering-walmart-store-associates-with-a-5d42c08d88da?source=collection_archive---------0-----------------------#2021-11-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d19567e0265344787a984e6a0c066edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7gmFHiCZjOymEF_F6g-0tA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Image by <a class="ae it" href="https://www.foxvalleysymphony.com/about-us/musicians-and-conductor/" rel="noopener ugc nofollow" target="_blank">Fox Valley Symphony Orchestra</a></figcaption></figure><h1 id="b2d4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">业务背景</strong></h1><p id="62af" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">沃尔玛在美国的4，700多家商店雇用了近160万名员工。每个员工负责完成各种任务，这些任务经常根据他们的日常日程和任务进行更新和修改。为了专业和准确地完成这些任务，为每个任务设置了协议。向员工提供最新的、易于获取的相关信息对员工和沃尔玛的成功至关重要。我们开发了Mozrt，这是一个用于沃尔玛学院应用程序的深度学习推荐系统，是沃尔玛商店和供应链员工的培训内容门户。沃尔玛学院应用程序可在所有公司管理的移动和桌面设备上使用。每次员工登录时，Mozrt都会提供一系列推荐转盘，帮助沃尔玛员工在销售区为顾客服务时，在正确的时间找到正确的内容。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kq"><img src="../Images/e25ffa9df99dd094e9e522b5113044a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ssWb8niDdffyuPArmSAhw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 1. Mozrt on Walmart Academy App</figcaption></figure><h1 id="f081" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">提议的模型架构</strong></h1><p id="c01c" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">整个系统架构是一个两阶段推荐系统，如下图所示。有两个主要部分:1)内容候选生成2)内容排序算法。候选生成快速筛选出最终推荐入选几率较低的候选内容，并为下一步生成一个简短的内容列表。排名算法使用候选生成中生成的入围内容作为输入来重新排名，并生成最终的推荐内容轮播。</p><p id="4d8d" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">当处理非常大的内容候选池时，两阶段推荐系统提供了有效的解决方案。例如，对于10，000个内容，每个内容需要10毫秒来生成预测分数，排名算法将需要100秒来对所有内容进行排名。这对于实时应用程序来说是不可接受的。利用两阶段推荐系统，内容候选生成过滤掉大约9，980个内容。排名算法可以在200毫秒内处理剩余的20个内容。</p><p id="1de2" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">我们使用协作过滤和基于内容的相似性模型作为候选人生成系统，根据历史观点来估计员工的内容需求。然后，内容候选流入深度学习排名模型。排名模型将考虑员工信息，如工作信息、工作区域、登录时间/日期和skip-gram算法中的内容嵌入，以高精度预测员工每次与沃尔玛学院应用程序互动时的需求。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es la"><img src="../Images/655152e29feefe7ccc6fbeeaabdd7cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sC9J_3NLOdmVS1LRQAkOIg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 2. Mozrt model architecture</figcaption></figure><h1 id="35f1" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">模型训练第一步:候选生成</strong></h1><h2 id="d0cd" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">协同过滤候选生成</strong></h2><p id="1922" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">Item2item协同过滤是推荐系统领域最流行的算法之一。例如，在Mozrt学习内容推荐系统中，我们将每个学习内容视为一个“项目”,并使用不同同事生成的点击历史来识别每个项目在向量空间中的位置。之后，我们找到前K个最近的邻居并存储它们。该算法选择第一组候选内容作为深度学习排序算法的输入。</p><h2 id="f94d" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">基于内容(NLP)的相似候选生成</strong></h2><p id="fc03" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">协同过滤可能无法找到对沃尔玛员工有价值的所有内容。例如，新创建的内容或具有很少观看历史的内容的用户点击矩阵将非常稀疏。因此，在向量空间中找到这些内容的准确位置将是一项挑战。因此，提出了基于内容的相似性模型来生成第二内容候选组作为深度学习排序算法的输入。</p><h2 id="3367" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak"> TextRank-IDF关键词提取</strong></h2><p id="8eca" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">对于每个学习内容网页，我们通过混合文本摘要技术(TextRank-IDF算法)获得一系列关键词并存储它们。</p><p id="9f2f" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">我们将学习网页文本中的每个单词视为图中的一个节点，上下文窗口中的任何两个单词对都被视为具有无向边。我们将上下文窗口表示为[W1，W2，…Wn]，并将上下文窗口大小指定为四个单词。例如:[W1，W2，W3，W4]。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lp"><img src="../Images/75a2d79d07beb015753bdeba8c06fc3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AfmnS3JzBZELRhJyRsFTyw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 3. TextRank algorithm</figcaption></figure><p id="c30b" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">我们使用PageRank算法迭代地计算每个“单词节点”的重要性分数。然后，我们通过逆文档频率(IDF)值来调整重要性分数。这个过程会对大多数学习内容中经常出现的单词进行加权(例如，Walmart、associate等。).具有最高调整后重要性分数的单词被用作关键词。</p><h2 id="263e" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">内容相似度计算</strong></h2><p id="22c7" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我们将一个学习内容页面中的关键字与第二个页面中的所有关键字进行比较，以计算基于内容的相似性得分。然后将所有关键字对的相似性得分汇总为一个得分。最终的相似性得分是从word2vec模型生成的嵌入中计算出来的。这个模型是从超过7000篇文章组成的整个沃尔玛学习内容语料库中训练出来的。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/7b4a44402fdfbf0a33a214829d74002c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKu50xJJNMZMwz2cGgmK-g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 4. Content-based similarity by keyword pairs. Note: URL_keywords refers the content in given URL.</figcaption></figure><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/4dc6c878c450acae2741f97b3d5dea92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RqnDD6yv4jnKEzym3Q0dGw.png"/></div></div></figure><p id="9fd2" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">我们找到K个最相似的学习内容页面并存储它们，其中K是相似学习内容页面的数量。</p><h1 id="6068" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">模型训练第二步:排序算法</h1><p id="7401" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">Mozrt使用深度因式分解机器算法作为排名算法[1]。训练数据从与内容(点击、观看、时间)的关联参与中收集，超参数通过离线贝叶斯优化来确定。</p><h2 id="ff4a" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">输入:跳过gram内容嵌入</strong></h2><p id="f502" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">任何实体都可以用一系列数字来表示，包括学习内容网页。在机器学习术语中，这个过程被称为嵌入。最近，许多科技公司开发了从用户-物品交互数据中获取物品嵌入的算法，如Airbnb的租赁列表作为嵌入，Pinterest的Pin作为嵌入在其Pin2vec算法中[2][3]。这些算法中的大多数都是使用神经语言模型(Word2vec)[4][5]开发的。</p><p id="bafc" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">经典的Word2vec模型有两个基本组成部分:单词和句子。如果两个单词位于同一个句子中，并且它们的距离不长于某个长度(上下文窗口)，我们就认为它们是“邻居”Word2vec模型为每个单词随机分配数字作为初始嵌入。在训练过程中，每个单词的嵌入被用作神经网络模型的输入，而其相邻单词的嵌入被用作输出(跳格)。在神经网络中多次迭代更新单词嵌入将实现每个单词的最终嵌入。</p><p id="b292" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">我们采用了与Word2vec类似的策略，为Mozrt的排名算法创建与学习内容相关的输入。我们利用员工的观看行为提出了单词和句子的概念。每个内容网页被分配一个唯一的内容ID。内容ID被视为“单词”,相关点击序列被视为“句子”。点击序列有不同的长度，就像Word2vec模型中的句子一样。内容ID句子被定义为同一用户的点击，其中网页之间的时间间隔不超过30分钟。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/1b77fa34bcf7c4978789ba0a650396b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O1Rb3rBQQF0Tw9MOuSlXrA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 5. Word embedding and content embedding</figcaption></figure><p id="30ff" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">随后，我们建立了一个skip-gram模型，为每个学习内容创建一个n维嵌入，表示它在向量空间中的位置。我们将嵌入内容存储为Mozrt排序算法的内容相关输入。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/6d365d47d50133e6069255ecd626bdc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OzdPxtls3P2lfV3UqEGXqQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 6. DeepFM model input</figcaption></figure><h2 id="4450" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">宽而深的建筑</strong></h2><p id="3769" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">准备好输入数据后，我们进入建模步骤。对于这一步，最大的障碍是<strong class="ju hi">平衡概括和记忆的能力。</strong>让我们稍微打开包装。</p><p id="9c5d" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">传统的深度学习算法具有良好的泛化能力。然而，这些算法有时无法“记住”历史数据中的模式。例如，我们希望推荐系统“记住”在感恩节之前向买家展示火鸡，但不要过度概括历史数据中的知识，并在另一个节日(如劳动节)之前推荐火鸡。</p><p id="80a8" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">2016年，Google研究人员提出了Wide &amp; Deep架构[1]；他们将一个宽组件与一个深组件结合起来，以提高深度神经网络的记忆能力。该架构由少数公司和研究机构(华为、脸书等)进行了优化。在接下来的几年里。</p><h2 id="d76c" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated">算法:<strong class="ak">深度因式分解机</strong></h2><p id="e361" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">既然我们已经选择了一个宽而深的架构来建立我们的排名模型，并使用宽组件来增加模型的记忆能力，下一个挑战是估计宽组件中交互特征的参数。</p><p id="1d26" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">Mozrt使用深度因式分解机[6]作为排序算法，这是wide &amp; deep架构中性能最好的算法之一。DeepFM的结构如图7所示。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/84606a7cba11eb081d5d56967df5ea1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*abJPaZN7ptfv8IZStXEoYg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 7. <a class="ae it" href="https://arxiv.org/pdf/1703.04247.pdf" rel="noopener ugc nofollow" target="_blank">Deep Factorization Machine</a> [6]</figcaption></figure><p id="c190" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">宽分量是一个<strong class="ju hi">一般线性回归</strong>。它负责<strong class="ju hi">记忆</strong>历史信息。该组件的主要挑战是如何减少大量潜在交互特征的参数(权重)数量，假设每个集成特征都有一个参数。例如，如果我们有2，000个特性，并且每个特性都可能与其他特性交互，那么潜在的交互特性将接近200万个。因此，我们使用因式分解机来估计相互作用特征的参数。我们假设交互特征的每个<strong class="ju hi">权重</strong>可以分解为<strong class="ju hi">两个潜在因子向量</strong>，并且在估计交互特征的参数时只拟合潜在因子向量。如果潜在因素向量维数是4，我们只需要拟合8000个参数。在“因子分解机”的帮助下，DeepFM可以在大规模推荐系统中自动定义交互特征，大幅减少wide component中的参数数量。</p><p id="d1d8" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated"><strong class="ju hi">深度</strong>组件是一个<strong class="ju hi">前馈神经网络</strong>。它负责<strong class="ju hi">概括</strong>，探索历史数据中从未出现过的特征组合。称为密集嵌入的深层组件中的关键层将独热编码特征转换成具有更少数值的密集(更少维度)矩阵(类似于单词嵌入，并将超过10，000个独热编码转换成大约100个维度。)</p><h1 id="8b83" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">模特再培训渠道</strong></h1><p id="8891" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我们使用气流来实现深度学习推荐系统的再训练管道。在本节中，我们将回顾重新训练频率、数据漂移和模型质量检查器的基本原理。</p><h2 id="f460" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">不同型号部件的重新训练频率</strong></h2><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/d0ad5f76fb262194d043986789e1a9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tNMZQtWNYp4ZYFoMH4W4fA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 8. Structure of Airflow re-train pipeline</figcaption></figure><p id="22f4" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">DeepFM模型具有很强的泛化能力。即使输入内容嵌入从未出现在训练数据中，DeepFM算法也能够准确预测。重新训练一个深度学习模型要消耗大量的计算资源；因此，我们每月重新训练。</p><p id="e68e" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">如果新创建的内容没有嵌入，它将不会收到来自DeepFM算法的预测，并且我们需要比DeepFM模型更频繁地重新训练内容嵌入模型。因此，内容嵌入模型计划每周重新训练。</p><p id="aa0d" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">候选生成模型是推荐系统的基础，尤其是在Mozrt中。如果DeepFM不产生预测，协同过滤和基于内容的相似性模型将作为“备份”并产生最终输出。因此，我们为这两个模型设置了每日再训练时间表。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/90dec26605ae9c4c9628147e36ec2422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fP2YOV2W7il6Yd5BoCO4jw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Table 1. Model retrain frequency</figcaption></figure><h2 id="8240" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">数据漂移检测</strong></h2><p id="f4d8" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我们在深度学习推荐系统中构建了一系列数据漂移检测器，监控异常离群值和意外的输入数据分布。如果有任何重大的数据漂移，重新训练过程将被暂停，一个自动的电子邮件警告将被发送到开发团队。</p><h2 id="4084" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">模型性能检查器</strong></h2><p id="c39b" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我们设置了决策节点，以检查在重新训练过程中，所有模型组件是否运行正常，性能是否满足标准。例如，如果新的DeepFM模型的AUC小于0.7，该模型将不会在Azure上注册，并且会自动向开发团队发送电子邮件提醒。</p><h1 id="e7a7" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">重述</strong></h1><p id="f7f5" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在Mozrt中，有两种候选生成算法。协同过滤通过关联的观看历史粗略地选择学习内容候选，而基于内容的相似性通过内容关键词相似性选择另一组候选。</p><p id="5ba9" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">每个内容都有一个唯一的内容id。我们使用内容id作为“单词”,相关点击序列作为“句子”,并运行跳图神经语言模型来获取嵌入，作为深度学习排序算法的内容相关输入。</p><p id="6b91" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">DeepFM算法输出学习内容候选的最终排名。宽分量是具有因式分解机器参数估计的一般线性回归，负责记忆历史信息。深度组件是一个前馈神经网络，具有很强的泛化能力。这两个组件协同工作，以高精度预测员工与应用程序交互时所需的学习内容。</p><p id="ac68" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">在模型再训练管道上设置了数据漂移检测器和模型性能检查器，以保证每个更新的模型版本都能正常工作。</p><p id="4fc0" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated"><strong class="ju hi">成功的简要示例</strong></p><p id="49a3" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">Mozrt学习推荐系统可以记住历史视图，并“预测”员工需要的内容。例如，唐娜是一名团队成员。当她在周三上午9点登录沃尔玛学院应用时，她会看到一篇文章，来自深度学习推荐系统的“完整的价格变化”，因为价格变化过程通常在工作日的早上实施。如果她在下午3点左右登录，她将获得“存放多余现金”的建议，因为这个过程通常在下午需要。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lx"><img src="../Images/ef6f1a61bdc4aa0d6bbe4dec013eed90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DgfmJND8mFemP1sgoFbLXQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Figure 9. Recommendations change at different time</figcaption></figure><h2 id="74c4" class="lb iv hh bd iw lc ld le ja lf lg lh je kd li lj ji kh lk ll jm kl lm ln jq lo bi translated"><strong class="ak">与其他推荐转盘的关系</strong></h2><p id="40ff" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我们在沃尔玛学院应用程序中编排了多个旋转木马，为员工提供全面的学习体验。基于您的查看历史记录的<strong class="ju hi"/>轮播使用深度学习推荐系统提供高度个性化的学习内容推荐，而【T2趋势】Now 和<strong class="ju hi"> Popular with your team </strong>轮播显示整个公司和员工团队中最受欢迎的学习内容网页。基于客户反馈的<strong class="ju hi">转盘</strong>扫描客户语音数据，推荐学习内容以改善客户体验。</p><p id="7d21" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated"><strong class="ju hi">实施DeepFM的思路</strong></p><p id="60bb" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">推荐系统不是一个单一的模型，而是一个复杂的系统，有多个模型、数据管道和编排器。每个组件在提供准确的建议方面都扮演着重要的角色。因此，按顺序开发每个组件<em class="ly">并不是</em>最佳策略。这不仅延迟了产品发布，降低了吞吐量，而且导致了对隐藏技术债务的忽略(<a class="ae it" href="https://matthewmcateer.me/blog/machine-learning-technical-debt/" rel="noopener ugc nofollow" target="_blank">这里有一个超出范围的更详细的讨论</a>)以及从一开始就过度强调模型的假设和复杂性。为了在开发过程中减少这些组件之间的依赖性，我们决定通过黑客马拉松活动开始构建整个系统架构，邀请数据工程、架构、网络安全、机器学习工程和软件开发方面的专家参加为期一周的作战室式讨论。我们首先在Mozrt的第一版中加入了一些启发式模型(基于频率的模型和基于分类的模型)。一旦开发并测试了DeepFM模型，我们很快在一个季度后的第二个版本中将DeepFM整合到现有系统中。该策略显著缩短了Mozrt的开发生命周期，提高了吞吐量。</p><p id="cc91" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated"><em class="ly">鸣谢:我们是数据科学人员，是沃尔玛全球技术中数据、战略和见解的一部分。我们构建AI/ML解决方案，为全球220万名员工提供数字、数据驱动的解决方案。感谢我们Learning scrum团队的10多名成员，以及我们在数据工程、关联产品、企业内容管理和学习技术领域的合作伙伴，是他们让这一切成为现实。</em></p><h1 id="539e" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">参考</strong></h1><p id="5805" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">[1] Cheng，H. T .，Koc L .，Harmsen，J. <em class="ly">等</em> (2016)。推荐系统的深度学习。<em class="ly">第一届推荐系统深度学习研讨会论文集。<a class="ae it" href="https://arxiv.org/pdf/1606.07792.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1606.07792.pdf</a>T21</em></p><p id="0604" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">[2]格博维奇，m .，，程，H. (2018)。使用airbnb搜索排名嵌入的实时个性化。第24届ACM SIGKDD知识发现国际会议论文集&amp;数据挖掘。<a class="ae it" href="https://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb" rel="noopener ugc nofollow" target="_blank">https://www . KDD . org/KDD 2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-Airbnb</a></p><p id="83f7" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">[3]<a class="ae it" rel="noopener" href="/the-graph/applying-deep-learning-to-related-pins-a6fee3c92f5e">https://medium . com/the-graph/applying-deep-learning-to-related-pins-a6 fee 3c 92 f 5e</a></p><p id="2a04" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">[4]t . miko lov，陈，k .，Corrado，g .，&amp; Dean，J. (2013)。向量空间中单词表示的有效估计。<a class="ae it" href="https://arxiv.org/pdf/1301.3781.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1301.3781.pdf</a></p><p id="d274" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated"><a class="ae it" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank">https://code.google.com/archive/p/word2vec/</a></p><p id="081a" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">[6]郭，黄，唐，叶，杨，李，何，谢(2017).一个基于因子分解机器的神经网络用于CTR预测。第26届国际人工智能联合会议论文集。(IJCAI-17)<a class="ae it" href="https://www.ijcai.org/proceedings/2017/0239.pdf" rel="noopener ugc nofollow" target="_blank">https://www.ijcai.org/proceedings/2017/0239.pdf</a></p><p id="6b69" class="pw-post-body-paragraph js jt hh ju b jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp ha bi translated">[7]Naumov，m .，Mudigere，d .，Shi，H. J. M. <em class="ly">等</em> (2019)。个性化和推荐系统的深度学习推荐模型。<a class="ae it" href="https://arxiv.org/pdf/1906.00091.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1906.00091.pdf</a></p></div></div>    
</body>
</html>