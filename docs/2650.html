<html>
<head>
<title>Hadoop Ecosystem — Get To Know The Hadoop Tools For Crunching Big Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hadoop生态系统—了解用于处理大数据的Hadoop工具</h1>
<blockquote>原文：<a href="https://medium.com/edureka/hadoop-ecosystem-2a5fb6740177?source=collection_archive---------1-----------------------#2016-10-28">https://medium.com/edureka/hadoop-ecosystem-2a5fb6740177?source=collection_archive---------1-----------------------#2016-10-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/dc716c8de46a35072048f756e7b4d329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ofQQBJw6UNiWaj_KtwRreg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Hadoop Ecosystem - Edureka</figcaption></figure><p id="15b1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在之前关于Hadoop教程的博客中，我们讨论了Hadoop、它的特性和核心组件。现在，下一步是了解Hadoop生态系统。在开始使用Hadoop之前，这是一个需要了解的基本主题。这篇Hadoop生态系统博客将让您熟悉全行业使用的大数据框架。</p><p id="feaf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Hadoop生态系统既不是编程语言，也不是服务，它是一个解决大数据问题的平台或框架。您可以将它视为一个套件，其中包含许多服务(摄取、存储、分析和维护)。让我们讨论一下，并简单了解一下服务是如何单独工作和协作的。</p><p id="6dfc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是Hadoop组件，它们共同构成了Hadoop生态系统，我将在本博客中逐一介绍:</p><ul class=""><li id="dd0c" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi">HDFS</strong>-&gt;T2【Hadoop分布式文件系统</li><li id="9514" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">纱</strong>-&gt;T6】又一个资源谈判者</li><li id="2aad" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">MapReduce</strong>-&gt;-<em class="jw">数据处理使用编程</em></li><li id="7259" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">火花</strong> - &gt;内存数据处理</li><li id="65ac" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi"> PIG，HIVE</strong>-&gt;-<em class="jw">数据处理服务使用查询(类SQL)</em></li><li id="5b32" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">h base</strong>-&gt;-<em class="jw">NoSQL数据库</em></li><li id="a2ec" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi"> Mahout，Spark ml lib</strong>-&gt;-T24】机器学习</li><li id="e771" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">Apache Drill</strong>-&gt;-<em class="jw">Hadoop上的SQL</em></li><li id="88eb" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">动物园管理员</strong>-&gt;-T32】管理集群</li><li id="f960" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">oo zie</strong>-&gt;-<em class="jw">作业调度</em></li><li id="f580" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi"> Flume，sq OOP</strong>-&gt;-<em class="jw">数据摄取服务</em></li><li id="ecb5" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">Solr&amp;Lucene</strong>-&gt;T44】搜索&amp;索引</li><li id="8703" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">Ambari</strong>-&gt;-<em class="jw">提供、监控和维护集群</em></li></ul><figure class="kd ke kf kg fd ii er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kc"><img src="../Images/dd9dfe0b306e93dec4bd3d99c470126e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tyAmTnvmvCG0xl9PmSLDg.png"/></div></div></figure><h1 id="9e5d" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">HDFS</h1><ul class=""><li id="bc92" class="jn jo hh ir b is lj iw lk ja ll je lm ji ln jm js jt ju jv bi translated"><strong class="ir hi"> <em class="jw"> Hadoop分布式文件系统</em> </strong>是核心组件或者你可以说，是Hadoop生态系统的主干。</li><li id="b47d" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">HDFS就是其中之一，它使得存储不同类型的大型数据集(即结构化、非结构化和半结构化数据)成为可能。</li><li id="4092" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">HDFS创造了一种对资源的抽象，从这里我们可以把整个HDFS看成一个整体。</li><li id="6c74" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它帮助我们在不同的节点上存储数据，并维护关于存储数据(元数据)的日志文件。</li><li id="dd24" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">HDFS有两个核心组件，即<strong class="ir hi"> NameNode和</strong>DataNode。</li></ul><ol class=""><li id="2e8d" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi"> NameNode </strong>是主节点，它不存储实际数据。它包含元数据，就像日志文件一样，或者可以说是内容表。因此，它需要较少的存储和较高的计算资源。</li><li id="11f2" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">另一方面，所有数据都存储在<strong class="ir hi">数据节点</strong>上，因此需要更多的存储资源。这些DataNodes是分布式环境中的商品硬件(如您的笔记本电脑和台式机)。这就是为什么Hadoop解决方案非常经济高效的原因。</li><li id="8d3a" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">在写入数据时，您总是与NameNode通信。然后，它在内部向客户机发送一个请求，请求在各种DataNodes上存储和复制数据。</li></ol><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/dc0f9a1408f7328f2a284d271f430f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*-EtAtA1XHmWdZwt15lGy6g.png"/></div></figure><h1 id="d5f2" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">故事</h1><p id="f399" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">将YARN视为您的Hadoop生态系统的大脑。它通过分配资源和调度任务来执行所有的处理活动。</p><ul class=""><li id="b22f" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">它有两个主要组件，即<strong class="ir hi">资源管理器和</strong>节点管理器。</li></ul><ol class=""><li id="a5cf" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi">资源管理器</strong>也是处理部门的一个主节点。</li><li id="3ad8" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">它接收处理请求，然后相应地将部分请求传递给相应的节点管理器，在那里进行实际的处理。</li><li id="bdae" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">每个DataNode上都安装了节点管理器。它负责在每个DataNode上执行任务。</li><li id="0026" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">调度程序:</strong>基于您的应用程序资源需求，调度程序执行调度算法并分配资源。</li><li id="6f54" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">application manager:</strong>当application manager接受作业提交时，与容器(即流程执行的数据节点环境)进行协商，以执行特定于应用的ApplicationMaster并监控进度。ApplicationMasters是驻留在DataNode上的代理，它与容器通信，以便在每个DataNode上执行任务。ResourceManager有两个组件，即<strong class="ir hi">调度器</strong>和<strong class="ir hi">应用管理器</strong>。</li></ol><h1 id="191c" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">MapReduce</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/d8adfbbf1f7e69965c6381fbcba35cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*S80SeZSNyLPWsSmrbnr04w.jpeg"/></div></figure><p id="fade" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它是Hadoop生态系统中处理的核心组件，因为它提供了处理逻辑。换句话说，<strong class="ir hi"> <em class="jw"> MapReduce </em> </strong>是一个软件框架，它帮助编写在Hadoop环境中使用分布式和并行算法处理大型数据集的应用程序。</p><ul class=""><li id="4d35" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">在一个MapReduce程序中，<strong class="ir hi"> Map()和Reduce() </strong>是两个函数。</li></ul><ol class=""><li id="93e2" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi">地图功能</strong>执行过滤、分组、排序等动作。</li><li id="023c" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">而<strong class="ir hi"> Reduce函数</strong>聚合和汇总map函数产生的结果。</li><li id="425a" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">Map函数生成的结果是一个键值对(K，V ),它充当Reduce函数的输入。</li></ol><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/063f85f35a6965512a70dbe909e2c263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*0vT-HruFW0TN5Jlv5YtVWg.png"/></div></figure><p id="2f5b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们举上面的例子来更好地理解MapReduce程序。</p><p id="d5c5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们有一个学生和他们各自系的样本案例。我们想计算每个系的学生人数。最初，Map程序将执行并计算出现在每个系中的学生，产生如上所述的键值对。这个键值对是Reduce函数的输入。Reduce函数将聚合每个系，计算每个系的学生总数，并产生给定的结果。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/7a11bc03cf51010175187a4ce40cf804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*55IS7TI0ry3mGaLqx6KGsw.png"/></div></figure><h1 id="f8c9" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇猪</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/965a2dfee1df3c1f0c91adb5f64ee350.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*cj09vpCgVKIABFq9tc8w_A.png"/></div></figure><ul class=""><li id="0b1a" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> <em class="jw">猪</em> </strong>有两部分:<strong class="ir hi">猪拉丁语</strong>，该语言与<strong class="ir hi">猪运行时不同，</strong>为执行环境。你可以更好的理解为Java和JVM。</li><li id="7d26" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">支持<em class="jw">猪拉丁</em>语言，有类似SQL的命令结构。</li></ul><p id="ef4c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因为每个人都不是来自编程背景。所以，阿帕奇猪缓解了他们。你可能很想知道是如何做到的？</p><p id="5ea4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好吧，我告诉你一个有趣的事实:</p><blockquote class="lw lx ly"><p id="87d0" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated"><strong class="ir hi"> 10行猪拉丁=约。200行Map-Reduce Java代码</strong></p></blockquote><p id="1539" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是当我说在Pig作业的后端执行一个map-reduce作业时，不要感到惊讶。</p><ul class=""><li id="e492" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">编译器在内部将pig latin转换为MapReduce。它产生一组连续的MapReduce作业，这是一个抽象(就像黑盒一样工作)。</li><li id="ac19" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">PIG最初是由雅虎开发的。</li><li id="1249" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它为您提供了一个为ETL(提取、转换和加载)构建数据流、处理和分析巨大数据集的平台。</li></ul><h2 id="e48f" class="mc km hh bd kn md me mf kr mg mh mi kv ja mj mk kz je ml mm ld ji mn mo lh mp bi translated"><strong class="ak">猪是怎么工作的？</strong></h2><p id="2750" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">在PIG中，首先，load命令加载数据。然后，我们对其执行各种功能，如分组、过滤、连接、排序等。最后，你要么把数据转储到屏幕上，要么把结果存储回HDFS。</p><h1 id="f064" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇蜂房</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/75b397d7053dbf0fe53f94be01135af3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*e-3qxQ4agjg7nNIc17tl3A.png"/></div></figure><ul class=""><li id="ae21" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">脸书为精通SQL的人创建了HIVE。因此，HIVE让他们在Hadoop生态系统中工作时有宾至如归的感觉。</li><li id="da99" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">基本上，HIVE是一个数据仓库组件，它使用类似SQL的接口在分布式环境中执行读取、写入和管理大型数据集。</li></ul><blockquote class="lw lx ly"><p id="9dbf" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated"><strong class="ir hi"> HIVE + SQL = HQL </strong></p></blockquote><ul class=""><li id="81f6" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">Hive的查询语言叫做Hive查询语言(HQL)，和SQL很像。</li><li id="83fe" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它有两个基本组件:<strong class="ir hi"> Hive命令行和JDBC/ODBC驱动</strong>。</li><li id="0276" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi"> Hive命令行</strong>接口用于执行HQL命令。</li><li id="d07a" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">而Java数据库连接(<strong class="ir hi"> JDBC </strong>)和对象数据库连接(<strong class="ir hi"> ODBC </strong>)用于建立来自数据存储的连接。</li><li id="5d59" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">其次，Hive的可扩展性很强。因为，它可以服务于两个目的，即大数据集处理(即批量查询处理)和实时处理(即交互式查询处理)。</li><li id="c5aa" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它支持SQL的所有原始数据类型。</li><li id="0105" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">您可以使用预定义的函数，或者编写定制的用户定义函数(UDF)来满足您的特定需求。</li></ul><h1 id="8e6d" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇看象人</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/88cabd85028e488cdf0fbe05b2811195.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*F8ckHQAeVFjAyhImKEGX8A.png"/></div></figure><p id="2162" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们谈谈因机器学习而闻名的Mahout。Mahout为创建可扩展的机器学习应用程序提供了一个环境。</p><p id="9702" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那么，<strong class="ir hi">什么是机器学习？</strong></p><p id="e500" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">机器学习算法允许我们建立自我学习的机器，无需显式编程即可自行进化。基于用户行为、数据模式和过去的经验，它做出重要的未来决策。你可以称之为人工智能(AI)的后代。</p><h2 id="f214" class="mc km hh bd kn md me mf kr mg mh mi kv ja mj mk kz je ml mm ld ji mn mo lh mp bi translated"><strong class="ak">看象人做什么？</strong></h2><p id="0270" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja lq jc jd je lr jg jh ji ls jk jl jm ha bi translated">它执行<strong class="ir hi">协作过滤、聚类和分类。</strong>也有人认为<strong class="ir hi">频繁项集缺失</strong>是看象人的功能。让我们分别理解它们:</p><ol class=""><li id="c9c5" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi">协同过滤:</strong> Mahout挖掘用户行为、他们的模式和他们的特征，并在此基础上预测和向用户提出建议。典型的用例是电子商务网站。</li><li id="63bd" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">聚类:</strong>它将一组相似的数据组织在一起，就像文章可以包含博客、新闻、研究论文等。</li><li id="22cf" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">分类</strong>:就是将数据分类归类到各个子部门，比如文章可以归类到博客、新闻、散文、研究论文等类别。</li><li id="e9e2" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">频繁项集丢失</strong>:这里Mahout检查哪些对象可能会一起出现，如果它们丢失了，就给出建议。比如手机和机盖一般都放在一起。所以，如果你搜索一部手机，它也会向你推荐它的外壳。</li></ol><p id="2e97" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Mahout提供了一个命令行来调用各种算法。它有一个预定义的库，其中已经包含了不同用例的不同内置算法。</p><h1 id="0d42" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇火花</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/1f7a323f6dbdd773eb9c157318bf8086.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Ec3AA_sWrs3KU6xeAyJD1g.png"/></div></figure><ul class=""><li id="fd9d" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> <em class="jw"> Apache Spark </em> </strong>是一个分布式计算环境下的实时数据分析框架。</li><li id="c892" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">Spark是用Scala编写的，最初是在加州大学伯克利分校开发的。</li><li id="8c39" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它执行内存中的计算，以提高Map-Reduce上的数据处理速度。</li><li id="315f" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">通过利用内存计算和其他优化，它在大规模数据处理方面比Hadoop快100倍。因此，它需要比Map-Reduce更高的处理能力。</li></ul><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/cc1388d36a01ac8d8c6a515c0a108f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*Qy8TXg3rRiK6IbuZOvUyVw.png"/></div></figure><p id="87ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如您所见，Spark附带了高级库，包括对R、SQL、Python、Scala、Java等的支持。这些标准库增加了复杂工作流程中的无缝集成。此外，它还允许各种服务与其集成，如MLlib、GraphX、SQL +数据帧、流服务等。来增强它的能力。</p><p id="5b50" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是每个人心中很常见的问题:</p><p id="01a9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"><em class="jw">“Apache Spark:黑仔还是Apache Hadoop的救星？”—奥雷利</em> </strong></p><p id="9cb5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个问题的答案是——这不是苹果之间的比较。Apache Spark最适合实时处理，而Hadoop旨在存储非结构化数据并在其上执行批处理。当我们将Apache Spark的能力(即高处理速度、高级分析和多重集成支持)与Hadoop在商用硬件上的低成本操作相结合时，它可以提供最佳结果。</p><p id="5ab5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就是为什么许多公司一起使用Spark和Hadoop来处理和分析他们存储在HDFS的大数据。</p><h1 id="cc34" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇HBASE</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/037bb478f27e0f64057baca9fc751ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*smhanCjzePRtPgcxZBgt0g.png"/></div></figure><ul class=""><li id="67c6" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> <em class="jw"> HBase </em> </strong>是一个开源的、非关系的分布式数据库。换句话说，这是一个NoSQL数据库。</li><li id="add9" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它支持所有类型的数据，这就是为什么它能够处理Hadoop生态系统中的任何事情。</li><li id="9581" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它模仿Google的BigTable，这是一个分布式存储系统，旨在处理大型数据集。</li><li id="3cbd" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">HBase被设计为运行在HDFS之上，并提供类似BigTable的功能。</li><li id="4c5a" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它为我们提供了一种存储稀疏数据的容错方式，这在大多数大数据用例中很常见。</li><li id="0173" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">HBase是用Java编写的，而HBase应用程序可以用REST、Avro和Thrift APIs编写。</li></ul><p id="2ed5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了更好地理解，让我们举个例子。您有数十亿封客户电子邮件，您需要找出在电子邮件中使用了“投诉”一词的客户数量。需要快速(即实时)处理该请求。因此，这里我们在检索少量数据的同时处理大量数据集。为了解决这类问题，设计了HBase。</p><h1 id="1a4b" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇演习</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/0d6494e5a38dcf8cfbe469e15daf5b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*7CaDWMxfzt2ZCKNbKkZAvQ.jpeg"/></div></figure><p id="07bf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">顾名思义，Apache Drill用于钻取任何类型的数据。这是一个开源应用程序，它与分布式环境一起工作来分析大型数据集。</p><ul class=""><li id="d151" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">它是谷歌Dremel的复制品。</li><li id="03a8" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它支持不同种类的NoSQL数据库和文件系统，这是Drill的一个强大特性。比如Azure Blob Storage，Google Cloud Storage，HBase，MongoDB，MapR-DB HDFS，MapR-FS，亚马逊S3，Swift，NAS，本地文件。</li></ul><p id="d6dc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，基本上，Apache Drill背后的主要目标是提供可伸缩性，以便我们可以高效地处理Pb和EB的数据(或者可以说在几分钟内)。</p><ul class=""><li id="cef3" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">Apache Drill的主要功能在于<strong class="ir hi"> <em class="jw">仅仅通过使用一个查询就可以组合多种数据存储。</em> </strong></li><li id="aa44" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">Apache Drill基本上遵循ANSI SQL。</li><li id="2aa1" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它在支持数百万用户和服务他们对大规模数据的查询请求方面具有强大的可伸缩性。</li></ul><h1 id="c48d" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇动物园管理员</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/a34cce4343a9d8b3b951fa17b7ba9bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*mu8cBSeU-XN13XcjgaAjng.png"/></div></figure><ul class=""><li id="6cb1" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">Apache Zookeeper是任何Hadoop工作的协调者，包括Hadoop生态系统中各种服务的组合。</li><li id="af7b" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">Apache Zookeeper在分布式环境中协调各种服务。</li></ul><p id="9b61" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在Zookeeper之前，在Hadoop生态系统中的不同服务之间进行协调是非常困难和耗时的。早期的服务在交互方面有很多问题，比如同步数据时的公共配置。即使配置了服务，服务配置的变化也会使其变得复杂和难以处理。分组和命名也是一个耗时的因素。</p><p id="0b42" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于上述问题，引入了Zookeeper。它通过执行<strong class="ir hi">同步、配置维护、分组和命名节省了大量时间。</strong></p><p id="aad3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">虽然这是一个简单的服务，但它可以用来构建强大的解决方案。</p><p id="063f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">像Rackspace，Yahoo，易贝这样的大公司在他们的许多用例中都使用这项服务，因此，你可以对Zookeeper的重要性有所了解。</p><h1 id="0ce6" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇OOZIE</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/8f36a22b78fbc6bd7602f673965a74ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*kivt0xxzbmjxcscixFaClA.png"/></div></figure><p id="e5a2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑将<strong class="ir hi"> <em class="jw"> Apache Oozie </em> </strong>作为Hadoop生态系统内部的时钟和闹钟服务。对于Apache作业，Oozie就像一个调度程序。它调度Hadoop作业，并将它们绑定在一起作为一个逻辑工作。</p><p id="0189" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有两种工作:</p><ol class=""><li id="aef9" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated">Oozie工作流(oo zie workflow):这是一系列要执行的动作<strong class="ir hi">。你可以假设它是一场接力赛。每个运动员等待最后一个人完成他的部分。</strong></li><li id="6745" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi"> Oozie协调器</strong>:这些是当数据对其可用时触发的Oozie作业。把这想象成我们身体中的反应-刺激系统。同样，当我们对外部刺激做出反应时，Oozie协调器会对数据的可用性做出反应，否则它就会停止工作。</li></ol><h1 id="3e32" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇水槽</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/c4601027279b6d576c1158cd848cd359.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*GofnhmDXwwDYsyNNeC1Ixw.png"/></div></figure><p id="0120" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接收数据是我们Hadoop生态系统的重要组成部分。</p><ul class=""><li id="ab22" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi"> <em class="jw"> Flume </em> </strong>是一项帮助将非结构化和半结构化数据吸收到HDFS中的服务。</li><li id="e645" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它为我们提供了一个可靠的分布式解决方案，帮助我们<strong class="ir hi">收集、聚合</strong>和<strong class="ir hi">移动大量数据集</strong>。</li><li id="59ec" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它帮助我们从网络流量、社交媒体、电子邮件、日志文件等各种来源获取在线流数据。在HDFS。</li></ul><p id="c125" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们从下图中了解Flume的架构:</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/bb693d290d1987510b86f8c599e4473d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*2LmcSlhfuTpcTOwkkLCW-w.png"/></div></figure><p id="5015" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有一个<strong class="ir hi"> Flume代理</strong>，它将来自不同数据源的流数据接收到HDFS。从图中可以很容易理解web服务器表示数据源。Twitter是流媒体数据的著名来源之一。</p><p id="1682" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">水槽代理有3个组件:<strong class="ir hi">源、汇和通道</strong>。</p><ol class=""><li id="1c62" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi">源</strong>:接受来自输入流线的数据，并将数据存储在通道中。</li><li id="3799" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi">通道:</strong>作为本地存储器或主存储器。通道是HDFS中数据源和持久数据之间的临时存储。</li><li id="da7f" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated"><strong class="ir hi"> Sink: </strong>然后，我们的最后一个组件(即Sink)从通道收集数据，并将数据永久提交或写入HDFS。</li></ol><h1 id="1c63" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">APACHE SQOOP</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/7b29c1be58e62e6da401c2cc43a66074.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*vbay6xswNJx-YyjC-8W4Dw.png"/></div></figure><p id="48ee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们谈谈另一种数据摄取服务，即<strong class="ir hi"><em class="jw">【Sqoop】</em></strong>。Flume和Sqoop的主要区别在于:</p><ul class=""><li id="c970" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">Flume只将非结构化数据或半结构化数据引入HDFS。</li><li id="cdff" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">而Sqoop可以将结构化数据从RDBMS或企业数据仓库导入和导出到HDFS，反之亦然。</li></ul><p id="491e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们使用下图来了解Sqoop的工作原理:</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/e7ac9a5671d337011b045dd9f7d7d5a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*xZBV351zUkZqMm1pwtGIIw.png"/></div></figure><p id="2e72" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们提交Sqoop命令时，我们的主任务被分成子任务，由单独的Map任务在内部处理。地图任务是子任务，它将部分数据导入Hadoop生态系统。总的来说，所有地图任务都会导入全部数据。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/2fef7068b9eddab5c9705b1b2335d41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*qXSTZb0SiyqQoFJyFVa6yw.png"/></div></figure><p id="c3b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">导出也以类似的方式工作。</p><p id="5308" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们提交作业时，它被映射到地图任务中，这些任务从HDFS带来大量数据。这些块被导出到结构化数据目标。结合所有这些导出的数据块，我们在目的地接收整个数据，在大多数情况下，目的地是RDBMS (MYSQL/Oracle/SQL Server)。</p><h1 id="8797" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇SOLR和LUCENE</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/0969ac0091ed2c7d6159c5fe1d532aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*mCoFvtJ4oNJ-cRqzoREQzg.png"/></div></figure><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/6d1036f1e7d672d713e15d7f2d1a44c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*UEVaZqCbc6JqfGCsPr314A.png"/></div></figure><p id="f505" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Apache Solr和Apache Lucene是Hadoop生态系统中用于搜索和索引的两个服务。</p><ul class=""><li id="4e92" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">Apache Lucene基于Java，这也有助于拼写检查。</li><li id="1893" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">如果说Apache Lucene是引擎，Apache Solr就是围绕它打造的汽车。Solr是一个围绕Lucene构建的完整应用。</li><li id="543d" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它使用Lucene Java搜索库作为搜索和全文索引的核心。</li></ul><h1 id="0c72" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">阿帕奇·安巴里</h1><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/3f4c325f507e00e33cd1b8f4e0efed71.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*phbUXsn0-sz68Uqu-iq-1Q.png"/></div></figure><p id="c56d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Ambari是一个Apache软件基金会项目，旨在使Hadoop生态系统更易于管理。</p><p id="f1bf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它包括用于<strong class="ir hi">供应、管理和监控</strong> Apache Hadoop集群的软件。</p><p id="1660" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Ambari提供:</p><ol class=""><li id="56d7" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated"><strong class="ir hi"> Hadoop集群配置</strong>:</li></ol><ul class=""><li id="f0e7" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">它为我们提供了在多个主机上安装Hadoop服务的一步一步的过程。</li><li id="5f58" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated">它还处理集群上Hadoop服务的配置。</li></ul><p id="2b34" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">2.<strong class="ir hi"> Hadoop集群管理:</strong></p><ul class=""><li id="29e2" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">它为启动、停止和重新配置集群中的Hadoop服务提供了一个中央管理服务。</li></ul><p id="1abb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">3.<strong class="ir hi"> Hadoop集群监控:</strong></p><ul class=""><li id="f341" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">为了监控健康和状态，Ambari为我们提供了一个仪表板。</li><li id="0a79" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm js jt ju jv bi translated"><strong class="ir hi">安珀警报框架</strong>是一种警报服务，它在需要注意时通知用户。例如，如果一个节点关闭或节点上的磁盘空间不足，等等。</li></ul><p id="147b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="jw">最后，我想提请大家注意三件重要的事情:</em> </strong></p><ol class=""><li id="2315" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lo jt ju jv bi translated">Hadoop生态系统的成功归功于整个开发者社区，许多大公司，如脸书、谷歌、雅虎、加州大学伯克利分校等。为增强Hadoop的功能贡献了自己的力量。</li><li id="fcf9" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">在Hadoop生态系统中，关于一两个工具(Hadoop组件)的知识不会有助于构建解决方案。你需要学习一套Hadoop组件，它们协同工作来构建一个解决方案。</li><li id="8454" class="jn jo hh ir b is jx iw jy ja jz je ka ji kb jm lo jt ju jv bi translated">根据使用案例，我们可以从Hadoop生态系统中选择一组服务，并为组织创建量身定制的解决方案。</li></ol><p id="2a4a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我希望这篇博客能给你带来信息和附加值。</p><p id="d59f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、Python、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="37b6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中解释大数据其他各方面的其他文章。</p><blockquote class="lw lx ly"><p id="65ef" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">1.<a class="ae mu" rel="noopener" href="/edureka/hadoop-tutorial-24c48fbf62f6"> Hadoop教程</a></p><p id="88f8" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">2.<a class="ae mu" rel="noopener" href="/edureka/hive-tutorial-b980dfaae765">蜂巢教程</a></p><p id="37c6" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">3.<a class="ae mu" rel="noopener" href="/edureka/pig-tutorial-2baab2f0a5b0">养猪教程</a></p><p id="7ac3" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">4.<a class="ae mu" rel="noopener" href="/edureka/mapreduce-tutorial-3d9535ddbe7c">地图缩小教程</a></p><p id="079e" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">5.<a class="ae mu" rel="noopener" href="/edureka/hbase-tutorial-bdc36ab32dc0"> HBase教程</a></p><p id="4245" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">6.<a class="ae mu" rel="noopener" href="/edureka/hdfs-tutorial-f8c4af1c8fde"> HDFS教程</a></p><p id="f0d1" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">7.<a class="ae mu" rel="noopener" href="/edureka/hadoop-3-35e7fec607a"> Hadoop 3 </a></p><p id="87ee" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">8.<a class="ae mu" rel="noopener" href="/edureka/apache-sqoop-tutorial-431ed0af69ee"> Sqoop教程</a></p><p id="467e" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">9.<a class="ae mu" rel="noopener" href="/edureka/apache-flume-tutorial-6f7150210c76">水槽教程</a></p><p id="6cab" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">10.<a class="ae mu" rel="noopener" href="/edureka/apache-oozie-tutorial-d8f7bbbe1591"> Oozie教程</a></p><p id="8e02" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">11.<a class="ae mu" rel="noopener" href="/edureka/big-data-tutorial-b664da0bb0c8">大数据教程</a></p><p id="b9f6" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">12.<a class="ae mu" rel="noopener" href="/edureka/hive-commands-b70045a5693a">HQL顶级配置单元命令及示例</a></p><p id="0873" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">13.<a class="ae mu" rel="noopener" href="/edureka/create-hadoop-cluster-with-amazon-emr-f4ce8de30fd"> Hadoop集群搭配亚马逊EMR？</a></p><p id="dd4e" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">14.<a class="ae mu" rel="noopener" href="/edureka/big-data-engineer-resume-7bc165fc8d9d">大数据工程师简历</a></p><p id="a5ec" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">15.<a class="ae mu" rel="noopener" href="/edureka/hadoop-developer-cc3afc54962c"> Hadoop开发人员-工作趋势和薪水</a></p><p id="6274" class="ip iq jw ir b is it iu iv iw ix iy iz lz jb jc jd ma jf jg jh mb jj jk jl jm ha bi translated">16.<a class="ae mu" rel="noopener" href="/edureka/hadoop-interview-questions-55b8e547dd5c"> Hadoop面试问题</a></p></blockquote></div><div class="ab cl mv mw go mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="ha hb hc hd he"><p id="d64e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jw">原载于2016年10月28日www.edureka.co</em><a class="ae mu" href="https://www.edureka.co/blog/hadoop-ecosystem" rel="noopener ugc nofollow" target="_blank"><em class="jw"/></a><em class="jw">。</em></p></div></div>    
</body>
</html>