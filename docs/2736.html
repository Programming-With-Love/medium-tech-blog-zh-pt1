<html>
<head>
<title>What Is Backpropagation? — A Step-By-Step Guide To Backpropagation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是反向传播？—反向传播的逐步指南</h1>
<blockquote>原文：<a href="https://medium.com/edureka/backpropagation-bd2cf8fdde81?source=collection_archive---------0-----------------------#2017-12-07">https://medium.com/edureka/backpropagation-bd2cf8fdde81?source=collection_archive---------0-----------------------#2017-12-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/ac02cf3f71c63211e96c9fe215b2e66f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Pj-TiAuyTGgno_5bHvM8Rw.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">What is Backpropagation? — Edureka</figcaption></figure><p id="5ad1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">反向传播是一种监督学习算法，用于训练多层感知器(人工神经网络)。</p><p id="9d3f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，你们中的一些人可能想知道为什么我们需要训练一个神经网络，或者训练的确切含义是什么。</p><h1 id="f5b7" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">为什么我们需要反向传播？</h1><p id="ffa1" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">在设计神经网络时，一开始，我们用一些随机值或任何变量初始化权重。</p><p id="9fb1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">很明显，我们不是超人。因此，我们选择的任何权重值都不必是正确的，也不必是最符合我们模型的。</p><p id="e46f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好吧，我们在开始时选择了一些权重值，但我们的模型输出与实际输出相差甚远，即误差值非常大。</p><p id="3ef7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，你将如何减少误差？</p><p id="c66d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">基本上，我们需要做的是，我们需要以某种方式解释模型来改变参数(权重)，这样误差变得最小。</p><p id="e8ea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">换句话说，我们需要训练我们的模型。</p><p id="b085" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">训练我们模型的一种方法叫做反向传播。考虑下图:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es kr"><img src="../Images/097c78d43cc0eb9a9cf8a63ba72310d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*TcIzUw5icGLNVnL_eqn_-Q.png"/></div></figure><p id="e781" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我为您总结一下步骤:</p><ul class=""><li id="11a7" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated"><strong class="ir hi">计算误差</strong> —你的模型输出与实际输出有多远。</li><li id="7b00" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><strong class="ir hi">误差最小</strong> —检查误差是否最小化。</li><li id="087a" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><strong class="ir hi">更新参数</strong> —如果误差很大，则更新参数(权重和偏差)。之后，再次检查错误。重复该过程，直到误差最小。</li><li id="72fc" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><strong class="ir hi">模型准备好进行预测</strong> —一旦误差变得最小，您可以向您的模型输入一些输入，它将产生输出。</li></ul><p id="ae4d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我很确定，现在你知道了，为什么我们需要反向传播，或者为什么，训练一个模型的意义是什么。</p><p id="3c1f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在是理解什么是反向传播的正确时机。</p><h1 id="06da" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是反向传播？</h1><p id="c8b7" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">反向传播算法使用称为delta规则或梯度下降的技术在权重空间中寻找误差函数的最小值。最小化误差函数的权重然后被认为是学习问题的解决方案。</p><p id="dbc0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们通过一个例子来理解它是如何工作的:</p><p id="ff56" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你有一个数据集，其中有标签。</p><p id="d1c8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑下表:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/d81f3e44db8f270751f743c3070c4c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WiMKc2aDP3VuwsBVAqZiAg.png"/></div></div></figure><p id="34db" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你的模型的输出当' W '值是3:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/c6d37af4b010cb8c6211b0d89473fc2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3BlTP2WD6Y80xk5BWWm2w.png"/></div></div></figure><p id="0edb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">注意实际输出和期望输出之间的差异:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lq"><img src="../Images/e6bebbb9a73ac0a6cb8210d29b12d9fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f40eRpFuAXZZn47Bwfm3VQ.png"/></div></div></figure><p id="15bb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们改变“W”的值。请注意“W”=“4”时的错误</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lr"><img src="../Images/9c28e7c0dba85f214125406b3c78d0e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pt7aCG1dXOKZ7GBk3nppMw.png"/></div></div></figure><p id="2240" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你注意到了，当我们增加W的值时，误差也增加了。因此，显然没有必要进一步增加“W”的值。但是，如果我减小W的值，会发生什么呢？考虑下表:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lr"><img src="../Images/4506ade5eb3ce2a67688d8fffef378f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WFgkOP9OKfaoo2eEandkWw.png"/></div></div></figure><p id="31d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们在这里做的是:</p><ul class=""><li id="ecf4" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">我们首先将一些随机值初始化为“W ”,然后向前传播。</li><li id="15bd" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">然后，我们注意到有一些错误。为了减少这种误差，我们向后传播并增加“W”的值。</li><li id="ee88" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">之后，我们也注意到误差增加了。我们开始知道，我们不能增加“W”值。</li><li id="ad70" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">因此，我们再次向后传播，我们降低了“W”值。</li><li id="d244" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">现在，我们注意到误差减小了。</li></ul><p id="9db7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们试图得到重量值，使误差最小。基本上，我们需要弄清楚是否需要增加或减少权重值。一旦我们知道了，我们继续在那个方向更新权重值，直到误差变得最小。您可能会达到一个点，如果您进一步更新权重，误差将会增加。这时你需要停下来，那就是你的最终重量值。</p><p id="d2ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑下图:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ls"><img src="../Images/95222ea7c229861d873876c5460746ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOFaMrJ0l2dwJ3tvXeCG8Q.png"/></div></div></figure><p id="dcfe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们需要达到“全球损失最小化”。</p><p id="22a3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这只不过是反向传播。</p><p id="fdf7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们理解反向传播背后的数学原理。</p><h1 id="faa5" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">反向传播是如何工作的？</h1><p id="cdd8" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">考虑下面的神经网络:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lt"><img src="../Images/bf6b9d11ba634447fb6025aa54fb2424.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*caT8f9FfjEu-GULseO3zcQ.png"/></div></div></figure><p id="486a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上述网络包含以下内容:</p><ul class=""><li id="8517" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">两个输入</li><li id="f4d0" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">两个隐藏的神经元</li><li id="e866" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">两个输出神经元</li><li id="de95" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">两种偏见</li></ul><p id="1abc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是反向传播涉及的步骤:</p><ul class=""><li id="cc02" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">步骤1:正向传播</li><li id="8f0e" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">步骤2:反向传播</li><li id="3108" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">步骤3:将所有值放在一起，并计算更新后的重量值</li></ul><h2 id="6d18" class="lu jo hh bd jp lv lw lx jt ly lz ma jx ja mb mc kb je md me kf ji mf mg kj mh bi translated">步骤1:正向传播</h2><p id="89fd" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我们将从向前传播开始。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mi"><img src="../Images/ac7b0003b8cc7b45adf5f61d439197ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dnK9XXLPUjPjFysmZOEr3g.png"/></div></div></figure><p id="49b6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将使用隐藏层神经元的输出作为输入，对输出层神经元重复这一过程。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mj"><img src="../Images/cdae4dd2fdcc93bdddbdd3890d12c065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXEmrEdEWP_t73bWdtROtg.png"/></div></div></figure><p id="60bf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们看看错误的值是什么:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mk"><img src="../Images/83af35bfd9fd7769151a81d8cef99494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4onFLd952rn5gqBfBtXnow.png"/></div></div></figure><h2 id="af84" class="lu jo hh bd jp lv lw lx jt ly lz ma jx ja mb mc kb je md me kf ji mf mg kj mh bi translated">步骤2:反向传播</h2><p id="b9fa" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">现在，我们将向后传播。这样，我们将尝试通过改变权重和偏差的值来减少误差。</p><p id="1611" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">考虑W5，我们将计算误差随重量W5变化的变化率。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ml"><img src="../Images/aaac9cec8058ddaf1add8adc8e98869d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xT7_e9VNSMWYa6p9jv6knA.png"/></div></div></figure><p id="f197" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于我们是反向传播，我们需要做的第一件事是，计算总误差相对于输出O1和O2的变化。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mm"><img src="../Images/99f8b9f1a3c9e24a0b0b706739bf71f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k17vOxK2IWnnbhrsH4aKPA.png"/></div></div></figure><p id="c631" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们将进一步向后传播，并计算输出O1 w.r.t相对于其总净输入的变化。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mn"><img src="../Images/bf68e18c82dde5ae04ba7cb66670d857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeDn-LpUEBEnYFxjyp4UMw.png"/></div></div></figure><p id="fd05" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们看看O1的总净输入对W5的影响有多大？</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mo"><img src="../Images/7caddc604e0eb217d3d93fd052014f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSBDTmNEoUSEufDG_v9-Ag.png"/></div></div></figure><h2 id="c6c0" class="lu jo hh bd jp lv lw lx jt ly lz ma jx ja mb mc kb je md me kf ji mf mg kj mh bi translated">步骤3:将所有值放在一起，并计算更新后的重量值</h2><p id="5d81" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">现在，让我们把所有的值放在一起:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mp"><img src="../Images/66055082c9eab100a055faf3f57de05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t2obVeU8f9jLvRi0qmeVZg.png"/></div></div></figure><p id="dcb5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们来计算W5的更新价值:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mq"><img src="../Images/a7969956ece3ba9091e2b1ff28fb5230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68RtxoemYy9E0udeGjiaPQ.png"/></div></div></figure><ul class=""><li id="b3d4" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">同样，我们也可以计算其他重量值。</li><li id="d95f" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">之后，我们将再次向前传播并计算输出。同样，我们将计算误差。</li><li id="974b" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">如果误差最小，我们将在那里停止，否则我们将再次向后传播并更新权重值。</li><li id="e82d" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">这个过程将不断重复，直到误差变得最小。</li></ul><h1 id="2d5e" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论:</h1><p id="625b" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">好吧，如果我不得不总结反向传播，最好的选择是写同样的伪代码。</p><h2 id="f0f7" class="lu jo hh bd jp lv lw lx jt ly lz ma jx ja mb mc kb je md me kf ji mf mg kj mh bi translated">反向传播算法；</h2><pre class="ks kt ku kv fd mr ms mt mu aw mv bi"><span id="8694" class="lu jo hh ms b fi mw mx l my mz">initialize network weights (often small random values)</span><span id="add6" class="lu jo hh ms b fi na mx l my mz">do</span><span id="caae" class="lu jo hh ms b fi na mx l my mz">forEach training example named ex</span><span id="a369" class="lu jo hh ms b fi na mx l my mz">prediction = neural-net-output(network, ex)  // forward pass</span><span id="d784" class="lu jo hh ms b fi na mx l my mz">actual = teacher-output(ex)</span><span id="61d5" class="lu jo hh ms b fi na mx l my mz">compute error (prediction - actual) at the output units</span><span id="7361" class="lu jo hh ms b fi na mx l my mz">compute {\displaystyle \Delta w_{h}} for all weights from hidden layer to output layer  // backward pass</span><span id="19df" class="lu jo hh ms b fi na mx l my mz">compute {\displaystyle \Delta w_{i}} for all weights from input layer to hidden layer   // backward pass continued</span><span id="1154" class="lu jo hh ms b fi na mx l my mz">update network weights // input layer not modified by error estimate</span><span id="6e52" class="lu jo hh ms b fi na mx l my mz">until all examples classified correctly or another stopping criterion satisfied</span><span id="775b" class="lu jo hh ms b fi na mx l my mz">return the network</span></pre><p id="d8ad" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就把我们带到了“反向传播”这篇文章的结尾。我希望这篇文章对你有所帮助，并增加了你的知识价值。</p><p id="6864" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="85d2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释深度学习的各个其他方面。</p><blockquote class="nc nd ne"><p id="1554" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">1.<a class="ae nb" rel="noopener" href="/edureka/tensorflow-tutorial-ba142ae96bca"> TensorFlow教程</a></p><p id="57ac" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">2.<a class="ae nb" rel="noopener" href="/edureka/pytorch-tutorial-9971d66f6893"> PyTorch教程</a></p><p id="a4e8" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">3.<a class="ae nb" rel="noopener" href="/edureka/perceptron-learning-algorithm-d30e8b99b156">感知器学习算法</a></p><p id="0344" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">4.<a class="ae nb" rel="noopener" href="/edureka/neural-network-tutorial-2a46b22394c9">神经网络教程</a></p><p id="9dd3" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">5.<a class="ae nb" rel="noopener" href="/edureka/backpropagation-bd2cf8fdde81"/><a class="ae nb" rel="noopener" href="/edureka/tensorflow-object-detection-tutorial-8d6942e73adc">tensor flow中的物体检测</a></p><p id="b3f7" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">6.<a class="ae nb" rel="noopener" href="/edureka/convolutional-neural-network-3f2c5b9c4778">卷积神经网络</a></p><p id="d368" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">7.<a class="ae nb" rel="noopener" href="/edureka/capsule-networks-d7acd437c9e">胶囊神经网络</a></p><p id="d529" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">8.<a class="ae nb" rel="noopener" href="/edureka/recurrent-neural-networks-df945afd7441">递归神经网络</a></p><p id="a1f9" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">9.<a class="ae nb" rel="noopener" href="/edureka/autoencoders-tutorial-cfdcebdefe37">自动编码器教程</a></p><p id="f1a6" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">10.<a class="ae nb" rel="noopener" href="/edureka/restricted-boltzmann-machine-tutorial-991ae688c154">受限玻尔兹曼机教程</a></p><p id="603d" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">11.<a class="ae nb" rel="noopener" href="/edureka/pytorch-vs-tensorflow-252fc6675dd7"> PyTorch vs TensorFlow </a></p><p id="a499" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">12.<a class="ae nb" rel="noopener" href="/edureka/deep-learning-with-python-2adbf6e9437d">用Python进行深度学习</a></p><p id="5e4f" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">13.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-tutorial-4257c66f5bb1">人工智能教程</a></p><p id="9525" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">14.<a class="ae nb" rel="noopener" href="/edureka/tensorflow-image-classification-19b63b7bfd95">张量流图像分类</a></p><p id="8530" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">15.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-applications-7b93b91150e3">人工智能应用</a></p><p id="97a6" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">16.<a class="ae nb" rel="noopener" href="/edureka/become-artificial-intelligence-engineer-5ac2ede99907">如何成为一名人工智能工程师？</a></p><p id="a793" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">17.<a class="ae nb" rel="noopener" href="/edureka/q-learning-592524c3ecfc">问学习</a></p><p id="ed8a" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">18.<a class="ae nb" rel="noopener" href="/edureka/apriori-algorithm-d7cc648d4f1e"> Apriori算法</a></p><p id="c887" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">19.<a class="ae nb" rel="noopener" href="/edureka/introduction-to-markov-chains-c6cb4bcd5723">马尔可夫链与Python </a></p><p id="285c" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">20.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-algorithms-fad283a0d8e2">人工智能算法</a></p><p id="1112" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">21.<a class="ae nb" rel="noopener" href="/edureka/best-laptop-for-machine-learning-a4a5f8ba5b">机器学习的最佳笔记本电脑</a></p><p id="3d62" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">22.<a class="ae nb" rel="noopener" href="/edureka/top-artificial-intelligence-tools-36418e47bf2a">12大人工智能工具</a></p><p id="95a9" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">23.<a class="ae nb" rel="noopener" href="/edureka/artificial-intelligence-interview-questions-872d85387b19">人工智能面试问题</a></p><p id="183a" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">24.<a class="ae nb" rel="noopener" href="/edureka/theano-vs-tensorflow-15f30216b3bc"> Theano vs TensorFlow </a></p><p id="28b7" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">25.<a class="ae nb" rel="noopener" href="/edureka/what-is-a-neural-network-56ae7338b92d">什么是神经网络？</a></p><p id="3740" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">26.<a class="ae nb" rel="noopener" href="/edureka/pattern-recognition-5e2d30ab68b9">模式识别</a></p><p id="8f17" class="ip iq kq ir b is it iu iv iw ix iy iz nf jb jc jd ng jf jg jh nh jj jk jl jm ha bi translated">27.<a class="ae nb" rel="noopener" href="/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a">人工智能中的阿尔法贝塔剪枝</a></p></blockquote></div><div class="ab cl ni nj go nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ha hb hc hd he"><p id="7962" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="kq">原载于2017年12月7日</em><a class="ae nb" href="https://www.edureka.co/blog/backpropagation/" rel="noopener ugc nofollow" target="_blank"><em class="kq">www.edureka.co</em></a><em class="kq">。</em></p></div></div>    
</body>
</html>