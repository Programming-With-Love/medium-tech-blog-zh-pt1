<html>
<head>
<title>Restricted Boltzmann Machine Tutorial — A Beginner’s Guide To RBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">受限玻尔兹曼机器教程——RBM初学者指南</h1>
<blockquote>原文：<a href="https://medium.com/edureka/restricted-boltzmann-machine-tutorial-991ae688c154?source=collection_archive---------1-----------------------#2018-11-20">https://medium.com/edureka/restricted-boltzmann-machine-tutorial-991ae688c154?source=collection_archive---------1-----------------------#2018-11-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/18ada01c87f8c7ab1c4a29fbc39dac57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*iCBEikIKEHOrjA3wHqboNg.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Restricted Boltzmann Machine Tutorial — Edureka</figcaption></figure><p id="64d1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在机器学习和深度学习的时代，<strong class="ir hi">受限玻尔兹曼机</strong>算法在降维、分类、回归等许多用于特征选择和特征提取的方面发挥着重要作用。本<strong class="ir hi">受限玻尔兹曼机器教程</strong>将按以下顺序为您提供对RBMs的全面了解:</p><ul class=""><li id="efb3" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">什么是受限玻尔兹曼机？</li><li id="36d9" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">自动编码器和RBM的区别</li><li id="bcca" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">受限玻尔兹曼机中的层</li><li id="e279" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">受限玻尔兹曼机的工作</li><li id="7473" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">受限玻尔兹曼机的训练</li><li id="41b5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">协同过滤</li></ul><p id="3089" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们从最基本的问题开始我们的文章，</p><h1 id="796f" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">什么是受限玻尔兹曼机？</strong></h1><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/1b1680ca3162287f0e7319491cc3988a.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*BAjkR9Qz3wJzMBzTbhXvOw.png"/></div></figure><p id="5a3e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">受限玻尔兹曼机器是一种无向图形模型，在最近的深度学习框架中起着主要作用。它最初由Paul Smolensky于1986年<em class="le">以<strong class="ir hi"> <em class="le"> Harmonium </em> </strong>的名称推出，近年来在Netflix奖<strong class="ir hi"><em class="le"/></strong>的背景下大受欢迎，其中受限玻尔兹曼机器在协作过滤方面实现了最先进的性能，并击败了大多数竞争对手。</em></p><p id="d6fa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是一种对降维、分类、回归、协作过滤、特征学习和主题建模有用的算法。</p><p id="6ee9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们看看受限玻尔兹曼机与其他自动编码器有何不同。</p><h1 id="3543" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">自动编码器和RBM的区别</h1><p id="ea51" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated"><strong class="ir hi">自动编码器</strong>是一个简单的三层神经网络，其中输出单元直接连接回输入单元<em class="le">。</em>通常，隐藏单元的数量远远少于可见单元的数量。训练的任务是最小化误差或重构，即找到输入数据的最有效的紧凑表示。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/021c9ad32b47f88a9a11ded909d3147f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*KvRZv5g8r7Gq3n6QCW4fjA.png"/></div></figure><p id="1436" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">RBM 也有类似的想法，但是它使用具有特定分布的随机单元，而不是确定性分布。训练的任务是找出这两组变量实际上是如何相互联系的。</p><p id="e7d3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">RBM区别于其他自动编码器的一个方面是它有两个偏好。</p><ul class=""><li id="4e7a" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">隐藏的偏置帮助RBM在<strong class="ir hi">正向传递</strong>时产生激活，而</li><li id="ae17" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">可见层的偏差帮助RBM学习在<strong class="ir hi">反向通道</strong>上的重建。</li></ul><p id="7078" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们知道了什么是受限玻尔兹曼机，RBM和自动编码器之间有什么区别，让我们继续我们的文章，看看他们的架构和工作。</p><h1 id="e733" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">受限玻尔兹曼机中的层</h1><p id="e708" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">受限玻尔兹曼机器是浅层的、两层的神经网络，构成了<strong class="ir hi"> <em class="le">深层信仰</em> </strong> <em class="le"> </em> <strong class="ir hi"> <em class="le">网络</em> </strong>的积木。RBM的第一层叫做<strong class="ir hi">可见</strong>或输入层，第二层叫做<strong class="ir hi">隐藏</strong>层。每个圆圈代表一个类似神经元的单元，称为节点<em class="le">。</em>节点跨层相互连接，但同一层没有两个节点链接。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/fabd2b416adfa3f0255a1860387f3b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*zs2y0Dy1jTuSWpTrGYdcXQ.png"/></div></figure><p id="d669" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">受限玻尔兹曼机中的<strong class="ir hi">限制</strong>是<strong class="ir hi">没有层内通信</strong>。每个节点都是处理输入的计算点，并从随机决定是否传输输入开始。</p><h1 id="1c9e" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">受限玻尔兹曼机的工作</h1><p id="10a0" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">每个可见节点从要学习的数据集中的一个项目中提取一个低级特征。在隐藏层的节点1处，<strong class="ir hi"> x乘以</strong>一个<strong class="ir hi"> <em class="le">权重</em> </strong>并加上一个<strong class="ir hi"> <em class="le">偏差</em> </strong>。这两个操作的结果被送入一个<strong class="ir hi"> <em class="le">激活函数</em> </strong>，该函数产生节点的输出，或者在给定输入x的情况下通过它的信号强度。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/781f6ffe94cd51b6067c1c85dced02e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*6kPHr7h0ljSreYs9nJXISQ.png"/></div></figure><p id="b6ca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，让我们看看几个输入如何在一个隐藏节点上组合。每个<strong class="ir hi"> x乘以</strong>一个单独的权重，乘积相加，加到偏差上，结果再次通过激活函数产生节点的输出。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/219d5c9f41bb67a7e56b99c40b85f594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*rEo_P1woswnkYE4rne3UZQ.png"/></div></figure><p id="d41c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在每个隐藏节点，每个输入<strong class="ir hi"> x乘以</strong>其各自的权重w。也就是说，单个输入x在这里将有三个权重，总共12个权重(4个输入节点x 3个隐藏节点)。两层之间的权重将始终形成一个矩阵，其中行等于输入节点，列等于输出节点。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/376d8e7979a1c3e16a4154db2733d022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*ITv4SipHNWu_Z-Ba2L-F7A.png"/></div></figure><p id="f8d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">每个隐藏节点接收乘以各自权重的四个输入。<strong class="ir hi">这些乘积的总和</strong>再次<strong class="ir hi">加到偏置</strong>(这至少迫使一些激活发生)，并且结果通过激活算法，为每个隐藏节点产生一个输出。</p><p id="8427" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你对受限玻尔兹曼机是如何工作的有了一个概念，让我们继续受限玻尔兹曼机教程，看看RBM训练中涉及的步骤。</p><h1 id="6d8b" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">受限玻尔兹曼机的训练</h1><p id="1cde" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">受限玻尔兹曼机器的训练不同于通过随机梯度下降的常规<strong class="ir hi">神经网络</strong>的训练。</p><p id="b60c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">两个主要的训练步骤是:</p><h2 id="76ff" class="lm kc hh bd kd ln lo lp kh lq lr ls kl ja lt lu kp je lv lw kt ji lx ly kx lz bi translated"><strong class="ak">吉布斯采样</strong></h2><p id="71d6" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">训练的第一部分叫做<em class="le">吉布斯采样</em>。给定输入向量<strong class="ir hi"> v </strong>，我们使用<strong class="ir hi"> p(h|v) </strong>来预测隐藏值<strong class="ir hi"> h. </strong>知道隐藏值后，我们使用<strong class="ir hi"> p(v|h) </strong>:</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/010100ffe31a1d686ce236e3476a37df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*6h_WJ83UMy464HlG2SkPcQ.png"/></div></figure><p id="26d2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">用于预测新的输入值<strong class="ir hi"> v </strong>。这个过程重复<em class="le"> k </em>次。在<em class="le"> k </em>次迭代之后，我们获得另一个输入向量<strong class="ir hi"> v_k </strong>，它是从原始输入值<strong class="ir hi"> v_0 </strong>重新创建的。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/ffe75cb230c0808e169dffe109765443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*I2VS3VxKymFkn_vcXeseHw.png"/></div></figure><h2 id="f5b1" class="lm kc hh bd kd ln lo lp kh lq lr ls kl ja lt lu kp je lv lw kt ji lx ly kx lz bi translated"><strong class="ak">对比发散步</strong></h2><p id="074f" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">权重矩阵的更新发生在<em class="le">对比发散</em>步骤期间。向量<strong class="ir hi"> v_0 </strong>和<strong class="ir hi"> v_k </strong>用于计算隐藏值<strong class="ir hi"> h_0 </strong>和<strong class="ir hi"> h_k : </strong>的激活概率</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/010100ffe31a1d686ce236e3476a37df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*6h_WJ83UMy464HlG2SkPcQ.png"/></div></figure><p id="3f84" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些概率与输入向量<strong class="ir hi"> v_0 </strong>和<strong class="ir hi"> v_k </strong>的外积之间的差导致更新的矩阵:</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/d1da478aae6b2a27274e0edff769f76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*57TGOa5moPFAqjOHG19KXg.png"/></div></figure><p id="c5bc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用更新矩阵，可以用梯度<strong class="ir hi">上升、</strong>计算新的权重，由下式给出:</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/9091808b8d1a14d30f8be608d50b33c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*y5It_HuDYLViTMFiewikkg.png"/></div></figure><p id="3b3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你对什么是受限玻尔兹曼机和RBM层有了一个概念，让我们继续我们的受限玻尔兹曼机教程，并借助一个例子来理解它们的工作。</p><h1 id="6f35" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">协同过滤</h1><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/6b48898ec63f058bf0fdc818a2a9ccb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*h5bWcfGFCYxZG2YieV2C0A.png"/></div></figure><p id="9c90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">RBM已经在降维、分类、协同过滤等方面得到应用。根据任务的不同，他们可以在有人监督或无人监督的情况下接受训练。</p><h2 id="1879" class="lm kc hh bd kd ln lo lp kh lq lr ls kl ja lt lu kp je lv lw kt ji lx ly kx lz bi translated">识别数据中的潜在因素</h2><p id="a299" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">让我们假设一些人被要求对一组电影进行1-5的评分，每部电影都可以用一组潜在因素来解释，如戏剧、幻想、动作等等。限制玻尔兹曼机器被用来分析和找出这些潜在的因素。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/40da4d086429369413e10ec4e397661a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*mK2OzeXReUbiDlbhaOckEQ.png"/></div></figure><p id="eea7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">隐藏因素的分析以二进制方式执行，即，用户仅告知他们是否喜欢(评级1)特定电影(评级0)，并且它表示输入/可见层的输入。给定输入，RMB然后试图在数据中发现可以解释电影选择的潜在因素，每个隐藏的神经元代表一个潜在因素。</p><p id="b1ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们考虑下面的例子，其中用户喜欢<em class="le">指环王</em>和<em class="le">哈利波特</em>但是不喜欢<em class="le">黑客帝国</em>、<em class="le">搏击俱乐部</em>和<em class="le">泰坦尼克号</em>。《霍比特人》还没有被看过，所以它的评级是-1。给定这些输入，玻尔兹曼机器可以识别三个隐藏因素<em class="le">戏剧</em>、<em class="le">奇幻</em>和<em class="le">科幻</em>，它们对应于电影类型。</p><h2 id="92d8" class="lm kc hh bd kd ln lo lp kh lq lr ls kl ja lt lu kp je lv lw kt ji lx ly kx lz bi translated">利用潜在因素进行预测</h2><p id="e0c3" class="pw-post-body-paragraph ip iq hh ir b is lf iu iv iw lg iy iz ja lh jc jd je li jg jh ji lj jk jl jm ha bi translated">在训练阶段之后，目标是预测尚未看过的电影的二进制评级。给定特定用户的训练数据，网络能够基于用户的偏好识别潜在因素，并且来自伯努利分布的样本可以用于找出哪些可见神经元现在变得活跃。</p><figure class="la lb lc ld fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/34d27092f366171a41fdadd894fb4ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*LHhF2yPl5op4cppucageRg.png"/></div></figure><p id="98f3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该图像显示了使用隐藏神经元值进行推断后的新评级。该网络将《T0》奇幻片《T1》确定为首选电影类型，并将《霍比特人T2》评为用户喜欢的电影。</p><p id="5ac0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从<strong class="ir hi">训练</strong>到<strong class="ir hi">预测</strong>阶段的过程如下:</p><ul class=""><li id="1d42" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">根据所有用户的数据训练网络</li><li id="efe5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">在推理期间，获取特定用户的训练数据</li><li id="eb9d" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">使用这些数据来获得隐藏神经元的激活</li><li id="2941" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">使用隐藏神经元值获得输入神经元的激活</li><li id="a137" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">输入神经元的新值显示了用户对尚未看过的电影的评价</li></ul><p id="8554" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="le">这就把我们带到了“受限玻尔兹曼机器教程”这篇文章的结尾。我希望这篇文章对你有所帮助，并增加了你的知识价值。</em></p><p id="af2e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，那么你可以参考<a class="ae ma" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=restricted-boltzmann-machine-tutorial" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释深度学习的各个其他方面。</p><blockquote class="mb mc md"><p id="1554" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">1.<a class="ae ma" rel="noopener" href="/edureka/tensorflow-tutorial-ba142ae96bca">张量流教程</a></p><p id="eddd" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">2.<a class="ae ma" rel="noopener" href="/edureka/pytorch-tutorial-9971d66f6893"> PyTorch教程</a></p><p id="2572" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">3.<a class="ae ma" rel="noopener" href="/edureka/perceptron-learning-algorithm-d30e8b99b156">感知器学习算法</a></p><p id="3f16" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">4.<a class="ae ma" rel="noopener" href="/edureka/neural-network-tutorial-2a46b22394c9">神经网络教程</a></p><p id="4048" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">5.什么是反向传播？</p><p id="3fcf" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">6.<a class="ae ma" rel="noopener" href="/edureka/convolutional-neural-network-3f2c5b9c4778">卷积神经网络</a></p><p id="41d4" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">7.<a class="ae ma" rel="noopener" href="/edureka/capsule-networks-d7acd437c9e">胶囊神经网络</a></p><p id="af60" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">8.<a class="ae ma" rel="noopener" href="/edureka/recurrent-neural-networks-df945afd7441">递归神经网络</a></p><p id="b77f" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">9.<a class="ae ma" rel="noopener" href="/edureka/autoencoders-tutorial-cfdcebdefe37">自动编码器教程</a></p><p id="ccd8" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">10.<a class="ae ma" rel="noopener" href="/edureka/tensorflow-object-detection-tutorial-8d6942e73adc">tensor flow中的对象检测</a></p><p id="0a3a" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">11.<a class="ae ma" rel="noopener" href="/edureka/pytorch-vs-tensorflow-252fc6675dd7"> PyTorch vs TensorFlow </a></p><p id="d8d6" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">12.<a class="ae ma" rel="noopener" href="/edureka/deep-learning-with-python-2adbf6e9437d">用Python进行深度学习</a></p><p id="938f" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">13.<a class="ae ma" rel="noopener" href="/edureka/artificial-intelligence-tutorial-4257c66f5bb1">人工智能教程</a></p><p id="6c0f" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">14.<a class="ae ma" rel="noopener" href="/edureka/tensorflow-image-classification-19b63b7bfd95"> TensorFlow图像分类</a></p><p id="0baf" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">15.<a class="ae ma" rel="noopener" href="/edureka/artificial-intelligence-applications-7b93b91150e3">人工智能应用</a></p><p id="725f" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">16.<a class="ae ma" rel="noopener" href="/edureka/become-artificial-intelligence-engineer-5ac2ede99907">如何成为一名人工智能工程师？</a></p><p id="01b8" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">17.<a class="ae ma" rel="noopener" href="/edureka/q-learning-592524c3ecfc">问学习</a></p><p id="7d13" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">18.<a class="ae ma" rel="noopener" href="/edureka/apriori-algorithm-d7cc648d4f1e"> Apriori算法</a></p><p id="8ad1" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">19.<a class="ae ma" rel="noopener" href="/edureka/introduction-to-markov-chains-c6cb4bcd5723">用Python实现马尔可夫链</a></p><p id="bdfc" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">20.<a class="ae ma" rel="noopener" href="/edureka/artificial-intelligence-algorithms-fad283a0d8e2">人工智能算法</a></p><p id="d43b" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">21.<a class="ae ma" rel="noopener" href="/edureka/best-laptop-for-machine-learning-a4a5f8ba5b">机器学习的最佳笔记本电脑</a></p><p id="5c3f" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">22.<a class="ae ma" rel="noopener" href="/edureka/top-artificial-intelligence-tools-36418e47bf2a">12大人工智能工具</a></p><p id="451d" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">23.<a class="ae ma" rel="noopener" href="/edureka/artificial-intelligence-interview-questions-872d85387b19">人工智能(AI)面试问题</a></p><p id="41ff" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">24.<a class="ae ma" rel="noopener" href="/edureka/theano-vs-tensorflow-15f30216b3bc"> Theano vs TensorFlow </a></p><p id="382e" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">25.<a class="ae ma" rel="noopener" href="/edureka/what-is-a-neural-network-56ae7338b92d">什么是神经网络？</a></p><p id="7ecc" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">26.<a class="ae ma" rel="noopener" href="/edureka/pattern-recognition-5e2d30ab68b9">模式识别</a></p><p id="08ae" class="ip iq le ir b is it iu iv iw ix iy iz me jb jc jd mf jf jg jh mg jj jk jl jm ha bi translated">27.<a class="ae ma" rel="noopener" href="/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a">人工智能中的阿尔法贝塔剪枝</a></p></blockquote></div><div class="ab cl mh mi go mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ha hb hc hd he"><p id="6427" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="le">原载于2018年11月20日www.edureka.co</em><a class="ae ma" href="https://www.edureka.co/blog/restricted-boltzmann-machine-tutorial/" rel="noopener ugc nofollow" target="_blank"><em class="le"/></a><em class="le">。</em></p></div></div>    
</body>
</html>