<html>
<head>
<title>How Pinterest Leverages Realtime User Actions in Recommendation to Boost Homefeed Engagement Volume</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pinterest如何在推荐中利用实时用户操作来提高Homefeed参与量</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/how-pinterest-leverages-realtime-user-actions-in-recommendation-to-boost-homefeed-engagement-volume-165ae2e8cde8?source=collection_archive---------0-----------------------#2022-11-04">https://medium.com/pinterest-engineering/how-pinterest-leverages-realtime-user-actions-in-recommendation-to-boost-homefeed-engagement-volume-165ae2e8cde8?source=collection_archive---------0-----------------------#2022-11-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="af71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">夏雪，软件工程师，Homefeed排名；能谷，软件工程师，内容与用户理解；Dhruvil Deven Badani，工程经理，Homefeed排名；Andrew Zhai，软件工程师，先进技术集团</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/d4f94e2751e95e3660b4861825cf5892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SUNAYGRd2kTgrBNh"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image from <a class="ae js" href="https://wallpapercave.com/neural-networks-wallpapers#google_vignette" rel="noopener ugc nofollow" target="_blank">https://wallpapercave.com/neural-networks-wallpapers#google_vignette</a></figcaption></figure><p id="0a41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博文中，我们将从机器学习模型设计的角度展示我们如何通过利用Homefeed推荐系统中的实时用户操作功能来提高Pinterest Homefeed的参与量。</p><h1 id="2560" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">背景</h1><p id="7c47" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">Pinterest的主页是pinners发现灵感的最重要的平台之一，并在整体用户参与度中占很大比例。显示在主页顶端位置的引脚需要个性化，以创建一个引人入胜的pinner体验。我们从Pinterest上创建的大量pin中检索一小部分，根据用户兴趣、关注的论坛等作为Homefeed候选pin。为了向pinners呈现最相关的内容，我们然后使用一个Homefeed排名模型(又名<a class="ae js" rel="noopener" href="/pinterest-engineering/pinnability-machine-learning-in-the-home-feed-64be2074bf60"> Pinnability </a>模型)通过准确预测它们与给定用户的个性化相关性来对检索到的候选内容进行排名。因此，Homefeed排名模型在改善pinner体验方面发挥了重要作用。Pinnability是一个最先进的神经网络模型，它消耗pin信号、用户信号、上下文信号等。并且预测给定pin的用户动作。高层架构如图3所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kw"><img src="../Images/bb2158d8065b2ac6cba998a0c9c11a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJpP_3UStKsaVq_sEij0Jg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 1. What Homefeed Ranking (Pinnability) does — image from <a class="ae js" rel="noopener" href="/pinterest-engineering/pinnability-machine-learning-in-the-home-feed-64be2074bf60">Pinnability: Machine learning in the home feed</a></figcaption></figure><p id="2d3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinnability模型一直使用一些预先训练的用户嵌入来模拟用户的兴趣和偏好。例如，我们使用<a class="ae js" href="https://arxiv.org/abs/2205.04507" rel="noopener ugc nofollow" target="_blank">pinner former</a>(pinner sage V3)，这是一种静态的、离线学习的用户表示，通过利用用户过去在Pinterest上的交互历史来捕捉用户的长期兴趣。</p><p id="121c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，仍有一些方面是PinnerSAGE等预训练嵌入没有涵盖的，我们可以通过使用实时用户操作序列功能来填补这一空白:</p><ul class=""><li id="7aa5" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated"><strong class="ig hi">模型pinners的短期兴趣</strong> : PinnerSAGE是用成千上万的用户长期行为训练出来的，所以它主要捕捉的是长期兴趣。另一方面，实时用户动作序列模拟短期用户兴趣，是对PinnerSAGE嵌入的补充。</li><li id="f5ff" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">响应更快</strong>:实时信号能够更快地响应，而不是其他静态特性。这是很有帮助的，尤其是对于新的、临时的和复活的用户，他们过去没有太多的参与。</li><li id="d22b" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">推荐模型目标的端到端优化</strong>:我们使用用户动作序列特征作为推荐模型的直接输入特征，直接针对模型目标进行优化。与PinnerSAGE不同，我们可以通过每个单独的序列动作来参与pin候选特征，以获得更大的灵活性。</li></ul><p id="d53d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了向pinners提供他们最近行为的实时反馈，并改善用户在Homefeed上的体验，我们提出将实时用户行为序列信号纳入推荐模型。</p><h1 id="089a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">特征:实时用户动作序列</h1><p id="18c7" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">一个稳定、低延迟、实时的特征管道支持一个健壮的在线推荐系统。我们将最新的100个用户操作作为一个序列，用pin嵌入和其他元数据填充。整个架构可以分为事件时间和请求，如图2所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/5c1906a1e6a0648bfe476382546f7e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4huwRe2es_TIIsLM"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 2. Realtime Feature Generation Pipeline</figcaption></figure><p id="7761" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了最大限度地减少应用停机时间和信号故障，我们在以下方面做出了努力:</p><p id="e1c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ML侧</p><ul class=""><li id="6892" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">功能/模式强制验证</li><li id="3758" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">延迟源事件处理以防止数据泄漏</li><li id="dfb1" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">一段时间内的逐项行动跟踪数据转移</li></ul><p id="a147" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">运营端</p><ul class=""><li id="35c9" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">对核心作业运行状况、延迟/吞吐量等进行统计监控。</li><li id="2fd1" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">全面的随叫随到服务，最大限度地减少应用停机时间</li><li id="fcd2" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">事件恢复策略</li></ul><p id="df8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们为Homefeed推荐模型生成了以下特征:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ll"><img src="../Images/f5176250ee330366e29b58e6c45ca2c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HxRnbdyFg5L72OtNl3qCww.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Table 1. Realtime User Action Sequence Features — learn more about <a class="ae js" href="https://arxiv.org/pdf/1806.01973.pdf" rel="noopener ugc nofollow" target="_blank">pinSAGE</a></figcaption></figure><h1 id="a31b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">建模:变压器编码器</h1><p id="fdfd" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">图3是我们的Homefeed排名模型的概述。该模型消耗一个<strong class="ig hi"> &lt;用户，pin &gt; </strong>对，并预测用户对候选pin采取的动作。我们对可定位性模型的输入包括各种类型的信号，包括pinner信号、用户信号、pin信号和上下文信号。我们现在添加一个独特的、实时的用户序列信号输入，并使用一个序列处理模块来处理序列特征。随着所有特征的转换，我们将它们提供给具有多个动作头部的MLP层，以预测用户在候选pin上的动作。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lm"><img src="../Images/1029686b21c4a3282b2d67456c8e474d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sfanBRZaU68rF5Hj"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 3. Pinterest Homefeed Ranking (Pinnabilty) Model</figcaption></figure><p id="fe61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近的文献已经使用变压器进行推荐任务。有些人将推荐问题建模为序列预测任务，其中模型的输入是(S1，S2，…，SL-1)，其预期输出是同一序列的“移位”版本:(S2，S3，…，SL)。为了保持当前的可定位架构，我们仅采用这些模型中的<strong class="ig hi">编码器</strong>部分。</p><p id="ac61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了构建transformer输入，我们利用了三个重要的实时用户序列特性:</p><ol class=""><li id="b6fe" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb ln ld le lf bi translated">参与pin嵌入:用户历史中过去100个参与pin的pin嵌入(已学习的GraphSage嵌入)</li><li id="21ae" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">动作类型:用户动作序列中的参与类型(例如，重复、点击、隐藏)</li><li id="62aa" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">时间戳:用户参与用户历史的时间戳</li></ol><p id="38a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还使用候选pin嵌入来执行与上述实时用户序列特征的早期融合。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/5da806ee6a77a2d2a261acb632ae1b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*95nEJ8AtUL9iInE9"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 4. initial architecture of user sequence transformer module (v1.0)</figcaption></figure><p id="498a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如图3所示，为了构建序列转换器模块的输入，我们将<strong class="ig hi">【candidate _ pin _ emb，action_emb，engaged _ pin _ emb】</strong>堆叠成一个矩阵。在线和离线实验证明，候选pin和用户序列的早期融合是非常重要的。我们还在序列中的条目上应用了一个<strong class="ig hi">随机时间窗口掩码</strong>，其中动作是在请求时间的一天内发生的。随机时间窗口掩码用于降低模型的响应性，并避免多样性下降。然后我们把它输入变压器编码器。对于最初的实验，我们只使用一个transformer编码器层。变压器编码器的输出是一个形状为<strong class="ig hi"> <em class="lo">【序列长度，隐藏尺寸】的矩阵。然后，我们将输出展平为一个矢量，并将其与所有其他特征一起输入MLP层，以预测多头用户的动作。</em></strong></p><p id="79cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在用户序列模块(1.1版)的第二次迭代中，我们在1.0版架构上做了一些调整。我们增加了变压器编码器层数，并压缩了变压器输出。我们没有展平整个输出矩阵，而是只取了前10个输出标记，将它们与max pooling标记连接起来，并展平为一个长度为<strong class="ig hi"><em class="lo">(10+1)* hidden _ dim</em></strong>的向量。前10个输出令牌捕获用户最近的兴趣，最大池令牌可以代表用户的长期偏好。因为输出尺寸变得更小，所以在完整的功能集上应用带有<a class="ae js" href="https://arxiv.org/abs/2008.13535" rel="noopener ugc nofollow" target="_blank"> DCN v2 </a>架构的显式功能交叉层是可以承受的，如图2所示</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/213a4a7e6ab607eaab3f20a8a90c8b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lu4lT5Xp-WwlxE4k"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 5. improved architecture of user sequence transformer module (v1.1)</figcaption></figure><h2 id="033b" class="lp ju hh bd jv lq lr ls jz lt lu lv kd ip lw lx kh it ly lz kl ix ma mb kp mc bi translated">挑战1:参与率下降</h2><p id="f21e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">通过在线实验，我们看到在进行实时动作序列处理的小组中，用户参与度指标逐渐衰减。图6展示了对于相同的模型架构，如果我们不对其进行重新训练，那么参与度的提高要比我们对新数据进行重新训练时小得多。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/651ee6476673b83196250662f9050539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0XNtesvLxL-Nr-kK"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 6. Engagement Rate Decay</figcaption></figure><p id="99a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的假设是，我们具有实时特性的模型对时间非常敏感，需要频繁的重新训练。为了验证这一假设，我们同时对控制组(没有实时用户动作特征)和处理组(具有实时用户动作特征)进行了再训练，并且我们对两种模型的再训练效果进行了比较。如图6所示，我们发现治疗模型中的再培训收益比控制模型中的多得多。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/66226ecc95a44a52266ff8b759d048bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1F1y7PaRhQ6lRZ5C"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 7. Retrain Comparison Between Control and Treatment</figcaption></figure><p id="1bfc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，为了应对参与度衰减的挑战，我们每周重新培训两次实时序列模型。通过这样做，参与率变得稳定多了。</p><h2 id="fae6" class="lp ju hh bd jv lq lr ls jz lt lu lv kd ip lw lx kh it ly lz kl ix ma mb kp mc bi translated">挑战2:为有机规模的大型模型提供服务</h2><p id="4531" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">随着转换器模块被引入推荐器模型，复杂性显著增加。在这项工作之前，Pinterest一直在CPU集群上服务Homefeed排名模型。我们的模型将CPU延迟增加了20倍以上。然后，我们迁移到为排名模型服务的GPU，并能够以相同的成本保持中性延迟。</p><h1 id="e82a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><p id="f3ef" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在Pinterest上，最重要的用户操作之一是repin，或save。列宾是该平台用户参与度的关键指标之一。因此，我们用列宾数量来估计用户参与度，并使用列宾数量来评估模型性能。</p><h2 id="1444" class="lp ju hh bd jv lq lr ls jz lt lu lv kd ip lw lx kh it ly lz kl ix ma mb kp mc bi translated">离线评估</h2><p id="56d2" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们对处理实时用户序列特征的不同模型进行离线评估。具体来说，我们尝试了以下架构:</p><ul class=""><li id="e6e1" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated"><strong class="ig hi">平均池</strong>:最简单的架构，使用用户序列中嵌入的pin的平均值来表示用户的短期兴趣</li><li id="41fb" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">(卷积神经网络(CNN): </strong>使用CNN对一系列pin嵌入进行编码。CNN适合于捕捉跨局部信息的依赖关系</li><li id="5079" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">递归神经网络(RNN): </strong>使用RNN对一系列pin嵌入进行编码。与CNN相比，RNN更好地捕捉了长期依赖。</li><li id="9f54" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">失去短期记忆(LSTM): </strong>使用LSTM，一个更复杂的RNN版本，通过使用记忆细胞和门控，比RNN更好地捕捉长期依赖关系。</li><li id="eb05" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">普通转换器:</strong>直接使用转换器模块仅对引脚嵌入序列进行编码。</li><li id="64d5" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated"><strong class="ig hi">改进的Transformer v1.0: </strong>改进的Transformer架构如图4所示。</li></ul><p id="59e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特别是对于Homefeed surface，两个最重要的指标是HIT@3 for repin和hide prediction。对于列宾，我们尽量提高HIT@3。对于隐藏，目标是减少命中@3。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mf"><img src="../Images/572b8fd55af0d00e7d93dfe915ed192c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhvfg9tc8GHI04Idk_Muog.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Table 2. Offline Evaluation Metrics</figcaption></figure><p id="2c44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">离线结果显示，即使使用普通变压器和仅有引脚嵌入，性能也已经优于其他架构。改进的变压器架构显示出非常强劲的离线结果:离线列宾+8.87%，隐藏下降-13.49%。从vanilla transformer改进的transformer 1.0的增益来自几个方面:</p><ol class=""><li id="8b1e" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb ln ld le lf bi translated">使用动作嵌入:这有助于模型区分积极参与和消极参与</li><li id="b141" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">候选pin和用户序列的早期融合:根据在线和离线实验，</li><li id="77a2" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">随机时间窗掩码:有助于多样性</li></ol><h2 id="bb9b" class="lp ju hh bd jv lq lr ls jz lt lu lv kd ip lw lx kh it ly lz kl ix ma mb kp mc bi translated">在线评估</h2><p id="0cae" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">然后，我们使用改进的transformer模型v1.0对总流量的1.5%进行了在线A/B实验。在在线实验过程中，我们观察到整体用户的repin量增加了6%。我们将新的、临时的、复活的用户集合定义为<strong class="ig hi"> <em class="lo">非核心用户</em> </strong>。我们观察到，非核心用户的repin交易量增长可以达到11%。与离线评估一致，生皮体积减少了10%。</p><p id="8d1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近，我们尝试了transformer版，如图4所示，我们在1.0版的基础上实现了额外5%的repin增益。隐藏音量在1.0版中保持中性。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/2ad2219922831b2e938e0f3794e8cc01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXrz3kZI7HggKKpXn0CZEQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Table 3. Online Experiment Metrics for Homefeed Surface</figcaption></figure><h2 id="826a" class="lp ju hh bd jv lq lr ls jz lt lu lv kd ip lw lx kh it ly lz kl ix ma mb kp mc bi translated">生产指标(全流量)</h2><p id="86be" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们想提出一个有趣的观察:在线实验低估了实时用户动作序列的力量。当我们将该模型作为生产Homefeed排名模型推广到全流量时，我们观察到了更高的收益。这是因为正反馈循环的学习效应:</p><ol class=""><li id="0efe" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb ln ld le lf bi translated">当用户看到一个响应性更强的主页时，他们倾向于使用更相关的内容，他们的行为也发生了变化(例如，更多的点击或重复)</li><li id="3bc3" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">随着这种行为变化，实时记录他们行为的实时用户序列也发生了变化。例如，序列中有更多的列宾动作。然后，我们用这个移位的用户序列特征生成训练数据。</li><li id="f81d" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated">当我们用这个转移的数据集重新训练Homefeed排名模型时，有一个积极的复合效应，使重新训练的模型更加强大，从而提高了参与率。然后我们回到1。</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/094fd47952c0380bf5d92afb19413d79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SDqNIpUvyczPn8dW"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Figure 8. Feedback Loop of Realtime Sequence Model</figcaption></figure><p id="e278" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在将该模型交付生产后观察到的实际Homefeed repin数量增长高于在线实验结果。不过，我们不会在这篇博客中透露确切的数字。</p><h1 id="9c9c" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="7722" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们在Pinterest的Homefeed推荐系统中使用实时用户动作信号的工作极大地提高了Homefeed的相关性。在其他传统的序列建模方法中，Transformer架构表现得最好。一路走来有各种各样的挑战，要解决这些挑战并不容易。我们发现，用实时序列重新训练模型对于保持用户参与度非常重要。并且GPU服务对于大规模、复杂的模型是不可或缺的。</p><h1 id="4332" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">未来的工作</h1><p id="c919" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">看到这项工作的巨大收获是令人兴奋的，但更令人兴奋的是，我们知道还有很大的改进空间。为了继续改善Pinner体验，我们将从以下几个方面着手:</p><ol class=""><li id="06c2" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb ln ld le lf bi translated"><strong class="ig hi">特性改进:</strong>我们计划开发一个更细粒度的实时序列信号，包括更多的动作类型和动作元数据。</li><li id="420d" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated"><strong class="ig hi"> GPU服务优化:</strong>这是第一个使用GPU集群为有机规模的大型模型提供服务的用例。我们计划提高GPU服务的可用性和性能。</li><li id="4687" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated"><strong class="ig hi">模型迭代</strong>:我们将继续进行模型迭代，以便充分利用实时信号。</li><li id="5658" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb ln ld le lf bi translated"><strong class="ig hi">在其他界面上的采用</strong>:我们将在其他界面上尝试类似的想法:相关的pin、通知、搜索等。</li></ol><h1 id="66a7" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">确认</h1><p id="bba4" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">这项工作是Pinterest多个团队合作的结果。非常感谢对本项目做出贡献的以下人员:</p><ul class=""><li id="c869" class="kx ky hh ig b ih ii il im ip kz it la ix lb jb lc ld le lf bi translated">GPU服务优化:Po-王巍，Pong Eksombatchai，Nazanin Farahpour，张志远，Saurabh Joshi，唐力</li><li id="35eb" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">关于ML的技术支持:Nikil Pancha</li><li id="f00d" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">信号生成和服务:周奕彤</li><li id="9cfd" class="kx ky hh ig b ih lg il lh ip li it lj ix lk jb lc ld le lf bi translated">快速可控性分布收敛:Ludek Cigler</li></ul><p id="ca16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lo">要在Pinterest上了解更多工程知识，请查看我们的</em> <a class="ae js" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="lo">工程博客</em> </a> <em class="lo">，并访问我们的</em><a class="ae js" href="https://www.pinterestlabs.com?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=xia-nov-4-2022" rel="noopener ugc nofollow" target="_blank"><em class="lo">Pinterest Labs</em></a><em class="lo">网站。要探索Pinterest的生活，请访问我们的</em> <a class="ae js" href="https://www.pinterestcareers.com?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=xia-nov-4-2022" rel="noopener ugc nofollow" target="_blank"> <em class="lo">职业</em> </a> <em class="lo">页面。</em></p></div></div>    
</body>
</html>