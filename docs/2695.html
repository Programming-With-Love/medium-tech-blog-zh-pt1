<html>
<head>
<title>What’s New in Hadoop 3.0 ?— Enhancements in Apache Hadoop 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hadoop 3.0有什么新功能？Apache Hadoop 3的增强功能</h1>
<blockquote>原文：<a href="https://medium.com/edureka/hadoop-3-35e7fec607a?source=collection_archive---------0-----------------------#2017-05-14">https://medium.com/edureka/hadoop-3-35e7fec607a?source=collection_archive---------0-----------------------#2017-05-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/3806d9faa790bc3794f2d399af8e6cdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*9l1T8Uzs0W9gxT_wnrOBqg.png"/></div><figcaption class="il im et er es in io bd b be z dx">What’s new in Hadoop 3 - Edureka</figcaption></figure><p id="cdc0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这篇“<strong class="ir hi"><em class="jn">Hadoop 3.0中的新特性</em> </strong>”文章关注Hadoop 3中预期的变化，因为它仍处于alpha阶段。Apache社区已经整合了许多变化，并且仍在对其中一些进行改进。因此，我们将从更广泛的角度来看待预期的变化。</p><p id="d2ab" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将讨论的主要变化是:</p><ul class=""><li id="9712" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">Hadoop 3中要求的最低Java版本是8</li><li id="217a" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">HDFS对擦除编码的支持</li><li id="6503" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">纱线时间线服务v.2</li><li id="ccca" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">外壳脚本重写</li><li id="f4cb" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">阴影客户端jar</li><li id="5e26" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">支持机会容器</li><li id="b851" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">MapReduce任务级本机优化</li><li id="cf50" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">支持2个以上的NameNodes</li><li id="6bc9" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">多个服务的默认端口已更改</li><li id="8041" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">支持文件系统连接器</li><li id="2851" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">DataNode内部平衡器</li><li id="c34c" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">返工守护进程和任务堆管理</li></ul><p id="1f21" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Apache Hadoop 3将在Hadoop-2.x的基础上整合多项增强功能。因此，让我们向前看一下每项增强功能。</p><h1 id="b960" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">1.Hadoop 3中所需的最低Java版本从7增加到8</h1><p id="4763" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">在Hadoop 3中，所有Hadoop JARs都是针对Java 8的运行时版本编译的。所以，仍在使用Java 7或更低版本的用户在开始使用Hadoop 3时，必须升级到Java 8。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/90b639bd0edfa3f17080bc629778f672.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*APRw0JXt0uHXY8-hFw4SqQ.png"/></div></figure><p id="f1c9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们讨论Hadoop 3的重要增强之一，即擦除编码，它将减少存储开销，同时提供与之前相同的容错级别。</p><h1 id="378f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">2.HDFS对擦除编码的支持</h1><p id="1acc" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">现在让我们先来了解一下什么是擦除编码。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/35b73efdffc2bbbb0fac7f99b294c530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P46ukB2FA2eZidDhGGVjxw.png"/></div></div></figure><p id="381b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一般在存储系统中，擦除编码多用于<strong class="ir hi"> <em class="jn">廉价磁盘冗余阵列(RAID) </em> </strong>。</p><p id="8f80" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如上图所示，RAID通过<strong class="ir hi"> <em class="jn">条带化</em> </strong>实现EC，其中逻辑上连续的数据(如文件)被分成更小的单元(如位、字节或块)，并将连续的单元存储在不同的磁盘上。</p><p id="9c97" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，对于原始数据单元的每个条带，计算并存储一定数量的<strong class="ir hi"> <em class="jn">奇偶校验单元</em> </strong>。这个过程叫做<strong class="ir hi"> <em class="jn">编码</em> </strong>。<em class="jn">任何条带单元上的错误都可以通过基于幸存数据单元和奇偶校验单元的解码计算来恢复</em>。</p><p id="81a5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">既然我们有了擦除编码的概念，现在让我们先来看看Hadoop 2.x中的早期复制场景。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/fb26da8953a87543a2d87241ccc30a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgCN_pi4VPXteIkTYZ6w0w.png"/></div></div></figure><p id="e7bd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="jn"> HDFS </em> </strong>中的默认复制因子是3，其中一个是原始数据块，另外两个是副本，每个副本都需要100%的存储开销。因此，这使得<strong class="ir hi"> <em class="jn">的存储开销为</em> </strong>的200%,并且会消耗网络带宽等其他资源。</p><p id="2f55" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，具有低I/O活动的冷数据集的副本在正常操作期间很少被访问，但仍然会消耗与原始数据集相同数量的资源。</p><p id="f78a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与HDFS复制相比，擦除编码以更少的空间开销存储数据并提供容错。擦除编码(EC)可用于替代复制，这将提供相同级别的容错，而存储开销更少。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/5ed886050581a1071fd0a20a12447ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-O0N_Bq4zDCXCxmqdmHyQ.png"/></div></div></figure><p id="2155" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">将EC与HDFS集成可以保持相同的容错能力，同时提高存储效率。例如，具有6个数据块的3x复制文件将消耗6*3 = 18个数据块的磁盘空间。但采用EC (6数据，3奇偶)部署，只会消耗9块(6数据块+ 3奇偶块)的磁盘空间。这只需要高达50%的存储开销。</p><p id="8c81" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于执行远程读取，擦除编码在数据重建中需要额外的开销，因此它通常用于存储不太频繁访问的数据。在部署擦除代码之前，用户应该考虑擦除编码的所有开销，如存储、网络和CPU开销。</p><p id="fd6c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，为了在HDFS有效地支持擦除编码，他们在体系结构上做了一些改变。让我们来看看架构的变化。</p><h2 id="bc8c" class="lq kd hh bd ke lr ls lt ki lu lv lw km ja lx ly kq je lz ma ku ji mb mc ky md bi translated">HDFS擦除编码:架构</h2><ul class=""><li id="b271" class="jo jp hh ir b is la iw lb ja me je mf ji mg jm jt ju jv jw bi translated"><strong class="ir hi"> NameNode扩展</strong>–HDFS文件被分成块组，这些块组具有一定数量的内部块。现在，为了减少这些额外块的NameNode内存消耗，引入了新的分层<strong class="ir hi"> <em class="jn">块命名协议</em> </strong>。块组的ID可以从其任何内部块的ID中推导出来。这允许在块组级别而不是块级别进行管理。</li><li id="5360" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><strong class="ir hi">客户端扩展</strong>–在HDFS实施擦除编码后，NameNode在块组级别工作&amp;客户端读写路径得到增强，可在<em class="jn">并行</em>的块组中的多个内部块上工作。</li></ul><ol class=""><li id="250e" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm mh ju jv jw bi translated">在输出/写入路径上，<em class="jn"> DFSStripedOutputStream </em>管理一组数据流，每个数据流对应一个在当前块组中存储内部块的DataNode。协调器负责整个块组的操作，包括结束当前块组、分配新的块组等。</li><li id="eeca" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm mh ju jv jw bi translated">在输入/读取路径上，<em class="jn"> DFSStripedInputStream </em>将请求的数据逻辑字节范围转换为存储在DataNodes上的内部块。然后，它并行发出读取请求。失败时，它会发出额外的解码读取请求。</li></ol><ul class=""><li id="96d2" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi"> DataNode扩展</strong><strong class="ir hi">–</strong>DataNode运行一个额外的ErasureCodingWorker (ECWorker)任务，用于失败的擦除编码块的后台恢复。NameNode检测到失败的EC块，然后选择一个DataNode来执行恢复工作。重建执行三项关键任务:</li></ul><ol class=""><li id="90fe" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm mh ju jv jw bi translated">从源节点读取数据，并只读取最少数量的输入块和奇偶校验块进行重建。</li><li id="ec3c" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm mh ju jv jw bi translated">从输入数据中解码出新的数据和奇偶校验块。所有丢失的数据和奇偶校验块一起被解码。</li><li id="0e35" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm mh ju jv jw bi translated">解码完成后，恢复的块将被传输到目标数据节点。</li></ol><ul class=""><li id="050f" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><strong class="ir hi">擦除编码策略</strong>–为了适应异构工作负载，我们允许HDFS集群中的文件和目录采用不同的复制和EC策略。关于编码&amp;解码文件的信息封装在ErasureCodingPolicy类中。它包含两条信息，即<em class="jn"> ECSchema &amp;剥离单元的大小。</em></li></ul><p id="fb6e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Hadoop 3中第二个最重要的增强是来自YARN版本1的YARN Timeline服务版本2(在Hadoop 2.x中)。他们正试图在第二版《YARN》中做出许多乐观的改变。</p><h1 id="35f7" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">3.纱线时间线服务v.2</h1><p id="b598" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">Hadoop推出了纱线时间轴服务的主要版本，即版本2 .纱线时间轴服务。它的开发是为了解决两个主要挑战:</p><ol class=""><li id="ef08" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm mh ju jv jw bi translated"><em class="jn">提高时间轴服务的可扩展性和可靠性</em></li><li id="76ef" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm mh ju jv jw bi translated"><em class="jn">通过引入流和聚合增强可用性</em></li></ol><p id="0515" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">开发人员可以测试YARN Timeline Service v.2，以提供反馈和建议。它应该只在测试容量中使用。YARN Timeline Service v.2中没有启用安全性。</p><p id="8c4f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，让我们首先讨论可伸缩性，然后我们将讨论流和聚合。</p><h2 id="7f36" class="lq kd hh bd ke lr ls lt ki lu lv lw km ja lx ly kq je lz ma ku ji mb mc ky md bi translated">纱线时间线服务v.2:可扩展性</h2><p id="da38" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">YARN版本1仅限于单个写/读实例，并且不能很好地扩展到小型集群之外。版本2使用了更具可伸缩性的分布式编写器架构和可伸缩的后端存储。它将数据的收集(写入)与数据的服务(读取)分开。它使用分布式收集器，基本上每个纱线应用一个收集器。读取器是独立的实例，专门用于通过REST API提供查询服务。</p><p id="6efb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">YARN Timeline Service v.2选择Apache HBase作为主要后备存储，因为Apache HBase可以很好地扩展到大规模，同时保持良好的读写响应时间。</p><h2 id="cea9" class="lq kd hh bd ke lr ls lt ki lu lv lw km ja lx ly kq je lz ma ku ji mb mc ky md bi translated">纱线时间线服务v.2:可用性改进</h2><p id="60cd" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">现在来谈谈可用性的改进，在很多情况下，用户感兴趣的是“流”级别的信息或者YARN应用程序的逻辑组。更常见的是启动一组或一系列的纱线应用程序来完成一个逻辑应用程序。时间轴服务v.2明确支持流的概念。此外，它支持在流程级别聚合指标，如下图所示。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/5562e3eca7971c1ba58ba96818a2b518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7thO4fFn5usHTjbwpGdQHQ.png"/></div></div></figure><p id="5ab0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们看看架构层面，YARN版本2是如何工作的。</p><h2 id="928c" class="lq kd hh bd ke lr ls lt ki lu lv lw km ja lx ly kq je lz ma ku ji mb mc ky md bi translated">纱线时间轴服务v.2:架构</h2><p id="8ead" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">YARN Timeline Service v.2使用一组收集器(写入器)将数据写入后端存储。收集器是分布式的，并与它们所服务的应用程序主机位于同一位置，如下图所示。属于该应用程序的所有数据都被发送到应用程序级时间线收集器，但资源管理器时间线收集器除外。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/13ea68746c370bee7d7c47e59f1954aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wfm19X5-AUeuWUqp15fZjQ.png"/></div></div></figure><p id="57aa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于给定的应用，应用主机可以将该应用的数据写入协同定位的时间线收集器。此外，运行应用程序容器的其他节点的节点管理器也将数据写入运行应用程序主程序的节点上的时间轴收集器。</p><p id="2722" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">资源管理器还维护自己的时间线收集器。它只发出普通的生命周期事件，以保持合理的写入量。</p><p id="26d8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">时间轴读取器是独立于时间轴收集器的守护进程，它们专门用于通过REST API提供查询服务。</p><h1 id="93fe" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">4.外壳脚本重写</h1><p id="5dca" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">Hadoop shell脚本已经过重新编写，修复了许多错误，解决了兼容性问题，并对一些现有安装进行了更改。它还包含了一些新功能。所以我会列举一些重要的例子:</p><ul class=""><li id="461a" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">所有的Hadoop shell脚本子系统现在执行<strong class="ir hi"> <em class="jn"> hadoop-env.sh，</em> </strong>，这允许所有的环境变量在一个位置。</li><li id="0cfd" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">通过<strong class="ir hi"><em class="jn">–daemon</em></strong>选项，守护进程已经从<strong class="ir hi"> <em class="jn"> *-daemon.sh </em> </strong>移动到bin命令中。在Hadoop 3中，我们可以简单地使用–daemon start来启动一个守护进程，使用–daemon stop来停止一个守护进程，使用–daemon status来设置$？守护进程的状态。例如，“HDFS–守护程序启动namenode”。</li><li id="1cea" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">如果安装了pdsh，触发ssh连接的操作现在可以使用pdsh。</li><li id="d023" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">${HADOOP\_CONF\_DIR} 现在在任何地方都可以正常使用，不需要符号链接和其他类似的技巧。</li><li id="76ae" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">脚本现在可以在守护程序启动时测试和报告日志和pid目录的各种状态的更好的错误消息。以前，未受保护的shell错误会显示给用户。</li></ul><p id="0b2e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当Hadoop 3处于测试阶段时，你会知道更多的功能。现在让我们讨论一下阴影客户端jar并了解它们的好处。</p><h1 id="63be" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">5.阴影客户端jar</h1><p id="5b06" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">hadoop 2.x版本中可用的<strong class="ir hi"><em class="jn">Hadoop-client</em></strong>将Hadoop的可传递依赖项拉到Hadoop应用程序的类路径中。如果这些可传递依赖项的版本与应用程序使用的版本冲突，这可能会产生问题。</p><p id="f946" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，在Hadoop 3中，我们有了新的hadoop-client-api和hadoop-client-runtime构件，它们将Hadoop的依赖关系隐藏在单个jar中。<em class="jn"> hadoop-client-api </em>是编译作用域&amp;<em class="jn">Hadoop-client-runtime</em>是运行时作用域，包含从<em class="jn"> hadoop-client </em>重新定位的第三方依赖。因此，您可以将依赖项捆绑到一个jar中，并测试整个jar的版本冲突。这避免了将Hadoop的依赖性泄漏到应用程序的类路径中。例如，HBase可以使用与Hadoop集群对话，而无需查看任何实施依赖关系。</p><p id="3289" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们继续了解Hadoop 3中引入的另一个新特性，即机会容器。</p><h1 id="2a10" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">6.支持机会容器和分布式调度</h1><p id="2346" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">引入了一种新的执行类型，即<strong class="ir hi"> <em class="jn">机会容器</em> </strong>，即使在调度时没有可用的资源，也可以被调度到节点管理器上执行。在这种情况下，这些容器将在NM处排队，等待资源可供它启动。机会容器的优先级低于默认的保证容器，因此如果需要的话，会被抢占，以便为保证容器腾出空间。这应该会提高集群的利用率。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/e346bec46ba4b2dd1215b44fc99c6cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQxzuEb731Z6CWWKqrQylA.png"/></div></div></figure><p id="142b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">保证容器</strong>对应现有纱线容器。它们是由容量调度程序分配的，一旦被分派到一个节点，就保证有可用的资源供它们立即开始执行。此外，只要没有故障，这些容器就会运行到完成。</p><p id="de41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">默认情况下，机会容器由中央RM分配，但也添加了支持，以允许机会容器由分布式调度程序分配，该调度程序实现为AMRMProtocol拦截器。</p><p id="93e1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们来看看MapReduce的性能是如何优化的。</p><h1 id="296f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">7.MapReduce任务级本机优化</h1><p id="b23e" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">在Hadoop 3中，MapReduce为地图输出收集器添加了一个本地Java实现。对于随机密集型作业，这可以将性能提高30%或更多。</p><p id="ab9a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">他们添加了地图输出收集器的本地实现。对于洗牌密集型工作，这可能提供30%或更多的速度提升。他们正致力于基于JNI的地图任务的原生优化。基本思想是添加一个NativeMapOutputCollector来处理映射器发出的键值对，因此排序、溢出、IFile序列化都可以在本机代码中完成。他们仍在研究合并代码。</p><p id="9938" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们来看看，Apache社区是如何努力使Hadoop 3更具容错性的。</p><h1 id="508f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">8.支持2个以上的NameNodes</h1><p id="0129" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">在Hadoop 2.x中，HDFS命名节点高可用性架构有一个活动命名节点和一个备用命名节点。通过将编辑内容复制到三个JournalNodes的仲裁中，这种体系结构能够容忍任何一个NameNode的失败。</p><p id="e5cb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，业务关键型部署需要更高程度的容错能力。所以，在Hadoop 3中允许用户运行多个备用NameNodes。例如，通过配置三个NameNodes个主动，2个被动)和五个JournalNodes，集群可以容忍两个节点的故障。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/42aac7a2627f2fa143a50ad550fad87b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P8sw0zL9EVB_Bpa_D0v2Yg.png"/></div></div></figure><p id="7d64" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，我们将了解Hadoop 3中已更改的Hadoop服务的默认端口。</p><h1 id="6f32" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">9.多个服务的默认端口已更改</h1><p id="9b93" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">此前，多个Hadoop服务的默认端口都在Linux <em class="jn">的短暂端口范围</em> (32768-61000)内。除非客户端程序明确请求特定的端口号，否则所使用的端口号是一个<strong class="ir hi"> <em class="jn">短暂的</em> </strong>端口号。因此，在启动时，服务有时会由于与另一个应用程序的冲突而无法绑定到端口。</p><p id="556e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，具有短暂范围的冲突端口已被移出该范围，影响多个服务的端口号，即NameNode、二级NameNode、DataNode等。其中一些重要的是:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/3f6b49c6833fb08af1a0f0ead7ff372b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5-j9xVLSQUbMPIg3LZqEQ.png"/></div></div></figure><p id="c351" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">还有几个是可以期待的。现在继续，让我们知道什么是新的Hadoop 3文件系统连接器。</p><h1 id="eace" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">10.支持文件系统连接器</h1><p id="e382" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">Hadoop现在支持与微软Azure数据湖和阿里云对象存储系统的集成。它可以用作替代的Hadoop兼容文件系统。首先添加了微软Azure数据湖，然后他们也添加了阿里云对象存储系统。你可能会期待更多。</p><p id="b7b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们了解一下<strong class="ir hi"> <em class="jn">平衡器</em> </strong> <em class="jn"> </em>在一个数据节点的多个磁盘中是如何改进的。</p><h1 id="7440" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">11.DataNode内部平衡器</h1><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/8018ea94b858f2087007d75cada821f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtKrgh6FWz0a885ebf-k4g.png"/></div></div></figure><p id="637f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">单个DataNode管理多个磁盘。在正常的写操作期间，数据被平均划分，因此，磁盘被平均填满。但是添加或更换磁盘会导致DataNode中的不对称。这种情况以前没有被现有的HDFS平衡器处理。这涉及到DataNode内部的不对称。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/b4ac23b041474fd31fefd30863f1d45e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1GCIPoFmIHX_TyLFi21cg.png"/></div></div></figure><p id="55dc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，Hadoop 3通过新的DataNode内平衡功能来处理这种情况，该功能通过hdfs磁盘平衡器CLI调用。</p><p id="f2a4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们看看各种内存管理是如何发生的。</p><h1 id="63a5" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">12.返工守护进程和任务堆管理</h1><p id="2f6f" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">对Hadoop守护进程和MapReduce任务的堆管理进行了一系列更改。</p><ul class=""><li id="37bf" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">配置守护进程堆大小的新方法。值得注意的是，现在可以根据主机的内存大小进行自动调优，HADOOP_HEAPSIZE变量已被弃用。取而代之的是，<strong class="ir hi"> HADOOP\_HEAPSIZE\_MAX和HADOOP\_HEAPSIZE\_MIN </strong>分别用于设置Xmx和Xms。所有全局和守护进程特定的堆大小变量现在都支持单位。如果变量只是一个数字，则大小假定为兆字节。</li><li id="362b" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">简化map的配置并减少任务堆大小，因此不再需要在任务配置中和作为Java选项指定所需的堆大小。已经指定两者的现有配置不受此更改的影响。</li></ul><p id="4f8c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我希望这篇文章能给你带来信息和附加值。Apache社区仍在致力于多项增强功能，这些功能可能会持续到测试阶段。</p><p id="2089" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、Python、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="ab6f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中解释大数据其他各方面的其他文章。</p><blockquote class="mi mj mk"><p id="9725" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">1.<a class="ae mo" rel="noopener" href="/edureka/hadoop-tutorial-24c48fbf62f6"> Hadoop教程</a></p><p id="bf6f" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">2.<a class="ae mo" rel="noopener" href="/edureka/hive-tutorial-b980dfaae765">蜂巢教程</a></p><p id="40bf" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">3.<a class="ae mo" rel="noopener" href="/edureka/pig-tutorial-2baab2f0a5b0">养猪教程</a></p><p id="8346" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">4.<a class="ae mo" rel="noopener" href="/edureka/mapreduce-tutorial-3d9535ddbe7c">地图缩小教程</a></p><p id="1a07" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">5.<a class="ae mo" rel="noopener" href="/edureka/hbase-tutorial-bdc36ab32dc0"> HBase教程</a></p><p id="cf45" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">6.<a class="ae mo" rel="noopener" href="/edureka/hdfs-tutorial-f8c4af1c8fde"> HDFS教程</a></p><p id="c978" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">7.<a class="ae mo" rel="noopener" href="/edureka/big-data-tutorial-b664da0bb0c8">大数据教程</a></p><p id="8d90" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">8.<a class="ae mo" rel="noopener" href="/edureka/apache-sqoop-tutorial-431ed0af69ee"> Sqoop教程</a></p><p id="6094" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">9.<a class="ae mo" rel="noopener" href="/edureka/apache-flume-tutorial-6f7150210c76">水槽教程</a></p><p id="88d3" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">10.<a class="ae mo" rel="noopener" href="/edureka/apache-oozie-tutorial-d8f7bbbe1591"> Oozie教程</a></p><p id="8f10" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">11.<a class="ae mo" rel="noopener" href="/edureka/hadoop-ecosystem-2a5fb6740177"> Hadoop生态系统</a></p><p id="55e3" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">12.<a class="ae mo" rel="noopener" href="/edureka/hive-commands-b70045a5693a">HQL顶级配置单元命令及示例</a></p><p id="ee68" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">13.<a class="ae mo" rel="noopener" href="/edureka/create-hadoop-cluster-with-amazon-emr-f4ce8de30fd"> Hadoop集群搭配亚马逊EMR？</a></p><p id="b0f6" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">14.<a class="ae mo" rel="noopener" href="/edureka/big-data-engineer-resume-7bc165fc8d9d">大数据工程师简历</a></p><p id="179f" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">15.<a class="ae mo" rel="noopener" href="/edureka/hadoop-developer-cc3afc54962c"> Hadoop开发人员-工作趋势和薪水</a></p><p id="d88d" class="ip iq jn ir b is it iu iv iw ix iy iz ml jb jc jd mm jf jg jh mn jj jk jl jm ha bi translated">16.<a class="ae mo" rel="noopener" href="/edureka/hadoop-interview-questions-55b8e547dd5c"> Hadoop面试问题</a></p></blockquote></div></div>    
</body>
</html>