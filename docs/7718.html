<html>
<head>
<title>Robust Factorization Machines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">鲁棒因式分解机</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/robust-factorization-machines-1a9ef9f75abf?source=collection_archive---------0-----------------------#2018-07-17">https://medium.com/walmartglobaltech/robust-factorization-machines-1a9ef9f75abf?source=collection_archive---------0-----------------------#2018-07-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/5046a52849864cfbf61aa03335c137a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xiWP_gj2va7bhfHJkex76w.png"/></div></div></figure><blockquote class="ip iq ir"><p id="5237" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">数据不全？嘈杂的设置？让我们来探索一下<a class="ae jr" href="https://dl.acm.org/citation.cfm?id=3186148" rel="noopener ugc nofollow" target="_blank">鲁棒因式分解机器</a>，这是监督学习领域中最新的防噪声产品。</p></blockquote><p id="ee52" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="iu">鲁棒因式分解机</em> </strong> <em class="iu">，</em>最近在WWW'18上提出，是一个非线性分类器家族，考虑到任何潜在的数据不完全性/噪声。他们将稳健优化的原则融入到高度表达的因式分解机器中。结果，经过训练的模型表现出高噪声弹性。</p><blockquote class="ip iq ir"><p id="7e82" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这篇博客试图提供对<em class="hh">鲁棒因子分解机</em>的直观理解。我们将跳过大部分数学和证明之类的东西。</p></blockquote><p id="32d7" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">严谨的数学解释请参考原<a class="ae jr" href="https://dl.acm.org/citation.cfm?id=3186148" rel="noopener ugc nofollow" target="_blank">论文</a>。<a class="ae jr" rel="noopener" href="/@surabhi.punjabi/robustness-for-user-response-prediction-1dd2253f62c5">这篇博客</a>很好地捕捉到了这篇论文背后的动机，以及在用户反应预测领域鲁棒性是多么令人满意。</p><p id="0f6a" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">让我们从理解两个关键词开始:<br/> 1。稳健性，<br/> 2。因式分解机。</p></div><div class="ab cl jv jw go jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="ha hb hc hd he"><h1 id="f042" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">稳健性</h1><p id="9fbe" class="pw-post-body-paragraph is it hh iv b iw la iy iz ja lb jc jd js lc jg jh jt ld jk jl ju le jo jp jq ha bi translated"><strong class="iv hi">最基本的机器学习(ML)流水线是什么样子的？<br/> </strong>取一些ML分类器，把数据放进去，出来一个模型！简单。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lf"><img src="../Images/0d60eb47a3c36052b1426558ab0d77d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MigF2KiBlhZfpznVJce2BA.png"/></div></div></figure><p id="ac48" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated"><strong class="iv hi">数据呢？<br/> </strong>数据质量很重要！数据科学家花费大量时间致力于获得“干净的数据集”。但正如许多人会同意的那样，只能做这么多的数据工程和清理工作。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lk"><img src="../Images/8a980e3b4da6d45574351e20e05a394c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GcmmpmnzCK8dYHRlVkAcxw.png"/></div></div></figure><blockquote class="ip iq ir"><p id="36a3" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果一个分类器可以解决这个问题，❤，会怎么样？</p></blockquote><h2 id="1e18" class="ll kd hh bd ke lm ln lo ki lp lq lr km js ls lt kq jt lu lv ku ju lw lx ky ly bi translated">鲁棒分类器优于标准分类器？</h2><p id="03c2" class="pw-post-body-paragraph is it hh iv b iw la iy iz ja lb jc jd js lc jg jh jt ld jk jl ju le jo jp jq ha bi translated">分类器在训练数据的处理上不同，因此优化问题也不同。</p><p id="a6e1" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated"><strong class="iv hi">标准分类器:<br/></strong>——假设数据精确已知。<br/> -被框定为损失最小化问题w.r.t. a权向量<em class="iu">(</em><strong class="iv hi"><em class="iu">w</em></strong><em class="iu">)</em><strong class="iv hi"><br/></strong>-如图1 (a)所示。</p><p id="6c82" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated"><strong class="iv hi">稳健分类器:<br/></strong>——假设<strong class="iv hi"> <em class="iu">不确定性</em> </strong>与每个数据点相关联。<em class="iu">确定性的概念，基于不确定性的集合</em><strong class="iv hi"><em class="iu"/></strong>。参见等式。1.这允许数据点现在存在于超矩形流形中的任何地方。参见图1。<br/> -框定为<strong class="iv hi"> <em class="iu">极小极大</em> </strong>问题，<strong class="iv hi"> <em class="iu">极小化</em> </strong>损失w.r.t .一个权重向量<em class="iu">(</em><strong class="iv hi"><em class="iu"/></strong><em class="iu">)</em>同时也<strong class="iv hi"> <em class="iu">最大化</em> </strong> w.r.t .一个不确定性<em class="iu">(</em><strong class="iv hi"><em class="iu"/><br/>——如图1 (b)所示。</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/3b1f5b7decd15c4095b198b0581ef7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*6HwxpOsyQ7YYDR6_sPfcLg.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx">Eq. 1. Uncertainty set definition. Uncertainty is defined over each datapoint. Here <strong class="bd ke"><em class="me">x</em></strong> represents a single data point and <strong class="bd ke">m</strong> is the number of data points.</figcaption></figure><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mf"><img src="../Images/d3ccd2cdad6fec370f6c981de43d8228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z16OkHsgfP1a23YNy9kcTQ.png"/></div></div><figcaption class="ma mb et er es mc md bd b be z dx">Fig. 1. (a) Standard classifier v/s (b) Robust classifier. Note how the introduction of uncertainty in (b) results in ‘hyper-rectangles’ over the data points, thus leading to change in the learnt classifier boundary.</figcaption></figure><blockquote class="ip iq ir"><p id="3651" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">简而言之，鲁棒优化寻求学习一个分类器，该分类器在<strong class="iv hi">最坏情况不确定性实现</strong>下保持<strong class="iv hi">可行</strong>和<strong class="iv hi">接近最优</strong>。</p></blockquote></div><div class="ab cl jv jw go jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="ha hb hc hd he"><h1 id="77d3" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">因式分解机器</h1><p id="34c3" class="pw-post-body-paragraph is it hh iv b iw la iy iz ja lb jc jd js lc jg jh jt ld jk jl ju le jo jp jq ha bi translated">让我们来看一个分类场景。<br/>对于具有两个特征(<em class="iu">项目_类别和设备)的购买预测问题，</em>如果我们知道<em class="iu">“服装”类别</em>经常在<em class="iu">“手机”</em>上购买，而不是在<em class="iu">“桌面”</em>上购买，我们如何捕捉这样的特征交互？一个模型如何捕捉诸如“设备=移动和类别=服装”这样的特征交互比只考虑单个特征更重要？<em class="iu"> </em>单靠一个<em class="iu"> </em>线性模型是不够的。</p><p id="3d52" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">Steffen Rendle提出的<strong class="iv hi"> <em class="iu">因子分解机器(FMs) </em> </strong>是一个非线性分类器家族，设计用于捕获潜在空间中的特征交互。也就是说，对于每个特征，学习一个<em class="iu"> p </em>维向量，产生一个<em class="iu"> d </em> x <em class="iu"> p </em>维权重矩阵，其中<em class="iu"> d </em>是特征的原始数量。然后，两个特征之间的相似性由这些潜在向量的点积给出，例如在图2中，交互强度b/w特征<em class="iu"> j </em>和<em class="iu"> k </em>将被计算为以下两个向量的点积:<em class="iu">特征j (v_j)的潜在向量</em>和特征k的<em class="iu">潜在向量(</em> v <em class="iu"> _k) </em>。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mg"><img src="../Images/4cacd1b07b73a20d1a2c64f5d6b5c59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3FxxXMa2NhrS7qoswJfBLQ.png"/></div></div><figcaption class="ma mb et er es mc md bd b be z dx">Fig. 2. Computation of similarity b/w feature j and feature k. Parameter Matrix V is learnt s.t. similarity of features j and k is computed using a dot product b/w rows j and k of the matrix V.</figcaption></figure></div><div class="ab cl jv jw go jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="ha hb hc hd he"><h1 id="a40a" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">鲁棒因式分解机</h1><p id="6dbd" class="pw-post-body-paragraph is it hh iv b iw la iy iz ja lb jc jd js lc jg jh jt ld jk jl ju le jo jp jq ha bi translated">既然我们已经开发了一些关于鲁棒性和因式分解机器的直觉，是时候揭示题为“<a class="ae jr" href="https://dl.acm.org/citation.cfm?id=3186148" rel="noopener ugc nofollow" target="_blank">用于用户响应预测的鲁棒性因式分解机器</a>”的论文的关键方面了。</p><p id="e9ec" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">这篇论文是利用<em class="iu">用户反应预测</em>问题中的噪声和不完整数据编写的。结帐我们的<a class="ae jr" rel="noopener" href="/@surabhi.punjabi/robustness-for-user-response-prediction-1dd2253f62c5"> <strong class="iv hi"> <em class="iu">博客</em> </strong> </a> <strong class="iv hi"> <em class="iu"> </em> </strong>描述了领域中对健壮性的需求。</p><p id="cf32" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">关键思想是使用稳健优化的原理来扩展因式分解机器。然后，通过导出损失w.r.t .的上限和不确定性矩阵<strong class="iv hi"> <em class="iu"> U </em> </strong>，将所得的极大极小公式转化为纯极小化问题。</p><blockquote class="ip iq ir"><p id="8a42" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">本文提出了两种新的算法:<br/> -鲁棒因子分解机(RFM)。<br/> -稳健的场感知因子分解机器(RFFM)。</p></blockquote><p id="3c89" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">在真实世界大规模数据集上的大量实验给出了所提出算法的性能和可扩展性的见解。</p><blockquote class="ip iq ir"><p id="89f2" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">有希望的结果:<br/> -在嘈杂的环境中对数损耗显著降低(4.45%至38.65%)。<br/> -在无噪音设置下，性能略有下降(-0.24%至-1.1%)。</p></blockquote><p id="6dbe" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd js jf jg jh jt jj jk jl ju jn jo jp jq ha bi translated">这里有一个基于Spark的开源分布式算法实现<a class="ae jr" href="https://www.dropbox.com/sh/ny6puvtopl98339/AACExLZ0waDL_ibWhfNItJfGa?dl=0" rel="noopener ugc nofollow" target="_blank">。在各种分类场景中评估RFM和RFFMs是一个值得探索的有趣领域。</a></p><blockquote class="mh"><p id="6c93" class="mi mj hh bd mk ml mm mn mo mp mq jq dx translated">RFMs和RFFMs是独立于域的公式，适用于任何有噪声/不完整数据的域。</p></blockquote></div><div class="ab cl jv jw go jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="ha hb hc hd he"><h2 id="f54c" class="ll kd hh bd ke lm ln lo ki lp lq lr km js ls lt kq jt lu lv ku ju lw lx ky ly bi translated">将健壮性放在首位</h2><p id="4923" class="pw-post-body-paragraph is it hh iv b iw la iy iz ja lb jc jd js lc jg jh jt ld jk jl ju le jo jp jq ha bi translated">随着输入信号中噪声的增加，设计包含这种不确定性的分类器是很重要的。区域渔业管理系统和区域渔业管理系统是朝着这个方向迈出的一步。在树集成和深度神经网络中结合鲁棒性是一个有前途的研究领域。</p></div></div>    
</body>
</html>