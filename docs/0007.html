<html>
<head>
<title>Overcoming Missing Values In A Random Forest Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">克服随机森林分类器中的缺失值</h1>
<blockquote>原文：<a href="https://medium.com/airbnb-engineering/overcoming-missing-values-in-a-random-forest-classifier-7b1fc1fc03ba?source=collection_archive---------0-----------------------#2015-04-07">https://medium.com/airbnb-engineering/overcoming-missing-values-in-a-random-forest-classifier-7b1fc1fc03ba?source=collection_archive---------0-----------------------#2015-04-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="3993" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者:阿洛克·古普塔</p><h2 id="8723" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">没有陌生人</h2><p id="f95e" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">Airbnb试图建立一个世界，在那里人们可以<a class="ae kc" href="http://blog.airbnb.com/belong-anywhere/" rel="noopener ugc nofollow" target="_blank">属于任何地方</a>，没有<a class="ae kc" href="http://blog.airbnb.com/creating-onelessstranger-stories-belonging/" rel="noopener ugc nofollow" target="_blank">没有陌生人</a>。这有助于主人敞开家门感到舒适，也有助于客人充满信心地环游世界，与他们从未谋面的人呆在一起。</p><p id="0355" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然Airbnb社区的几乎所有成员都本着善意互动，但寻求利用该平台获利的不良行为者群体正在不断缩小。这个问题并不是Airbnb独有的:社交网络与试图向用户发送垃圾邮件或钓鱼来获取其详细信息的行为进行斗争；电子商务网站试图防止被盗信用卡的使用。Airbnb的<a class="ae kc" href="https://www.airbnb.com/trust" rel="noopener ugc nofollow" target="_blank">信任和安全</a>团队不知疲倦地工作，从Airbnb社区中清除不良行为者，并帮助使该平台成为一个更安全和值得信赖的地方，以体验归属感。</p><h2 id="0c5c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">随机林中缺少值</h2><p id="2f50" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">我们可以训练机器学习模型来识别新的不良因素(更多详细信息请参见之前的博客文章<a class="ae kc" href="http://nerds.airbnb.com/architecting-machine-learning-system-risk/" rel="noopener ugc nofollow" target="_blank">为风险构建机器学习系统</a>)。我们使用的一个特殊的模型系列是随机森林分类器(RFC)。RFC是一个树的集合，每个树都是使用带标签的完整输入训练数据独立生长的。通过完成，我们明确地表示没有缺失值，即空值或NaN值。但实际上，数据经常会有(许多)缺失值。特别是，预测性很强的要素并不总是有可用的值，因此必须在训练随机森林之前对其进行估算。</p><p id="6e60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，随机森林方法/包鼓励两种处理缺失值的方式:a)丢弃缺失值的数据点(不推荐)；b)用中位数(对于数值)或众数(对于分类值)填充缺失值。虽然a)没有通过删除数据点来使用所有可用的信息，但b)有时会对具有许多间隙和重要结构的数据集刷得太宽。</p><p id="e435" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有一些替代技术可以处理缺失值，但大多数技术的计算开销都很大，例如，重复迭代随机森林训练来计算邻近度。我们在本文中提出的是一种单步预计算方法，该方法对要素进行归一化处理，以构建一个距离度量，用于使用k个最近邻的中值来填充缺失值。</p><p id="25fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的欺诈预测模型中的所有特征分为两种类型:a)数字型和b)分类型。布尔特征可以被认为是分类特征的一个特例。由于我们从事欺诈检测业务，我们的标签是二元的:如果数据点不是欺诈，则为0，如果数据点是欺诈，则为1。下面是一些我们希望比较的缺失值处理的特征转换。</p><h2 id="56be" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">转换</h2><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kd"><img src="../Images/0ecd82bc423af3692f21e6cb058346fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*lo9GiUferroWAxoVbNg3nA.png"/></div></figure><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kl"><img src="../Images/3f3e83d382bfc40b8820cf3bccc83e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*bO69s9-W9B-py6_aIqIhOw.png"/></div></figure><h2 id="720c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">解释</h2><p id="ccc9" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">缩放变换Fn和Fc的目的是双重的。首先要使转换可逆，这样就不会丢失任何信息。其次，<em class="km">对于每个特征，在区间[0，1]内均匀分布</em>有欺诈的数据点。如果我们将数据视为N维空间中的点，其中N是特征的数量，那么两个数据点之间在每个维度中的距离变得可比较。所谓可比较，我们是指在第一维度中距离为0.4包含的欺诈数据点是第二维度中距离为0.2的两倍。这使得能够更好地构建距离度量来识别欺诈。</p><h2 id="1e93" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">使用K-最近邻的插补</h2><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kn"><img src="../Images/253936c70e8c8d94c850b4fefd6b29f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*lbcUKfDkPId4AYnNOLoHAA.png"/></div></figure><h2 id="0c80" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">实验</h2><p id="0b55" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">为了查看上述特征变换的效果，我们使用来自<a class="ae kc" href="http://archive.ics.uci.edu/ml/" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>的成人数据集，并评估模型在不同特征变换和缺失值比例下的性能。数据集包含32，561行和14个特征，其中8个是分类的，其余4个是数字的。布尔标签对应于成年人的收入水平是高于还是低于每年$50k。我们以4:1的比例将数据集分别划分为训练集和测试集。</p><p id="b92b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在第一个实验中，我们使用以下方法比较了不同的模型:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es ko"><img src="../Images/f4d7b4d70bd27b8e3baf011701b4ed6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*mvDMR7WNEQ7-yu0Q7gPwwA.png"/></div></figure><p id="bfcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，M和λ是未指定的参数，我们将在实验过程中循环这些参数的不同值。将使用曲线下面积(AUC)分数来判断每个模型的性能，该分数测量受试者操作特征(ROC)图下的面积(这是真阳性率对假阳性率的图)。我们将测试以下九种型号:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kp"><img src="../Images/3b15296d148562843e2dd0e237fd54c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*MfgBkdw4DQDXISEC8ONm3Q.png"/></div></figure><h1 id="9c53" class="kq jd hh bd je kr ks kt ji ku kv kw jm kx ky kz jp la lb lc js ld le lf jv lg bi translated">结果</h1><h2 id="805c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">模型比较</h2><p id="65b0" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">首先，我们考虑对于在RFC训练过程中具有固定数量的树(100)和用于NNMV插补的固定数量的最近邻(100)的不同[latex]M[/latex]和[latex]\lambda[/latex]值，模型如何表现。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/22278a30b71ef89f91f86b81ae710873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QuWmDi4Ive74Ri0_.png"/></div></div></figure><p id="3a82" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图展示了一些有趣的模式，有些直观，有些令人惊讶:</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es lm"><img src="../Images/ea965cdc7a50eb79952b82777c413eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*2IQ4nowOmLyqJgFC5BSXvg.png"/></div></figure><h1 id="52d8" class="kq jd hh bd je kr ks kt ji ku kv kw jm kx ky kz jp la lb lc js ld le lf jv lg bi translated">鲁棒性检查</h1><p id="a5ef" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">观察到模型8)优于其他候选模型后，我们接下来检查模型8)如何与基线进行比较，因为我们改变了RFC训练中的树的数量和NNMV插补中的最近邻居的数量。我们采用上面的第四种情况，其中60%的值丢失，我们选择λ=0.5。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/13a200bca03da2d810c9ca7459169b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xrOjv3ju5VchTsp9.png"/></div></div></figure><p id="78bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">左边的图没有表明模型8)的性能随着NNMV插补中使用的最近邻的数量而提高。然而，随着树的数量增加，性能的提高有一个一致的模式，在大约100棵树后达到稳定。右边的图显示了使用转换后的特征集训练RFC的速度有多快。这是意料之中的，因为我们没有在基线模型中将分类特征分解为许多二元特征，而是在模型8)中保持固定的特征数量。</p><h2 id="738e" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">效率影响</h2><p id="4f01" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">考虑上述场景之一的ROC曲线，比如说，树的数量是100，使用的最近邻居的数量是100。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es ln"><img src="../Images/df102105a811c7debe243da26b2037f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/0*T5vLmbujO5im3vLK.png"/></div></figure><p id="0763" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">举例来说，ROC曲线的改善表明，当保持回忆固定在80%时，假阳性率从26%下降到24%。假设每天我们对100万个事件进行评分，其中99%是非欺诈性的，每个标记的事件都需要人工审核，每个审核需要10秒钟。那么前面提到的误报率的降低可以节省复习1，000，000 x 0.99 x 0.02 = 19，800个事件或者19，800 / (6 x 60) =每天55个小时的复习！这就是为什么即使一个RFC的auc分数提高了个位数或十进制数，也会对部门的效率产生巨大影响。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es lo"><img src="../Images/3913f6470a7657e02386189e67b4eb30.png" data-original-src="https://miro.medium.com/v2/resize:fit:108/format:webp/1*YsUOrWx3mRxZZljtc9xZyw.png"/></div></figure><h2 id="888d" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">在<a class="ae kc" href="http://airbnb.io" rel="noopener ugc nofollow" target="_blank"> airbnb.io </a>查看我们所有的开源项目，并在Twitter上关注我们:<a class="ae kc" href="https://twitter.com/AirbnbEng" rel="noopener ugc nofollow" target="_blank">@ Airbnb eng</a>+<a class="ae kc" href="https://twitter.com/AirbnbData" rel="noopener ugc nofollow" target="_blank">@ Airbnb data</a></h2></div><div class="ab cl lp lq go lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ha hb hc hd he"><p id="fedc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="km">原载于2015年4月7日nerds.airbnb.com</em><em class="km"/><a class="ae kc" href="http://nerds.airbnb.com/large-scale-payments-systems-ruby-rails/" rel="noopener ugc nofollow" target="_blank"><em class="km">。</em></a></p></div></div>    
</body>
</html>