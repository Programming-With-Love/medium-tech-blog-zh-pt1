<html>
<head>
<title>How to Fine-Tune Sentence-BERT for Question Answering on Slack Bots</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何微调Slack机器人问答系统中的句子-BERT</h1>
<blockquote>原文：<a href="https://medium.com/capital-one-tech/how-to-fine-tune-sentence-bert-for-question-answering-5107fa5224c9?source=collection_archive---------0-----------------------#2021-07-07">https://medium.com/capital-one-tech/how-to-fine-tune-sentence-bert-for-question-answering-5107fa5224c9?source=collection_archive---------0-----------------------#2021-07-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="1c29" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一个关于使用句子变形库微调问题匹配的句子变形库的简单教程</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/d28eac4becaaf23ec38dfcf047bda906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f-Iu9JoSM5lebrxO.jpg"/></div></div></figure><p id="c0af" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我是Alison，Capital One的一名工程师，正在开发一个内部问答聊天机器人。在Capital One，我们团队沟通的主要方式之一是Slack，这里有数百个讨论频道，讨论的话题从部署软件到公司旅行。在每个渠道中，员工就指定主题进行问答，但许多相同的问题会被重复询问。为了通过自动回答最常见的问题来简化这一支持过程，我的团队开发了一个<a class="ae ke" href="https://slack.com/help/articles/115005265703-Create-a-bot-for-your-workspace" rel="noopener ugc nofollow" target="_blank"> Slack bot </a>。该bot目前用于130多个不同的内部Capital One Slack渠道，其中许多渠道包含超过1000名成员。</p><p id="be53" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">当一个团队希望将我们的机器人添加到他们的频道时，他们会创建一组问答组，包括(1)某个问题的多种表达方式，以及(2)问题变体的相应答案。在生产中，bot使用这些问答组来微调问题匹配模型，该模型将传入的Slack消息与已知问题进行匹配。当bot在Slack通道中收到消息时，它可以用问题建议或与传入消息非常匹配的问题进行回复。当一个问题推荐被点击后，机器人会回复与之对应的答案。随着时间的推移，问答组的集合可以被修改，模型可以再次微调。我们用于问题匹配的模型是<a class="ae ke" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT </a>(来自变形金刚的双向编码器表示)，具体来说就是句子-BERT。</p><p id="0309" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在这篇文章中，我将根据我为Capital One构建这个内部机器人的经验，分享一些关于如何微调问题匹配的<a class="ae ke" href="https://arxiv.org/abs/1908.10084" rel="noopener ugc nofollow" target="_blank">句子-BERT </a>的技巧。</p><h1 id="1e3c" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">什么是句子-伯特？</h1><p id="4f0e" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">句子-BERT是一个单词嵌入模型。<a class="ae ke" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>模型用于通过将短语、单词或单词片段(单词的一部分)转换成矢量来用数字表示语言。这些模型可以在大型背景语料库(数据集)上进行预训练，然后用针对特定领域或任务的较小语料库进行更新。这个过程被称为微调。</p><p id="5c5d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">最好的单词嵌入模型能够表示文本含义，包括上下文。例如，两个不同单词sleepy和疲惫的向量表示将非常相似，因为它们往往出现在相似的上下文中。BERT就是这些高性能模型中的一个，句子-BERT就是从这个模型中派生出来的。它是由谷歌研究人员在2018年开发的，并在超过11，000本书和整个维基百科上进行训练。</p><p id="ba9a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我们特别选择了Sentence-BERT，因为它已经针对单个句子级别的更快相似性计算进行了优化，这使得它非常适合我们的问题匹配任务。正如你在下面的表格中看到的，Sentence-BERT在各种NLP任务中表现非常好，最显著的是我们在<a class="ae ke" href="https://paperswithcode.com/sota/semantic-textual-similarity-on-sts-benchmark" rel="noopener ugc nofollow" target="_blank">语义文本相似度</a> (STS)上的用例。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lc"><img src="../Images/11c7380c650383719404af1395b161d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*goCtY35ukNaFj01R5RtKGQ.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><em class="lh">“Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks” (https://arxiv.org/abs/1908.10084) by Nils Reimers and Iryna Gurevych is licensed under CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/).</em></figcaption></figure><p id="fed3" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">尽管仅使用预训练的句子-BERT模型就可能获得有意义的结果，但我们看到了预训练模型和我们仅使用来自我们自己的Slack数据的7，000个新话语(问题和答案)进行微调的模型之间在准确性上的巨大差异。当在200个新测试问题上评估这两个模型时，预训练模型的问题匹配准确率为52%，微调模型的问题匹配准确率为79%。随着我们增加用于微调的数据量，精确度进一步提高。</p><h1 id="5646" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">教程:使用句子-BERT进行问题匹配</h1><p id="5e19" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">假设我们想要使用Sentence-BERT来确定哪些问答组与传入的Slack消息最匹配。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es li"><img src="../Images/693638b64e7dc126596e13077c6d8a01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MVSzXPzJjIU7cG2Jy1yChw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><em class="lh">User Icon Source (http://freepik.com/), Robot Icon Source (http://flaticon.com/) — (made by user Good Ware)</em></figcaption></figure><p id="709b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我们使用<a class="ae ke" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子转换库</a>，这是一个用于最先进的句子和文本嵌入的Python框架。我们整理数据，微调模型，然后用最终的模型进行问题匹配。让我们来看一下实现它的步骤，从数据集开始，到推理结束。</p><h1 id="a867" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">一.数据示例</h1><p id="3f41" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">假设我们希望我们的机器人回答关于烹饪博客的问题。我们的数据集有三个问题组。每组包含一些问题变体和相应的答案。问题变体越多越好，但是为了保持这个句子-BERT教程的简单，我们将只使用几个。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lj lk l"/></div></figure><p id="9b3f" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">问题与其对应的答案之间是多对一的关系。我们有三个问答小组，每个小组有两到三个不同的问题。我们希望模型能够学习每组问题之间的语义关系。例如，如果我们从组1中选取两个示例问题，并使用模型将每个问题转换为单词嵌入向量:</p><p id="afdf" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ll">有哪些我会做的一锅饭？→ v1 </em></p><p id="a5e2" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ll">有哪些简单易做的食谱？→ v2 </em></p><p id="a7f8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我们希望v1和v2根据一个<a class="ae ke" href="https://en.wikipedia.org/wiki/Metric_(mathematics)" rel="noopener ugc nofollow" target="_blank">距离度量</a>像<a class="ae ke" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦距离</a>彼此接近。另一方面，如果我们从组3获取一条消息，我在您的一个配方中发现了一个错别字，并将其转换为v3，我们希望v3根据相同的度量远离v1和v2。</p><h1 id="8267" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">二。三重损失</h1><p id="e1fd" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">在微调过程的每次迭代期间，我们选择锚向量v1来关注。然后，我们选择一个正数据点和一个负数据点进行比较:v2来自与v1相同的组，v3来自不同的组。然后，我们最小化v1和v2之间的距离(锚和正)，同时最大化v1和v3之间的距离(锚和负)。这种优化的损失函数被称为<a class="ae ke" href="https://en.wikipedia.org/wiki/Triplet_loss" rel="noopener ugc nofollow" target="_blank">三重损失</a>。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/58093c6241a4bc2e65bcdd540870f80f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ujFg-c-OQH22QHo-C92Vlw.png"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx"><em class="lh">“Given a triplet of (anchor, positive, negative), the loss minimizes the distance between anchor and positive while it maximizes the distance between anchor and negative.” (Nils Reimers: </em><a class="ae ke" href="https://www.sbert.net/docs/package_reference/losses.html#tripletloss)." rel="noopener ugc nofollow" target="_blank"><em class="lh">https://www.sbert.net/docs/package_reference/losses.html#tripletloss).</em></a><em class="lh"> loss = max(distance(anchor, positive) — distance(anchor, negative) + margin, 0).</em></figcaption></figure><h1 id="6849" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">三。向模型输入数据</h1><p id="168e" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">让我们看看输入到模型中进行微调的最终数据。我们将这些数据放入一个<a class="ae ke" href="https://en.wikipedia.org/wiki/Tab-separated_values" rel="noopener ugc nofollow" target="_blank"> TSV文件</a>中，其中每一行包含一个组号，后跟问题或答案文本。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="lj lk l"/></div></figure><p id="0ee9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">请注意，我们在每个编号组的末尾都包含了答案。虽然答案的结构通常与其相关问题不同，但它们通常包括对部分问题或其他相关信息的重新表述。我们发现模型可以从这种语义关系中学习。将答案包含在数据中进行微调，即使在推理过程中仅使用问题进行比较，也会在问题匹配准确性方面产生显著差异。</p><h1 id="24ab" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">四。微调模型</h1><p id="b097" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">现在我们的数据已经准备好了，我们可以继续微调模型。<strong class="jk hi">下面的代码是一个玩具示例</strong>-我已经成功地使用了7000多个数据点，但没有尝试使用更少的数据点，您需要调整<strong class="jk hi">批量大小</strong>和<strong class="jk hi">周期数</strong>，这取决于您拥有的数据量和您发现的最佳表现。在微调过程中，您可能还想对测试数据使用<a class="ae ke" href="https://www.sbert.net/docs/package_reference/evaluation.html#sentence_transformers.evaluation.TripletEvaluator" rel="noopener ugc nofollow" target="_blank"> TripletEvaluator </a>，但是为了保持本教程的简单，我没有在这里包括它。</p><pre class="ix iy iz ja fd lm ln lo lp aw lq bi"><span id="0670" class="lr kg hh ln b fi ls lt l lu lv"># sentence-transformers==1.0.4, torch==1.7.0.<br/>import random<br/>from collections import defaultdict<br/>from sentence_transformers import SentenceTransformer,SentencesDataset<br/>from sentence_transformers.losses import TripletLoss<br/>from sentence_transformers.readers import LabelSentenceReader, InputExample<br/>from torch.utils.data import DataLoader </span><span id="ece7" class="lr kg hh ln b fi lw lt l lu lv"># Load pre-trained model - we are using the original Sentence-BERT for this example.<br/>sbert_model = SentenceTransformer('bert-base-nli-stsb-mean-tokens') </span><span id="131c" class="lr kg hh ln b fi lw lt l lu lv"># Set up data for fine-tuning<br/>sentence_reader = LabelSentenceReader(folder='~/tsv_files')<br/>data_list = sentence_reader.get_examples(filename='recipe_bot_data.tsv')<br/>triplets = triplets_from_labeled_dataset(input_examples=data_list)<br/>finetune_data = SentencesDataset(examples=triplets, model=sbert_model)<br/>finetune_dataloader = DataLoader(finetune_data, shuffle=True, batch_size=16)</span><span id="3175" class="lr kg hh ln b fi lw lt l lu lv"># Initialize triplet loss<br/>loss = TripletLoss(model=sbert_model)</span><span id="f6b5" class="lr kg hh ln b fi lw lt l lu lv"># Fine-tune the model<br/>sbert_model.fit(train_objectives=[(finetune_dataloader, loss)], epochs=4,output_path='bert-base-nli-stsb-mean-tokens-recipes')</span></pre><h1 id="990e" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">动词 （verb的缩写）推理</h1><p id="491e" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">现在我们有了新的微调模型，我们可以用它来转换任何文本。对于我们推荐点击问题以接收其相关答案的任务，我们使用余弦距离来确定松弛消息和已知问题之间的语义相似性。</p><p id="aa97" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">为简单起见，我们将新问题与已知问题进行比较，而不是与答案进行比较。然而，我们也可以直接将新问题与答案选项进行比较，特别是因为我们已经在微调过程中包含了答案。</p><p id="f9b7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在生产中，预计算<strong class="jk hi">问题向量</strong>并将其与相应的<strong class="jk hi">答案</strong>一起存储是很有用的。这使我们能够快速计算传入消息和现有问题之间的距离，按距离排序，然后提供与传入消息最接近的问题对应的答案。然而，为了简单起见，从数据库或文件中读取预存数据不包括在下面的示例代码中。</p><p id="bec1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">假设我们刚刚收到Slack消息<em class="ll">厨师好，我想从一些简单的食谱开始。有什么建议吗？</em>以下是我们制作相关问答的步骤。</p><p id="0cad" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">1.使用我们的微调模型将传入的Slack消息转换为向量。</p><p id="a7af" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">样本输入:</p><pre class="ix iy iz ja fd lm ln lo lp aw lq bi"><span id="eb5d" class="lr kg hh ln b fi ls lt l lu lv">new_question = """Hello chefs, I would like to get started with some easy recipes. Any suggestions?"""<br/>recipe_model = SentenceTransformer('bert-base-nli-stsb-mean-tokens-recipes')<br/>encoded_question = recipe_model.encode([new_question])</span></pre><p id="987d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">2.将结果向量与<strong class="jk hi"> <em class="ll"> q_a_mappings </em> </strong>中所有预先计算的问题向量进行比较，排序，并显示前<em class="ll"> n </em>个匹配。在本例中，我们显示两个匹配项。我们将问题向量(嵌入)、问题文本和答案存储在三个相同长度的平行列表中。这样，相关的嵌入、问题和答案都可以方便地位于每个列表的相同索引处。相似度计算代码是受<a class="ae ke" href="https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic-search/semantic_search.py" rel="noopener ugc nofollow" target="_blank">这个例子</a>的启发。</p><pre class="ix iy iz ja fd lm ln lo lp aw lq bi"><span id="2948" class="lr kg hh ln b fi ls lt l lu lv"># scipy==1.5.4, numpy==1.19.5<br/>from scipy import spatial<br/>import numpy as np</span><span id="7f67" class="lr kg hh ln b fi lw lt l lu lv">q_a_mappings = {'Question Embedding': [[ ], [ ], [ ], ...], 'Question Text': ['What should I cook after work?', 'What are some one-pot meals I can cook?', ...], 'Corresponding Answer': ['For easy one-pot or weeknight recipes, please access this [link].', 'For easy one-pot or weeknight recipes, please access this [link].', ...]}</span><span id="2355" class="lr kg hh ln b fi lw lt l lu lv">question_embeddings = q_a_mappings['Question Embedding'] question_texts = q_a_mappings['Question Text']<br/>answer_mappings = q_a_mappings['Corresponding Answer']</span><span id="98b3" class="lr kg hh ln b fi lw lt l lu lv">distances = spatial.distance.cdist(np.array(encoded_question), question_embeddings, 'cosine')[0]<br/>results = zip(range(len(distances)), distances)<br/>results = sorted(results, key=lambda x: x[1])</span><span id="c567" class="lr kg hh ln b fi lw lt l lu lv">for idx, distance in results[0:2]: # just getting top<br/>    print(f"\nMatch {idx+1}:")<br/>    print(question_texts[idx])<br/>    print(answer_mappings[idx])</span></pre><p id="2741" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">样本输出:</p><pre class="ix iy iz ja fd lm ln lo lp aw lq bi"><span id="0564" class="lr kg hh ln b fi ls lt l lu lv">Match 1:<br/>What are some easy recipes to make?<br/>For easy one-pot or weeknight recipes, please access this [link].</span><span id="9098" class="lr kg hh ln b fi lw lt l lu lv">Match 2:<br/>Do you have advice on how to get started with cooking?<br/>Beginner cooking tutorials can be accessed [here].</span></pre><h1 id="a5f2" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">不及物动词结论</h1><p id="cb97" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">这就对了。这是一个简单的介绍，关于如何使用句子变形库来微调问题回答的句子-BERT。请查看<a class="ae ke" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">库文档</a>，了解更多使用方法。</p><p id="cae8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><a class="ae ke" href="https://www.freepik.com/vectors/background" rel="noopener ugc nofollow" target="_blank"> <em class="ll">背景矢量</em> </a> <em class="ll">由starline创建—【www.freepik.com】<a class="ae ke" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank"><em class="ll"/></a></em></p></div><div class="ab cl lx ly go lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ha hb hc hd he"><p id="4040" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ll">披露声明:2021资本一。观点是作者个人的观点。除非本帖中另有说明，否则Capital One不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</em></p><p id="3b5f" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ll">最初发表于</em><a class="ae ke" href="https://www.capitalone.com/tech/machine-learning/how-to-finetune-sbert-for-question-matching/" rel="noopener ugc nofollow" target="_blank"><em class="ll">【https://www.capitalone.com】</em></a><em class="ll">。</em></p></div></div>    
</body>
</html>