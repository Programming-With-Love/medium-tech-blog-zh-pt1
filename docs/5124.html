<html>
<head>
<title>How to use Google’s vision API with Java — Mendix How-to</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Java中使用Google的vision API——Mendix How-to</h1>
<blockquote>原文：<a href="https://medium.com/mendix/how-to-use-googles-vision-api-with-java-mendix-how-to-41ec961832b?source=collection_archive---------4-----------------------#2021-06-10">https://medium.com/mendix/how-to-use-googles-vision-api-with-java-mendix-how-to-41ec961832b?source=collection_archive---------4-----------------------#2021-06-10</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><figure class="ht hu fm fo hv hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff hs"><img src="../Images/a65b623b131ceda49747170491f8e07e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tuzARk12TCgakB--F5yGpA.png"/></div></div></figure><div class=""/><h1 id="fe9b" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">最近我一直在重新观看去年的一些会议。因此，当我偶然发现我的同事Alistair Crawford关于使用谷歌的面部检测API，使用他们的Java库的一个会话时，我必须尝试一下。</h1><h1 id="f454" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">虽然我在大学里学过Java，但我很少在我的职业生活中使用它，而且我已经很久没有练习使用这些技能了，所以我跳到了<a class="ae ka" href="https://github.com/mxcrawford/mx-world-2-0-face-detect-blur" rel="noopener ugc nofollow" target="_blank"> github repo </a>上，并沉迷其中。</h1><figure class="kb kc kd ke fq hw"><div class="bz el l di"><div class="kf kg l"/></div></figure><h1 id="f6ad" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">开始之前</h1><p id="c382" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">在我们出发之前，我们需要一些东西，所以在我们开始之前，花一点时间来确保你有所有的东西。</p><p id="2319" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">您将需要:</p><blockquote class="lj lk ll"><p id="0afd" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">Mendix Studio Pro 8以上版本(本例我用的是8.12)。</p><p id="4b65" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">你可以在www.Eclipse.org/downloads/的<a class="ae ka" href="https://www.eclipse.org/downloads/" rel="noopener ugc nofollow" target="_blank">下载Eclipse IDE。</a></p><p id="ec2e" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">一个启用了<a class="ae ka" href="https://cloud.google.com/vision/?hl=en_GB" rel="noopener ugc nofollow" target="_blank"> Google Vision API </a>的<a class="ae ka" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Cloud </a>项目。</p><p id="4b3c" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">添加到Google Cloud项目中的<a class="ae ka" href="https://cloud.google.com/iam/docs/service-accounts" rel="noopener ugc nofollow" target="_blank">服务帐户</a>，角色为“所有者”。</p><p id="35a1" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">你需要确保谷歌视觉API启用和设置计费，这将不会与它一起工作。</p><p id="e284" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated">请务必观看来自Mendix World 2020的Alistairs原创<a class="ae ka" href="https://mxworld2020.mendix.com/session/extending-mendix-apps-with-java/" rel="noopener ugc nofollow" target="_blank">会议</a>。</p></blockquote><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div class="fe ff lq"><img src="../Images/dad7076f5ddd5951cfcddce5ec525198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*pstaRhc78kcUZgTiBO5B2A.png"/></div><figcaption class="lr ls fg fe ff lt lu bd b be z ek"><a class="ae ka" href="https://bit.ly/MXW21" rel="noopener ugc nofollow" target="_blank">https://bit.ly/MXW21</a></figcaption></figure><h1 id="3fb2" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">获取API的访问密钥</h1><p id="0ca7" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">通常，为了调用API，您需要将自己认证为允许的用户，这是使用访问密钥来完成的。</p><p id="ecf6" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">为此:</p><p id="6250" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">-转到谷歌云项目概述中的项目。在左侧，转到<strong class="bd lv"> IAM &amp; Admin </strong>，然后转到<strong class="bd lv">服务账户。</strong></p><p id="f54b" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">-打开添加到项目中的服务帐户。您现在应该会看到这样的屏幕:</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff lw"><img src="../Images/36ee8b62942436abb7cdeb9b954e951c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cl12_9AeBA5_O8GK.png"/></div></div></figure><p id="fc60" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">-在页面顶部的选项卡中，转到<strong class="bd lv">键</strong></p><p id="8cd2" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">-点击<strong class="bd lv">添加键</strong></p><p id="45e6" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">-选择<strong class="bd lv"> JSON </strong>作为密钥类型，点击<strong class="bd lv">创建</strong></p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff lx"><img src="../Images/309400a4f126e40acedaff2d78875383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QP-yHFaCDctHYAr3.png"/></div></div></figure><p id="dd72" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">单击create后，会要求您保存JSON文件。请务必这样做，因为您在这里只有这个选项。您将无法选择以后重新下载它，如果它丢失了，您将不得不创建一个新的密钥，所以要100%确定它保存在某个安全的地方。</p><h1 id="7f14" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">该编码了！</h1><p id="1a43" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">你可以从<a class="ae ka" href="https://github.com/mxcrawford/mx-world-2-0-face-detect-blur" rel="noopener ugc nofollow" target="_blank"> Github </a>获得项目文件。一旦你在Studio Pro中下载并打开了你的应用，你会注意到我们已经做了很多准备工作。域模型中有一些实体:照片、凭证和FaceLocation。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div class="fe ff ly"><img src="../Images/94e060927f9e79255083fbf72306177b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/0*aeKDgQqqgwGeY_9N.png"/></div></figure><ul class=""><li id="b417" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated">照片是上传的图片，我们想处理。</li><li id="7b5a" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">Credentials是一个文件文档，它将保存我们刚刚下载的身份验证密钥。</li><li id="d853" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">面部位置是从Java操作返回的对象或对象列表。</li></ul><h1 id="d631" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">让应用程序运行</h1><p id="3483" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">如果你已经尝试运行你的应用程序，你可能会注意到少了什么，这会导致Java编译错误并阻止你的应用程序启动。</p><p id="a96a" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">这是因为它缺少一些依赖项，我们现在将添加这些依赖项。Mendix可以支持多种Java的依赖管理工具，比如Maven或者Ivy。这个项目使用Ivy，所以我们需要让Ivy自动更新或添加任何缺失的依赖项。</p><ul class=""><li id="798d" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated">打开终端并导航到您的项目目录。</li></ul><p id="b969" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated"><code class="eh mn mo mp mq b">cd C:\\YourProjectLocation</code></p><ul class=""><li id="6823" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated">使用为Ivy运行import命令。</li></ul><p id="64e4" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated"><code class="eh mn mo mp mq b">runivy.cmd</code></p><ul class=""><li id="5fc4" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated">等待它完成。</li></ul><blockquote class="lj lk ll"><p id="3deb" class="kh ki lm bd b kj le kl km kn lf kp kq ln lg kt ku lo lh kx ky lp li lb lc ld hn dt translated"><strong class="bd lv">如果你没有将路径添加到你的Java JDK中作为</strong> <a class="ae ka" href="https://www.digitalcitizen.life/simple-questions-what-are-environment-variables/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lv">系统环境变量</strong> </a> <strong class="bd lv">这将会失败。你可以在这里</strong>  <strong class="bd lv">了解更多关于如何设置这个</strong> <a class="ae ka" href="https://techoral.com/blog/java/adoptopenjdk-install-windows.html" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lv">。</strong></a></p></blockquote><h1 id="7f93" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">上传Google Vision API密钥</h1><p id="1073" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">一旦你的应用程序编译并成功运行，你就必须上传我们从谷歌云控制台下载的API密钥。</p><p id="3ebd" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">运行您的应用程序，并在浏览器中导航至该应用程序。一旦你进入应用程序的主页，你会看到有2个标签:</p><ol class=""><li id="3d13" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld mr mf mg mh dt translated">人脸检测</li><li id="a796" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld mr mf mg mh dt translated">资格证书</li></ol><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff ms"><img src="../Images/554f4ef1c67a03c4bd2649430ec5e4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6g9PKnFui0y8kI_q.png"/></div></div></figure><p id="27f8" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">单击凭据选项卡，然后单击新建。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mt"><img src="../Images/89132798ed1d7e1201ffe00428473af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VXZIki6o6BMjh0YR.png"/></div></div></figure><p id="cffa" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">在弹出窗口中，单击browse并在出现的文件浏览器中选择我们从Google Cloud控制台下载的JSON文件。要结束，请单击保存。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mu"><img src="../Images/52329725bad248dca4b003c33ff5231c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Tzt-as_lnhBmniDX.png"/></div></div></figure><h1 id="2d86" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">测试它</h1><p id="eefd" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">你现在可以第一次完全测试这个应用了。为此，请返回应用程序主页上的“人脸检测”选项卡，然后单击“新建”按钮。</p><p id="9365" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">在出现的弹出窗口中，单击上传图像字段上的浏览，并选择任何包含人脸的照片。为了测试的目的，我使用了一些由人工智能在线创建的计算机生成的人脸图像。单击保存关闭窗口。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mv"><img src="../Images/45b5eeb41779491cd06e17bd0d0451ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pNmeEfZGqVWUeCvw.png"/></div></div></figure><p id="2b84" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">现在，您应该会看到您上传的照片出现在表单中。你现在可以点击模糊面孔来测试这个应用程序。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mw"><img src="../Images/13242cb278871967b604c7d15d076d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ro4YU5Boo8kixSn5.png"/></div></div></figure><p id="29ab" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">您应该会看到类似这样的:</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff mx"><img src="../Images/7554c955872421d63492492e1038322f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cEiREhzjigz6zyuv.png"/></div></div></figure><h1 id="0654" class="jc jd if bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">仔细看看代码</h1><p id="bb38" class="pw-post-body-paragraph kh ki if bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld hn dt translated">现在我们已经让它工作了，让我们看看这段代码实际上在做什么。如果我们检查连接到主页上模糊面孔按钮的微流ACT_ProcessImage。在内部，我们可以看到一个相当简单的流程，它检索我们从数据库上传的凭证文件，然后将它和我们试图处理的图像一起传递到两个独立的Java操作中。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff my"><img src="../Images/7ed0a1c000d0cebfbdd9c73f881f4cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AjUK6MJy2SVwn77_.png"/></div></div></figure><p id="4c11" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">为了找出这些动作在做什么，我们必须在Eclipse中打开这个项目。为此，在Studio Pro中，按F6键为Eclipse部署项目。然后打开eclipse，通过点击顶部导航栏中的File导入项目，然后选择Open projects from file system。</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/e1043da944c9adfe97f0e3159fd6fba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/0*LecYtqK7O7dWt9Zz.png"/></div></figure><p id="d983" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">在打开的新窗口中，选择导入源下的目录，并选择项目的根文件夹，然后单击完成以完成导入</p><figure class="kb kc kd ke fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff na"><img src="../Images/602984984f59d43644273afc0e02fa1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AxWq9172MyXJi4K7.png"/></div></div></figure><p id="ccaa" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">一旦您的项目在左侧的Package explorer中打开，查找Javasource，然后查找子文件夹myfirstmodule.actions。</p><ul class=""><li id="2d17" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated">JA _检测面孔</li><li id="a4e5" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">JA _ BlurBoxes</li></ul><p id="6e1e" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">JA_DetectFaces包含的完整代码如下所示。有关详细信息，请查看粗体行内注释。</p><pre class="kb kc kd ke fq nb mq nc nd aw ne dt"><span id="b93f" class="nf jd if mq b fv ng nh l ni nj">// This file was generated by Mendix Studio Pro.<br/>//<br/>// WARNING: Only the following code will be retained when actions are regenerated:<br/>// - the import list<br/>// - the code between BEGIN USER CODE and END USER CODE<br/>// - the code between BEGIN EXTRA CODE and END EXTRA CODE<br/>// Other code you write will be lost the next time you deploy the project.<br/>// Special characters, e.g., Ã©, Ã¶, Ã , etc. are supported in comments.</span><span id="f36e" class="nf jd if mq b fv nk nh l ni nj">package myfirstmodule.actions;</span><span id="dead" class="nf jd if mq b fv nk nh l ni nj">import java.io.FileInputStream;<br/>import java.io.IOException;<br/>import java.io.InputStream;<br/>import java.util.ArrayList;<br/>import java.util.List;<br/>import com.google.api.gax.core.CredentialsProvider;<br/>import com.google.auth.Credentials;<br/>import com.google.auth.oauth2.GoogleCredentials;<br/>import com.google.cloud.vision.v1.AnnotateImageRequest;<br/>import com.google.cloud.vision.v1.AnnotateImageResponse;<br/>import com.google.cloud.vision.v1.BatchAnnotateImagesResponse;<br/>import com.google.cloud.vision.v1.BoundingPoly;<br/>import com.google.cloud.vision.v1.FaceAnnotation;<br/>import com.google.cloud.vision.v1.Feature;<br/>import com.google.cloud.vision.v1.Image;<br/>import com.google.cloud.vision.v1.ImageAnnotatorClient;<br/>import com.google.cloud.vision.v1.ImageAnnotatorSettings;<br/>import com.google.common.collect.Lists;<br/>import com.google.protobuf.ByteString;<br/>import com.mendix.core.Core;<br/>import com.mendix.systemwideinterfaces.core.IContext;<br/>import com.mendix.webui.CustomJavaAction;<br/>import com.mendix.systemwideinterfaces.core.IMendixObject;<br/>import myfirstmodule.proxies.FaceLocation;</span><span id="286b" class="nf jd if mq b fv nk nh l ni nj">public class JA_DetectFaces extends CustomJavaAction&lt;java.util.List&lt;IMendixObject&gt;&gt;<br/>{<br/> private IMendixObject __SourceImage;<br/> private myfirstmodule.proxies.Photo SourceImage;<br/> private IMendixObject __CredentialsFile;<br/> private myfirstmodule.proxies.Credential CredentialsFile;</span><span id="cd3b" class="nf jd if mq b fv nk nh l ni nj">public JA_DetectFaces(IContext context, IMendixObject SourceImage, IMendixObject CredentialsFile)<br/> {<br/>  super(context);<br/>  this.__SourceImage = SourceImage;<br/>  this.__CredentialsFile = CredentialsFile;<br/> }</span><span id="bc32" class="nf jd if mq b fv nk nh l ni nj"><a class="ae ka" href="http://twitter.com/java" rel="noopener ugc nofollow" target="_blank">@java</a>.lang.Override<br/> public java.util.List&lt;IMendixObject&gt; executeAction() throws Exception<br/> {<br/>  this.SourceImage = __SourceImage == null ? null : myfirstmodule.proxies.Photo.initialize(getContext(), __SourceImage);</span><span id="3156" class="nf jd if mq b fv nk nh l ni nj">this.CredentialsFile = __CredentialsFile == null ? null : myfirstmodule.proxies.Credential.initialize(getContext(), __CredentialsFile);</span><span id="509b" class="nf jd if mq b fv nk nh l ni nj">// BEGIN USER CODE</span><span id="b404" class="nf jd if mq b fv nk nh l ni nj"><strong class="mq ig">// Setup credentials for Google Vision</strong></span><span id="a0a6" class="nf jd if mq b fv nk nh l ni nj">  IContext ctx = getContext();<br/>  InputStream credentialsFIle = Core.getFileDocumentContent(ctx, __CredentialsFile);<br/>  CredentialProvider provider = new CredentialProvider(credentialsFIle);<br/>  ImageAnnotatorSettings imageAnnotatorSettings =<br/>    ImageAnnotatorSettings.newBuilder()<br/>    .setCredentialsProvider(provider)<br/>    .build();<br/>  <br/>  <strong class="mq ig">// Convert photo into format useable for Google Vision</strong><br/>  InputStream fis =  Core.getFileDocumentContent(ctx, __SourceImage);<br/>  ByteString imgBytes = ByteString.readFrom(fis);<br/>  Image img = Image.newBuilder().setContent(imgBytes).build();<br/>  <br/>  <strong class="mq ig">// Set the feature type to Facial Detection</strong></span><span id="6360" class="nf jd if mq b fv nk nh l ni nj">  Feature feat = Feature.newBuilder().setType(Feature.Type.FACE_DETECTION).build();<br/> <strong class="mq ig"> <br/>  // Prepare the request for the API</strong></span><span id="009d" class="nf jd if mq b fv nk nh l ni nj">  AnnotateImageRequest request =<br/>    AnnotateImageRequest.newBuilder().addFeatures(feat).setImage(img).build();<br/>  List&lt;AnnotateImageRequest&gt; requests = new ArrayList&lt;&gt;();<br/>  requests.add(request);</span><span id="f518" class="nf jd if mq b fv nk nh l ni nj"><strong class="mq ig">// Handle responses</strong></span><span id="cb81" class="nf jd if mq b fv nk nh l ni nj">  ArrayList&lt;IMendixObject&gt; faceLocations = new ArrayList&lt;IMendixObject&gt;();<br/>  try (ImageAnnotatorClient client = ImageAnnotatorClient.create(imageAnnotatorSettings)) {<br/>   BatchAnnotateImagesResponse response = client.batchAnnotateImages(requests);<br/>   List&lt;AnnotateImageResponse&gt; responses = response.getResponsesList();<br/>   for (AnnotateImageResponse res : responses) {<br/>    if (res.hasError()) {<br/>     return faceLocations;<br/>    }<br/>    <br/>    <strong class="mq ig">// For each face gather information needed</strong></span><span id="e72d" class="nf jd if mq b fv nk nh l ni nj">    for (FaceAnnotation annotation : res.getFaceAnnotationsList()) {<br/>     BoundingPoly boundingBox = annotation.getBoundingPoly();<br/>     List&lt;com.google.cloud.vision.v1.Vertex&gt; boxVertices = boundingBox.getVerticesList();<br/>     <br/>   <strong class="mq ig">  // Gather X,Y, Width &amp; Height</strong></span><span id="3f71" class="nf jd if mq b fv nk nh l ni nj">     int X = Math.round(boxVertices.get(0).getX());<br/>     int Y = Math.round(boxVertices.get(0).getY());<br/>     int Width = Math.round(boxVertices.get(2).getX()) - X;<br/>     int Height = Math.round(boxVertices.get(2).getY()) - Y;<br/>     <br/>     <strong class="mq ig">// Set FaceLocation Attributes</strong></span><span id="e9f0" class="nf jd if mq b fv nk nh l ni nj">     FaceLocation faceLocation = new FaceLocation(ctx);<br/>     faceLocation.setX(X);<br/>     faceLocation.setY(Y);<br/>     faceLocation.setWidth(Width);<br/>     faceLocation.setHeight(Height);<br/>     <br/>     <strong class="mq ig">// Add new location to List</strong></span><span id="5ead" class="nf jd if mq b fv nk nh l ni nj">     faceLocations.add(faceLocation.getMendixObject());<br/>    }<br/>   }<br/>  }<br/>  return faceLocations;<br/>  // END USER CODE<br/> }</span><span id="8ab8" class="nf jd if mq b fv nk nh l ni nj">/**<br/>  * Returns a string representation of this action<br/>  */<br/> <a class="ae ka" href="http://twitter.com/java" rel="noopener ugc nofollow" target="_blank">@java</a>.lang.Override<br/> public java.lang.String toString()<br/> {<br/>  return "JA_DetectFaces";<br/> }</span><span id="fdd3" class="nf jd if mq b fv nk nh l ni nj">// BEGIN EXTRA CODE<br/> public class CredentialProvider implements CredentialsProvider {</span><span id="0f5d" class="nf jd if mq b fv nk nh l ni nj">private InputStream authStream;<br/>  private boolean usePath=false;<br/>  private String path;</span><span id="72a9" class="nf jd if mq b fv nk nh l ni nj">public CredentialProvider(InputStream inputStream) {<br/>   this.authStream = inputStream;<br/>   this.usePath=false;<br/>  }</span><span id="a194" class="nf jd if mq b fv nk nh l ni nj">public CredentialProvider(String inputPath) {<br/>   this.path = inputPath;<br/>   this.usePath=true;<br/>  }</span><span id="9c6a" class="nf jd if mq b fv nk nh l ni nj"><a class="ae ka" href="http://twitter.com/Override" rel="noopener ugc nofollow" target="_blank">@Override</a><br/>  public Credentials getCredentials() throws IOException {<br/>   // TODO Auto-generated method stub<br/>   if (this.usePath)<br/>   {<br/>    return GoogleCredentials.fromStream(new FileInputStream(path))<br/>      .createScoped(Lists.newArrayList("<a class="ae ka" href="https://www.googleapis.com/auth/cloud-platform" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/cloud-platform</a>"));<br/>   }<br/>   else<br/>   {<br/>    return GoogleCredentials.fromStream(authStream)<br/>      .createScoped(Lists.newArrayList("<a class="ae ka" href="https://www.googleapis.com/auth/cloud-platform" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com/auth/cloud-platform</a>"));<br/>   }<br/>  }</span><span id="a0a2" class="nf jd if mq b fv nk nh l ni nj">}<br/> // END EXTRA CODE<br/>}</span></pre><p id="3030" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">这个动作完成后，应用程序调用第二个动作JA_BlurFaces，你可以在下面看到完整的代码，再次寻找加粗的评论了解详情。</p><pre class="kb kc kd ke fq nb mq nc nd aw ne dt"><span id="6d47" class="nf jd if mq b fv ng nh l ni nj">// This file was generated by Mendix Studio Pro.<br/>//<br/>// WARNING: Only the following code will be retained when actions are regenerated:<br/>// - the import list<br/>// - the code between BEGIN USER CODE and END USER CODE<br/>// - the code between BEGIN EXTRA CODE and END EXTRA CODE<br/>// Other code you write will be lost the next time you deploy the project.<br/>// Special characters, e.g., Ã©, Ã¶, Ã , etc. are supported in comments.</span><span id="8adf" class="nf jd if mq b fv nk nh l ni nj">package myfirstmodule.actions;</span><span id="f875" class="nf jd if mq b fv nk nh l ni nj">import java.awt.Graphics;<br/>import java.awt.image.BufferedImage;<br/>import java.awt.image.BufferedImageOp;<br/>import java.awt.image.ColorModel;<br/>import java.awt.image.ConvolveOp;<br/>import java.awt.image.Kernel;<br/>import java.io.ByteArrayInputStream;<br/>import java.io.ByteArrayOutputStream;<br/>import java.io.InputStream;<br/>import javax.imageio.ImageIO;<br/>import com.mendix.core.Core;<br/>import com.mendix.systemwideinterfaces.core.IContext;<br/>import com.mendix.webui.CustomJavaAction;<br/>import com.mendix.systemwideinterfaces.core.IMendixObject;<br/>import myfirstmodule.proxies.FaceLocation;</span><span id="6726" class="nf jd if mq b fv nk nh l ni nj">public class JA_BlurBoxes extends CustomJavaAction&lt;java.lang.Boolean&gt;<br/>{<br/> private IMendixObject __SoureImage;<br/> private myfirstmodule.proxies.Photo SoureImage;<br/> private IMendixObject __DestinationImage;<br/> private myfirstmodule.proxies.Photo DestinationImage;<br/> private java.util.List&lt;IMendixObject&gt; __FaceLocations;<br/> private java.util.List&lt;myfirstmodule.proxies.FaceLocation&gt; FaceLocations;</span><span id="6353" class="nf jd if mq b fv nk nh l ni nj">public JA_BlurBoxes(IContext context, IMendixObject SoureImage, IMendixObject DestinationImage, java.util.List&lt;IMendixObject&gt; FaceLocations)<br/> {<br/>  super(context);<br/>  this.__SoureImage = SoureImage;<br/>  this.__DestinationImage = DestinationImage;<br/>  this.__FaceLocations = FaceLocations;<br/> }</span><span id="6ff3" class="nf jd if mq b fv nk nh l ni nj"><a class="ae ka" href="http://twitter.com/java" rel="noopener ugc nofollow" target="_blank">@java</a>.lang.Override<br/> public java.lang.Boolean executeAction() throws Exception<br/> {<br/>  this.SoureImage = __SoureImage == null ? null : myfirstmodule.proxies.Photo.initialize(getContext(), __SoureImage);</span><span id="967c" class="nf jd if mq b fv nk nh l ni nj">this.DestinationImage = __DestinationImage == null ? null : myfirstmodule.proxies.Photo.initialize(getContext(), __DestinationImage);</span><span id="216f" class="nf jd if mq b fv nk nh l ni nj">this.FaceLocations = new java.util.ArrayList&lt;myfirstmodule.proxies.FaceLocation&gt;();<br/>  if (__FaceLocations != null)<br/>   for (IMendixObject __FaceLocationsElement : __FaceLocations)<br/>    this.FaceLocations.add(myfirstmodule.proxies.FaceLocation.initialize(getContext(), __FaceLocationsElement));</span><span id="2531" class="nf jd if mq b fv nk nh l ni nj">// BEGIN USER CODE<br/>  IContext ctx =  getContext();<br/>  try {</span><span id="a5e3" class="nf jd if mq b fv nk nh l ni nj">  <strong class="mq ig"> // Get input stream from Mendix object and read into Buffered image</strong></span><span id="e839" class="nf jd if mq b fv nk nh l ni nj">   InputStream fis = Core.getFileDocumentContent(ctx, __SoureImage);<br/>   BufferedImage readOnlyImage = ImageIO.read(fis);</span><span id="2733" class="nf jd if mq b fv nk nh l ni nj">   <strong class="mq ig">// New Image, prep for drawing...</strong></span><span id="9e8a" class="nf jd if mq b fv nk nh l ni nj">   BufferedImage image =<br/>     new BufferedImage(readOnlyImage.getWidth(),readOnlyImage.getHeight(), BufferedImage.TYPE_INT_RGB);</span><span id="183c" class="nf jd if mq b fv nk nh l ni nj">Graphics gfx = image.getGraphics();<br/>   gfx.drawImage(readOnlyImage, 0, 0, null);<br/>   gfx.dispose();<br/>   <br/>  <strong class="mq ig"> // A 3x3 kernel that blurs an image</strong></span><span id="dcbf" class="nf jd if mq b fv nk nh l ni nj">   float[] matrix = new float[2500];<br/>   for (int i = 0; i &lt; 2500; i++)<br/>    matrix[i] = 1.0f/2500.0f;<br/>   Kernel kernel = new Kernel(50, 50, matrix);<br/>   BufferedImageOp op = new ConvolveOp(kernel, ConvolveOp.EDGE_NO_OP,null);</span><span id="3fd8" class="nf jd if mq b fv nk nh l ni nj"><strong class="mq ig">// Iterate and blur sub images based on each location</strong><br/>   <br/>   for (FaceLocation location : FaceLocations) {<br/>    BufferedImage dest = image.getSubimage(<br/>      (location.getX()),<br/>      location.getY(),<br/>      location.getWidth(),<br/>      location.getHeight());<br/>    ColorModel cm = dest.getColorModel();<br/>    BufferedImage src = new BufferedImage(cm,<br/>      dest.copyData(dest.getRaster().createCompatibleWritableRaster()),<br/>      cm.isAlphaPremultiplied(),<br/>      null)<br/>      .getSubimage(0, 0, dest.getWidth(), dest.getHeight());<br/>    op.filter(src, dest);<br/>   }<br/>   <br/>   <br/>   <strong class="mq ig">// Write result to Byte array to be stored back in mx object</strong></span><span id="1d8f" class="nf jd if mq b fv nk nh l ni nj">   ByteArrayOutputStream output = new ByteArrayOutputStream();<br/>   ImageIO.write(image, "jpg", output);</span><span id="1b50" class="nf jd if mq b fv nk nh l ni nj"><strong class="mq ig">//Store in InputStream and Write to Mendix object</strong></span><span id="4267" class="nf jd if mq b fv nk nh l ni nj">   InputStream is = new ByteArrayInputStream(output.toByteArray());<br/>   Core.storeImageDocumentContent(ctx, DestinationImage.getMendixObject(), is, image.getWidth(), image.getHeight());</span><span id="0e1e" class="nf jd if mq b fv nk nh l ni nj"><strong class="mq ig">// Cleanup</strong><br/>   output.close();<br/>   is.close();</span><span id="5a2c" class="nf jd if mq b fv nk nh l ni nj">return true;<br/>  } catch (Exception e) {<br/>   throw e;<br/>  }<br/>  // END USER CODE<br/> }</span><span id="c0e9" class="nf jd if mq b fv nk nh l ni nj">/**<br/>  * Returns a string representation of this action<br/>  */<br/> <a class="ae ka" href="http://twitter.com/java" rel="noopener ugc nofollow" target="_blank">@java</a>.lang.Override<br/> public java.lang.String toString()<br/> {<br/>  return "JA_BlurBoxes";<br/> }</span><span id="d1ad" class="nf jd if mq b fv nk nh l ni nj">// BEGIN EXTRA CODE<br/> // END EXTRA CODE<br/>}</span></pre><h2 id="eafd" class="nf jd if bd je nl nm nn ji no np nq jm kr nr ns jq kv nt nu ju kz nv nw jy nx dt translated">代码摘要:</h2><ul class=""><li id="86fe" class="lz ma if bd b kj kk kn ko kr ny kv nz kz oa ld me mf mg mh dt translated">图像和凭证文件被传递到JA_Detect faces中。然后，该操作将凭证和图像发送到Google Vision API。</li><li id="7e0f" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">如果成功，API将返回检测到人脸的位置数组。</li><li id="2e1a" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">然后，结果被映射到FaceLocation对象的列表中，并由操作返回。</li><li id="1c50" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">然后，图像和面部位置列表被传递到JA_BlurFaces。</li><li id="24b4" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">JA_BlurFaces然后使用google提供的位置遍历人脸列表，并使用一些图像绘制库，对人脸进行模糊处理。</li><li id="7abc" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated">结果是提交到数据库，覆盖上传的原始图像，并刷新浏览器中的图像，现在应该显示最终结果。</li></ul></div><div class="ab cl ob oc hb od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="hn ho hp hq hr"><h2 id="1402" class="nf jd if bd je nl nm nn ji no np nq jm kr nr ns jq kv nt nu ju kz nv nw jy nx dt translated">阅读更多</h2><div class="ht hu fm fo hv oi"><a href="https://bit.ly/MXW21" rel="noopener  ugc nofollow" target="_blank"><div class="oj ab ej"><div class="ok ab ol cl cj om"><h2 class="bd ig fv z el on eo ep oo er et ie dt translated">Mendix World 2021 |召集您的应用开发团队2021年9月7日至9日</h2><div class="op l"><h3 class="bd b fv z el on eo ep oo er et ek translated">好像你需要说服…在一个全球制造商社区，他们想通过探索什么来相互学习…</h3></div><div class="oq l"><p class="bd b gc z el on eo ep oo er et ek translated">bit.ly</p></div></div><div class="or l"><div class="os l ot ou ov or ow ib oi"/></div></div></a></div><div class="ht hu fm fo hv oi"><a href="https://www.mendix.com/mendix-world/tracks/" rel="noopener  ugc nofollow" target="_blank"><div class="oj ab ej"><div class="ok ab ol cl cj om"><h2 class="bd ig fv z el on eo ep oo er et ie dt translated">曲目|门迪克斯世界2021</h2><div class="op l"><h3 class="bd b fv z el on eo ep oo er et ek translated">在今年Mendix World开幕之前，手工制作您的议程。浏览专为您量身定制的8个专题讲座中的85个以上专题讲座…</h3></div><div class="oq l"><p class="bd b gc z el on eo ep oo er et ek translated">www.mendix.com</p></div></div><div class="or l"><div class="ox l ot ou ov or ow ib oi"/></div></div></a></div><ul class=""><li id="85ee" class="lz ma if bd b kj le kn lf kr mb kv mc kz md ld me mf mg mh dt translated"><a class="ae ka" href="https://docs.mendix.com/refguide/java-actions" rel="noopener ugc nofollow" target="_blank">https://docs.mendix.com/refguide/java-actions</a></li><li id="93ee" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated"><a class="ae ka" href="https://docs.mendix.com/howto/logic-business-rules/java-api-tutorial" rel="noopener ugc nofollow" target="_blank">https://docs . mendix . com/how to/logic-business-rules/Java-API-tutorial</a></li><li id="de55" class="lz ma if bd b kj mi kn mj kr mk kv ml kz mm ld me mf mg mh dt translated"><a class="ae ka" href="https://docs.mendix.com/apidocs-mxsdk/apidocs/" rel="noopener ugc nofollow" target="_blank">https://docs.mendix.com/apidocs-mxsdk/apidocs/</a></li></ul></div><div class="ab cl ob oc hb od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="hn ho hp hq hr"><p id="f0b6" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated"><em class="lm">来自发布者- </em></p><p id="0c44" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated"><em class="lm">如果你喜欢这篇文章，你可以在我们的</em> <a class="ae ka" href="https://medium.com/mendix" rel="noopener"> <em class="lm">媒体页面</em> </a> <em class="lm">或我们自己的</em> <a class="ae ka" href="https://developers.mendix.com/community-blog/" rel="noopener ugc nofollow" target="_blank"> <em class="lm">社区博客网站</em> </a> <em class="lm">找到更多类似的文章。</em></p><p id="50ef" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated"><em class="lm">希望入门的创客，可以注册一个</em> <a class="ae ka" href="https://signup.mendix.com/link/signup/?source=direct" rel="noopener ugc nofollow" target="_blank"> <em class="lm">免费账号</em> </a> <em class="lm">，通过我们的</em> <a class="ae ka" href="https://academy.mendix.com/link/home" rel="noopener ugc nofollow" target="_blank"> <em class="lm">学苑</em> </a> <em class="lm">即时获取学习。</em></p><p id="6084" class="pw-post-body-paragraph kh ki if bd b kj le kl km kn lf kp kq kr lg kt ku kv lh kx ky kz li lb lc ld hn dt translated">有兴趣更多地参与我们的社区吗？你可以加入我们的 <a class="ae ka" href="https://join.slack.com/t/mendixcommunity/shared_invite/zt-hwhwkcxu-~59ywyjqHlUHXmrw5heqpQ" rel="noopener ugc nofollow" target="_blank"> <em class="lm"> Slack社区频道</em> </a> <em class="lm">或者想更多参与的人，看看加入我们的</em> <a class="ae ka" href="https://developers.mendix.com/meetups/#meetupsNearYou" rel="noopener ugc nofollow" target="_blank"> <em class="lm">遇见ups </em> </a> <em class="lm">。</em></p></div></div>    
</body>
</html>