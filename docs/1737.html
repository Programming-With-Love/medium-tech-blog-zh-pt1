<html>
<head>
<title>Reproducible, Distributed Machine Learning on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes上可重复的分布式机器学习</h1>
<blockquote>原文：<a href="https://medium.com/capital-one-tech/reproducible-distributed-machine-learning-on-kubernetes-capital-one-fb6e39a54f87?source=collection_archive---------4-----------------------#2020-05-12">https://medium.com/capital-one-tech/reproducible-distributed-machine-learning-on-kubernetes-capital-one-fb6e39a54f87?source=collection_archive---------4-----------------------#2020-05-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="4e45" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">在Kubernetes上的分布式模型改装工作流程中收集的见解</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/922f6df4e460a3d1dd78004f9252aac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mfok_eKp2WWf3AmE.jpg"/></div></div></figure><p id="4b7e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi"> <em class="ke">作者Evan Curtin，数据科学首席助理，Card MLGlen Pine，数据科学高级经理，Card ML以及尼克·格罗泽夫斯基，ML和数据实现部首席数据工程师</em>T3】</strong></p><p id="b914" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">作为数据科学家和工程师，我们都希望有一种干净、可重复、分布式的方式来定期改装我们的机器学习模型。但有时我们会面临来自各个方向的障碍。也许您的整个数据生命周期感觉是串连在一起的，团队成员每个人只知道拼图的一部分，或者每个团队成员都有他们自己的定制工作流组件。也许你正在浪费计算能力，并撞上资源的极限。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es kf"><img src="../Images/7c4cd16ccf985c09bf5a941254791b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l8hxBkfVafLA2p_a"/></div></div></figure><p id="50d8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">如果以上任何一个听起来耳熟，我们可以联系起来。我们是遇到过这些问题的平台数据工程师、平台数据科学家和应用数据科学家。在这里，我们通过Kubernetes上的分布式模型改装工作流提供了一些在克服这些问题时收集的见解。我们的过程包括通过Spark的分布式计算引擎转换大量数据，用H2O进行模型训练，并将所有东西都连接到Argo工作流中。结果是一个管道将许多不同的步骤结合在一个统一的方法中，该方法可以扩展以满足需求，并且在不使用时可以缩减到零。</p><h1 id="8b2b" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">这种方法的好处</h1><p id="94cc" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">为了将我们将在下面概述的方法的好处放在上下文中，让我们从基于我们已经看到的一些常见企业机器学习设置的有问题的机器学习工作流开始。假设工作流程大致有五个步骤:</p><ol class=""><li id="a642" class="ld le hh jk b jl jm jo jp jr lf jv lg jz lh kd li lj lk ll bi translated"><strong class="jk hi"> <em class="ke">抓取、连接、转换</em> — </strong>在此步骤中，从数据存储中抓取特征。通过令牌、用户、角色等授予访问权限，即其访问是非标准化的。一旦获取了数据，Spark就会运行连接和转换。</li><li id="83b0" class="ld le hh jk b jl lm jo ln jr lo jv lp jz lq kd li lj lk ll bi translated"><strong class="jk hi"> <em class="ke"> SSH进入EMR </em> </strong> —部落知识规定了如何配置EMR。</li><li id="1f3b" class="ld le hh jk b jl lm jo ln jr lo jv lp jz lq kd li lj lk ll bi translated"><strong class="jk hi"> <em class="ke">培训</em> </strong> —团队使用H20、Spark或其他框架，以极其手工的方式进行培训(例如，如上面的#2，通过SSH-ing到EMR中)。</li><li id="5cdb" class="ld le hh jk b jl lm jo ln jr lo jv lp jz lq kd li lj lk ll bi translated"><strong class="jk hi"> <em class="ke">保存并分析</em> — </strong>模型被保存到S3，在那里它们的血统仍然不清楚。</li><li id="c80d" class="ld le hh jk b jl lm jo ln jr lo jv lp jz lq kd li lj lk ll bi translated"><strong class="jk hi"> <em class="ke">移动到prod </em> </strong> —转换保存的对象，例如将其编译成jar。</li></ol><p id="ec4a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">使用上述开发模式的团队可能会遇到各种各样的问题，例如:</p><h2 id="1ea1" class="lr kh hh bd ki ls lt lu km lv lw lx kq jr ly lz ks jv ma mb ku jz mc md kw me bi translated">不可复制的机器学习流水线</h2><p id="6c7c" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">首先，ML管道不是可复制的，而是需要多个独立的步骤，知识分布在团队中或隔离在单一故障点。大多数团队成员可能不完全理解管道。比较实验在最好的情况下是具有挑战性的，在最坏的情况下是不可能的。</p><h2 id="df7f" class="lr kh hh bd ki ls lt lu km lv lw lx kq jr ly lz ks jv ma mb ku jz mc md kw me bi translated">计算资源不足/浪费</h2><p id="b8bd" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">接下来，你可能会面临计算能力太强和太弱的问题。一个大节点可能仍然不足以训练和调整机器学习模型；或者，它可能比你需要的要多得多。(在大规模EMR集群上生成matplotlib图可能是一种浪费)。这种方法无法利用水平扩展和分布式计算的能力。</p><h2 id="3338" class="lr kh hh bd ki ls lt lu km lv lw lx kq jr ly lz ks jv ma mb ku jz mc md kw me bi translated">高度手动的流程</h2><p id="dfff" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">最后，这一过程因高度人工化而受到影响。团队小心翼翼地从一个步骤移动到下一个步骤，浪费了时间和精力。如果工作从一个团队成员转移到另一个团队成员，或者有一个新人加入，就需要付出巨大的努力。更糟糕的是，工作流程中的每一次运行都存在无数出错的机会。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mf"><img src="../Images/b9a0052c084e0db45ddd566477d2e487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gcXJt-fXLuyGjRYE"/></div></div></figure><p id="be74" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我们真正要解决的是将建模生命周期中许多不同的步骤组合成可重复的管道。利用工作流引擎和分布式计算的能力，我们可以将建模生命周期中的每个特定阶段隔离到其自己的离散任务中，并在更高的级别上协调它们。</p><p id="8cbc" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">让我们深入了解允许我们在Kubernetes上构建可重复工作流的每个组件。</p><h1 id="8afb" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">利用分布式计算</h1><p id="0328" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">随着数据量的增长，单实例计算变得低效或完全不可能。诸如<a class="ae mg" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Spark </a>、<a class="ae mg" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> Dask </a>和<a class="ae mg" href="https://developer.nvidia.com/rapids" rel="noopener ugc nofollow" target="_blank"> Rapids </a>等分布式计算工具可以用来规避成本高昂的垂直扩展的限制。虽然所有这些工具都可以在Kubernetes上运行(参见<a class="ae mg" href="https://kubernetes.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> Dask Kubernetes </a>、<a class="ae mg" href="https://github.com/dask/helm-chart" rel="noopener ugc nofollow" target="_blank"> Dask Helm </a>、<a class="ae mg" href="https://devblogs.nvidia.com/making-data-science-teams-productive-kubernetes-rapids/" rel="noopener ugc nofollow" target="_blank"> RAPIDS K8s </a>)，但我们重点关注Spark，因为它广泛用于数据处理领域，我们可以部署到Kubernetes，而无需开发人员重写任何源代码。</p><p id="abf9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">例如，使用下面的PySpark代码来训练一个梯度增强的树分类器:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mh"><img src="../Images/7ad8c968df4e950adc2c8274fb52049f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3aKAgVsQvh2yb2QF"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx">Code sample taken from the Spark documentation at — <a class="ae mg" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier</a></figcaption></figure><p id="055a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">使用Spark操作符可以轻松地将这段代码打包并部署到Kubernetes，下一节将更详细地探讨这一点。</p><p id="fa28" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">但是Kubernetes从Spark 2.3开始就可以作为官方后端调度程序使用，而且有直接在Kubernetes上运行Spark作业的<a class="ae mg" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="noopener ugc nofollow" target="_blank">例子</a>。Spark Operator扩展了这种本地支持，允许声明性的应用程序规范使<em class="ke">“运行Spark应用程序就像在Kubernetes上运行其他工作负载一样简单和习惯。”</em></p><p id="049d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><a class="ae mg" href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="noopener ugc nofollow" target="_blank"> Kubernetes操作员模式</a> <em class="ke">“旨在捕捉管理一项或一组服务的操作员的关键目标。”</em>考虑到管理分布式计算引擎的开销，尽可能多地自动化维护至关重要，尤其是在为分析师和数据科学家设计模式时，他们可能不像代码或Kubernetes上的Spark集群管理那样熟悉基础设施。</p><h1 id="8933" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">火花算子体系结构</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mm"><img src="../Images/add613b855b447303048d030391871e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rGSZDU5zk4fPIsS4"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx">Image taken from the Spark documentation at — <a class="ae mg" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html#how-it-works" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/running-on-kubernetes.html#how-it-works</a></figcaption></figure><p id="745e" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">上图显示了本地Kubernetes Spark调度程序的架构。客户端通过使用<em class="ke"> spark-submit </em>与Kubernetes的API服务器进行交互，传递spark作业运行的配置和代码。一个Spark驱动程序Pod由API服务器启动，它启动所需数量的执行器来运行完整的Spark作业。下面是一个<em class="ke"> spark-submit </em>提交的例子:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mn"><img src="../Images/acc10911f65d282a35cec6eb5a3fb5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*30K3B_v3o98puEP3"/></div></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mo"><img src="../Images/1029b0e45961769e0a51c8d20eb5026e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i-yi0cH-LMkN8cTH"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx"><em class="mp">Image taken from Google Cloud Platform GitHub </em><a class="ae mg" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/architecture-diagram.png" rel="noopener ugc nofollow" target="_blank"><em class="mp">https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/architecture-diagram.png</em></a></figcaption></figure><p id="3045" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">Spark操作符在这些基础上进行构建，添加了自定义资源定义(CRD)作为对原生Kubernetes API规范的扩展。用户可以指定一个<em class="ke"> SparkApplication </em>或<em class="ke">ScheduledSparkApplication</em>清单，并像提交任何其他Kubernetes清单一样提交它，比如一个Pod或服务。Spark操作控制器监听这些对象上的创建、更新和删除事件，并相应地采取行动。<em class="ke">提交运行器</em>代表用户处理对Kubernetes API服务器的<em class="ke"> spark-submit </em>调用。<em class="ke">火花盒监视器</em>监视运行中的驱动器和执行器盒，并向控制器发送更新。最后，<em class="ke">变异准入Webhook </em>处理驱动程序和执行器容器的配置，例如挂载外部卷和任何其他Spark Kubernetes后端无法处理的配置。</p><p id="672d" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">如果我们回头看看上面的梯度增强树分类器代码，我们可以将其简单地容器化，并作为<em class="ke"> SparkApplication </em>来执行，如下所示:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mq"><img src="../Images/9d789f79960091a78594427273ca32c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OshoFrCJ0RvJUw50"/></div></div></figure><p id="da36" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">Spark操作符本身处理诸如应用程序重启和故障处理以及资源清理之类的事情。</p><h1 id="6fe2" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">用Argo工作流编排工作流</h1><p id="3823" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">虽然我们在Kubernetes上为大规模分布式计算作业提供了解决方案，这很好，但并不是每个任务都需要那么多的计算量。特别是当谈到整个建模生命周期时，为每项工作使用正确的工具是非常必要的。</p><p id="fad3" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ke"> Argo工作流</em>是<em class="ke">“一个开源的容器本地工作流引擎，用于在Kubernetes上编排并行作业。”</em> <em class="ke"> Argo工作流</em>用容器定义底层工作流中的每个节点。多步骤和相关任务可以组合在一起作为一个DAG(有向无环图)。这个项目是作为一个定制资源定义实现的，使它成为Kubernetes-native，并在其核心赋予它Kubernetes固有的水平可伸缩性。</p><p id="b3d2" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">与其他工作流管理解决方案相比，使用<em class="ke"> Argo工作流</em>的最大优势之一是能够在每一步为任务使用正确的工具。在每个节点使用容器允许每个步骤都有自己独立于工作流其余部分的依赖关系。这样，我们就可以开始将整个建模生命周期中通常完全不同的技术组合成一个单一的、可重复的、可扩展的工作流。</p><h2 id="f2b8" class="lr kh hh bd ki ls lt lu km lv lw lx kq jr ly lz ks jv ma mb ku jz mc md kw me bi translated">利用Argo工作流的灵活性</h2><p id="26df" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">难以将研究模型转化为生产就绪模型的原因之一是数据科学研究人员和生产运营团队之间使用的工具链的异构性。在我们的例子中，我们有一个用于向客户提供模型的生产Java代码库，但是所有的数据科学代码都是用Python编写的。为了弥合这一差距，我们使用了H2O库的功能，将一个用Python训练的模型导出为Java代码。对这一过程的任何修改都需要数据科学家在不熟悉的编程语言和环境中修改代码。Argo工作流使我们能够将此步骤打包到单个组件中，并将此步骤的配置与工作流的所有其他部分隔离开来:</p><h2 id="bcf2" class="lr kh hh bd ki ls lt lu km lv lw lx kq jr ly lz ks jv ma mb ku jz mc md kw me bi translated">用于将H2O MOJO转换为Java库的Argo工作流模板</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mr"><img src="../Images/afeaf30f3458767a30876e5b76099b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*chqf-b_fwCIZWqfm"/></div></div></figure><p id="fee7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">数据科学家只需要将一个经过训练的模型工件传递到Argo工作流步骤中，而不是下载Maven和Java，并计算出要运行的所有东西的正确版本。作为包的测试套件的一部分，我们传入一堆示例预测，以验证模型在打包的代码中产生的结果与它在模型训练时产生的结果相同。我们已经有效地将配置和打包模型的手动过程转换成了一个功能。因为我们对所有事情都使用Argo工作流，所以我们可以在模型训练完成后运行此步骤，并且我们每次训练新模型时都会自动获得一个打包的模型库。这允许我们使用打包的函数来分析我们的模型，因此我们可以确信我们的分析不会因为一些翻译错误而失效。</p><p id="b1ed" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">由于这个功能已经被提取到一个<em class="ke"> Argo工作流模板</em>中，我们可以轻松地在多个不同的<em class="ke"> Argo工作流</em>中重用它。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mf"><img src="../Images/c86034d6b02bf13e10d72384092fef94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-hrm8QSeXlc7S41g"/></div></div></figure><h1 id="fd81" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">在Argo工作流中利用Kubernetes缩放</h1><p id="43b9" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">使用<em class="ke"> Argo工作流</em>的另一个巨大优势是其内置的从工作流本身管理Kubernetes资源的能力。使用该功能，我们可以将上面定义的<em class="ke"> SparkApplications </em>包含在更大的<em class="ke"> Argo工作流</em>的上下文中，在需要的地方提供分布式计算的好处。Argo工作流程固有的并行性也允许我们在单个工作流程内或跨多个参数化工作流程同时运行多个试验。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mf"><img src="../Images/d728fbac8083e2f7daf1747c3da72573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*alj9zlAQJPhGqs_C"/></div></div></figure><h1 id="739f" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">但是等等，库伯弗洛怎么办？</h1><p id="3e1d" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">很明显，我们不是唯一需要解决这个问题的人。那些更熟悉Kubernetes机器学习生态系统的人可能想知道这些工具与Kubeflow有何不同。幸运的是，它们一点也没有不同！"<em class="ke">kube flow项目致力于使在Kubernetes上部署机器学习(ML)工作流变得简单、可移植和可扩展。我们的目标不是重新创建其他服务，而是提供一种简单的方法，将ML的最佳开源系统部署到不同的基础设施上</em>。</p><p id="8841" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在Kubeflow管道的掩护下，Argo被用来协调Kubernetes的资源。此外，一些训练组件实际上只是操作符，旨在以与Spark操作符相同的方式使用。其中一些是<a class="ae mg" href="https://www.kubeflow.org/docs/components/training/pytorch/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>、<a class="ae mg" href="https://www.kubeflow.org/docs/components/training/tftraining/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae mg" href="https://www.kubeflow.org/docs/components/training/mxnet/" rel="noopener ugc nofollow" target="_blank"> MXNet </a>培训操作员。Kubeflow非常好地将所有这些不同的工具结合到一个一致的平台中，供最终用户进行交互。</p><h1 id="6ad1" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">结论</h1><p id="be9c" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">具有容器化应用程序的云计算世界为模型创建和改装带来了各种新的数据生命周期挑战。然而，同样的模式创造了克服这些挑战的新模式。在这里，我们提供了我们的分布式计算和再现性的解决方案，涉及Spark算子和Argo。虽然那些工具可能对你也有用，但我们的只是许多可能的解决方案之一。我们的目标不是提倡特定的工具，而是用一个例子来说明Kubernetes上分布式机器学习的通用方法。</p><h1 id="a792" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">资源</h1><p id="eae9" class="pw-post-body-paragraph ji jj hh jk b jl ky ii jn jo kz il jq jr la jt ju jv lb jx jy jz lc kb kc kd ha bi translated">Argo工作流:<a class="ae mg" href="https://argoproj.github.io/argo" rel="noopener ugc nofollow" target="_blank">https://argoproj.github.io/argo</a><br/>Spark操作符:<a class="ae mg" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">https://github . com/Google cloud platform/Spark-on-k8s-Operator</a><br/>Kubernetes操作符模式:<a class="ae mg" href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" rel="noopener ugc nofollow" target="_blank">https://Kubernetes . io/docs/concepts/extend-Kubernetes/Operator/</a><br/>KubeFlow:<a class="ae mg" href="https://www.kubeflow.org/docs/" rel="noopener ugc nofollow" target="_blank">https://www.kubeflow.org/docs/</a><br/>KubeFlow管道:<a class="ae mg" href="https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/" rel="noopener ugc nofollow" target="_blank">https://www . KubeFlow . org/docs/Pipelines/overview</a></p><p id="b210" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ke">原载于</em><a class="ae mg" href="https://www.capitalone.com/tech/machine-learning/reproducible-distributed-machine-learning-kubernetes/" rel="noopener ugc nofollow" target="_blank"><em class="ke">https://www.capitalone.com</em></a><em class="ke">。</em></p></div><div class="ab cl ms mt go mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ha hb hc hd he"><p id="f071" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ke">披露声明:2020资本一。观点是作者个人的观点。除非本帖中另有说明，否则Capital One不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</em></p></div></div>    
</body>
</html>