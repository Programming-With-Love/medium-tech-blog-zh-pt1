<html>
<head>
<title>A Comprehensive Guide To Logistic Regression In R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R逻辑回归综合指南</h1>
<blockquote>原文：<a href="https://medium.com/edureka/logistic-regression-in-r-2d08ac51cd4f?source=collection_archive---------1-----------------------#2019-01-28">https://medium.com/edureka/logistic-regression-in-r-2d08ac51cd4f?source=collection_archive---------1-----------------------#2019-01-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/6b438a3f3eb1daf705e0323e36da58f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ZG8iDPZwPwE6r1nbyHOdTQ.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">Logistic Regression in R -Edureka</figcaption></figure><p id="a3e9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">机器学习的演变改变了整个21世纪。它开始重新定义我们的生活方式，现在是我们理解它是什么以及它为什么重要的时候了。逻辑回归是最广泛使用的机器学习算法之一，在这篇关于R语言的逻辑回归的文章中，你将理解它的工作原理和使用R语言的实现。</p><p id="af81" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这篇R中的逻辑回归文章中，我将涉及以下主题:</p><ol class=""><li id="06f5" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">机器学习导论</li><li id="ec76" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">分类与回归</li><li id="f45a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">什么是回归分析？</li><li id="3aa2" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">我们为什么以及何时使用逻辑回归？</li><li id="04d8" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">什么是逻辑回归？</li><li id="0c67" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">逻辑回归的类型</li><li id="4ea5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">逻辑回归是如何工作的？</li><li id="a2c6" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">逻辑回归的实际应用</li></ol><h1 id="6524" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">机器学习导论</h1><p id="6cf5" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">机器学习是一门科学，它通过向计算机提供数据并让它们自己学习一些技巧来让计算机行动，而无需显式编程来这样做。机器有三种不同的学习方法:</p><ul class=""><li id="49b7" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">监督学习</li><li id="8a47" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">无监督学习</li><li id="1a3a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">强化学习</li></ul><p id="4bfa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你对不同类型的机器学习有了一个概念，对于这篇文章，我们将把重点放在逻辑回归上，这是一种监督机器学习算法。</p><p id="7112" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lf">监督学习算法可用于解决两类问题:</em></p><ol class=""><li id="2a9b" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">分类问题</li><li id="baf9" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">回归问题</li></ol><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lg"><img src="../Images/8605eab6ad05c08a6d5c47357a016d8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bKxt7Mdl-mWPDWTq0nVO8Q.png"/></div></div></figure><p id="7f4b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我们进一步讨论逻辑回归之前，让我们试着在分类和回归问题之间划一条线。</p><h1 id="15c3" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">分类与回归</h1><p id="e2ee" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated"><em class="lf">分类问题用于给输入变量分配标签，也就是说，它们用于将一个变量分为两类中的一类。</em></p><p id="4d8b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">假设您想将您的电子邮件分为两类，垃圾邮件和非垃圾邮件。对于这类问题，您必须将输入数据分配到不同的类中，您可以利用分类算法。这里需要注意的重要一点是，分类问题的响应变量本质上是绝对的。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lp"><img src="../Images/4a8ad7296358764d673235d4f8510b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Bxx-lxgpMKFiQ0hz4DSF0Q.png"/></div></div></figure><p id="aa76" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您也可以浏览我们关于分类算法的内容，以更好地了解机器学习中使用的各种分类算法。</p><p id="54e3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">另一方面，<em class="lf">回归用于预测连续量</em>。连续变量基本上是一个有无限种可能性的变量。比如说，一个人的体重。有人可能重180磅，他们可能重180.10磅，或者他们可能重180.1110磅。重量的可能性是无限的。这就是连续变量。</p><p id="c482" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你已经对分类和回归有了一个简单的了解，让我们把重点放在回归分析上，这是逻辑回归背后的基本思想。</p><h1 id="7f96" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">什么是回归分析？</h1><p id="9a27" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">回归分析是一种用于预测连续量的预测技术。连续变量基本上是一个有无限多种可能性的变量。</p><p id="13ef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">比如一个人的身高。有人可能身高165厘米，或者他们可能身高165.02厘米，或者他们可能身高165.022厘米。高度的可能性是无限的。这就是连续变量。</p><p id="9300" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，回归基本上是一种用于预测连续变量的预测分析技术。在这里，你不必将数据分为不同的类别，相反，你必须预测最终的结果，比如说，你想预测一段时间内的股票价格。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/bdf08d8de2edec9b27a8931eba0c89b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*2xjf6LuS-Ckz0HOX_Bkcdw.png"/></div></figure><p id="f596" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于这类问题，你可以通过研究因变量(股票价格)和自变量(时间)之间的关系来利用回归。</p><h1 id="096f" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">我们为什么以及何时使用逻辑回归？</h1><p id="b9db" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">为了理解我们为什么使用逻辑回归，让我们考虑一个小场景。</p><p id="c22f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">假设你的妹妹正在努力进入研究生院，你想预测她是否会被她梦想中的学校录取。所以，根据她的CGPA和过去的数据，你可以使用逻辑回归来预见结果。</p><p id="f8eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">逻辑回归允许您分析一组变量并预测分类结果。由于这里我们需要预测她是否会进入学校，这是一个分类问题，逻辑回归将是理想的。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/7e117f9ecf7b8628808904291a52bc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*J89DaLjb-OrAX7l0Ly2Rhw.png"/></div></figure><p id="52b4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你可能想知道为什么我们在这种情况下不使用线性回归。<em class="lf">原因是线性回归用于预测一个连续的量，而不是一个分类的量</em>。因此，当结果只能取2个可能的值时，最好有一个模型预测该值为0或1，或者以介于0和1之间的概率形式。</p><p id="5c90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">线性回归没有这个能力。如果使用线性回归对二元结果进行建模，得到的模型将不会预测0到1范围内的Y值，因为线性回归适用于连续的因变量，而不适用于分类变量。这就是为什么我们使用逻辑回归。</p><h1 id="d7fe" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">什么是逻辑回归？</strong></h1><p id="a912" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">逻辑回归是用于解决分类问题的最基本和最广泛使用的机器学习算法之一。它被命名为“逻辑回归”的原因是它的主要技术与线性回归非常相似。</p><p id="c750" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lf">逻辑回归是一种在给定自变量(X)的情况下预测因变量(Y)的方法，因此因变量是分类变量</em>。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/7e117f9ecf7b8628808904291a52bc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*J89DaLjb-OrAX7l0Ly2Rhw.png"/></div></figure><p id="b339" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我说分类变量时，我的意思是它包含1或0，是或否，真或假等值。所以基本上，在逻辑回归中，结果总是绝对的。</p><h1 id="b331" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">逻辑回归模型的类型</h1><p id="a20a" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">逻辑回归的优点之一是，它可以通过使用多项式和有序逻辑模型来解决多类分类问题。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/5460fb995d313430b168a5bcb83715b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*lXo_U1_T7de-iP14tjE_Bg.png"/></div></figure><h2 id="93c4" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated"><strong class="ak">多项逻辑回归:</strong></h2><p id="e575" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">多项式回归是二元逻辑回归的扩展，当响应变量有两个以上类别时使用。多项式回归用于处理多类分类问题。</p><p id="31d4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">假设我们的响应变量有K = 3类，那么多项式逻辑模型将适合K-1个独立的二元逻辑模型，以便计算最终结果。</p><h2 id="0a32" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">有序逻辑回归:</h2><p id="321d" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">有序逻辑回归也称为有序分类，是一种预测建模技术，用于响应变量本质上是有序的情况。</p><p id="0348" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">顺序变量是指值的顺序很重要，但值之间的差异不重要。例如，你可以让一个人给一部电影打分，从1到5。4分比3分好得多，因为这意味着这个人喜欢这部电影。但是等级4和3之间的差别可能不同于等级4和1之间的差别。这些值只是表示一个顺序。</p><p id="ec52" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以上是不同逻辑模型的简要概述。然而，在本文中，我们将只关注二元逻辑回归。</p><h1 id="2bd2" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">逻辑回归是如何工作的？</strong></h1><p id="bac7" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">为了理解逻辑回归的工作原理，让我们来看看线性回归方程:</p><p id="83ff" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">T5】Y =βo+β1X+∈T7】</strong></p><ul class=""><li id="dbc7" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">y代表需要预测的因变量。</li><li id="d2dc" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">β0是Y轴截距，基本上是直线上与Y轴相交的点。</li><li id="4fed" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">β1是直线的斜率(斜率可以是负的，也可以是正的，取决于因变量和自变量之间的关系。)</li><li id="517d" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">这里的x代表独立变量，用于预测我们的合成因变量。</li><li id="43d6" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">∈表示计算中的误差</li></ul><p id="60d5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那么，假设X是解释变量(自变量)，Y是响应变量(因变量)，我们如何表示p(X)=Pr(Y=1|X)和X之间的关系呢？</p><p id="0388" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，Pr(Y=1|X)表示给定某个X值时Y=1的概率。</p><p id="2381" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">线性回归将这些概率建模为:</p><p id="cae4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="lf"> p(X)=β0 + β1X </em> </strong></p><p id="d74d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">逻辑回归方程是从同一个方程推导出来的，除了我们需要做一些改动，因为响应变量必须只接受分类值。</p><p id="c649" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">逻辑回归不一定将结果计算为0或1，而是计算变量落入0类或1类的概率(范围在0和1之间)。<em class="lf">因此，我们可以得出结论，合成(因变量)必须是正的，并且应该在0和1之间，即必须小于1 </em>。</p><p id="e0e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了满足上述条件，我们必须做到以下几点:</p><ul class=""><li id="ee6a" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">以方程的指数为例，因为任何值的指数都是正数</li><li id="dbbf" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">第二，一个数被它自己+ 1除后将永远小于1</li></ul><p id="5487" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，公式为:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/2e2f02d9863887d0bd87f2447a130d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*AJt9bJNAxFFYBPfQlZcNxQ.png"/></div></figure><p id="04ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下一步是计算<em class="lf"> logit() </em>函数。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lg"><img src="../Images/ef5c36d9ba56dfe25eb0e8a9b163c7dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kGsl7ZmC2wFshWyrzM5byw.png"/></div></div></figure><p id="046b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面的推导相当简单，我们只要交叉相乘，取e(β0 + β1X)的公。RHS表示自变量的线性方程，LHS表示优势比，也称为logit函数。</p><p id="b2c0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">logit函数是以S曲线或S形曲线表示的链接函数，范围在0-1之间，用于计算响应变量的概率。</p><p id="33ba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lf">在逻辑回归中,“X”增加一个度量，logit的变化系数为β0。简而言之，回归系数描述了预测变量单位变化的对数变化。</em></p><p id="ad3c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你已经很好的理解了逻辑回归是如何工作的，让我们继续演示吧。</p><h1 id="ba5f" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">逻辑回归的实际应用</h1><p id="91a6" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">在我们开始之前，我将使用R语言来实现逻辑回归模型。</p><h2 id="0ead" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated"><strong class="ak">数据集描述:</strong></h2><p id="cf09" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">在这个演示中，我们将使用由<em class="lf"> ISLR </em>包提供的默认数据。该数据集包含大约一万名客户的信息，例如客户是否违约、是否是学生、客户的平均余额以及客户的收入。</p><h2 id="881d" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated"><strong class="ak">问题陈述:</strong></h2><p id="ad44" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated"><em class="lf">拟合逻辑回归模型，根据客户持有的平均余额预测客户违约的概率。</em></p><p id="f886" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将通过安装以下软件包来开始演示:</p><ul class=""><li id="8a09" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">tidyverse:用于数据操作和可视化</li><li id="1d2e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">modelr:用于管道建模功能的简单实现</li><li id="37a7" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">broom:用于模型化输出的适当组织</li><li id="956e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">ISLR:包含约10，000个客户平均余额和违约信息观察的数据集。</li></ul><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="26c8" class="lr kc hh mg b fi mk ml l mm mn">#loading Packages<br/>library(tidyverse)<br/>library(modelr)<br/>library(broom)<br/>#Install ISLR Package<br/>install.packages('ISLR')<br/>#Load ISLR Package<br/>library('ISLR')</span></pre><p id="f66f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们的下一步是导入数据集并将其显示为tibble:</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="a785" class="lr kc hh mg b fi mk ml l mm mn"># Load data<br/>(mydata &lt;- as_tibble(ISLR::Default))<br/># A tibble: 10,000 x 4<br/>default student balance income</span><span id="cb89" class="lr kc hh mg b fi mo ml l mm mn">1 No No 730. 44362.<br/>2 No Yes 817. 12106.<br/>3 No No 1074. 31767.<br/>4 No No 529. 35704.<br/>5 No No 786. 38463.<br/>6 No Yes 920. 7492.<br/>7 No No 826. 24905.<br/>8 No Yes 809. 17600.<br/>9 No No 1161. 37469.<br/>10 No No 0 29275.<br/># ... with 9,990 more rows</span></pre><p id="5e94" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，让我们检查一下NA值，如果您在知道最好去掉它们之前已经处理过NA值:</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="12e2" class="lr kc hh mg b fi mk ml l mm mn">#Checking for NA values<br/>sum(is.na(mydata))<br/>[1] 0</span></pre><p id="ca2b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">幸运的是，数据中没有空值。下一步是将数据分割成训练和测试数据集，这也称为数据拼接。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="d960" class="lr kc hh mg b fi mk ml l mm mn">#Creating the Training and Testing data set<br/>sample &lt;- sample(c(TRUE, FALSE), nrow(mydata), replace = T, prob = c(0.6,0.4))<br/>train &lt;- mydata[sample, ]<br/>test &lt;- mydata[!sample, ]</span></pre><p id="492d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，我们按照60:40的比例分割数据，这样，60%的数据用于训练，剩下的40%用于测试模型。</p><h2 id="7e77" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">建立逻辑回归模型</h2><p id="7a76" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">拆分数据后，我们的下一步是使用训练数据集来构建逻辑模型。逻辑模型试图:</p><ul class=""><li id="c57e" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">根据客户的平均余额对客户违约的概率建模</li><li id="9f5c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">估计客户违约的概率与不违约的概率</li><li id="4aea" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">将客户分为两类(违约者和非违约者)</li></ul><p id="b787" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了构建逻辑回归模型，我们将使用glm()函数。逻辑回归属于一类称为广义线性模型(GLM)的模型，可使用glm()函数构建。</p><p id="606f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">glm()函数的语法是:</p><p id="7aef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"><em class="lf">【glm(公式，数据，家族)</em> </strong></p><p id="25e1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在上面的语法中:</p><ul class=""><li id="52b6" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated"><strong class="ir hi">公式:</strong>公式表示因变量和自变量之间的关系</li><li id="85ab" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated"><strong class="ir hi">数据:</strong>应用公式的数据集</li><li id="f183" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated"><strong class="ir hi">系列:</strong>该字段指定回归模型的类型。在我们的情况下，这是一个二元逻辑回归模型</li></ul><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="e045" class="lr kc hh mg b fi mk ml l mm mn">#Fitting a logistic regression model<br/>logmodel &lt;- glm(default ~ balance, family = "binomial", data = train)</span></pre><p id="ed28" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">glm()函数使用最大似然法来计算模型。</p><h2 id="a091" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">最大似然法是什么？</h2><p id="f692" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">该方法确定系数(β0，β1)的值，使得预测概率尽可能接近实际概率。简而言之，对于二元分类，最大似然估计器将尝试找到β0和β1的值，以使所得概率最接近1或0。似然函数表示为:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/96998057b9bbe71030f9061a05ef88af.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*JdkEWAR-gBxPLwbiYNlX4w.png"/></div></figure><p id="8881" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">建立逻辑模型后，我们现在可以可视化响应变量和预测变量之间的关系。为此，我们使用由r。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="02fd" class="lr kc hh mg b fi mk ml l mm mn">#Plotting a graph: Probability of default Vs Balance<br/>mydata %&gt;%<br/>mutate(prob = ifelse(default == "Yes", 1, 0)) %&gt;%<br/>ggplot(aes(balance, prob)) +<br/>geom_point(alpha = .15) +<br/>geom_smooth(method = "glm", method.args = list(family = "binomial")) +<br/>ggtitle("Logistic regression model fit") +<br/>xlab("Balance") +<br/>ylab("Probability of Default")</span></pre><p id="592e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">结果是预期的S曲线或S形曲线。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lg"><img src="../Images/50d64ea30cc5bd728784ccba6dd5b3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toJVv1ZL8qadDuOAvrUdxg.png"/></div></div></figure><h2 id="a231" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">逻辑回归模型诊断</h2><p id="ddf7" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">建立模型的最关键步骤之一是评估效率和检查模型的重要性。我们可以通过使用R:</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="6fdf" class="lr kc hh mg b fi mk ml l mm mn">#Summary of the Logistic Regression Model<br/>summary(logmodel)<br/>Call:<br/>glm(formula = default ~ balance, family = "binomial", data = train)<br/> <br/>Deviance Residuals:<br/>Min 1Q Median 3Q Max<br/>-2.2905 -0.1395 -0.0528 -0.0189 3.3346<br/> <br/>Coefficients:<br/>Estimate     Std. Error    z value   Pr(&amp;gt;|z|)<br/>(Intercept) -1.101e+01  4.887e-01   -22.52   &amp;lt;2e-16 ***<br/>balance      5.669e-03    2.949e-04   19.22     &amp;lt;2e-16 ***<br/>---<br/>Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/> <br/>(Dispersion parameter for binomial family taken to be 1)<br/> <br/>Null deviance: 1723.03 on 6046 degrees of freedom<br/>Residual deviance: 908.69 on 6045 degrees of freedom<br/>AIC: 912.69<br/>Number of Fisher Scoring iterations: 8</span></pre><p id="ac39" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面的总结告诉我们一些事情:</p><ul class=""><li id="d8e9" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">Call:是对逻辑回归模型的函数调用</li><li id="a3ec" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">偏差:偏差是模型拟合优度的统计度量。具有较低偏差值的模型被认为是非常适合的模型，而较高的数值总是表明不适合。有两种类型的异常:</li></ul><ol class=""><li id="3d47" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">零偏差</li><li id="06d3" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">剩余偏差</li></ol><ul class=""><li id="8ad3" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated"><em class="lf">零偏差</em>表示仅包含截距(大平均值)而不包含独立变量或预测变量的模型对响应变量的预测程度</li><li id="d8cb" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated"><em class="lf">剩余偏差</em>显示了包括所有特征和模型系数的模型对响应变量的预测程度</li><li id="7c5f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm le jt ju jv bi translated">系数:代表贝塔系数及其统计意义。</li></ul><p id="3c80" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">密切注意系数的Pr(&gt;|z|)或p值。只有当p值小于预定的统计显著性水平(理想情况下为0.05)时，逻辑回归模型才具有统计显著性。每个系数的p值表示为概率Pr(&gt;|z|)。</p><p id="0c83" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们可以看到，这两个系数都具有非常低的p值，这意味着这两个系数在计算响应变量时都很重要。</p><p id="0d3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对应于p值的星号表示相应变量的显著性。由于在我们的模型中，两个p值都有一个3星，这表明这两个变量在预测响应变量中是非常重要的。</p><ul class=""><li id="e58b" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm le jt ju jv bi translated">AIC: Akaike信息标准是一种拟合的统计方法，它对预测变量数量的逻辑模型进行惩罚。具有最小AIC值的模型被认为是非常适合的模型。逻辑回归模型中的AIC相当于线性回归中的调整后的R</li></ul><p id="8307" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上述指标用于检查逻辑回归模型的适用性，因此关注这些值至关重要。</p><h2 id="3910" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">评估逻辑回归模型</h2><p id="e7b3" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">在训练数据集上训练模型之后，最后是使用测试数据集评估模型的时候了。在下面的代码行中，我们将使用我们之前构建的逻辑回归模型来预测测试数据的响应变量(defaulter class(0/1))。</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="b714" class="lr kc hh mg b fi mk ml l mm mn">#Fitting a logistic regression model on the testing data<br/>logmodel &lt;- glm(default ~ balance, family = "binomial", data = test)</span></pre><p id="762a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们来看看模型的总结:</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="a56b" class="lr kc hh mg b fi mk ml l mm mn">summary(logmodel)<br/>Call:<br/>glm(formula = default ~ balance, family = "binomial", data = test)<br/> <br/>Deviance Residuals:<br/>Min 1Q Median 3Q Max<br/>-2.2021 -0.1574 -0.0676 -0.0272 3.6743<br/> <br/>Coefficients:<br/>Estimate    Std. Error   z value   Pr(&amp;gt;|z|)<br/>(Intercept) -1.020e+01  5.372e-01  -18.98    &amp;lt;2e-16 ***<br/>balance       5.286e-03   3.329e-04   15.88    &amp;lt;2e-16 ***<br/>---<br/>Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/> <br/>(Dispersion parameter for binomial family taken to be 1)<br/>Null deviance: 1197.10 on 3952 degrees of freedom<br/>Residual deviance: 685.05 on 3951 degrees of freedom<br/>AIC: 689.05<br/>Number of Fisher Scoring iterations: 8</span></pre><p id="2fc9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在研究模型总结时，很明显，这两个系数都很重要，因为它们的p值很小，而且与训练阶段相比，AIC和偏差值也下降了，这是一件好事。</p><h2 id="205a" class="lr kc hh bd kd ls lt lu kh lv lw lx kl ja ly lz kp je ma mb kt ji mc md kx me bi translated">预测结果</h2><p id="b70e" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">我们的最后一步是通过对预测变量的特定值进行预测来评估模型的效率。因此，这里我们要预测一个余额为2000美元的客户是否会成为违约者。为此，我们将在R:</p><pre class="lh li lj lk fd mf mg mh mi aw mj bi"><span id="7b45" class="lr kc hh mg b fi mk ml l mm mn">predict(logmodel, data.frame(balance = c(2000)), type = "response")<br/>1<br/>0.5820893</span></pre><p id="5f77" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从上面的结果可以清楚地看出，客户属于Y=1类，因此是一个违约者。</p><p id="b6a2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">就这样，我们到了这篇文章的结尾。如果你想查看更多关于Python、DevOps、Ethical Hacking等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释数据科学的各个方面。</p><blockquote class="mr ms mt"><p id="0461" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 1。</em> <a class="ae mq" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="59a2" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 2。</em> <a class="ae mq" rel="noopener" href="/edureka/math-and-statistics-for-data-science-1152e30cee73"> <em class="hh">数据科学的数学与统计</em> </a></p><p id="f479" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 3。</em><a class="ae mq" rel="noopener" href="/edureka/machine-learning-with-r-c7d3edf1f7b"><em class="hh">R中的机器学习</em> </a></p><p id="08e8" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 4。</em> <a class="ae mq" rel="noopener" href="/edureka/machine-learning-algorithms-29eea8b69a54"> <em class="hh">机器学习算法</em> </a></p><p id="5e1a" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 5。</em><a class="ae mq" rel="noopener" href="/edureka/linear-regression-in-r-da3e42f16dd3"><em class="hh">R中线性回归</em> </a></p><p id="2632" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 6。</em> <a class="ae mq" rel="noopener" href="/edureka/classification-algorithms-ba27044f28f1"> <em class="hh">分类算法</em> </a></p><p id="3def" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 7。</em> <a class="ae mq" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="5e3d" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 8。</em> <a class="ae mq" rel="noopener" href="/edureka/a-complete-guide-on-decision-tree-algorithm-3245e269ece"> <em class="hh">决策树中的R </em> </a></p><p id="b2b0" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated">9。 <a class="ae mq" rel="noopener" href="/edureka/introduction-to-machine-learning-97973c43e776"> <em class="hh">机器学习入门</em> </a></p><p id="fee6" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 10。</em> <a class="ae mq" rel="noopener" href="/edureka/naive-bayes-in-r-37ca73f3e85c"> <em class="hh">朴素贝叶斯在R </em> </a></p><p id="e34b" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 11。</em> <a class="ae mq" rel="noopener" href="/edureka/statistics-and-probability-cf736d703703"> <em class="hh">统计与概率</em> </a></p><p id="a01f" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 12。</em> <a class="ae mq" rel="noopener" href="/edureka/decision-trees-b00348e0ac89"> <em class="hh">如何创建一个完美的决策树？</em>T47】</a></p><p id="b85c" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 13。</em> <a class="ae mq" rel="noopener" href="/edureka/data-scientists-myths-14acade1f6f7"> <em class="hh">关于数据科学家角色的十大误区</em> </a></p><p id="7d58" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 14。</em> <a class="ae mq" rel="noopener" href="/edureka/data-science-projects-b32f1328eed8"> <em class="hh">顶级数据科学项目</em> </a></p><p id="0bed" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 15。</em> <a class="ae mq" rel="noopener" href="/edureka/data-analyst-vs-data-engineer-vs-data-scientist-27aacdcaffa5"> <em class="hh">数据分析师vs数据工程师vs数据科学家</em> </a></p><p id="2b59" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 16。</em> <a class="ae mq" rel="noopener" href="/edureka/types-of-artificial-intelligence-4c40a35f784"> <em class="hh">人工智能的种类</em> </a></p><p id="2d04" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 17。</em><a class="ae mq" rel="noopener" href="/edureka/r-vs-python-48eb86b7b40f"><em class="hh">R vs Python</em></a></p><p id="aefc" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 18。</em> <a class="ae mq" rel="noopener" href="/edureka/ai-vs-machine-learning-vs-deep-learning-1725e8b30b2e"> <em class="hh">人工智能vs机器学习vs深度学习</em> </a></p><p id="5811" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 19。</em> <a class="ae mq" rel="noopener" href="/edureka/machine-learning-projects-cb0130d0606f"> <em class="hh">机器学习项目</em> </a></p><p id="6368" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 20。</em> <a class="ae mq" rel="noopener" href="/edureka/data-analyst-interview-questions-867756f37e3d"> <em class="hh">数据分析师面试问答</em> </a></p><p id="c4c9" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 21。</em> <a class="ae mq" rel="noopener" href="/edureka/data-science-and-machine-learning-for-non-programmers-c9366f4ac3fb"> <em class="hh">面向非程序员的数据科学和机器学习工具</em> </a></p><p id="67c2" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 22。</em> <a class="ae mq" rel="noopener" href="/edureka/top-10-machine-learning-frameworks-72459e902ebb"> <em class="hh">十大机器学习框架</em> </a></p><p id="fa5f" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated">23。 <a class="ae mq" rel="noopener" href="/edureka/statistics-for-machine-learning-c8bc158bb3c8"> <em class="hh">统计机器学习</em> </a></p><p id="14ec" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 24。</em> <a class="ae mq" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="4bcd" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 25。</em> <a class="ae mq" rel="noopener" href="/edureka/breadth-first-search-algorithm-17d2c72f0eaa"> <em class="hh">广度优先搜索算法</em> </a></p><p id="bd19" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated">26。<a class="ae mq" rel="noopener" href="/edureka/linear-discriminant-analysis-88fa8ad59d0f"><em class="hh">R中的线性判别分析</em> </a></p><p id="330b" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 27。</em> <a class="ae mq" rel="noopener" href="/edureka/prerequisites-for-machine-learning-68430f467427"> <em class="hh">机器学习的先决条件</em> </a></p><p id="b985" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated">28。 <a class="ae mq" rel="noopener" href="/edureka/r-shiny-tutorial-47b050927bd2"> <em class="hh">互动WebApps使用R闪亮</em> </a></p><p id="33e6" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 29。</em> <a class="ae mq" rel="noopener" href="/edureka/top-10-machine-learning-books-541f011d824e"> <em class="hh">十大机器学习书籍</em> </a></p><p id="ca89" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated">30。 <a class="ae mq" rel="noopener" href="/edureka/unsupervised-learning-40a82b0bac64"> <em class="hh">无监督学习</em> </a></p><p id="8c60" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 31。</em> <a class="ae mq" rel="noopener" href="/edureka/10-best-books-data-science-9161f8e82aca"> <em class="hh"> 10本最好的数据科学书籍</em> </a></p><p id="4b70" class="ip iq lf ir b is it iu iv iw ix iy iz mu jb jc jd mv jf jg jh mw jj jk jl jm ha bi translated"><em class="hh"> 32。</em> <a class="ae mq" rel="noopener" href="/edureka/supervised-learning-5a72987484d0"> <em class="hh">监督学习</em> </a></p></blockquote></div><div class="ab cl mx my go mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ha hb hc hd he"><p id="462e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lf">原载于2019年1月28日</em><a class="ae mq" href="https://www.edureka.co/blog/logistic-regression-in-r" rel="noopener ugc nofollow" target="_blank"><em class="lf">www.edureka.co</em></a><em class="lf">。</em></p></div></div>    
</body>
</html>