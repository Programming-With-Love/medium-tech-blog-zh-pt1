<html>
<head>
<title>Unifying visual embeddings for visual search at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pinterest视觉搜索的统一视觉嵌入</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/unifying-visual-embeddings-for-visual-search-at-pinterest-74ea7ea103f0?source=collection_archive---------3-----------------------#2019-08-08">https://medium.com/pinterest-engineering/unifying-visual-embeddings-for-visual-search-at-pinterest-74ea7ea103f0?source=collection_archive---------3-----------------------#2019-08-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="fcff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Andrew Zhai | Pinterest视觉搜索技术主管</strong></p><p id="1ae6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多年来，Pinterest已经推出了各种由计算机视觉驱动的视觉搜索产品，以帮助人们发现新的想法和产品。我们在2015年开始使用我们的<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/introducing-a-new-way-to-visually-search-on-pinterest-67c8284b3684">视觉裁剪工具</a>，允许用户在一个大头针的图像内搜索(例如一个更大的客厅场景中的一盏灯)，并在Pinterest上浏览视觉上相似的内容。2017年，我们推出了<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/building-pinterest-lens-a-real-world-visual-discovery-system-59812d8cbfbc">镜头相机搜索</a>，通过将每一个Pinner的手机相机变成一个强大的发现系统，将Pinterest的视觉搜索开放到现实世界。2019年，我们推出了<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/automating-shop-the-look-on-pinterest-a17aeff0eae2">自动化购物外观</a>，以便Pinners可以在Pinterest家居装饰场景中找到并购买确切的产品。视觉搜索是Pinterest增长最快的产品之一，每月有数亿次搜索。</p><p id="ed76" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些视觉搜索技术的核心是<strong class="ig hi">视觉嵌入</strong>，它为匹配系统提供动力，使Pinners能够通过Pin或相机浏览任何图像中的2000多个想法，并搜索准确的产品。视觉搜索不仅将发现从在线扩展到了离线，还允许Pinterest上的任何Pinterest链接，并进一步搜索。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/2890e010251457f9e78ae5760bbb1903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1S_4d6Ml8D-Qnfw3"/></div></div></figure><h1 id="bfd7" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">视觉嵌入的演变</h1><p id="4af3" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">这些年来，Pinterest视觉嵌入在建模和数据方面都有所发展。</p><p id="1c6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在2014年开始了视觉嵌入的工作，因为我们的目标是开发我们第一个生产化的视觉搜索产品:<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/introducing-a-new-way-to-visually-search-on-pinterest-67c8284b3684">视觉裁剪工具</a>。我们大量利用Pinterest的参与度数据集，因为我们的目标是制作一个查询和语料库都是Pin图像的产品。当我们在2016年开始研究<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/building-pinterest-lens-a-real-world-visual-discovery-system-59812d8cbfbc">镜头</a>时，我们面临的最大挑战是学习相机查询图像到大头针图像的域转换。因为相机图像通常不是我们通常在Pinterest上看到的高度引人入胜的视觉内容类型，所以我们收集了一个人类策划的数据集，将相机图像与Pin图像进行匹配。同样，当我们的目标是在2018年<a class="ae jc" rel="noopener" href="/@Pinterest_Engineering/automating-shop-the-look-on-pinterest-a17aeff0eae2">实现外观</a>的自动化商店时，我们希望专门针对精确的产品匹配进行优化。使用现有的Shop the Look数据集作为嘈杂的候选集，我们再次利用人工监管来生成高质量的精确产品匹配训练数据集。在数据集工作的同时，我们自然地推进了SOTA图像分类架构，从2014年的AlexNet和VGG16开始，到2016年的ResNet和ResNeXt，以及2018年的SE-ResNeXt。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kt"><img src="../Images/17db6f81be000e314a9962e0247c4eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KW95O8pqYdi2-5fM"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Visual cropper, Lens, and Shop-the-Look optimize for different objectives. With the visual cropper, we want to optimize for general Pinterest browsing over our corpus of 200B+ ideas, with Lens we need to optimize for the domain shift of camera to Pin images, and with Shop-the-Look, we look to find exact product matches from our catalog of products.</strong></figcaption></figure><p id="0c2a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当用新的嵌入来改进现有的应用程序时，我们会用更新的、性能更好的嵌入来替换旧的嵌入。然而，在为新应用开发嵌入时，本着模块化设计和简单性的精神，我们将特定于应用的数据集与SOTA模型架构一起应用，并为新应用生成<strong class="ig hi">新的独立</strong>嵌入。然而，随着时间的推移，我们观察到每个应用(视觉裁剪器、镜头相机搜索、购物外观)都有单独的嵌入成为了一项技术债务<strong class="ig hi">随着我们的重点转移到为每个新应用开发/改进现有应用的嵌入，同时底层培训基础设施也在发展。这方面的一个例子是在2019年之前，视觉裁剪器嵌入最后一次部署是在2015年，使用Caffe作为训练/服务框架，以VGG16作为主干模型。相比之下，2018年嵌入的商店外观依赖于我们的PyTorch培训和以SE-ResNeXt为骨干的Caffe2服务基础设施。视觉裁剪器嵌入作为Pinterest内10多个客户的一般内容信号也非常重要，因为它是通过Pinterest参与培训的，而我们较新的嵌入专注于人类策划的信号，对Pinterest生态系统的影响较小。</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/b132e101f14eb0de0f66bac9207eac58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yR6cEORGJSB-Y01s"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Over the years, we developed independent embeddings for specific visual search products, making it difficult to simultaneously improve our visual search products. We look to simplify with one unified visual embedding for all visual search products.</strong></figcaption></figure><p id="0064" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就我们所拥有的工程资源而言，我们显然无法继续用我们当前的嵌入式开发范例扩展到新的应用程序。由于成本和工程资源的限制以及对提高性能的兴趣，我们的目标是学习一种统一的多任务视觉嵌入，它可以在所有三种视觉搜索应用程序中运行良好。</p><h1 id="f66e" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">度量学习背景</h1><p id="449b" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">我们的视觉嵌入是图像的压缩矢量化表示，它是卷积神经网络的输出，该网络通过度量学习针对目标相似性进行训练。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kz"><img src="../Images/4321b087dc0a12494cbd2f087b99b0fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pahC6R9jYVF9hjAd"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Visual similarity is defined by the distance between visual embeddings extracted from convolutional neural networks.</strong></figcaption></figure><p id="d0d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">传统上，度量学习在显式关系数据集上训练，其中一个例子是三元组数据集(<strong class="ig hi"> q </strong>、<strong class="ig hi"> p </strong>、<strong class="ig hi"> n </strong>)，其中我们有一个<strong class="ig hi"> q </strong>锚图像、一个已知与<strong class="ig hi"> q </strong>相关的<strong class="ig hi"> p </strong>正图像和一个不相关的<strong class="ig hi"> n </strong>负图像。在训练期间，图像嵌入被明确地相互比较。度量学习的主要挑战之一是决定如何选择最有信息量的负面图像。</p><p id="a734" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或者，基于代理的度量学习在分类数据集(<strong class="ig hi"> q、</strong>“钉子”)、(<strong class="ig hi"> p </strong>“钉子”)、(<strong class="ig hi"> n </strong>“碗”)上训练，其中图像之间的关系被隐式定义；相似的图像共享相同的标签，而不同的图像具有不同的标签。在训练期间，图像嵌入与分类损失中的标签嵌入(代理)进行比较。负采样问题通过基于代理的方法得以缓解，因为我们通常具有比图像少得多的标签，这允许我们在训练的每个小批迭代期间比较大量负标签嵌入的图像嵌入(有时将所有标签嵌入放入GPU存储器中)。在Pinterest，我们用<strong class="ig hi">基于代理的范例</strong>来训练我们的视觉嵌入，因为我们已经看到<a class="ae jc" href="https://arxiv.org/abs/1811.12649" rel="noopener ugc nofollow" target="_blank">至少基于代理的方法与传统度量学习方法的性能</a>相当。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/ebcdaaeefd9172f8b87dfc5da5de148d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uetvf_piCEy6MP4N"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Metric Learning learns relationships between images explicitly. Proxy-Based Metric Learning learns relationships between images implicitly by clustering images to their relevant labels</strong></figcaption></figure><h1 id="09b7" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">作为解决方案的统一视觉嵌入</h1><p id="d4ac" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">扩展了我们之前的工作中<a class="ae jc" href="https://arxiv.org/abs/1811.12649" rel="noopener ugc nofollow" target="_blank">的<strong class="ig hi">基于代理的方法</strong>，我们通过将特定于应用的数据集与多个softmax分类损失相结合来训练我们的多任务视觉嵌入。特定于应用的数据集被均匀地混合在每个微型批次中，并且所有任务共享一个公共基础网络，直到生成嵌入，此时每个任务分裂成其各自的分支。每个任务分支只是一个完全连接的层(其中权重是代理)，后跟softmax交叉熵损失。我们用PyTorch以分布式数据并行方式训练我们的模型，用FP16训练，使用</a><a class="ae jc" href="https://github.com/NVIDIA/apex" rel="noopener ugc nofollow" target="_blank"> Apex </a>库和<a class="ae jc" href="https://github.com/NVIDIA/apex/pull/252" rel="noopener ugc nofollow" target="_blank">扩展</a>来支持我们的架构。请查看我们的<a class="ae jc" href="https://arxiv.org/abs/1908.01707" rel="noopener ugc nofollow" target="_blank">KDD 19年论文</a>了解详情，例如特定应用数据集的可视化、训练期间的子采样代理以提高训练效率，以及我们嵌入的二进制化以提高服务效率。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/e6a60b7bddaafc9edf7574c3d11c5d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iXRxcV-XmJs6-q5a"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Our visual embedding model architecture trained with PyTorch DistributedDataParallel with FP16 Mixed Precision training</strong></figcaption></figure><p id="adfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用每个应用程序的离线检索指标(视觉裁剪器(图钉内的视觉搜索)、镜头相机搜索、购物外观)，我们看到:</p><ol class=""><li id="1f31" class="lb lc hh ig b ih ii il im ip ld it le ix lf jb lg lh li lj bi translated">数据集上的多任务处理导致所有应用程序的性能优于在相应应用程序上使用相同架构在每个特定于应用程序的数据集上进行的训练。</li><li id="4fde" class="lb lc hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">我们的统一嵌入优于旧部署的应用程序专用嵌入，后者的改进来自更新的数据集和更好的模型架构。有了我们的统一嵌入，我们现在有了一个既易于维护(一个模型来训练和维护)又优于现有基准的框架。</li></ol><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/a10057ca61e0acf6ea56f09d24908654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vgUVKczp-bun7P7C"/></div></div></figure><h1 id="2e1d" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">影响</h1><p id="b641" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">离线指标显示，我们的统一嵌入优于现有系统。然而，为了推出我们的嵌入，真正重要的是在线A/B实验，我们跨应用测试了两个版本的系统，一个使用统一嵌入，另一个使用当前为相应应用部署的专用嵌入。在Pinterest，我们衡量参与度和相关性，前者来自实时用户反馈，后者来自专门针对特定产品目标的人工判断模板(例如，浏览与购物、视觉裁剪与相机)。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lq"><img src="../Images/83ecd4b6978f4da737d704beafbdd5fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UWE68DvFUE1lIrjc"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Human Judgement (first row) and A/B experiment engagement results on our visual search products. Overall our unified visual embedding led to significant gains in relevance and engagement over our existing specialized embeddings.</strong></figcaption></figure><p id="23c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总的来说，统一嵌入在参与度和相关性方面表现非常好，如上表所示。重复和点击率衡量的是参与该行为的用户百分比，而重复和点击率衡量的是行为量。自动化商店当我们评估我们的统一嵌入时，外观正在开发中，因此没有它的实时A/B实验结果。统一嵌入也导致了大量的成本节约，因为我们能够在一个嵌入下统一我们的视觉搜索检索基础设施。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/0c1e49b0bf37a24e75dd1d11ac5a5b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JYNgHZGRzGf0-rn-"/></div></div><figcaption class="ku kv et er es kw kx bd b be z dx"><strong class="bd js">Visualization of the specialized embeddings (first row) vs unified visual embedding (second row) on the Visual Cropper. We can see by combining all training datasets into one model, we have a unified visual search system that is optimized for Pin engagement, can find exact products, and semantically understand camera images well.</strong></figcaption></figure><h1 id="f4bb" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="d0d8" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">我们已经在Pinterest的所有视觉搜索产品中推出了统一嵌入并替换了专用嵌入。嵌入式统一使我们能够简化我们的培训和服务基础设施，并在全球范围内迭代所有产品，因此我们可以更快地实现我们最重要的目标:为Pinners构建和改进Pinterest。</p><p id="3d40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读！这项工作的更多细节在我们的<a class="ae jc" href="https://arxiv.org/abs/1908.01707" rel="noopener ugc nofollow" target="_blank">KDD 19年的论文</a>中呈现。</p><p id="5e09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jd">鸣谢:视觉嵌入是Pinterest的一项合作成果。特别感谢、Eric Tzeng、Dong Huk Park、Chuck Rosenberg、Raymond Shiau、Kunlong Gu、、Josh Beal、Eric Kim、Jeffrey Harris、Angela Guo、Dmitry Kislyuk和Michael Feng在本项目中的合作。</em></p></div></div>    
</body>
</html>