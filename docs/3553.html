<html>
<head>
<title>PoseNet: Your Gateway to Gesture Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PoseNet:手势检测的入口</h1>
<blockquote>原文：<a href="https://medium.com/globant/posenet-your-gateway-to-gesture-detection-a15d0ed0ae40?source=collection_archive---------0-----------------------#2020-11-23">https://medium.com/globant/posenet-your-gateway-to-gesture-detection-a15d0ed0ae40?source=collection_archive---------0-----------------------#2020-11-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d7230b4090497d3bf42251005851a0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_uv_ubFw84LzAUNpaVnorA.jpeg"/></div></div></figure><p id="3a5f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">您是否想过这些年来我们都是如何提供反馈的？</p><p id="a072" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们通常会写一张便条并把它放在一个邮箱里，我们会拨打他们的反馈电话，或者通过电子邮件向他们发送我们的建议。</p><p id="5a6c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你有机会观看我们Globant UI工程工作室的年度旗舰活动，“UI Next 的<strong class="ir hi"> UI”，你会看到我们制作的一个应用程序，帮助我们的客人使用手势提供反馈。</strong></p><p id="9198" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们看一个小视频来一窥究竟。</p><figure class="jn jo jp jq fd ii"><div class="bz dy l di"><div class="jr js l"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">Feedback Form</figcaption></figure><p id="fc94" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们还开发了另一款类似的应用，名为<strong class="ir hi">深蹲计算器</strong>。它有助于计算一个人在笔记本电脑前深蹲的时间。</p><figure class="jn jo jp jq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jx"><img src="../Images/886ba6d88ea2605e08d8c5b4f46eae20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0nU_Dp5egZTTt9Yqzv9QQ.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Squats Calculator</figcaption></figure><p id="99f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使这成为可能的是一个名为PoseNet的库，它构建在TensorFlow平台之上。</p><p id="67d8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">给你一个简单的描述，<strong class="ir hi"> TensorFlow </strong>是一个机器学习的开源平台，它为你提供了一个完整的工具生态系统来构建这些ML应用。</p><p id="bad7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">PoseNet为我们提供了检测用户手势所需的预训练模型。这些预先训练好的模型在我们的浏览器中运行，这就是PoseNet与其他API依赖库的区别。因此，我们不必将我们的私人数据发送到后端服务器。隐私保护是PoseNet优于其他API依赖库的地方。</p><p id="e246" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">此外，任何人只要有一台配有摄像头的台式机或手机，就可以在他们的网络浏览器中体验这项技术。我们不需要一些庞大的类似服务器的资源来识别这些手势。我们可以用普通机器最少的东西来应付。</p><blockquote class="jy jz ka"><p id="298e" class="ip iq kb ir b is it iu iv iw ix iy iz kc jb jc jd kd jf jg jh ke jj jk jl jm ha bi translated"><strong class="ir hi">pose net到底为我们做了什么？</strong></p></blockquote><p id="4e90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">顾名思义，它估计对我们构成了威胁。</p><blockquote class="kf"><p id="5597" class="kg kh hh bd ki kj kk kl km kn ko jm dx translated">姿势估计是指计算机视觉技术，它可以检测我们通过网络摄像头提供的图像和视频中的人物，以便它能够为我们确定我们的肘部、手腕或任何其他身体关节在图像中的位置。</p></blockquote><p id="e401" class="pw-post-body-paragraph ip iq hh ir b is kp iu iv iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ha bi translated">下图展示了PoseNet如何实时估计用户的关键点或姿势。</p><figure class="jn jo jp jq fd ii er es paragraph-image"><div class="er es ku"><img src="../Images/2e8c83c8e8e77677f42e20600310edfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/1*50uiLFHm9fJFGau5n4ichg.gif"/></div></figure><p id="5d26" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">PoseNet给了我们总共<strong class="ir hi"> 17个可以利用的姿势要点</strong>，从我们的眼睛和耳朵到膝盖和脚踝。</p><figure class="jn jo jp jq fd ii er es paragraph-image"><div class="er es kv"><img src="../Images/12df07525b533346a900ec07202f45a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*ipww1HiES8dlxUnH1RnRQA.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx">17 Pose key-points</figcaption></figure><blockquote class="jy jz ka"><p id="60af" class="ip iq kb ir b is it iu iv iw ix iy iz kc jb jc jd kd jf jg jh ke jj jk jl jm ha bi translated"><strong class="ir hi">如果我们提供给PoseNet的图像不够清晰怎么办？</strong></p></blockquote><p id="12d9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">PoseNet给出了它能够识别图像或图像中特定关键点的准确度的置信度分数。</p><figure class="jn jo jp jq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kw"><img src="../Images/b24f72b64025b611e380fe4183bbb2ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*TvK8CEvd2ljunApmpm-raQ.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">Confidence Score</figcaption></figure><p id="1574" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如上图所示，人1的置信度为0.8，而视觉不太清晰的人2的置信度相对较低，为0.7。这被表示为一个JSON响应。</p><p id="7d91" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi"> <em class="kb">得分</em> </strong>”表示该人或特定关键点的置信度得分。“<strong class="ir hi"><em class="kb">x</em></strong>’&amp;’<strong class="ir hi"><em class="kb">y</em></strong>”表示该特定关键点在图像中的各自坐标。</p><figure class="jn jo jp jq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/88ff303e5a24efeb74f13ede8d621571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtSQEwj21i8c9Znof6tBJg.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx">PoseNet Response</figcaption></figure><p id="9108" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你有什么想法，想继续写代码，你可以从<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/tree/master/posenet/demos" rel="noopener ugc nofollow" target="_blank">这里</a>克隆代码，然后转到camera.js文件。</p><p id="9d7b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这个文件中，您可以看到下面的代码片段，其中发生了实际的响应操作。这是你发挥创造力的地方。</p><figure class="jn jo jp jq fd ii"><div class="bz dy l di"><div class="kz js l"/></div></figure><h2 id="42d0" class="la lb hh bd lc ld le lf lg lh li lj lk ja ll lm ln je lo lp lq ji lr ls lt lu bi translated"><strong class="ak">我们从PoseNet收到的是一条原始的JSON信息，但是我们如何可视化这17个关键点和置信度得分，并作为开发人员使用它们，取决于我们自己。</strong></h2><h2 id="6be5" class="la lb hh bd lc ld le lf lg lh li lj lk ja ll lm ln je lo lp lq ji lr ls lt lu bi translated">让我们以此为基础构建一些东西，帮助人们的日常生活！</h2></div><div class="ab cl lv lw go lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ha hb hc hd he"><p id="f276" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">参考&amp;信用链接</strong></p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">用TensorFlow.js实现浏览器中的实时人体姿态估计</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">Dan Oved，谷歌创意实验室的自由创意技术专家，NYU ITP大学的研究生。编辑和…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt in mf"/></div></div></a></div><div class="mc md ez fb me mf"><a href="https://github.com/tensorflow/tfjs-models/tree/master/posenet" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">张量流/tfjs-模型</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">这个包包含一个名为PoseNet的独立模型，以及一些演示，用于运行实时姿态估计…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">github.com</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt in mf"/></div></div></a></div></div></div>    
</body>
</html>