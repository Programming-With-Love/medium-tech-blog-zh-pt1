<html>
<head>
<title>Lessons From Alpha Zero (part 5): Performance Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Alpha Zero的经验(第5部分):性能优化</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e?source=collection_archive---------0-----------------------#2018-07-03">https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e?source=collection_archive---------0-----------------------#2018-07-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/40d226fa92ba27244151905268ad8d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QLueTV9tB5egH1j2"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@cadop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mathew Schwartz</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7fc8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是我们关于实施AlphaZero的经验教训系列的第五部分。查看 <a class="ae it" rel="noopener" href="/oracledevs/lessons-from-implementing-alphazero-7e36e9054191"> <em class="js">第一部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-connect-four-e4a0ae82af68"><em class="js">第二部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5"><em class="js">第三部分</em></a><em class="js"/><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-4-improving-the-training-target-6efba2e71628"><em class="js">第四部分</em> </a> <em class="js">。</em></p><p id="0613" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我们回顾了AlphaZero实现的一些方面，这些方面让我们大大提高了游戏生成和训练的速度。</p><h1 id="2035" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">概观</h1><p id="39c4" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">实现AlphaZero的任务令人生畏，不仅因为算法本身错综复杂，还因为作者们在研究中使用了大量资源:在许多小时的过程中使用了5000个TPU来训练他们的算法，这可能是在花费了大量时间来确定最佳参数以允许它快速训练之后。</p><p id="e2f4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过选择Connect Four作为我们的第一个游戏，我们希望在利用更适度的资源的同时，实现AlphaZero的可靠实现。但在开始后不久，我们意识到即使像Connect Four这样简单的游戏也需要大量的资源来训练:在我们最初的实现中，在一台支持gpu的计算机上训练需要数周时间。</p><p id="b674" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">幸运的是，我们能够进行一些改进，使我们的培训周期时间从几周缩短到大约一天。在这篇文章中，我将回顾一些我们最有影响力的变化。</p><h1 id="379f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">瓶颈</h1><p id="bbbd" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">在深入研究我们为减少AZ训练时间所做的一些调整之前，让我们描述一下我们的训练周期。尽管AlphaZero的作者使用了连续和异步的过程来执行模型训练和更新，但是对于我们的实验，我们使用了以下三阶段同步过程，我们选择该过程是因为它的简单性和可调试性:</p><p id="9e06" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> While(我的模型不够好):</strong></p><ol class=""><li id="5fdd" class="kw kx hh iw b ix iy jb jc jf ky jj kz jn la jr lb lc ld le bi translated"><strong class="iw hi">生成游戏:</strong>每个模型周期，使用最新的模型，游戏代理生成7168个游戏，这相当于大约140-220k个游戏位置。</li><li id="de4e" class="kw kx hh iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated"><strong class="iw hi">训练新模型:</strong>基于开窗算法，我们从历史数据中采样，并训练改进的神经网络。</li><li id="4db5" class="kw kx hh iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated"><strong class="iw hi">部署新模型:</strong>我们现在采用新模型，将其转换为可部署的格式，并将其推送到我们的云中，以进行下一轮培训</li></ol><p id="4672" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">毫无疑问，这个过程的最大瓶颈是游戏生成，当我们刚开始时，每个周期要花一个多小时。正因为如此，最小化游戏生成时间成为我们关注的焦点。</p><h1 id="c8e4" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">模型尺寸</h1><p id="4590" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">阿尔法零是非常推理重在自我发挥。事实上，在我们典型的游戏生成周期中，MCTS需要超过1.2亿个位置评估。根据模型的大小，这可能会转化为大量的GPU时间。</p><p id="8060" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在AlphaZero的最初实现中，作者使用了一种架构，其中大部分计算在20个剩余层中执行，每个层有256个过滤器。这相当于一个超过90兆字节的模型，这对于Connect Four来说似乎太大了。此外，考虑到我们最初有限的GPU资源，使用这样大小的模型是不切实际的。</p><p id="7c89" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">相反，我们从一个非常小的模型开始，只使用了5层和64个过滤器，只是为了看看我们是否可以让我们的实现学习任何东西。随着我们不断优化我们的管道和改进我们的结果，我们能够将我们的模型大小提高到20X128，同时仍然在我们的硬件上保持合理的游戏生成速度。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lk"><img src="../Images/5c45a8f3e3451801b5e549abf128f564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pASBf-x2S7N3WV6r8xXpeg.png"/></div></div></figure><h1 id="dd2f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">分布式推理</h1><p id="67c8" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">从一开始，我们就知道我们需要不止一个GPU来实现我们所寻求的训练周期时间，因此我们创建了允许我们的Connect 4游戏代理执行远程推理来评估位置的软件。这使得我们能够将大量使用GPU的推理资源与只需要CPU的游戏资源分开。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/0cb9f08e410b6cfcfcc3a350c365cf30.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*1y_ELuqkgH2a-Eh2Etpl2w.gif"/></div></figure><h1 id="a296" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">并行游戏生成</h1><p id="3f99" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">GPU资源是昂贵的，所以我们想确保我们在播出期间尽可能多地饱和它们。这比我们想象的要棘手。</p><p id="a529" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们实施的第一批优化之一是在同一进程的并行线程上运行许多游戏。也许最大的直接好处是，它允许我们缓存位置评估，这可以在不同的线程之间共享。这将发送到我们的远程推理服务器的请求数量减少了两倍多:</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/a8a9ce983be8807e421fee2246752252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQVLlHQRpVptlHnBZFbZrg.png"/></div></div></figure><p id="2bf7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">缓存是一个巨大的胜利，但是我们仍然希望以高效的方式处理剩余的未缓存请求。为了最大限度地减少网络延迟并最大限度地利用GPU并行化，我们将来自不同工作线程的推理请求合并到一个桶中，然后将其发送到我们的推理服务。这样做的缺点是，如果桶没有被及时填满，任何调用线程都会一直等待，直到桶超时。在这种方案下，选择合适的推理桶大小和超时值非常重要。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/8d77c601a57136b57976e82dbb539620.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*EFR6d0kRab0lqW-_ueojHw.gif"/></div></figure><p id="5434" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们发现在游戏生成批次的整个过程中，桶填充率会有所不同，主要是因为一些游戏会比其他游戏更早完成，留下越来越少的线程来填充桶。这导致一批游戏的最后一个游戏要花很长时间才能完成，而GPU的利用率却下降到了零。我们需要一种更好的方式来保持我们的水桶装满。</p><h1 id="b452" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">平行MCTS</h1><p id="5fb8" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">为了帮助解决我们的未填充桶问题，我们实现了并行MCTS，这在AZ的论文中讨论过。最初，我们忽略了这个细节，因为它似乎对竞技性的一对一游戏最重要，因为并行游戏不适用。遇到前面提到的问题后，我们决定试一试。</p><p id="b605" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">并行MCTS背后的想法是允许多线程承担累积树统计数据的工作。虽然这听起来很简单，但naiive方法有一个基本问题:如果N个线程同时开始，并根据当前的树统计选择一条路径，它们将选择完全相同的路径，从而削弱MCTS的探索组件。</p><p id="b1f2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了抵消这一点，AlphaZero使用了虚拟损失的概念，这是一种临时将游戏损失添加到模拟过程中遍历的任何节点的算法。锁用于防止多个线程同时修改节点的模拟和虚拟丢失统计。在访问了一个节点并应用了虚拟丢失之后，当下一个线程访问同一节点时，它将被阻止遵循同一路径。一旦线程到达终点并备份其结果，这种虚拟丢失将被删除，从而从模拟中恢复真实的统计数据。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/5bbc021253cd192bcee899cd8b0a2afb.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/1*aavWOWmSuAhwFtJMCeOcvw.gif"/></div></figure><p id="cce3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">随着虚拟损失的到位，我们终于能够在游戏生成周期的大部分时间内实现95%以上的GPU利用率，这是我们接近硬件设置的真正极限的标志。</p><p id="09c9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从技术上来说，虚拟损失增加了游戏播出的某种程度的探索，因为它迫使选择沿着MCTS可能不自然倾向于访问的路径移动，但我们从未测量过由于它的使用而产生的任何有害(或有益)影响。</p><h1 id="4ceb" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">TensorRT/TensorRT+INT8</h1><p id="419e" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">虽然没有必要使用与AlphaZero论文中描述的模型一样大的模型，但我们发现从更大的模型中学习更好，所以希望使用尽可能大的模型。为了帮助解决这个问题，我们尝试了<a class="ae it" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank"> TensorRT </a>，这是Nvidia创造的一项技术，用于优化模型推理的性能。</p><p id="533d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用几个脚本就可以很容易地将现有的Tensorflow/Keras模型转换为TensorRT。不幸的是，在我们开发这个的时候，还没有发布TensorRT远程服务组件，所以我们自己写了。</p><p id="8c84" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用TensorRT的默认配置，我们注意到推理吞吐量略有增加(约11%)。我们对这种适度的改进感到高兴，但希望通过使用TensorRT的INT8模式，性能会有更大的提高。INT8模式需要更多的努力，因为当使用INT8时，您必须首先生成一个校准文件，以告诉推理引擎在使用8位近似数学时将什么比例因子应用于您的层激活。这种校准是通过将您的数据样本输入Nvidia的校准库来完成的。</p><p id="f12d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因为我们观察到校准运行质量的一些变化，所以我们将尝试对3组不同的样本数据进行校准，然后根据保留数据验证结果配置。在三次校准尝试中，我们选择了验证误差最小的一次。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/86beab7e8f49a059eafcda2b8098188f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*vip7XkJR2i3b4qOulauxwA.png"/></div></figure><p id="e3da" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一旦我们的INT8实现到位，我们看到推理吞吐量比股票libtensorflow增加了近4倍，这使我们能够使用比其他方式更大的模型。</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/4faf76fab63a0ef0a6735727ca86a5a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0gViVfjG-p4-3yVUqI9EQ.png"/></div></div></figure><p id="537e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用INT8的一个缺点是，在某些情况下，它可能会有损耗并且不精确。虽然我们在训练的早期没有观察到严重的精度问题，但随着学习的进行，我们会观察到推理的质量开始下降，特别是在我们的值输出上。这最初导致我们只能在培训的早期阶段使用INT8。</p><p id="0286" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">意外地，当我们开始尝试增加头部网络中卷积滤波器的数量时，我们能够几乎消除INT8精度问题，这是我们从<a class="ae it" href="https://github.com/LeelaChessZero/lczero" rel="noopener ugc nofollow" target="_blank"> Leela Chess </a>得到的想法。下面是我们的值输出的平均误差图，值头中有32个过滤器，与AZ默认值1:</p><figure class="ll lm ln lo fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/5724e79f56fc56310374bc1a42d0cfd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*X3h0bY7l1n3jFBer8GpX9Q.png"/></div></figure><p id="f67c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的理论是，给这些层增加额外的基数会减少激活的差异，这使得模型更容易精确量化。这些天来，我们总是在启用INT8的情况下运行我们的游戏，即使在AZ训练即将结束时也没有看到任何不良影响。</p><h1 id="28e9" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">摘要</h1><p id="4dcb" class="pw-post-body-paragraph iu iv hh iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr ha bi translated">通过使用所有这些方法，我们最终能够训练一个具有高GPU利用率和良好周期时间的体面模型。最初看起来，完成一次完整的训练需要几周时间，但现在我们可以在不到一天的时间内训练出一个像样的模型。这很棒，但事实证明我们才刚刚开始——在下一篇文章中，我们将讨论我们如何调整AlphaZero本身以获得更好的学习速度。</p><p id="16d8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae it" rel="noopener" href="/oracledevs/lessons-from-alpha-zero-part-6-hyperparameter-tuning-b1cfcbe4ca9a">第六部</a>现在出来了。</p></div></div>    
</body>
</html>