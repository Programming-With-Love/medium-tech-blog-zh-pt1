<html>
<head>
<title>Pinterest Home Feed Unified Lightweight Scoring: A Two-tower Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pinterest Home Feed统一轻量级评分:双塔方法</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/pinterest-home-feed-unified-lightweight-scoring-a-two-tower-approach-b3143ac70b55?source=collection_archive---------0-----------------------#2021-09-09">https://medium.com/pinterest-engineering/pinterest-home-feed-unified-lightweight-scoring-a-two-tower-approach-b3143ac70b55?source=collection_archive---------0-----------------------#2021-09-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8dc7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大方何|软件工程师，家考生代；廖骏伦；Dhruvil Deven Badani |软件工程师，Homefeed排名；Poorvi BhargavaSangmin Shin |工程经理，首页排名；张铎|工程经理，候选人生成；Jay Adams |软件工程师，Inspire</p><h1 id="7a83" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">介绍</h1><p id="7546" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinterest是一个用户(Pinners)可以保存和发现来自网络和移动平台的内容的地方，越来越多的创作者可以将原生内容发布到Pinterest。我们在语料库中拥有数十亿的内容(pin ),并提供个性化的推荐，激励Pinners创造他们热爱的生活。Pinterest最关键也是最复杂的界面之一是home feed，Pinners可以在这里根据他们的参与度和兴趣看到个性化的feed。在这篇博客中，我们将讨论如何在支持home feed推荐的各种候选生成器之间统一轻量级评分层。</p><h1 id="48e1" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">动机</h1><p id="baf8" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinners打开Pinterest应用时首先看到的是Home feed。为了提供相关和多样的推荐，我们使用一个包含许多不同来源的推荐系统。例如，一个主要的来源是<a class="ae kf" rel="noopener" href="/pinterest-engineering/an-update-on-pixie-pinterests-recommendation-system-6f273f737e1b"> Pixie </a> [1]，它基于<a class="ae kf" href="https://en.wikipedia.org/wiki/Bipartite_graph" rel="noopener ugc nofollow" target="_blank">二部针板图</a>的随机行走。基于Pixie平台，我们能够生成多种不同的来源，一些来源基于参与历史直接从随机漫步返回pin，一些来源基于从Pixie随机漫步返回的电路板检索的pin。除了Pixie，我们还有接受主题或基于嵌入的推荐源。这些候选生成器通常有自己的轻量级评分模型，该模型对最相关的候选进行排名和选择，并将其发送到最终排名。例如，我们有一个随机行走后在生产中使用的gbdt轻量级评分模型[2]。首页提要推荐引擎的总体情况如图1所示。</p><p id="cb4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些推荐源大多具有:</p><ol class=""><li id="c6b8" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">个人培训数据生成管道</li><li id="2108" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">不同的在线服务方式</li><li id="5d3d" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">不同的轻型型号在服务期间具有不同的功能集。</li></ol><p id="60a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">开发仅服务于一个特定候选生成器的单个机器学习模型需要大量的工程工作。这大大限制了ML工程师的开发速度。</p><p id="e3da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除了开发速度之外，如果我们为了改进轻量级模型而增加特性集，我们还会看到在线服务成本的增加。这是因为每个候选源将需要对一大组候选源(pin)进行相对复杂的在线模型计算。例如，对于一个由pixie轻量级评分[2]支持的源，它在服务中使用gbdt模型，并且需要计算每个请求的数千个pin的排名。这种计算开销使得很难在不引入大量服务成本的情况下进行特征工程。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/5e8a5e4503c323988224604dfd043d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zkpteuKvYYXwHk7m"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Fig. 1. <em class="lk">Overview of current home feed recommendation pipeline. </em>Home feed recommendation is powered by many different candidate generators. Each of them serves a unique role and has its own light-weight ranking layer.</figcaption></figure><p id="0451" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后但同样重要的是，对于某些候选来源，许多功能在在线申请阶段也不可用。添加这些功能会带来基础设施开销，并且在实际收集数据和运行实验之前很难证明性能提升的合理性。Pixie lws的博客帖子中也提到了这个痛点。</p><p id="0534" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有这些因素促使我们<strong class="ig hi">为这些候选生成器统一</strong>我们的机器学习建模和服务方法，以便为最终排名模型提供一组更个性化的候选。因此，我们决定使用统一的双塔模型[3]，[4]进行轻量级建模。</p><h1 id="03de" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">双塔建筑</h1><p id="11da" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在这一节中，我们将描述我们的双塔建模方法，用于统一灯光评分，目标是解决上述棘手问题。</p><p id="0dda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">双塔架构的概述如图2所示。它有一个单独的用户塔和一个Pin塔，最终的点积计算给定用户和给定Pin之间的相似性。引脚塔从给定引脚获取特征，并为其生成引脚嵌入。所使用的特征包括密集特征如Pin的最近表现以及稀疏特征如类别。稀疏特征将在发送到pin的MLP进行最终嵌入计算之前被传递到嵌入层。用户塔将参与历史特征作为输入，并生成用户特定的嵌入。最后，我们基于两个嵌入做了一个简单的点积，作为Pinner与Pin接合的可能性的度量。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ll"><img src="../Images/619660619b774b08d519ac383cc80335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vT2CJzQnHbEHIUam"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Figure 2. <em class="lk">The overview of two-tower architecture used in unified light-weight scoring. On the left side, it is the pin tower that computes the pin’s embedding, and on the right side we have the user tower that generates the user embedding.</em></figcaption></figure><h1 id="ef15" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">培养</h1><p id="205b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">对于轻量级排序层上双塔模型的优化，我们必须将其与排序层上的建议区别对待，因为与将用于排序的pin相比，我们将在候选生成器级别上面对更多负面候选。因此，我们应用批内负抽样方法[5]，并在我们的训练中使用6000的批量大小，以便使每个正候选与免费产生的足够的负候选相结合。我们发现，通过应用这一点，我们能够实现更好的离线指标，如通过在top k的召回所测量的。</p><h1 id="ebe9" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">服务</h1><p id="a28f" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在这一部分，我们将描述我们如何服务于机器学习模型来支持在线候选人检索推荐。服务架构将包括两个部分:Pin嵌入服务和用户嵌入服务。我们将在这里分别讨论这两个部分。</p><h2 id="b095" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">嵌线上菜</strong></h2><p id="993c" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinterest中所有可能的候选pin的Home feed powers推荐。因此，我们必须计算所有引脚的嵌入。通常对于推荐引擎来说，内容分发将遵循长尾规则，并且对于我们来说重要的是避免每次对于在线请求重新计算相同的pin嵌入，因为许多请求将被归因于相同的pin。另一方面，pin的内容不会移动太多，所以它们的嵌入相对稳定。因此，我们应该能够在离线工作流中计算大多数引脚的嵌入。在在线请求中，我们只需要检索预先计算的嵌入，而不是重新计算。对于新的pin(在几小时内进入Pinterest生态系统的pin)，我们将需要为它们进行在线推断，因为它们不会被离线工作流拾取。因此，我们将引脚的嵌入计算分离到两个不同的管道中，如图3所示。</p><h2 id="1ceb" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">用户嵌入服务</strong></h2><p id="eb35" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">Pinners倾向于立即改变他们的状态。例如，如果一个销针与一个卡特彼勒销接合，他们很可能在不久的将来与另一个卡特彼勒销接合。因此，捕捉反映他们实时兴趣的状态变化对我们来说很重要。为此，每当有新的用户请求时，我们就启用在线用户嵌入计算。添加这样的东西不会是一个昂贵的计算，因为我们每个请求只计算一次。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ma"><img src="../Images/9b9635971e5316f010fda491b054cfc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0tiU-pEm-XS9lyR5"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx">Figure 3. <em class="lk">The overall serving pipeline for candidate retrieval with two-tower embedding computation. Most of the existing pins will be inserted into candidate generators with an offline workflow that computes pin embeddings, while new pins will be inserted to be served after they get online pin embedding computation</em>.</figcaption></figure><h1 id="c339" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">视窗网际网路名称服务</h1><p id="b12a" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">为了评估统一轻量级评分方法的性能，我们做了一个在线实验，将轻量级评分层应用于所有候选生成器。我们看到了以下几个方面的收获。</p><h2 id="384a" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">订婚胜利</strong></h2><p id="dbe6" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">通过对所有候选生成器应用轻量级排序层，我们看到了巨大的参与度提升。例如，总储蓄和特写都增加了2-3%。我们也看到总皮革量下降了3-4%。这些指标的胜利证明了相关性的改善，同时使用双塔架构来取代旧的轻量级排名方法。我们认为这是因为双塔方法可以利用Pin和Pinner的所有相关功能，因此我们可以为两者获得更好的嵌入表示。</p><h2 id="aece" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">多样性</strong></h2><p id="0e53" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">将同一模型应用于所有候选生成器的一个问题是，这将使我们的推荐不那么多样化。作为一个旨在激励Pinners的平台，我们不想放弃我们的推荐多样性。然而，在我们的在线实验中，我们实际上看到采用的多样性增加了(保存、特写等)。我们认为这是因为(1)生成的用户嵌入可以基于参与历史编码多样化的兴趣。(2)由双塔方法提供的更好的推荐过滤掉了不相关的引脚，并且推荐的项目更有可能被采用。</p><h2 id="f0bf" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">基础设施成本</strong></h2><p id="8438" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">每个请求使用数千个引脚的在线计算成本很高。考虑到我们正在处理的候选生成器的数量，情况尤其如此。通过使用双塔方法在轻量级排名层应用简单的点积，我们显著降低了每个请求的在线服务成本。考虑具有两个64维嵌入向量的点积，我们只需要n次乘法运算和n次加法运算。这比，例如，具有在线特征转换的逻辑回归模型，桶化，要便宜得多。通常，在我们最初的服务系统中，这最终会导致一个长向量和巨大的在线服务成本。</p><h1 id="db70" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">总结&amp;未来作品</strong></h1><p id="8b82" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在这篇文章中，我们概述了目前在Homefeed中使用的统一轻量级排名层。我们关注这些努力的主要动机以及从中获得的经验。总之，从机器学习建模的角度来看，密集编码的学习嵌入向量提供了更好的推荐，我们不仅在参与度方面取得了收益，而且在采用多样性和基础设施成本节约方面也取得了收益。同时，我们能够在不同候选生成器使用的不同服务基础设施之间应用相同的模型。</p><p id="f0a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在未来的工作中，我们将尝试使用更好的功能和ML建模来不断改进轻量级排名模型。我们还将尝试将该模型应用于其他一些新添加的候选生成器，以进一步统一我们的轻量级评分层。</p><h1 id="02e0" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">鸣谢:</strong></h1><p id="c753" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">邓宝文、吴、谢海滨、傅、尚雯婕、张世元、姜建清、米开朗琪罗、、王迪伦、、、陈蜜蜂、张良。</p><p id="a982" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mb">要在Pinterest了解更多工程知识，请查看我们的</em> <a class="ae kf" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="mb">工程博客</em> </a> <em class="mb">，并访问我们的</em><a class="ae kf" href="https://www.pinterestlabs.com/?utm_source=medium&amp;utm_medium=blog-article&amp;utm_campaign=he-et-al-september-9-2021" rel="noopener ugc nofollow" target="_blank"><em class="mb">Pinterest Labs</em></a><em class="mb">网站。要查看和申请空缺职位，请访问我们的</em> <a class="ae kf" href="https://www.pinterestcareers.com/?utm_source=medium&amp;utm_medium=blog-article&amp;utm_campaign=he-et-al-september-9-2021" rel="noopener ugc nofollow" target="_blank"> <em class="mb">职业</em> </a> <em class="mb">页面。</em></p><h2 id="eade" class="lm jd hh bd je ln lo lp ji lq lr ls jm ip lt lu jq it lv lw ju ix lx ly jy lz bi translated"><strong class="ak">参考文献:</strong></h2><p id="d327" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">[1] Pixie:一个向2亿多用户实时推荐30多亿件商品的系统</p><p id="67d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2] Pixie lws博文:<a class="ae kf" rel="noopener" href="/pinterest-engineering/improving-the-quality-of-recommended-pins-with-lightweight-ranking-8ff5477b20e3">https://medium . com/Pinterest-engineering/improving-the-quality-of-recommended-pins-with-lightweight-ranking-8ff 5477 b20e 3</a></p><p id="3f29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3]用于youtube推荐的深度神经网络。p .科文顿，j .亚当斯和e .萨金。</p><p id="9283" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4]通过gramian估计对非常大的语料库进行有效训练。克里钦，w .，马约拉斯，n .，伦德，s .，张，l .，易，x .，洪，l .，迟，e .，安德森，J</p><p id="2643" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[5]用于大语料库项目推荐的采样偏差校正的神经建模。信阳易洪陆。</p></div></div>    
</body>
</html>