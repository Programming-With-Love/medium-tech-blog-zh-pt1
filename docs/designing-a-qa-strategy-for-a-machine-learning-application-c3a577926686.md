# 为机器学习应用程序设计问答策略

> 原文：<https://medium.com/globant/designing-a-qa-strategy-for-a-machine-learning-application-c3a577926686?source=collection_archive---------1----------------------->

软件测试中的人工智能

# 介绍

本文的目标是为所有面临为一个系统设计测试计划的质量分析师提供指导，该系统实现了一个基于监督学习的人工智能模型。鉴于这一主题的广泛性质，并且出于实际目的，需要解决一些机器学习概念，并且在非常高的水平上解释它们。主要目的是为适用于设计每个阶段的不同测试技术提供指导。

# 基于人工智能的系统与“传统”应用

基于人工智能的实现不同于传统项目，甚至在测试策略方面也是如此。传统的*“确定性”*测试方法仅仅基于实际结果与预期结果的比较，可能不够准确。

这并不意味着输入和输出条件之间没有逻辑关系，但是现有的相关性并不总是那么明显和线性的，最重要的是，我们不是在验证明确的结果(例如:密码正确，用户正确，然后成功登录……)，而是验证模型所具有的学习能力。

这是因为对于基于人工智能的系统来说，我们正在测试什么、我们如何测试以及我们何时测试的概念有很大的不同，在基于人工智能的系统中，其功能是预测或分类(任何类型的)数据，而不是遵循一系列基于脚本的操作，这些操作的预期结果取决于之前执行的步骤。

记住:测试中最重要的功能是学习的*能力。*

话虽如此，在人工智能系统中，质量分析师的角色变得更具战略性和分析性。

# 什么时候考虑实施 AI？

*   当我们由于影响结果的变量的复杂性或多样性而无法对规则进行编程时
*   当大量因素取决于结果时
*   当要处理的信息量非常大时

一些例子:

*   一家航空公司希望根据历史数据自动计算未来几年的机票价格。
*   一家计算机安全系统制造商希望开发一种软件，能够识别来自真实请求的攻击或入侵。
*   一家房地产咨询公司希望根据具有相似特征的房屋的历史数据来计算一处房产的销售价格。
*   一个流媒体平台希望实现专门针对那些可能取消订阅的用户的定制营销活动。

# QA 应该在何时(何地)开始？

# 基于人工智能的系统开发周期的不同阶段(以及质量在每个阶段的作用)

让我们从一个有点争议的声明开始，这将允许我们在人工智能测试的世界中迈出第一步:从 QA 的角度来看，开始参与人工智能的世界，你不需要*对机器学习模型的数学或代数基础有深刻的理解。*

这种理解系统的方式为我们所熟知:一种**黑盒**测试**策略。在这种方法下，智能代理是一个盒子，我们对知道里面发生了什么不感兴趣(*至少现在…* )，我们只对这个系统与*环境*的交互感兴趣。我们需要知道*它做什么*而不是*它如何做*。从这个前提出发，我们准备好定义我们可以为基于人工智能的系统实现的许多测试策略之一的基础。**

为了在人工智能实施的不同发展阶段确定质量工程师的角色和预期结果，我们可以定义以下阶段:

*(请记住，这种分类是为了说明的目的，包括最常见的分类，但当然，它可能会根据每个特定的实施而有所不同)*

# 设定目标

这是一切开始的地方。设定目标显然与商业策略和想要达到的结果有关。人工智能并不总是为任何实现提供可行和合理的替代方案(许多问题可以在不实现这种类型的技术的情况下解决)。但是，在处理大量数据并且可以通过深度分析和理解获得有价值的信息的情况下，人工智能变得至关重要，不仅可以加快开发时间，还可以加快结果的获得。

# 收集数据

一旦定义了目标，下一步就是选择业务分析师和产品所有者首先考虑的、可能与执行预测相关的数据。这项任务可以与数据科学家共同定义。

让我们假设一个系统被设计来预测流媒体平台的哪些用户可以取消他们的订阅，并基于此实施某种预测性的营销行动。也许一条相关的信息是确定那些进行了多次不成功搜索的用户，那些没有根据自己的兴趣获得结果的用户，或者仅仅是最近几个月没有访问该平台的用户。这被认为是相关数据，因为在这些事件和服务的可能取消之间可能存在*【逻辑】*联系。

从 QA 的角度来看，我们在这一点上能做些什么？嗯，当我们与业务分析师一起定义测试范围、测试用例套件以及数据源(及其特征)时，这与“传统”项目中的情况相同。总有一些我们可以从想象中做出贡献的场景。作为有经验的质量分析师,“如果……”是我们最喜欢的句子之一……这个简单的问题可以改变一个项目的进程。

# 准备数据

在这一点上，质量分析师的角色变得更加重要，你已经可以想象为什么了。一旦我们选择了将作为模型输入变量的所有相关数据，我们必须确保它们的“表示”是正确的，因为随后需要对其进行处理。这与传统意义上的*大数据测试*有着内在联系。

在这里，我们必须应用一种类似于我们在 ETL 过程中实现的测试方法。我们可以从标准化引用相同数据的标签开始。这可能是我们质量战略的良好开端。

这是因为，在所有的 ETL 过程中，我们必须考虑相同类型的数据来自不同来源的可能性。让我们回到流媒体平台用户的例子。也许，涉及“用户”的字段来自不同的开发和平台，并且没有*“标准化”*标签，例如，游戏控制台的用户可以从智能电视发送为*“user _ id”*和*“user”*，从移动电话发送为“customer_id”。从数据集中排除所有超出平均值的值，分析那些不代表样本的奇点，寻找空值或“null”值，检查字段的格式、类型、预期值的范围…请始终记住，我们的模型是由数据提供的。不管程序设计得多好，如果我们传递给它的数据是不正确的，这个模型就会失败，我们不能责怪他。

# 选择算法

正如我们之前所说，实现机器学习的目标是创建一个模型，允许我们解决给定的任务。一旦定义了模型，就会使用大量数据对其进行训练。该模型从这些数据中学习，然后能够做出预测。根据您想要执行的任务，使用一种或另一种算法会更合适。

现有算法的多样性、它们的特征、算法背后的数学基础以及它们在机器学习中的应用是一个迷人的世界，我建议对其进行研究，但当然，这超出了本文的目的。

一些最重要的监督学习算法是:

*   线性回归
*   非线性回归
*   广义线性模型
*   决策树
*   神经网络

通常，质量工程师不是定义要实现的模型的人，这构成了数据科学家的主要职责，并且是整体实现设计的一部分。但是，正如我们将在后面看到的，质量分析师的责任是根据我们可以从模型中获得的不同度量标准来衡量模型的性能，并提供反馈，这当然以最佳方式符合与业务规则相关的目标。因此，从质量的角度来看，如果我们发现模型的行为不符合预期，数据的类型与预期的输入不匹配，我们可以向数据科学家提供反馈，这种想法是合理的，并且根据反馈，数据科学家可以“重新思考”最佳策略，包括使用另一个模型，这种想法也没有风险。但我坚持认为，这在正常情况下是不可预料的…

![](img/f6fccf13c1d89ca69759b3f838b4ad96.png)

# 培训模式

关于训练机器学习模型需要多少数据，这是一个远远超出本文目的的问题，我们可以找到很多关于这个主题的文章。有兴趣的推荐以下帖子:[“如何知道自己有足够的训练数据？](https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee)

训练模型是数据科学家执行的主要且最关键的任务。对于负责测试的质量分析师来说，理解它是如何执行的至关重要。

我们之前说过，为了训练一个模型，我们需要收集数据。训练数据的质量、数量和准确性将决定您的预测模型有多好。

通常，数据集被分成*训练*、*验证、*和*测试*数据。通常将 50%的数据分配给定型集，25%的数据分配给测试集，其余的数据分配给验证集。训练集包括输入“示例”,将通过调整参数来训练模型。当模型根据评估结果调整其参数时，验证数据集允许模型从其错误中学习。最后，测试数据集将允许对模型进行最终评估，我们可以从中获得不同的指标，如准确度、精确度等。在测试数据集中，我们想要预测的值不会传递给模型。它将根据训练和验证数据*“猜测”。*

# *评估模型*

*这里是我们的指标出现的地方。用于评估分类模型的三个主要因素是**准确度**、**精确度**和**召回**。我们将在*“我们可以从混淆矩阵中获得的指标”*一节中详细了解这些指标*

# *做预测*

*一旦模型准备好了，就该从功能的角度进行预测了。*

*通常，从 QA 的角度来看，在这个阶段，模型嵌入到应用程序中，我们可以通过用户界面访问我们的嵌入式模型，或者开发人员可以为我们提供 API，以便直接访问系统。无论如何，这是我们应用程序集成测试的开始。*

*最后一步，在生产中部署模型后，执行回归测试，以确保在发布底层更改时现有模型不会崩溃，并确保使用“真实世界”数据在生产中保持准确性。*

*根据验收标准评估应用程序只是 QA 的预期结果之一。另一个，也许是最重要的部分，是用统计术语评估模型，例如，90%确定应用程序将在给定范围内产生预期的输出。我们将看到更多帮助我们衡量模型有效性的详细指标*

# *机器学习类型*

*既然我们对基于人工智能的系统的开发周期的不同阶段有了概念，让我们更详细地了解不同类型的机器学习以及何时应用它们。*

*我们可以总结为，人工智能基于三种类型的学习:*

*   *监督学习*
*   *无监督学习*
*   *强化学习。*

*在本文中，我们将重点讨论第一个问题，其中数据的“人工”分析和分类(标记，以避免混淆)起着重要的作用。*

*不同的质量技术将应用于各种类型的机器学习，因为数据(系统的输入变量)的处理和分类是显著不同的。*

# *监督学习*

*在这篇文章中，我们将关注监督学习。这种类型的学习基于发现*输入*和*输出*变量之间的**关系**。与无监督学习相反，无监督学习发生在“标记”数据不可用于训练并且我们只知道输入数据时(例如，在输入数据中寻找相似性模式，这也被称为*聚类*)。*

*在监督学习模型中，学习发生在教导这些算法在展示了许多例子之后，我们对于某个值想要获得什么结果。*

*另一方面，强化学习是机器学习的一个子领域，其中“代理”学习如何在特定环境下从所有可用的可能性中选择一个动作，以随着时间的推移使“回报”最大化(让我们想象一只学会给我们带回棍子的狗，因为它知道我们会给他一些食物作为对他动作的奖励)*

*如果条件满足，算法将能够给出正确的结果，即使当你显示你以前没有见过的它的值。*

*让我们看看下面的例子:假设我们需要测试一个系统，其目的是分析与商业航班相关的不同变量，并基于此，能够根据作为变量提供给其“输入”的历史数据来预测航班是否会有某种延误。*

*我们的业务分析师和数据科学家认为以下变量与预测延迟相关，因为随着时间的推移，通过分析历史数据，他们已经得出初步结论，即这些变量与他们想要预测的结果之间存在直接关系。*

*   *出发机场*
*   *目的地机场*
*   *气象条件*
*   *航空公司*
*   *机场之间的距离*
*   *启程日期*

**![](img/f3063366fd3b3376bb3aaf58da3600d9.png)**

# **机器学习分类模型的性能评估**

**出于举例说明的目的，让我们继续航空业的例子，定义什么是外部和内部 KPI，让我们看看如何从这两个角度来衡量我们的模型的有效性。**

# **外部 KPI**

**我们可以将这些度量定义为那些从我们的模型的正确实现中出现的度量。作为其正确实施的逻辑或预期结果。我们假设，如果我们的模型实现了它的设计目的，我们将能够在操作层面或业务层面获得正确的指标。这正是我们在本文开头提到的“业务目标”。一些例子是:**

*   **与航班延误相关的运营成本(机场费)**
*   **客户满意度指标**
*   **改期航班的可用座位**
*   **总收入**
*   **劳动力成本、运营费用**

# **内部模型的 KPI**

**这里是我们衡量模型效率的地方，我们使用了一系列为此目的而获得的指标。从功能的角度来看，我们获得了一系列的“数字”,这些数字表明了我们的模型进行预测的能力。**

## **混淆矩阵**

**在人工智能和机器学习领域，混淆矩阵是一种允许可视化监督学习算法性能的工具。矩阵的每一列代表每一类的预测数，而每一行代表真实类中的实例。换句话说，实际上，它允许我们看到我们的模型同时考虑了哪些类型的成功和错误。**

**虽然混淆矩阵本身不是一个度量，但它给了我们一个矩阵作为输出，并描述了模型的完整性能。**

****我们示例中的四个选项是:****

1.  **延误的航班，模型将其归类为延误。这将是一个真正的积极或 TP。**
2.  **未延误的航班，模型将其归类为未延误。这将是一个真正的负数或 TN。**
3.  **延误的航班，模型将其归类为未延误。这将是一个假阴性或 FN。**
4.  **没有延误的航班，模型将其归类为延误。这是一个假阳性或 FP。**

**现在更清楚了，我们可以在矩阵中找出错误所在(黄色方框)。**

**![](img/a3fc99a9f1d18900ed2dd79084555126.png)**

# **我们可以从混淆矩阵中获得的度量**

**预期结果或业务目标与外部和内部 KPI 都相关。例如，达到一定百分比的“准确性”可以决定质量验收。我们可以从我们的模型中获得的最常见的指标以及对每个指标的简要说明如下:**

## **准确(性)**

**准确性是衡量模型成功预测的案例百分比的指标，是总测试数据集的正确预测分类(真阳性和真阴性)的比率。**

***精度*=*TP*+*TN/*(*TP*+*TN*+*FP*+*FN)***

**在我们的例子中，这个指标回答了这样一个问题:在所有的航班中，系统正确地分类了多少个航班(真阳性或真阴性)？**

## **精确**

**精度是真阳性和所有阳性之间的比率。**

**该指标回答了问题*“实际上正确的肯定识别比例是多少？”*，**

***精度* = *TP/TP+FP***

**精度是正确预测阳性观察值(真阳性)的结果与系统总预测阳性观察值(真阳性和假阳性)的比率。**

## **回忆**

**召回率是正确预测阳性真阳性观察结果的结果与所有实际阳性结果的比率。一个模型能够预测的真阳性的百分比，或者换句话说，在所有实际延误的航班中，系统正确分类为延误的航班有多少？**

***回忆* = *TP/(TP+ FN)***

## **F1 分数**

**这个分数考虑了假阳性和假阴性，并且被认为是精确度和召回率的调和平均值。虽然我们可以取两个分数的简单平均值，但这个指标更能抵抗异常值。**

***F1 得分* = *2x(精准+召回)/精准+召回***

# **结论**

**为人工智能实现设计测试计划不仅限于验证测试场景并将其与预期结果进行比较。我们正在评估一个模型执行预测的能力，当然，初步结果是很好的指标，但不是唯一的指标。挑战在于当模型被部署到生产中并开始处理真实世界的数据时，要验证学习能力。**

**质量策略从场景的定义、输入变量的分类、数据的验证和模型的最终评估开始。**

**我们将在多大程度上参与理解每个模型如何工作完全取决于我们，尽管在本文中我们已经解释了基于*“黑盒”*监督学习模型测试的方法，理解每个机器学习算法背后的数学基础将允许我们转向*“白盒”*方法，例如，通过“调整”超参数来改善模型性能，这将允许我们向数据科学家和开发人员提供更全面的反馈。**

**在理解机器学习的基础上，我们可以采取的每一步都是对测试策略非常重要的附加值，并将帮助我们提高交付的质量。**