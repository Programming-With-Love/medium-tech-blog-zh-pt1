<html>
<head>
<title>CTR Optimization via Thompson Sampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过Thompson采样优化CTR</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/ctr-optimization-via-thompson-sampling-83df19fa577f?source=collection_archive---------0-----------------------#2020-01-14">https://medium.com/walmartglobaltech/ctr-optimization-via-thompson-sampling-83df19fa577f?source=collection_archive---------0-----------------------#2020-01-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d779e68692a237829110a37e97471ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBaZYikBdxRsUe0-8ZEfcA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo credit: <a class="ae it" href="https://pixabay.com/photos/slot-machine-one-armed-bandit-play-425713/" rel="noopener ugc nofollow" target="_blank">khfalk</a></figcaption></figure><p id="2a45" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">沃尔玛实验室是一家数据驱动的公司。许多业务和产品决策都基于从数据分析中获得的洞察力。我在Expo工作，这是沃尔玛的A/B测试平台。作为该平台的一部分，我们开发了一个功能来优化基于Walmart.com点击率的实验。CTR(点击率)是导致点击的印象的百分比。CTR优化的目标是将流量动态分配给具有较高CTR的变体，同时将较少的流量分配给具有较低CTR的变体。该功能是基于多臂土匪(MAB)内容测试范式开发的。</p><h1 id="c80d" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">多股武装匪徒</h1><p id="6973" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">以此类推，“多臂强盗”是一台有多条手臂的机器，每条手臂都有不同的预期回报值。玩家需要计算出哪只手支付的金额最高。为了识别具有最高预期回报的一个，拉出不同的分支的阶段被称为“<strong class="iw hi">探索</strong>”。到目前为止最有利可图的阶段被称为“<strong class="iw hi">开发</strong>”。</p><p id="0ba5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">“多臂强盗”问题的目标是构造一个策略，以最大化特定标准为目标，在探索和开发之间取得平衡。多臂土匪有勘探和开发两个阶段，根据武器的持续性能以适应性方式交替进行。这种模式非常适合网站优化，我们希望根据特定的标准，如点击率，动态地将流量转移到获胜的变化。</p><p id="56c4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">探索或利用的决定取决于所使用的bandit算法，在我们的例子中，所使用的bandit算法是Thompson采样。</p><p id="e0a4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="kv">MAB相对于A/B测试的一些优势:</em></p><p id="3fc6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于短期活动/应用，等待A/B测试结果的成本使MAB成为更好的选择，因此通过尽早利用可以获得巨大收益。</p><p id="7584" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">MAB还可以用于自动化测试过程，避免分析师为执行重复的A-B测试而进行的重复干预。</p><p id="3b52" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当被测项目在一段时间内发生显著变化，导致A/B测试结果无效时，MAB可用于捕捉动态变化。在这种情况下，MAB通过不断探索提供了一个最优策略。</p><h1 id="e89f" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">算法的目标</h1><p id="c377" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">bandit算法的目标是将流量动态分配给表现良好的变体，而将较少的流量分配给表现不佳的变体。首先，它应该显示随机选择的用户的所有变体，并测量哪些变体被更频繁地点击。随着时间的推移，它将使用这些观察来推断哪个变化具有更高的CTR。然后，一旦对CTR的估计变得更加精确，它将逐渐将流量移向获胜的变化。</p><h1 id="39b4" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">优化工作流程</h1><figure class="kx ky kz la fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kw"><img src="../Images/f1eaf4242f8cb22acb4b871bbe8cb661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w-IPTUPHf1Vti9Q5mzEUmA.png"/></div></div></figure><p id="8ba5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们为优化实验设置提供了一个用户界面。作为优化实验设置的一部分，我们提供的3个关键配置如下:<br/> 1 .优化等待期(这是为了让优化指标“预热”:获得合理的点击数，因此我们不会基于太少的数据重新分配流量。默认值为24小时。)<br/> 2。优化间隔(这是设置优化频率的配置。例如，对于主页，我们通常可以每1小时优化一次，而对于浏览量较低的类别页面，优化引擎可以每几个小时优化一次。默认值为1小时。)<br/> 3。每个变化的最小流量(这是为了防止优化引擎做出“过于仓促”的流量调整以支持一个变化，并允许探索其他变化。默认值为10%。)</p><p id="dd29" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于实验的所有变化，初始流量分配是相等的百分比。一旦实验开始，游客的分配将根据分配的百分比发生变化。实时spark结构化流作业用于收集每个变体的每分钟点击/展示次数，并存储在时间序列数据库中。点击/印象每小时被提供给bandit模型以产生新的流量百分比。任何流量调整本身都是在达到优化等待周期后以优化间隔的频率进行的。</p><h1 id="4399" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">使用Thompson采样进行探索/利用</h1><p id="d385" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在多武装强盗场景中，Thompson采样的基本思想是，算法从关于预期报酬的先验信念开始。在试验过程中，从每只手臂的前侧抽取一个随机样本。所选择的臂是具有提供最佳臂的最高样本的臂。反馈后，先验信念被更新为后验信念。由于我们使用共轭先验，先验和后验具有相同的形式，我们可以继续采样过程，将后验视为新的先验。该算法确保在间歇地探索表现不佳的arm的同时，更多地利用具有较大期望回报的arm。</p><p id="d013" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="kv">以下部分描述了我们采用的探索/利用方法，以及我们如何使用Thompson采样对优化实验进行动态流量调整。</em></p><p id="9e63" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们记录积极和消极的观察结果。这里积极的观察是点击。负面观察是(印象-点击)。<br/>贝塔分布用作先验。我们使用共轭先验，这意味着后验分布与先验分布是同一个族。<br/>原始先验被选为β(20，980)。基于历史上看到的2%的CTR，我们使用1000个印象中的20个正面观察和980个负面观察作为先验。在1000个印象之前，我们不想做任何移动。随着数据量的增长，先验的影响可以忽略不计。</p><p id="e8ad" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">每次算法收到反馈时，我们都会更新正面和负面的观察结果。每当我们需要访问后验分布时，我们就计算贝塔分布的参数。我们将使用这些参数从beta分布中随机抽取一个样本。</p><p id="f80b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们还应用了一个衰减因子。7天前的所有数据权重为1，前一周权重为𝛌，前一周权重为𝛌，依此类推。目前，𝛌设定为0.8。</p><p id="ef08" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">大约200，000个样本来自贝塔二项分布的后验分布，我们通过计算给定变异被选择的次数比例来构建经验分布。流量分割基于每个变体的获胜百分比。例如:如果变体1的30%时间获胜，而变体2的70%时间获胜。变体1的流量分配为30%，变体2的流量分配为70%。在稳定状态下，我们期望获胜的变体拥有100%的流量。</p><p id="eef9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是一个样例代码，说明如何使用Thompson Sampling根据观察到的点击和印象进行动态流量调整。</p><figure class="kx ky kz la fd ii"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h1 id="be1e" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><p id="62d7" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">我们已经进行了几次试运行，并观察到CTR有良好的提升。我们还观察到，对于MAB来说，通过缩短勘探阶段，尽早进行开采可以获得巨大收益的短期活动是一个很好的选择。</p><p id="0503" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下一步，我们希望增强系统，以支持其他指标的优化，如购物车添加率、转换率、收入，最大限度地降低跳出率。我们还希望增强基于内容的治疗类型以外的功能。如果一个页面中有多个组件需要不断优化，我们希望使用MAB方法作为框架来自动化优化过程。</p></div></div>    
</body>
</html>