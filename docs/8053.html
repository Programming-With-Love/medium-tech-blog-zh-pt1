<html>
<head>
<title>Autoencoders Applications in Store Returns Anomaly Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动编码器在商店退货异常检测中的应用</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/autoencoders-applications-in-store-returns-anomaly-detection-ea71b5e6a62e?source=collection_archive---------1-----------------------#2021-08-19">https://medium.com/walmartglobaltech/autoencoders-applications-in-store-returns-anomaly-detection-ea71b5e6a62e?source=collection_archive---------1-----------------------#2021-08-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6c739116a3f31bfbe1605c90110eadb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gW6mTSKe93iRPHf2cGnJnw.jpeg"/></div></div></figure><h1 id="d6d3" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><strong class="ak">零售商商店退货</strong></h1><p id="5604" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">零售巨头每天处理全美各地的大量销售，也产生大量的商店退货，尽管退货仅占销售额的一小部分。为了进一步改善客户购物和退货体验，必须使用最先进的机器学习技术来分析潜在的客户退货模式，特别是异常退货。</p><p id="03ea" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">但是，在对商店退货进行异常检测时，需要克服一些挑战:</p><ol class=""><li id="fbb9" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk kv kw kx ky bi translated">如前所述，对于大型零售商来说，由于销售量巨大，店内退货量可能会很大。因此，商店退货数据集非常大。</li><li id="dbe8" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">让人类专家审查每一次商店退货并识别退货异常是不可行的。因此，这类预测问题很少有预定义的标签。</li></ol><p id="31e6" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">您可能已经知道，监督学习是使用一种算法来学习映射函数。)从输入<em class="le"> x </em>到输出<em class="le"> Y </em>:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/f89ec1d476bf00cb475b62b0cf4bf141.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*J0FmzbKtsZ9o2soYLLDu5A.png"/></div></figure><p id="d47c" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">没有输出<em class="le"> Y </em>，我们必须应用<strong class="jp hi">无监督学习</strong>或<strong class="jp hi">半监督学习</strong>方法来表征或揭示输入<em class="le"> x </em>的底层分布和结构。</p><p id="e882" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">3.数据是巨大的，然而，回报异常是非常罕见的识别。识别和调查退货异常可能有助于提高商品质量，优化退货流程，最重要的是提供世界级的客户体验。</p><p id="d96e" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">4.商店销售和退货总是有季节性的。因此，回报率异常确实是不断变化的目标，而且在各个地区变化很快。为了应对波动性和不确定性，当涉及到商店退货异常检测时，<strong class="jp hi">无监督学习</strong>或<strong class="jp hi">半监督学习</strong>方法优于<strong class="jp hi">监督学习</strong>。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="fee4" class="ip iq hh bd ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji lv jk jl jm bi translated">为什么选择自动编码器？</h1><p id="2a2e" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">Autoencoder作为无监督的神经网络，将输入数据压缩成低维表示/嵌入，然后基于该表示/嵌入重构原始输入。</p><p id="ff9f" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">具体来说，自动编码器由三个组件组成:</p><p id="da39" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> </strong> <strong class="jp hi">编码器</strong>:该部分包括全连接的前馈神经网络，将输入数据压缩成降维的潜在表示。</p><p id="b791" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">代码</strong>或<strong class="jp hi">瓶颈</strong>或<strong class="jp hi">压缩表示</strong>:该部分包括关于输入数据的重要特征和表示，允许解码器尽可能恢复输入。</p><p id="b828" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">解码器</strong>:这部分也由完全连接的前馈神经网络组成，它从潜在表示中重建输出。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/cfd65763d4f15b46c430d26c94188204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YINkypAWAN1PbFs5eyMUeg.png"/></div></div><figcaption class="lx ly et er es lz ma bd b be z dx">An example of autoencoders architecture</figcaption></figure><p id="7747" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">自动编码器具有对称的体系结构，并且学习输入和嵌入之间的非线性关系。自动编码器的目的是将数据压缩成潜在特征，并尽可能精确地重建原始输入，主要采用一种损失函数，如下所示:</p><p id="ee20" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">【均方误差(MSE) </strong>，也被称为<strong class="jp hi">重构误差</strong>，被定义为输入和输出之间的平均差:</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/04a3d5041b57a2bfa21c7cb588d2c902.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*Pg18wYXrcrBBH3s7hMpD_w.png"/></div><figcaption class="lx ly et er es lz ma bd b be z dx">MSE formula</figcaption></figure><p id="8314" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">其中<strong class="jp hi"> <em class="le"> M </em> </strong>为特征维数，<strong class="jp hi"> <em class="le"> N </em> </strong>为数据集中的数据点数。</p><p id="18f1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们选择自动编码器作为退货异常检测的首选技术，因为:</p><p id="6aab" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> </strong>自动编码器不需要预定义的标签，因为它通过潜在特征压缩输入并重构输出。</p><p id="13ca" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> </strong>作为一种基于深度学习的方法，当数据变大时，自动编码器优于传统的机器学习方法。</p><p id="8d4b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"/>auto encoder在常见模式的商店退货上接受训练，因此它将学习大多数退货交易的模式，并识别它们的潜在特征。当返回异常出现时，该模型预计会产生较高的重建误差，因为它的行为不同于大多数返回。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="e526" class="ip iq hh bd ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji lv jk jl jm bi translated"><strong class="ak">在商场退货异常检测和绩效中的应用</strong></h1><p id="4b6e" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><strong class="jp hi">数据</strong></p><p id="ddf3" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们在具有常见模式的返回数据上训练了autoencoder深度学习模型。我们在另一个超时返回数据上测试了模型性能。</p><p id="91c6" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">特征是关于当前回访的一些信息，例如项目类别、一天中进行回访的时间等。，以及其他一些有价值的信息，如商店/区域级退货模式等。</p><p id="3fdc" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">模型架构</strong></p><p id="ae21" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们实现的autoencoder模型有6层，拥有简单的对称架构设计，每层的节点数为<strong class="jp hi"> 279 — 128 — 64 — 64 — 128 — 279 </strong>，其中279是输入和输出维度，128是编码和解码维度，64是隐藏/潜在维度。</p><p id="359a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">激活函数是<strong class="jp hi"> ReLu </strong>并且<strong class="jp hi"> Adam </strong>被用作优化器。最后，该模型被训练200个时期。</p><p id="5306" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">型号性能和对比</strong></p><p id="6aec" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们将autoencoder模型与已经投入生产的<strong class="jp hi">梯度推进机(GBM) </strong>模型进行了比较，该模型支持商店退货异常检测。以下是我们如何评估autoencoder型号的性能:</p><ul class=""><li id="3076" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk mc kw kx ky bi translated">通过自动编码器模型和梯度推进机器模型运行测试数据集，并记录每个悬挂物返回输入的重建误差和GBM模型分数。</li><li id="db2e" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk mc kw kx ky bi translated">基于自动编码器重构误差分布和GBM模型分数带，我们将商店退货分成不同的桶。例如，商店退货输入分为前X% (X = 0.01%、0.05%、0.1%等)。)自动编码器重构误差的桶(以降序排列)。同样，商店退货输入被映射到前X% (X = 0.01%，0.05%，0.1%，等等)。)GBM分数桶(降序排列)。</li><li id="38e3" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk mc kw kx ky bi translated">在autoencoder模型和GBM模型的每个存储桶中，领域专家彻底检查了每个商店退货，并决定是否发现了异常情况。我们招募了几个领域专家来审查所有的测试用例。</li><li id="56aa" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk mc kw kx ky bi translated">接下来，我们根据领域专家的决定计算了回报率异常的百分比，以及autoencoder模型的前X%桶和GBM模型的前X%桶之间的重叠百分比。</li></ul><p id="8bc8" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">重要发现和进一步措施</strong></p><ol class=""><li id="d360" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk kv kw kx ky bi translated">在autoencoder模型和GBM模型的退货异常率都超过80%的前几个时段(即0.01%、0.05%和0.1%)中，商店退货输入几乎没有重叠。这表明autoencoder模型可以捕获与GBM模型不同的回报异常，因此提供了有希望的增量提升。</li><li id="3a6f" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">在autoencoder模型的前几个桶中，我们将研究回报及其行为，这是我们之前从未注意到的。我们将获得数据和业务洞察力，并产生可操作的项目。</li></ol></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="7ffd" class="ip iq hh bd ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji lv jk jl jm bi translated"><strong class="ak">结论</strong></h1><p id="b407" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">总之，自动编码器是异常检测的特别有用的无监督深度学习模型，当与传统的监督学习模型结合时，它将提供有前途的增量提升。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="3d11" class="ip iq hh bd ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji lv jk jl jm bi translated">参考</h1><p id="9ebf" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">【https://www.deeplearningbook.org/contents/autoencoders.html T4】</p><div class="me mf ez fb mg mh"><a href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">在Keras中构建自动编码器</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">这个帖子写于2016年初。因此，它已经严重过时了。在本教程中，我们将回答一些常见的…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">blog.keras.io</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv in mh"/></div></div></a></div></div></div>    
</body>
</html>