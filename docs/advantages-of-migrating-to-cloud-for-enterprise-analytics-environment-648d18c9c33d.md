# 为企业分析环境迁移到云的优势

> 原文：<https://medium.com/walmartglobaltech/advantages-of-migrating-to-cloud-for-enterprise-analytics-environment-648d18c9c33d?source=collection_archive---------3----------------------->

**简介**

我们是一个数据团队。我们将大部分精力用于构建从运营系统到决策支持基础设施的数据管道。我们从运营数据流中合成分析数据资产，并发布这些资产供整个企业使用。我们的 ETL 管道使用内部 ETL 框架构建，工作流在 Map Reduce 上运行，并使用 TEZ 参数和一些使用 Apache Spark 的工作负载进行调整。数据通过一系列逻辑阶段从整个组织的各种来源流入“原始区域”、“净化”和“转换”，以构建适合企业团队用例的多个事实表。然后，数据被展平并加载到消费层，以便于业务分析和报告。这些工作在今天的大多数公司中可能是常见的，我们希望我们关于通过云迁移克服一系列挑战的故事能够与您和您的团队产生共鸣。

![](img/c52df0312e513a80b1a57986ac9e8401.png)

Image taken by author

**以下旅程与我们用于内部报告的分析环境有关，它不是面向客户的生产环境。**

**迁移前的情况:**

我们使用本地多租户静态 Hadoop 集群进行数据加载。所有租户在同一时间对资源的需求达到峰值，这将使群集进入过度利用状态，并在服务级别协议截止日期之前完成我们的工作。没有时间进行上游延迟、数据验证以及我们可能必须解决的任何潜在数据问题。本地多租户共享集群设计使安全策略实施变得复杂，并降低了 Ranger 的使用效率。它也不太适合流数据，因为它不能支持全天波动的数据需求。

![](img/7ee5448cb357173b660f7e65c5f83a24.png)

**迁移到云平台**

为了克服所有这些限制，我们开始寻找具有托管 Hadoop 和 Spark 环境的云服务提供商，并优化迁移我们的 Hadoop 工作流和数据。我们将简要讨论如何克服上述问题。

![](img/1bb7a3c24a9fdfeb30a7a996e13d8fec.png)

**集群弹性:**

云提供了选择集群类型的灵活性，并且可以根据需要启动任意多的集群。所有这些集群都使用 Hive 元存储管理 Hadoop 服务。根据您的使用情况，您可以使用下面提到的任何集群或集群类型的组合来克服有限的集群弹性。

**集群类型:**

静态集群有一定数量的节点，并且不会自动伸缩，除非手动添加或删除更多节点。

自动扩展集群主要有两种类型:基于时间的集群(按照配置的时间间隔进行集群横向扩展)和基于指标的集群(基于某些指标，如集群的利用率百分比进行集群横向扩展)。

临时集群是仅在作业完成之前存在的类型。

我们根据我们的域组、工作负载的性质(增量、历史和修正)、资源需求、时间和频率来选择集群的数量和类型。

较小的工作负载或运行更频繁的工作负载；例如，可以在静态集群上调度每 30 分钟运行一次的作业，因为上升/下降时间的成本实质上降低了自动伸缩的任何好处。

每天具有相同数据量的工作负载可以在基于时间的集群上进行调度。例如，SLA 绑定的作业可能在每天凌晨 1 点左右开始，6 点左右结束，在这些时间间隔之后，这些群集可以缩小规模，以最少的核心定义运行。在缩减之前包括一些缓冲时间是很重要的，以确保作业在资源缩减之前完成。

频繁运行的工作负载及其数据量变化很大，可以在基于指标的集群上进行调度。务必确保放大和缩小计时不会影响作业的执行。

另一种方法是采用混合方法，即保留一些使用基于时间的集群的内核，并在一天的其余时间基于指标进行横向扩展，甚至在需要时增加临时集群。

使用上述选项可以根据日历事件或根据资源需求自动扩展/缩小集群。在规划群集资源时，这种群集选项组合为我们提供了静态和自动扩展(基于时间或基于指标)配置的自定义选择。

**集群利用率:**

由于存储和计算是分开的，云使我们能够在内存、内核和可用性方面更好地配置集群，并且还可以根据需求自动扩展。自动扩展解决了集群的过度利用，轻松满足了节假日的计算需求和处理波动数据的需求。

**低维护灾难恢复环境:**

在云中，存储可以是多区域的，即使一个集群宕机，我们也可以通过另一个集群访问云存储。我们已经为一些选定的数据资产设置了具有重叠访问的多个集群，并且使用相同的配置和交换机构建新的集群非常容易。云环境为高可用性提供了多区域/分区存储桶。在云中，灾难恢复需要更少的维护，并带有更好的监控工具。

**独立的开发和生产环境:**

在云中，我们可以通过适当的访问控制，将开发和生产集群与云存储上的底层数据源隔离开来。这将具有成本效益，开发人员可以根据需要剥离集群，从而加快开发周期。

**安全和访问设置:**

在内部，关于 HDFS 的数据是通过 Ranger 策略控制的。由于多个团队都有权管理策略，因此对数据资产访问的控制越来越少，策略就变得越来越复杂。

在云中，我们使用 IAM(身份和访问管理)创建了具有所需访问控制的多区域云存储位置。每个群集都有一个安全和非安全的服务帐户以及一个登录 AD (Active Directory)组。根据使用情形和数据敏感性，用户组会添加到为该群集配置的登录 AD 组中。云存储上的数据资产将通过其集群 SA(服务帐户)具有读/写访问权限。

**迁移是如何进行的:**

**数据和工作迁移:**

在开始迁移之前，我们冻结了业务中的任何新需求。我们不得不从原始、转移和消费层迁移所有数据，总大小约为 500 TB，工作流程超过 300 个。数据被分区并存储在 ORC 中，用 finder 压缩。我们将数据从内部分发到云中，然后根据内部数据进行验证。除此之外，我们还用 Scala 将所有工作迁移到 Spark，以减少工作运行时间，获得更好的性能。

**工程准备状态:**

Scrum 团队是围绕特定的数据资产组建的，每个团队都致力于将数据转移到云和迁移工作流。整个团队都接受了 Scala 和云技术公司的 Spark 培训。我们成立了一个领导小组，负责协调所有团队的工作。我们每天都与我们的架构师、平台团队和云提供商团队进行同步，以讨论问题和澄清。

**业务就绪:**

我们与业务合作伙伴密切合作，以验证数据并获得 UAT 的认可。我们与合规团队合作，以满足所有标准。为了确保我们的迁移成功，以及我们的最终用户对新技术堆栈感到满意，我们提前两个月交付了一项关键数据资产。就这一关键数据资产对最终用户进行培训，有助于他们在新环境中看到熟悉的数据，从而为新技术堆栈创造支持/宣传。一项关键数据资产的早期迁移使最终用户很容易看到新技术的好处，并减少对整体变化的担忧。

我们向所有利益相关方发送了关于移民身份和截止日期的信息。我们的业务合作伙伴和沟通团队确保将信息发送给最终用户，并确保他们迁移到新环境。同时，他们还发布了与培训、网络研讨会和可用帮助链接相关的必要信息。此外，我们并行运行作业一个月，让最终用户和应用程序团队将其现有的内部流程迁移到云中。我们还遵循“培训培训师”方法，在客户群中宣传这一新平台。我们找到了一些精通技术的关键业务合作伙伴，并对他们进行了新技术堆栈方面的培训，反过来，他们也帮助我们为最终用户做好了准备。

**迁移后和关键要点:**

**访问控制&安全性**:云使我们能够在各种级别添加访问控制，如模式、表&分区、比数据资产更精细的子集。它还提供了对访问数据集的应用程序/用户的更多可见性。

**绩效**:专用集群帮助我们显著提高了工作绩效，并且每天都能满足 SLA 要求。在我们迁移到云后的过去三个月中，我们看到整体核心利用率降低了 57.24%。尽管我们平均多处理 2.5 倍的数据，但我们还是看到了 30 到 45 分钟的总体收益。

**可伸缩性**:它为我们提供了更高的灵活性，可以根据日历事件或根据资源需求自动扩展/缩小集群。该功能为我们提供了非常定制的静态&自动扩展(基于时间或基于指标)配置选择，同时规划集群资源。

**可用性/可访问性**:无需其他应用程序安装/实用软件即可在用户端访问数据。简单的云服务提供商的用户界面可以让最终用户轻松访问数据，不受操作系统的影响。

**数据即服务:**由于该基础设施可以处理大量数据并以低延迟获得洞察力，因此我们可以提取数据并将其作为 API 提供给其他团队。它有助于将数据的使用与特定软件环境或平台的成本分开，并集中管理数据的质量、安全性、合规性和治理。