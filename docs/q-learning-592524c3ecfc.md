# q å­¦ä¹ :å…³äºå¼ºåŒ–å­¦ä¹ ä½ éœ€è¦çŸ¥é“çš„ä¸€åˆ‡

> åŸæ–‡ï¼š<https://medium.com/edureka/q-learning-592524c3ecfc?source=collection_archive---------0----------------------->

![](img/b1e684a1d712990d58e4065282080b14.png)

Q Learning â€” Edureka

äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ æ˜¯è¡Œä¸šä¸­æœ€çƒ­é—¨çš„å‡ ä¸ªé¢†åŸŸï¼Œè¿™æ˜¯æœ‰å……åˆ†ç†ç”±çš„ã€‚è€ƒè™‘åˆ°å…¶ä¸»è¦ç›®æ ‡æ˜¯è®©æœºå™¨æ¨¡ä»¿äººç±»è¡Œä¸ºï¼Œäººå·¥æ™ºèƒ½å°†åœ¨ 2020 å¹´å‰åˆ›é€  230 ä¸‡ä¸ªå·¥ä½œå²—ä½ã€‚å¾ˆå¥‡æ€ªï¼Œä¸æ˜¯å—ï¼Ÿå› æ­¤ï¼Œä»Šå¤©æˆ‘ä»¬å°†æŒ‰ä»¥ä¸‹é¡ºåºè®¨è®º Q å­¦ä¹ ï¼Œå³å¼ºåŒ–å­¦ä¹ çš„æ„å»ºæ¨¡å—:

*   ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Ÿ
*   q-å­¦ä¹ è¿‡ç¨‹
*   è´å°”æ›¼æ–¹ç¨‹
*   é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹
*   æ¼”ç¤º:NumPy

# ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Ÿ

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»ã€‚æˆ‘ä»¬åœ¨ç¯å¢ƒä¸­æ‰§è¡Œè®¸å¤šä»»åŠ¡ï¼Œæœ‰äº›ä»»åŠ¡ä¼šç»™æˆ‘ä»¬å¸¦æ¥å›æŠ¥ï¼Œæœ‰äº›åˆ™ä¸ä¼šã€‚æˆ‘ä»¬ä¸æ–­å¯»æ‰¾ä¸åŒçš„é€”å¾„ï¼Œè¯•å›¾æ‰¾å‡ºå“ªæ¡é€”å¾„ä¼šå¸¦æ¥å›æŠ¥ï¼Œå¹¶æ ¹æ®æˆ‘ä»¬çš„è¡ŒåŠ¨æ”¹è¿›æˆ‘ä»¬å®ç°ç›®æ ‡çš„ç­–ç•¥ã€‚è¿™æ˜¯å¼ºåŒ–å­¦ä¹ çš„ä¸€ä¸ªæœ€ç®€å•çš„ç±»æ¯”ã€‚

ä¸»è¦å…³æ³¨é¢†åŸŸ:

*   ç¯å¢ƒ
*   è¡ŒåŠ¨
*   æŠ¥é…¬
*   çŠ¶æ€

![](img/03a0a5a28221b676f6228a644f21a96b.png)

å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒå…è®¸ç³»ç»Ÿä»è‡ªå·±çš„å†³ç­–ç»“æœä¸­å­¦ä¹ ã€‚å®ƒè§£å†³äº†ä¸€ç§ç‰¹æ®Šçš„é—®é¢˜ï¼Œå³å†³ç­–æ˜¯è¿ç»­çš„ï¼Œç›®æ ‡æ˜¯é•¿æœŸçš„ã€‚

# q-å­¦ä¹ è¿‡ç¨‹

è®©æˆ‘ä»¬ç”¨è¿™é‡Œçš„é—®é¢˜é™ˆè¿°æ¥ç†è§£ä»€ä¹ˆæ˜¯ Q å­¦ä¹ ã€‚å®ƒå°†å¸®åŠ©æˆ‘ä»¬å®šä¹‰å¼ºåŒ–å­¦ä¹ è§£å†³æ–¹æ¡ˆçš„ä¸»è¦ç»„æˆéƒ¨åˆ†ï¼Œå³ä»£ç†ã€ç¯å¢ƒã€è¡ŒåŠ¨ã€å¥–åŠ±å’ŒçŠ¶æ€ã€‚

## **æ±½è½¦å·¥å‚ç±»æ¯”:**

æˆ‘ä»¬åœ¨ä¸€ä¸ªè£…æ»¡æœºå™¨äººçš„æ±½è½¦å·¥å‚ã€‚è¿™äº›æœºå™¨äººå¸®åŠ©å·¥å‚å·¥äººè¿é€ç»„è£…æ±½è½¦æ‰€éœ€çš„å¿…è¦é›¶ä»¶ã€‚è¿™äº›ä¸åŒçš„é›¶ä»¶ä½äºå·¥å‚å†… 9 ä¸ªå·¥ä½çš„ä¸åŒä½ç½®ã€‚é›¶ä»¶åŒ…æ‹¬åº•ç›˜ã€è½¦è½®ã€ä»ªè¡¨æ¿ã€å‘åŠ¨æœºç­‰ã€‚å·¥å‚ä¸»å°†å®‰è£…æœºç®±çš„ä½ç½®ä½œä¸ºæœ€é«˜ä¼˜å…ˆçº§ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™é‡Œçš„è®¾ç½®:

![](img/14620f20ef3c2631ec32168687c8c503.png)

**å·:**

![](img/e41ab8d66546129ac1b556fa029610c0.png)

æœºå™¨äººåœ¨ç‰¹å®šæƒ…å†µä¸‹æ‰€å¤„çš„ä½ç½®ç§°ä¸ºå…¶çŠ¶æ€ã€‚å› ä¸ºå¯¹å®ƒè¿›è¡Œç¼–ç æ¯”ç”¨åå­—æ¥è®°å¿†æ›´å®¹æ˜“ã€‚è®©æˆ‘ä»¬æŠŠä½ç½®æ˜ å°„åˆ°æ•°å­—ä¸Šã€‚

**åŠ¨ä½œ:**

åŠ¨ä½œåªä¸è¿‡æ˜¯æœºå™¨äººç§»åŠ¨åˆ°ä»»ä½•åœ°æ–¹ã€‚å‡è®¾ä¸€ä¸ªæœºå™¨äººä½äº L2 ä½ç½®ï¼Œå®ƒå¯ä»¥ç§»åŠ¨åˆ°çš„ç›´æ¥ä½ç½®æ˜¯ L5ã€L1 å’Œ L3ã€‚è®©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£è¿™ä¸€ç‚¹ï¼Œå¦‚æœæˆ‘ä»¬æŠŠå®ƒå½¢è±¡åŒ–:

![](img/701b13f410727192be535c7a7bae8c7f.png)

**å¥–åŠ±:**

æœºå™¨äººç›´æ¥ä»ä¸€ä¸ªå·åˆ°å¦ä¸€ä¸ªå·ä¼šå¾—åˆ°å¥–åŠ±ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä» L2 ç›´æ¥åˆ°è¾¾ L5ï¼Œåä¹‹äº¦ç„¶ã€‚å› æ­¤ï¼Œåœ¨ä»»ä½•ä¸€ç§æƒ…å†µä¸‹éƒ½å°†æä¾› 1 çš„å¥–åŠ±ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¥–åŠ±è¡¨:

![](img/db546b9a5a22d6a2512588fe4cd09672.png)

è¿˜è®°å¾—å·¥å‚ä¸»ä¼˜å…ˆè€ƒè™‘åº•ç›˜ä½ç½®çš„æ—¶å€™å—ï¼Ÿå®ƒæ˜¯ L7ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†æŠŠè¿™ä¸ªäº‹å®çº³å…¥æˆ‘ä»¬çš„å¥–åŠ±è¡¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åœ¨(L7ï¼ŒL7)ä½ç½®åˆ†é…ä¸€ä¸ªéå¸¸å¤§çš„æ•°å­—(æœ¬ä¾‹ä¸­ä¸º 999)ã€‚

![](img/1cca5080b039530ec36541b94f13535f.png)

# è´å°”æ›¼æ–¹ç¨‹

ç°åœ¨å‡è®¾ä¸€ä¸ªæœºå™¨äººéœ€è¦ä» A ç‚¹åˆ° b ç‚¹ï¼Œå®ƒä¼šé€‰æ‹©ä¸€æ¡èƒ½äº§ç”Ÿç§¯æå›æŠ¥çš„è·¯å¾„ã€‚ä¸ºæ­¤ï¼Œå‡è®¾æˆ‘ä»¬ä¸ºå®ƒæä¾›ä¸€ä¸ªè¶³è¿¹å¥–åŠ±ã€‚

![](img/a1e9c7943ce925d56f77e05cafec9801.png)

ä½†æ˜¯ï¼Œå¦‚æœæœºå™¨äººä»ä¸¤è€…ä¹‹é—´çš„æŸä¸ªåœ°æ–¹å¼€å§‹ï¼Œå®ƒå¯ä»¥çœ‹åˆ°ä¸¤æ¡æˆ–æ›´å¤šçš„è·¯å¾„ã€‚æœºå™¨äººå› æ­¤ä¸èƒ½åšå‡ºå†³å®šï¼Œè¿™ä¸»è¦æ˜¯å› ä¸ºå®ƒæ²¡æœ‰**è®°å¿†**ã€‚è¿™å°±æ˜¯è´å°”æ›¼æ–¹ç¨‹å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚

> **V(s) = max(R(sï¼Œa)+ğœ¸v(s')**

å…¶ä¸­:

*   s =ç‰¹å®šçš„å·
*   a =è¡ŒåŠ¨
*   sâ€²=æœºå™¨äººä» s è¿›å…¥çš„çŠ¶æ€
*   ğœ¸ =è´´ç°å› å­
*   R(sï¼Œa) =é‡‡ç”¨çŠ¶æ€(s)å’ŒåŠ¨ä½œ(a)å¹¶è¾“å‡ºå¥–åŠ±å€¼çš„å¥–åŠ±å‡½æ•°
*   V(s) =å¤„äºç‰¹å®šçŠ¶æ€çš„å€¼

ç°åœ¨ç›®çš„åœ°ä¸‹é¢çš„æ–¹å—ä¼šæœ‰ 1 çš„å¥–åŠ±ï¼Œè¿™æ˜¯æœ€é«˜çš„å¥–åŠ±ï¼Œä½†æ˜¯å¦ä¸€ä¸ªæ–¹å—å‘¢ï¼Ÿå—¯ï¼Œè¿™å°±æ˜¯æŠ˜ç°ç³»æ•°çš„æ¥æºã€‚è®©æˆ‘ä»¬å‡è®¾ä¸€ä¸ªæŠ˜æ‰£ç³»æ•°ä¸º 0.9ï¼Œå¹¶é€ä¸€å¡«å……æ‰€æœ‰çš„å—ã€‚

![](img/d8035675fd83535f13592920858e0f46.png)

# é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹

æƒ³è±¡ä¸€ä¸ªæœºå™¨äººåœ¨æ©™è‰²æ–¹å—ä¸Šï¼Œéœ€è¦åˆ°è¾¾ç›®çš„åœ°ã€‚ä½†æ˜¯ï¼Œå³ä½¿æœ‰è½»å¾®çš„åŠŸèƒ½éšœç¢ï¼Œæœºå™¨äººä¹Ÿä¼šä¸çŸ¥é“è¯¥èµ°å“ªæ¡è·¯ï¼Œè€Œä¸æ˜¯å‘ä¸Šèµ°ã€‚

![](img/64c042d72ed6d2efe0b0c89d24933980.png)

æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¿®æ”¹å†³ç­–è¿‡ç¨‹ã€‚å®ƒå¿…é¡»**éƒ¨åˆ†éšæœº**å’Œ**éƒ¨åˆ†å—æ§äºæœºå™¨äºº**ã€‚éƒ¨åˆ†æ˜¯éšæœºçš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“æœºå™¨äººä»€ä¹ˆæ—¶å€™ä¼šå‡ºæ•…éšœï¼Œéƒ¨åˆ†æ˜¯å¯æ§çš„ï¼Œå› ä¸ºè¿™ä»ç„¶æ˜¯æœºå™¨äººçš„å†³å®šã€‚è¿™æ„æˆäº†é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„åŸºç¡€ã€‚

**é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(MDP)æ˜¯ä¸€ç§ç¦»æ•£æ—¶é—´éšæœºæ§åˆ¶è¿‡ç¨‹ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ•°å­¦æ¡†æ¶ï¼Œç”¨äºåœ¨ç»“æœéƒ¨åˆ†éšæœºã€éƒ¨åˆ†å—å†³ç­–è€…æ§åˆ¶çš„æƒ…å†µä¸‹å¯¹å†³ç­–è¿›è¡Œå»ºæ¨¡ã€‚**

æ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä»¬æœ€åˆçš„è´å°”æ›¼æ–¹ç¨‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œä¿®æ”¹ã€‚æˆ‘ä»¬ä¸çŸ¥é“çš„æ˜¯ä¸‹ä¸€ä¸ªçŠ¶æ€ã€‚**sâ€™ã€‚**æˆ‘ä»¬æ‰€çŸ¥é“çš„æ˜¯è½¬å¼¯çš„æ‰€æœ‰å¯èƒ½æ€§ï¼Œè®©æˆ‘ä»¬æ”¹å˜ç­‰å¼ã€‚

**V(s) = max(R(sï¼Œa)+ğœ¸v(s ')**

**V(s) = max(R(sï¼Œa)+ğœ¸Ïƒs ' p(sï¼Œaï¼Œs ')v(s ')**

**Ïƒs ' P(sï¼Œaï¼Œs') V(s') :** æœºå™¨äººçš„éšæœºæ€§æœŸæœ›

![](img/8d356b8a13c4ef8267494e7eb85c69c8.png)

V(s) = max(R(sï¼Œa) + ğœ¸ ((0.8V(æˆ¿é—´å‘ä¸Š))+ (0.1V(æˆ¿é—´å‘ä¸‹)+ â€¦ã€‚))

ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿‡æ¸¡åˆ° Q å­¦ä¹ ã€‚Q-Learning æå‡ºäº†ä¸€ç§è¯„ä¼°ç§»åŠ¨åˆ°ä¸€ä¸ªçŠ¶æ€çš„åŠ¨ä½œçš„è´¨é‡çš„æ€æƒ³ï¼Œè€Œä¸æ˜¯ç¡®å®šå®ƒè¢«ç§»åŠ¨åˆ°çš„çŠ¶æ€çš„å¯èƒ½å€¼ã€‚

![](img/1ef17ca93035815b698d8a7363128ffa.png)

è¿™å°±æ˜¯æˆ‘ä»¬æ‰€å¾—åˆ°çš„ï¼Œå¦‚æœæˆ‘ä»¬æŠŠè¯„ä¼°ç§»åŠ¨åˆ°æŸä¸ªçŠ¶æ€ s 'çš„åŠ¨ä½œè´¨é‡çš„æƒ³æ³•ç»“åˆè¿›æ¥ã€‚ä»æ›´æ–°åçš„è´å°”æ›¼æ–¹ç¨‹ä¸­ï¼Œå¦‚æœæˆ‘ä»¬å»æ‰å®ƒä»¬çš„**æœ€å¤§**åˆ†é‡ï¼Œæˆ‘ä»¬å‡è®¾å¯èƒ½çš„åŠ¨ä½œåªæœ‰ä¸€ä¸ªè¶³è¿¹ï¼Œé™¤äº†åŠ¨ä½œçš„**è´¨é‡**ä¹‹å¤–ä»€ä¹ˆéƒ½æ²¡æœ‰ã€‚

**Q(sï¼Œa) = (R(sï¼Œa)+ğœ¸Ïƒs ' p(sï¼Œaï¼Œs ')v(s ')**

åœ¨è¿™ä¸ªé‡åŒ–è¡ŒåŠ¨è´¨é‡çš„ç­‰å¼ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾ V(s)æ˜¯ Q(sï¼Œa)æ‰€æœ‰å¯èƒ½å€¼çš„æœ€å¤§å€¼ã€‚æ‰€ä»¥è®©æˆ‘ä»¬ç”¨ Q()çš„å‡½æ•°æ¥ä»£æ›¿ v(s ')ã€‚

**Q(sï¼Œa) = (R(sï¼Œa)+ğœ¸Ïƒs ' p(sï¼Œaï¼Œs') max Q(s 'ï¼Œa ')**

æˆ‘ä»¬ç¦» Q å­¦ä¹ çš„æœ€ç»ˆæ–¹ç¨‹å¼åªæœ‰ä¸€æ­¥ä¹‹é¥ã€‚æˆ‘ä»¬å°†å¼•å…¥ä¸€ä¸ª**æ—¶é—´å·®**æ¥è®¡ç®—ç¯å¢ƒéšæ—¶é—´å˜åŒ–çš„ Q å€¼ã€‚ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•è§‚å¯Ÿ Q çš„å˜åŒ–å‘¢ï¼Ÿ

**TD(sï¼Œa) = (R(sï¼Œa)+ğœ¸Ïƒs ' p(sï¼Œaï¼Œs') max Q(s 'ï¼Œa ')â€”q(sï¼Œa)**

æˆ‘ä»¬ç”¨åŒæ ·çš„å…¬å¼é‡æ–°è®¡ç®—æ–°çš„ Q(sï¼Œa)ï¼Œå¹¶ä»ä¸­å‡å»ä»¥å‰å·²çŸ¥çš„ Q(sï¼Œa)ã€‚æ‰€ä»¥ï¼Œä¸Šé¢çš„ç­‰å¼å˜æˆäº†:

**Qt (sï¼Œa) = Qt-1 (sï¼Œa) + Î± TDt (sï¼Œa)**

**Qt (sï¼Œa) =** å½“å‰ Q å€¼

**Qt-1 (sï¼Œa) =** å‰ä¸€ä¸ª Q å€¼

**Qt (sï¼Œa) = Qt-1 (sï¼Œa) + Î± (R(sï¼Œa) + ğœ¸æœ€å¤§ Q(s 'ï¼Œa') â€” Qt-1(sï¼Œa))**

# æ¼”ç¤º:NumPy

æˆ‘å°†ä½¿ç”¨ Python NumPy æ¥æ¼”ç¤º Q å­¦ä¹ æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

**æ­¥éª¤ 1:å¯¼å…¥ã€å‚æ•°ã€çŠ¶æ€ã€åŠ¨ä½œå’Œå¥–åŠ±**

```
import numpy as np

gamma = 0.75 # Discount factor
alpha = 0.9 # Learning rate

location_to_state = {
    'L1' : 0,
    'L2' : 1,
    'L3' : 2,
    'L4' : 3,
    'L5' : 4,
    'L6' : 5,
    'L7' : 6,
    'L8' : 7,
    'L9' : 8
}

actions = [0,1,2,3,4,5,6,7,8]

rewards = np.array([[0,1,0,0,0,0,0,0,0],
              [1,0,1,0,0,0,0,0,0],
              [0,1,0,0,0,1,0,0,0],
              [0,0,0,0,0,0,1,0,0],
              [0,1,0,0,0,0,0,1,0],
              [0,0,1,0,0,0,0,0,0],
              [0,0,0,1,0,0,0,1,0],
              [0,0,0,0,1,0,1,0,1],
              [0,0,0,0,0,0,0,1,0]])
```

**æ­¥éª¤ 2:å°†ç´¢å¼•æ˜ å°„åˆ°ä½ç½®**

```
state_to_location = dict((state,location) for location,state in location_to_state.items())
```

**ç¬¬ä¸‰æ­¥:ä½¿ç”¨ Q å­¦ä¹ è¿‡ç¨‹è·å¾—æœ€ä½³è·¯çº¿**

```
def get_optimal_route(start_location,end_location):
    rewards_new = np.copy(rewards)
    ending_state = location_to_state[end_location]
    rewards_new[ending_state,ending_state] = 999

    Q = np.array(np.zeros([9,9]))

    # Q-Learning process
    for i in range(1000):
        # Picking up a random state
        current_state = np.random.randint(0,9) # Python excludes the upper bound
        playable_actions = []
        # Iterating through the new rewards matrix
        for j in range(9):
            if rewards_new[current_state,j] > 0:
                playable_actions.append(j)
        # Pick a random action that will lead us to next state
        next_state = np.random.choice(playable_actions)
        # Computing Temporal Difference
        TD = rewards_new[current_state,next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state,next_state]
        # Updating the Q-Value using the Bellman equation
        Q[current_state,next_state] += alpha * TD

    # Initialize the optimal route with the starting location
    route = [start_location]
    #Initialize next_location with starting location
    next_location = start_location

    # We don't know about the exact number of iterations needed to reach to the final location hence while loop will be a good choice for iteratiing
    while(next_location != end_location):
        # Fetch the starting state
        starting_state = location_to_state[start_location]
        # Fetch the highest Q-value pertaining to starting state
        next_state = np.argmax(Q[starting_state,])
        # We got the index of the next state. But we need the corresponding letter.
        next_location = state_to_location[next_state]
        route.append(next_location)
        # Update the starting location for the next iteration
        start_location = next_location

    return route
```

**ç¬¬å››æ­¥:æ‰“å°è·¯çº¿**

```
print(get_optimal_route('L1', 'L9'))
```

![](img/b8e2a92f8f4bbd32915b30132ae39963.png)

è¿™æ ·ï¼Œæˆ‘ä»¬å°±ç»“æŸäº† Q-Learningã€‚æˆ‘å¸Œæœ›ä½ å·²ç»äº†è§£äº† Q å­¦ä¹ çš„å·¥ä½œåŸç†ä»¥åŠå„ç§å„æ ·çš„ä¾èµ–å…³ç³»ï¼Œæ¯”å¦‚æ—¶é—´å·®ï¼Œè´å°”æ›¼æ–¹ç¨‹ç­‰ç­‰ã€‚

å¦‚æœä½ æƒ³æŸ¥çœ‹æ›´å¤šå…³äºäººå·¥æ™ºèƒ½ã€DevOpsã€é“å¾·é»‘å®¢ç­‰å¸‚åœºæœ€çƒ­é—¨æŠ€æœ¯çš„æ–‡ç« ï¼Œä½ å¯ä»¥å‚è€ƒ Edureka çš„å®˜æ–¹ç½‘ç«™ã€‚

è¯·ç•™æ„æœ¬ç³»åˆ—ä¸­çš„å…¶ä»–æ–‡ç« ï¼Œå®ƒä»¬å°†è§£é‡Šæ·±åº¦å­¦ä¹ çš„å„ä¸ªå…¶ä»–æ–¹é¢ã€‚

> 1. [TensorFlow æ•™ç¨‹](/edureka/tensorflow-tutorial-ba142ae96bca)
> 
> 2. [PyTorch æ•™ç¨‹](/edureka/pytorch-tutorial-9971d66f6893)
> 
> 3.[æ„ŸçŸ¥å™¨å­¦ä¹ ç®—æ³•](/edureka/perceptron-learning-algorithm-d30e8b99b156)
> 
> 4.[ç¥ç»ç½‘ç»œæ•™ç¨‹](/edureka/neural-network-tutorial-2a46b22394c9)
> 
> 5.ä»€ä¹ˆæ˜¯åå‘ä¼ æ’­ï¼Ÿ
> 
> 6.[å·ç§¯ç¥ç»ç½‘ç»œ](/edureka/convolutional-neural-network-3f2c5b9c4778)
> 
> 7.[èƒ¶å›Šç¥ç»ç½‘ç»œ](/edureka/capsule-networks-d7acd437c9e)
> 
> 8.[é€’å½’ç¥ç»ç½‘ç»œ](/edureka/recurrent-neural-networks-df945afd7441)
> 
> 9.[è‡ªåŠ¨ç¼–ç å™¨æ•™ç¨‹](/edureka/autoencoders-tutorial-cfdcebdefe37)
> 
> 10.[å—é™ç»å°”å…¹æ›¼æœºæ•™ç¨‹](/edureka/restricted-boltzmann-machine-tutorial-991ae688c154)
> 
> 11. [PyTorch vs TensorFlow](/edureka/pytorch-vs-tensorflow-252fc6675dd7)
> 
> 12.[ç”¨ Python è¿›è¡Œæ·±åº¦å­¦ä¹ ](/edureka/deep-learning-with-python-2adbf6e9437d)
> 
> 13.[äººå·¥æ™ºèƒ½æ•™ç¨‹](/edureka/artificial-intelligence-tutorial-4257c66f5bb1)
> 
> 14.[å¼ é‡æµå›¾åƒåˆ†ç±»](/edureka/tensorflow-image-classification-19b63b7bfd95)
> 
> 15.[äººå·¥æ™ºèƒ½åº”ç”¨](/edureka/artificial-intelligence-applications-7b93b91150e3)
> 
> 16.[å¦‚ä½•æˆä¸ºä¸€åäººå·¥æ™ºèƒ½å·¥ç¨‹å¸ˆï¼Ÿ](/edureka/become-artificial-intelligence-engineer-5ac2ede99907)
> 
> 17.[tensor flow ä¸­çš„å¯¹è±¡æ£€æµ‹](/edureka/tensorflow-object-detection-tutorial-8d6942e73adc)
> 
> 18. [Apriori ç®—æ³•](/edureka/apriori-algorithm-d7cc648d4f1e)
> 
> 19.[é©¬å°”å¯å¤«é“¾ä¸ Python](/edureka/introduction-to-markov-chains-c6cb4bcd5723)
> 
> 20.[äººå·¥æ™ºèƒ½ç®—æ³•](/edureka/artificial-intelligence-algorithms-fad283a0d8e2)
> 
> 21.[æœºå™¨å­¦ä¹ çš„æœ€ä½³ç¬”è®°æœ¬ç”µè„‘](/edureka/best-laptop-for-machine-learning-a4a5f8ba5b)
> 
> 22.[12 å¤§äººå·¥æ™ºèƒ½å·¥å…·](/edureka/top-artificial-intelligence-tools-36418e47bf2a)
> 
> 23.[äººå·¥æ™ºèƒ½(AI)é¢è¯•é—®é¢˜](/edureka/artificial-intelligence-interview-questions-872d85387b19)
> 
> 24. [Theano vs TensorFlow](/edureka/theano-vs-tensorflow-15f30216b3bc)
> 
> 25.[ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ](/edureka/what-is-a-neural-network-56ae7338b92d)
> 
> 26.[æ¨¡å¼è¯†åˆ«](/edureka/pattern-recognition-5e2d30ab68b9)
> 
> 27.[äººå·¥æ™ºèƒ½ä¸­çš„é˜¿å°”æ³•è´å¡”å‰ªæ](/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a)

*åŸè½½äº 2019 å¹´ 6 æœˆ 12 æ—¥ https://www.edureka.co*[](https://www.edureka.co/blog/q-learning/)**ã€‚**