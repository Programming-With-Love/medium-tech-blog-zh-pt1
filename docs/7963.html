<html>
<head>
<title>Decoding Memory in Spark — Parameters that are often confused</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark中的解码记忆——经常被混淆的参数</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/decoding-memory-in-spark-parameters-that-are-often-confused-c11be7488a24?source=collection_archive---------0-----------------------#2021-01-04">https://medium.com/walmartglobaltech/decoding-memory-in-spark-parameters-that-are-often-confused-c11be7488a24?source=collection_archive---------0-----------------------#2021-01-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/4b6f75c6472063804dcba0a19dd538f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3GOCGheKkJksPham"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Photo by <a class="ae it" href="https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Chris Ried</a> on <a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="97a7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Apache spark ️is最活跃的开源项目之一。它在每个版本中不断改进其以前的模型，这导致了大量令人困惑的参数和配置，这些参数和配置有时看起来相似，但实际上有不同的用例。在本帖中，我们来看一看Spark中关于内存管理的常见误解参数。</p><h1 id="3f77" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">火花记忆块—快速回顾</h1><p id="2e91" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">Spark是使用Scala作为主要语言开发的。因此，Spark中的操作发生在JVM内部，即使用户的代码是用不同的语言编写的，如python或r。Spark运行时将驱动程序和执行器中的JVM堆空间分成4个不同的部分:</p><ol class=""><li id="0e8e" class="kv kw hh iw b ix iy jb jc jf kx jj ky jn kz jr la lb lc ld bi translated"><strong class="iw hi">存储内存</strong> —为缓存数据保留的JVM堆空间</li><li id="42ba" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><strong class="iw hi">执行内存</strong> —洗牌操作(连接、分组和聚合)期间数据结构使用的JVM堆空间。更早的时候(Spark 1.6之前)，混洗内存这个术语也是用来描述这部分内存的。</li><li id="3a65" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><strong class="iw hi">用户内存</strong> —用于存储由用户代码创建和管理的数据结构</li><li id="b002" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><strong class="iw hi">保留内存</strong> —由Spark保留供内部使用。</li></ol><p id="d6a6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">除了JVM堆，还有两个内存段被Spark访问</p><ol class=""><li id="4c33" class="kv kw hh iw b ix iy jb jc jf kx jj ky jn kz jr la lb lc ld bi translated"><strong class="iw hi">堆外内存</strong> —这部分内存位于JVM之外，但是被JVM用于某些用例(例如，字符串的内部化)。Spark也可以显式地使用堆外内存来存储序列化的数据帧和rdd。</li><li id="9724" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><strong class="iw hi">外部进程内存</strong> —特定于PySpark和SparkR，这是驻留在JVM之外的python/R进程使用的内存。</li></ol><p id="ab77" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有一些很好的文章(参见<a class="ae it" href="#7a05" rel="noopener ugc nofollow">参考文献</a>)详细讨论了这些内存扇区。</p><p id="4a52" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但偶尔也有火花配置看似一样。但是对这些配置的深入理解有助于理解它们各自的含义，以及通过调整相同的值来解决什么问题。</p><h1 id="6f25" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">火花存储存储器</h1><h2 id="c5c1" class="lj jt hh bd ju lk ll lm jy ln lo lp kc jf lq lr kg jj ls lt kk jn lu lv ko lw bi translated">spark . storage . memory分数vs spark . memory . storage分数</h2><p id="e04f" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">这两个参数都设置了用作存储内存(用于缓存数据)的JVM空间量。但是不清楚应该设置哪个参数。</p><p id="a49e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Spark在1.6版本中对存储和执行空间的处理做了重大的检修。遗留的处理模式被称为<a class="ae it" href="https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/StaticMemoryManager.scala" rel="noopener ugc nofollow" target="_blank"> StaticMemoryManager </a>，新的模式是<a class="ae it" href="https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/memory/UnifiedMemoryManager.scala" rel="noopener ugc nofollow" target="_blank">unifiedmorymanager</a>。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/8587e8347fd9d38be261d2c57b9c9435.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*gGjzSn5hseVRAqMLVv9W2w.png"/></div></figure><p id="7dd9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在StaticMemoryManager中，存储和执行内存(在本例中为shuffle内存)在配置中是固定的。配置参数<code class="du mc md me mf b">spark.storage.memoryFraction</code>和<code class="du mc md me mf b">spark.shuffle.memoryFraction</code>分别控制存储和随机存储器的大小。这些参数从Spark 1.6开始被弃用，设置这些参数没有任何效果，除非<code class="du mc md me mf b">spark.memory.useLegacyMode</code>设置为true。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/1df9e8e6ab440ded15a9529b468e13ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*bNfD1AwGHZPo44KVy6kcUA.png"/></div></figure><p id="f170" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在UnifiedMemoryManager中，存储内存和执行内存之间的界限是不固定的。因此，如果存储块是空闲的，它可以占用部分执行内存，反之亦然。参数<code class="du mc md me mf b">spark.memory.fraction</code>决定了专用于Spark的总内存(用于混洗和存储)。受保护不被驱逐的存储内存量由<code class="du mc md me mf b">spark.memory.storageFraction</code>控制。</p><blockquote class="mh mi mj"><p id="637d" class="iu iv mk iw b ix iy iz ja jb jc jd je ml jg jh ji mm jk jl jm mn jo jp jq jr ha bi translated"><strong class="iw hi">TL；DR:最好使用</strong> <code class="du mc md me mf b"><strong class="iw hi">spark.memory.fraction</strong></code> <strong class="iw hi">和</strong> <code class="du mc md me mf b"><strong class="iw hi">spark.memory.storageFraction</strong></code> <strong class="iw hi">来配置火花存储段。</strong></p></blockquote><h1 id="22b6" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">堆外内存</h1><h2 id="0533" class="lj jt hh bd ju lk ll lm jy ln lo lp kc jf lq lr kg jj ls lt kk jn lu lv ko lw bi translated">spark . executor . memory overhead vs . spark . memory . off heap . size</h2><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/fbd45c1e00b7321b8d599e95d5a71295.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*QiEGPjaFlLgACMKhT0hboQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">JVM Heap vs Off-Heap Memory</figcaption></figure><p id="dc6d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">尽管Spark中的大多数操作发生在JVM内部，并且随后使用JVM堆作为其内存，但是每个执行器都能够在某些情况下利用堆外空间。这个堆外空间位于JVM空间之外，通常通过<code class="du mc md me mf b">sun.misc.Unsafe</code>API来访问。堆外内存不在垃圾收集的范围内，因此它为应用程序开发人员提供了更细粒度的内存控制。</p><p id="f94d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Spark使用堆外内存有两个目的:</p><ul class=""><li id="66d4" class="kv kw hh iw b ix iy jb jc jf kx jj ky jn kz jr mp lb lc ld bi translated">一部分堆外内存由Java内部使用，用于字符串存储和JVM开销等目的。</li><li id="c3f6" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr mp lb lc ld bi translated">作为<a class="ae it" href="https://issues.apache.org/jira/browse/SPARK-7075" rel="noopener ugc nofollow" target="_blank">项目钨</a><a class="ae it" href="#f407" rel="noopener ugc nofollow">【5】</a>的一部分，Spark也可以明确使用堆外内存来存储其数据。</li></ul><p id="b0a0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Spark执行器的总堆外内存由<code class="du mc md me mf b">spark.executor.memoryOverhead</code>控制。默认值是10%的执行器内存，最少384MB。这意味着，即使用户没有明确设置这个参数，Spark也会为VM开销留出10%的执行器内存(或384MB，以较高者为准)。Spark用来存储实际数据帧的堆外内存量由<code class="du mc md me mf b">spark.memory.offHeap.size</code>控制。这是一个可选功能，可通过将<code class="du mc md me mf b">spark.memory.offHeap.use</code>设置为真来启用。</p><p id="43b5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在Spark 3.x之前，由memoryOverhead指示的总堆外内存还包括Spark数据帧的堆外内存。因此，在为memoryOverhead设置参数时，用户还必须考虑数据帧对Spark堆外内存的使用。Spark 3.0使Spark离堆成为一个独立于memoryOverhead的实体，因此用户在设置executor memoryOverhead时不必显式地考虑它。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/15aa576c0781fd13b5368305104fef46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dh9it_gMQai4Zj8NbD3-fA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Off-Heap Memory Allocation in Spark</figcaption></figure><blockquote class="mh mi mj"><p id="925a" class="iu iv mk iw b ix iy iz ja jb jc jd je ml jg jh ji mm jk jl jm mn jo jp jq jr ha bi translated"><strong class="iw hi">TL；DR:对于Spark 1.x和2.x，总堆外内存= Spark . executor . Memory overhead(Spark . Off Heap . size包含在内)<br/>对于Spark 3.x，<em class="hh"> </em>总堆外内存= Spark . executor . Memory overhead+Spark . Off Heap . size</strong></p></blockquote><h1 id="ac31" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">Python内存</h1><h2 id="4846" class="lj jt hh bd ju lk ll lm jy ln lo lp kc jf lq lr kg jj ls lt kk jn lu lv ko lw bi translated">spark . python . worker . memory vs spark . executor . py spark . memory</h2><p id="26e7" class="pw-post-body-paragraph iu iv hh iw b ix kq iz ja jb kr jd je jf ks jh ji jj kt jl jm jn ku jp jq jr ha bi translated">在执行PySpark时，这两个参数似乎都限制了分配给python的内存。但实际上，它们限制了executor中非常不同的内存部分。在PySpark中，两个独立的进程在执行器中运行，一个JVM执行代码的Spark部分(连接、聚合和洗牌),一个python进程执行用户的代码。这两个进程通过一个<a class="ae it" href="https://www.py4j.org/" rel="noopener ugc nofollow" target="_blank"> Py4J桥</a>进行通信，这个桥公开了python进程中的JVM对象，反之亦然。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/d8f0b4fac621868f45273f792225e245.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*mzfRwPRAiTwi8OdCCSSUQw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx">Configuring Python worker memory</figcaption></figure><p id="516a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">参数<code class="du mc md me mf b">spark.python.worker.memory</code>控制为每个pyspark工作线程保留的内存量，超过该内存量，它将溢出到磁盘。换句话说，它是在Spark操作期间通过Py4J桥创建的对象可以占用的内存量。如果未设置该参数，默认值为512MB。</p><p id="e6c4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在Spark 2.4中引入的<code class="du mc md me mf b">spark.executor.pyspark.memory</code>控制python工作进程的实际内存。使用python中的<code class="du mc md me mf b">system.RLIMIT_AS</code>属性为每个python工作进程设置了它可以寻址的内存空间的限制。</p><p id="0c03" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果没有通过<code class="du mc md me mf b">spark.executor.<br/>pyspark.memory</code>设置python工作内存，python工作进程可能会占用整个节点的内存。由于这部分内存不是由YARN跟踪的，这可能会导致节点中的过度调度(因为YARN假设python worker占用的内存是空闲的)。这会导致内存中的页面交换，并降低该节点上所有纱线容器的速度。</p><blockquote class="mh mi mj"><p id="93e5" class="iu iv mk iw b ix iy iz ja jb jc jd je ml jg jh ji mm jk jl jm mn jo jp jq jr ha bi translated"><strong class="iw hi">TL；DR: </strong> <code class="du mc md me mf b"><strong class="iw hi">spark.python.worker.memory</strong></code> <strong class="iw hi">限制Python对象在JVM中的内存，而</strong> <code class="du mc md me mf b"><strong class="iw hi">spark.executor.pyspark.memory</strong></code> <strong class="iw hi">限制Python进程的实际内存</strong></p></blockquote><h1 id="63e8" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">总容器内存</h1><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/dc91721f68c498ce96cb32c77e4c1639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8yviZQXq9rXgBoup8W-kHA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Total Memory Request to YARN</figcaption></figure><p id="dc91" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如图所示，Spark向容器管理器(如YARN)请求的总内存是执行器内存、内存开销和python工作内存限制的总和。这确保了执行器的适当资源调度。</p><h1 id="7a05" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">参考</h1><ol class=""><li id="8153" class="kv kw hh iw b ix kq jb kr jf mt jj mu jn mv jr la lb lc ld bi translated"><a class="ae it" href="https://spark.apache.org/docs/latest/configuration.html" rel="noopener ugc nofollow" target="_blank">火花配置</a></li><li id="6db4" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><a class="ae it" href="https://spark.apache.org/docs/latest/tuning.html#memory-management-overview" rel="noopener ugc nofollow" target="_blank">调优火花:内存管理概述</a></li><li id="c760" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><a class="ae it" href="https://0x0fff.com/spark-memory-management/" rel="noopener ugc nofollow" target="_blank">火花存储器管理</a></li><li id="5f38" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><a class="ae it" rel="noopener" href="/analytics-vidhya/apache-spark-memory-management-49682ded3d42"> Apache Spark内存管理</a></li><li id="f407" class="kv kw hh iw b ix le jb lf jf lg jj lh jn li jr la lb lc ld bi translated"><a class="ae it" href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html" rel="noopener ugc nofollow" target="_blank">钨计划:让阿帕奇火花更接近裸机</a></li></ol></div></div>    
</body>
</html>