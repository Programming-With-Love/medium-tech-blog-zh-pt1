<html>
<head>
<title>Open-sourcing Terrapin: A serving system for batch generated data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开源Terrapin:一个批量生成数据的服务系统</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/open-sourcing-terrapin-a-serving-system-for-batch-generated-data-7aa2f38c4472?source=collection_archive---------0-----------------------#2015-09-14">https://medium.com/pinterest-engineering/open-sourcing-terrapin-a-serving-system-for-batch-generated-data-7aa2f38c4472?source=collection_archive---------0-----------------------#2015-09-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2d92" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Varun Sharma | Pinterest基础设施工程师</p><p id="354e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们广泛采用Hadoop批处理作业，从构建建议到机器学习的计算功能和模型，以及围绕Pinners、pin和Boards连接各种数据。这些数据集由批量ETL作业生成，并作为推荐、机器学习和几个支持Pinterest上内容发现的产品的基础。</p><p id="523b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天在脸书<a class="ae jc" href="https://www.atscaleconference.com/schedule#session/terrapin-a-serving-system-for-batch-generated-data-sets" rel="noopener ugc nofollow" target="_blank"> @scale </a>大会上，我们宣布了<a class="ae jc" href="https://github.com/pinterest/terrapin" rel="noopener ugc nofollow" target="_blank"> Terrapin </a>的开源，这是一个用于处理Hadoop作业生成的大型数据集的服务系统。Terrapin提供了对这种大型数据集的低延迟随机键值访问，这些数据集是不可变的，并且是整体(重新)生成的。Terrapin可以从HDFS S3或直接从MapReduce作业中获取数据，并且具有足够的弹性、容错性和性能，可用于Pinterest上的各种在线应用，如<a class="ae jc" href="https://engineering.pinterest.com/blog/pinnability-machine-learning-home-feed" rel="noopener ugc nofollow" target="_blank">定位</a>和<a class="ae jc" href="https://engineering.pinterest.com/blog/creating-serving-storing-data-discovery" rel="noopener ugc nofollow" target="_blank">发现数据</a>。</p><h2 id="8604" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">现状</h2><p id="c457" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">以前，我们使用Apache HBase来提供批量生成的数据。我们发现，直接写入HBase既昂贵又缓慢，而且只适用于较小的数据集(几十个GB)。我们还尝试使用批量上传功能将HFiles从我们的计算Hadoop集群直接上传到我们的服务HBase集群。虽然数据传输速度大大加快，但系统没有数据局部性(即HBase区域的数据分布在整个集群中，而不是集中在区域服务器上)。如果没有数据局部性，延迟就会受到影响，特别是在第90和第99百分位。我们必须运行压缩来恢复数据局部性，并对以前上传的数据进行垃圾收集。压缩给集群增加了不小的负载，也影响了延迟。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kd"><img src="../Images/cd8e460227c706136120f5b5d018c3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/0*mq08xctKI9pZfDOK.png"/></div></figure><p id="7984" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这些问题，我们构建了一个系统，该系统将从S3提取由MapReduce作业生成的HFiles，并将它们分发到一个服务器池中。它有一些很好的特性，比如实时交换和从一个数据集版本到另一个数据集版本改变MapReduce碎片数量的便利性。该系统速度很快，因为数据总是在本地访问，但我们失去了HBase和HDFS带来的灵活性、容错性和易操作性。很难扩展这个系统。</p><p id="63b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据以前的经验，我们意识到，如果我们能够以某种方式将数据局部性与HDFS结合起来，我们就可以实现对弹性、容错和性能的所有要求。最重要的是，Hadoop ETL作业可以相当快地将数据加载到HDFS，从而控制Hadoop管道的运行时间。</p><h2 id="a3ea" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">体系结构</h2><p id="85f9" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">与HBase不同，h base只是将HDFS视为分布式文件系统，Terrapin考虑了HDFS数据块的分布，并在物理存储HDFS数据块的相同节点上提供相应的服务碎片。这是可能的，因为Terrapin提供不可变的数据集，这些数据集只能通过批处理作业定期重新生成。</p><figure class="ke kf kg kh fd ki er es paragraph-image"><div class="er es kl"><img src="../Images/a0ffe5b1df73bebe7de69f9455733595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*iSBCcGGbgzhLYtQx.png"/></div></figure><p id="4a50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图说明了Terrapin的各种组件。一个Hadoop作业以HFiles的形式将数据写入一个Terrapin集群，由HDFS提供支持。Terrapin集群由以下部分组成:</p><ul class=""><li id="c24a" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated">一个<strong class="ig hi"> ZooKeeper仲裁</strong>存储集群状态，将它传播到客户端，并帮助驱动集群协调。</li><li id="12ac" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">一个<strong class="ig hi"> Terrapin服务器</strong>进程在每个HDFS数据节点上运行。Terrapin服务器负责提供针对HFiles的键值查找服务。Terrapin服务器与ZooKeeper进行交互，以接收关于需要服务哪些HFiles的通知。Terrapin控制器定期查询每个HFile的当前HDFS块位置，计算要发送到Terrapin服务器的适当通知，并将它们写入ZooKeeper。在群集中添加/删除节点或HDFS重新平衡数据时，控制器可确保数据的局部性。控制器还负责执行实时交换和旧版本的垃圾收集。<em class="la">注意:我们写的HFile的块大小更大，为4G，所以每个HFile只跨越1个HDFS块。我们没有发现使用更大块大小的任何问题。</em></li><li id="fced" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated"><strong class="ig hi"> Java客户端库</strong>从ZooKeeper读取分片信息，并适当地路由键值查找。分片信息告诉应该向哪个Terrapin服务器查询存储在特定HFile分片中的密钥。因为一个HFile shard可以有多个副本，所以Java客户端还会在另一个副本上重试失败的读取。</li></ul><p id="c766" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在该设计中，Terrapin控制器将系统推向100%的数据局部性，Terrapin实现了低延迟，同时充分利用了HDFS和Hadoop的易操作性、可扩展性和弹性。</p><h2 id="d769" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">设计选择</h2><p id="7bf9" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">我们的设计选择使我们能够通过提供正确的构建模块和节省宝贵的工程周期来满足我们的要求。</p><ul class=""><li id="9641" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated">我们选择<strong class="ig hi"> HDFS </strong>作为底层存储，是因为它的弹性、容错性、易操作性以及与MapReduce的紧密集成。</li><li id="7809" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">我们选择了<strong class="ig hi">HFiles</strong>作为文件格式，因为我们已经在HBase在线服务方面取得了相当大的成功。通过Hadoop作业很容易消费和生成HFiles。</li><li id="3335" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">我们使用<strong class="ig hi"> Apache Helix </strong>进行基于ZooKeeper的集群协调。许多公司使用Apache Helix来管理有状态服务。</li></ul><p id="595e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Terrapin提供以下功能:</p><ul class=""><li id="287a" class="km kn hh ig b ih ii il im ip ko it kp ix kq jb kr ks kt ku bi translated">文件集:Terrapin集群上的数据被命名为“文件集”新数据被加载/重新加载到文件集中。</li><li id="d902" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">动态交换和多版本:通过动态交换将新数据加载到现有文件集中，不会出现服务中断。Terrapin支持为关键文件集保留多个版本，这使得在数据加载不良的情况下能够快速回滚。</li><li id="d5fe" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">S3/HDFS/Hadoop/Hive:一个Hadoop作业可以直接向Terrapin写数据。否则，Hadoop作业可以将数据写入HDFS/S3，并且可以在后续步骤中被Terrapin接收。Terrapin还可以摄取Hive上的表，并基于某一列(标记为key)提供随机访问。</li><li id="a2d7" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">易于更改输出碎片的数量:对于相同的文件集，跨不同的数据负载更改输出碎片的数量是很容易的。这使得开发人员可以通过调整reducers的数量来灵活地调整MapReduce作业。</li><li id="fd41" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">可扩展的服务/存储格式:可以插入其他(更有效的)服务格式，比如rocksdb。sst等。</li><li id="c4ba" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">监控:Terrapin通过HTTP接口导出延迟和值大小分位数以及集群健康状态。</li><li id="a998" class="km kn hh ig b ih kv il kw ip kx it ky ix kz jb kr ks kt ku bi translated">推测性执行:terrapin附带了一个客户端抽象，可以针对服务于相同文件集的两个Terrapin集群发出请求，并选择较早满足的一个。该功能对于提高可用性和减少延迟非常有效。</li></ul><h2 id="a56e" class="jd je hh bd jf jg jh ji jj jk jl jm jn ip jo jp jq it jr js jt ix ju jv jw jx bi translated">带着水龟去兜风吧！</h2><p id="9e5a" class="pw-post-body-paragraph ie if hh ig b ih jy ij ik il jz in io ip ka ir is it kb iv iw ix kc iz ja jb ha bi translated">Terrapin已经在Pinterest上运行了一年多。包括我们的web/移动前端、流处理系统和中间件服务在内的几个系统查询我们的Terrapin集群。我们的MapReduce管道每天将数TB的数据转储到Terrapin。我们一直在EC2上的数百个节点上运行Terrapin，服务累计150万QPS，服务器端p99延迟的&lt; 5ms. Today, our Terrapin deployment stores ~180T of data. The data is split across ~ 100 filesets and over 50 thousand files.</p><p id="d42f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">You can now access the <a class="ae jc" href="https://github.com/pinterest/terrapin" rel="noopener ugc nofollow" target="_blank">源代码</a>、<a class="ae jc" href="https://github.com/pinterest/terrapin/blob/master/docs/SETUP.md" rel="noopener ugc nofollow" target="_blank">设置</a>和<a class="ae jc" href="https://github.com/pinterest/terrapin/blob/master/docs/USAGE.md" rel="noopener ugc nofollow" target="_blank">使用</a>指令供自己使用。如果您有任何问题或意见，请通过<a class="ae jc" href="mailto:terrapin-users@googlegroups.com" rel="noopener ugc nofollow" target="_blank">terrapin-users@googlegroups.com</a>联系我们</p><p id="31c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鸣谢:这项工作是由房建、瓦伦·夏尔马和两名软件工程实习生康奈尔·多纳吉和杰森·钟共同完成的。我们还要感谢Discovery团队，他们是这项技术的早期采用者，并帮助在生产中强化这项技术。</p></div></div>    
</body>
</html>