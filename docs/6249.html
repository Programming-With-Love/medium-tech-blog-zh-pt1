<html>
<head>
<title>Empowering Pinterest data scientists and machine learning engineers with PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过PySpark为Pinterest数据科学家和机器学习工程师提供支持</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/empowering-pinterest-data-scientists-and-machine-learning-engineers-with-pyspark-f41b0d1dd1b8?source=collection_archive---------0-----------------------#2020-06-30">https://medium.com/pinterest-engineering/empowering-pinterest-data-scientists-and-machine-learning-engineers-with-pyspark-f41b0d1dd1b8?source=collection_archive---------0-----------------------#2020-06-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="186d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tien T. Nguyen |机器学习平台，Jingge Zhou |机器学习平台，Zirui Li |数据处理平台</p><p id="669e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinterest的数据科学家和机器学习工程师发现自己在现有工具上遇到了重大挑战。Hive和Presto是易于访问的大规模数据转换工具，但是复杂的逻辑很难用SQL编写。一些工程师在Cascading或Scala Spark作业中编写复杂的逻辑，但这些作业有一个陡峭的学习曲线，需要更多的时间来学习和构建作业。此外，数据科学家和机器学习工程师经常在小规模的笔记本环境中训练模型，但他们缺乏执行大规模推理的工具。</p><p id="8c3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了应对这些挑战，我们(机器学习和数据处理平台工程师)构建并生产了PySpark基础设施。PySpark基础设施为我们的用户提供了以下功能:</p><ul class=""><li id="285d" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">在允许试验新包的隔离环境中，使用熟悉的Python语言和库编写逻辑。</li><li id="153e" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">从我们的JupyterHub部署进行快速原型开发，使用户能够交互式地尝试功能转换、模型想法和数据处理工作。</li><li id="f339" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">与我们的内部工作流系统集成，以便用户可以轻松地将他们的PySpark应用程序生产为预定的工作流。</li></ul><h1 id="10e7" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">PySpark在Kubernetes上作为最低可行产品(MVP)</h1><p id="4255" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">我们首先使用<a class="ae kt" href="https://spark.apache.org/docs/latest/spark-standalone.html" rel="noopener ugc nofollow" target="_blank"> Spark独立模式</a>在Pinterest Kubernetes基础设施上构建了一个MVP PySpark基础设施，并针对用户反馈进行了测试。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/1238eb8cb7d55f740a4f455c1b2367cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QLqZPLi287DXe2qY"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd js">Figure 1. An overview of the MVP architecture</strong></figcaption></figure><p id="9c69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基础设施由执行不同任务的Kubernetes吊舱组成:</p><ul class=""><li id="085a" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">Spark Master管理集群资源</li><li id="1aca" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">工人——产生星火执行者的地方</li><li id="ad17" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">分配给每个用户的Jupyter服务器</li></ul><p id="2ff8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当用户从这些Jupyter服务器启动PySpark应用程序时，Spark驱动程序在与Jupyter相同的pod中创建，而请求的执行器在worker pods中创建。</p><p id="76ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个架构让我们的用户第一次体验到了PySpark的强大功能。数据科学家能够快速掌握Python UDFs，转换要素，并使用万亿字节的数据对张量流模型进行批量推断。</p><p id="a148" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，这种体系结构有一些限制:</p><ul class=""><li id="2163" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">Jupyter笔记本和PySpark驱动程序共享资源，因为它们在同一个pod中。</li><li id="7fb0" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">驱动程序的端口和地址在配置中是硬编码的。</li><li id="3fad" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">用户在每个指定的Jupyter服务器上只能启动一个PySpark应用程序。</li><li id="d960" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">每个用户/团队对Python的依赖是很困难的。</li><li id="b411" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">资源管理限于所有用户的FIFO方法(没有定义队列)。</li></ul><p id="b5c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着对PySpark需求的增长，我们开发了基于Yarn、Livy和Sparkmagic的生产级PySpark基础设施。</p><h1 id="a738" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">生产级PySpark基础设施</h1><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/f382b10bdc3a31dc8d0bbfc66ed7a3e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KtANkvgBYcNpoAL-"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd js">Figure 2: An overview of the production architecture</strong></figcaption></figure><p id="f4d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个架构中，每个Spark应用程序都运行在YARN集群上。我们使用<strong class="ig hi"> Apache Livy </strong>在我们的内部JupyterHub、Spark应用程序和YARN cluster之间进行代理。在Jupyter上，<strong class="ig hi"> Sparkmagic </strong>提供了一个PySpark内核，将PySpark代码转发给正在运行的Spark应用程序。<strong class="ig hi"> Conda </strong>为每个应用提供隔离的Python环境。</p><p id="e553" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过这种架构，我们提供了两种开发方法。</p><p id="cf6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">互动开发:</strong></p><ol class=""><li id="dd4c" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb lk ji jj jk bi translated">用户创建一个包含他们需要的Python包(如果有的话)的conda环境zip。</li><li id="042a" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">从JupyterHub，他们用Sparkmagic的PySpark内核创建了一个笔记本。</li><li id="fd48" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">在笔记本中，他们声明所需的资源、conda环境和其他配置。Livy在纱线集群上启动了一个Spark应用程序。</li><li id="560f" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">Sparkmagic将用户的Jupyter细胞(通过Livy)发送到PySpark应用程序。Livy将结果代理回Jupyter笔记本。</li></ol><p id="ae59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请参见随附的图片(见附录)了解Jupyter笔记本的完整注释示例。</p><p id="ab77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">非交互式开发</strong>(临时和生产工作流程运行):</p><ol class=""><li id="fb4b" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb lk ji jj jk bi translated">Pinterest-internal <em class="ll">作业提交服务</em>充当了YARN集群的网关。</li><li id="9250" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">在开发中，用户的本地Python代码库被打包到一个档案中，并提交以启动YARN中的PySpark应用程序。</li><li id="369a" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">在计划的生产运行中，将提交生产版本的归档文件。</li></ol><h1 id="6584" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">利益</h1><p id="ad7c" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">该基础架构为我们提供了以下优势:</p><ol class=""><li id="4f1c" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb lk ji jj jk bi translated">Jupyter笔记本和PySpark驱动程序之间没有资源共享</li><li id="b37d" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">没有硬编码的驱动程序端口和地址</li><li id="1625" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">用户可以启动许多PySpark应用程序</li><li id="42f4" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">高效的资源分配和隔离，通过积极的动态分配实现高资源利用率</li><li id="f73f" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">支持每个用户的Python依赖性</li><li id="7354" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">资源问责</li><li id="f664" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb lk ji jj jk bi translated">PySpark工作分析的大象博士</li></ol><h1 id="e0c3" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">技术细节</h1><p id="14b8" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated"><strong class="ig hi"> Pinterest JupyterHub集成<em class="ll"> : </em> </strong>(好处#1，2，3)</p><p id="c9f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们让Sparkmagic <a class="ae kt" href="https://github.com/jupyter-incubator/sparkmagic" rel="noopener ugc nofollow" target="_blank">内核</a>在Jupyter中可用。当内核被选中时，由ZooKeeper管理的配置会加载所有必要的依赖项。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/0304a852daeca8647ca53b3a074c8f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8m_vBjDfy6W9pPOU"/></div></div></figure><p id="eee9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们设置了Apache <a class="ae kt" href="https://livy.apache.org/" rel="noopener ugc nofollow" target="_blank"> Livy </a>，它提供了一个从Jupyter到YARN cluster和PySpark应用程序的REST API代理。</p><p id="5240" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">一个纱线集群:(</strong>效益#4)</p><ul class=""><li id="3e2f" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated"><strong class="ig hi">高效的资源分配和隔离。</strong>我们使用<a class="ae kt" href="https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-site/FairScheduler.html" rel="noopener ugc nofollow" target="_blank">公平调度器</a>定义了一个队列结构，以确保专用资源，并且在某些条件下(例如，在等待至少10分钟之后)是可抢占的，但是一部分不可抢占的资源将被保留给设置了minResource的队列。调度程序和资源管理器日志用于管理集群资源。</li><li id="b680" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">高资源利用率的积极动态分配策略</strong>。我们设置了一个策略，PySpark应用程序最多持有一定数量的执行器，并在它们不需要时自动释放资源。该策略确保资源循环更快，从而提高资源利用率。</li></ul><p id="415f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Python依赖管理:</strong>(好处#5)</p><p id="9c6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用户可以尝试各种Python库(例如不同的ML框架)，而无需要求平台工程师安装它们。为此，我们创建了一个Jenkins作业，根据一个需求文件打包conda环境，并在S3上将它归档为zip文件。PySpark应用程序使用“— archives”启动，将zip文件与所有执行器一起广播给驱动程序，并重置“PYSPARK_PYTHON”(针对驱动程序)和“spark . yarn . appmasterenv . PySpark _ PYTHON”(针对执行器)。这样，每个应用程序都可以在一个隔离的Python环境中运行，并且需要所有的库。</p><p id="8e58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">与Pinterest-内部职位提交服务(JSS)集成:</strong>(好处#6)</p><p id="66ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了生产PySpark应用程序，用户可以利用内部工作流系统进行调度。我们提供了一个工作流模板来集成作业提交接口，以指定要使用的代码位置、参数和Python环境工件。</p><p id="b56c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">自助工作绩效分析:</strong>(福利#7)</p><p id="3139" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们派生了开源的<a class="ae kt" href="https://github.com/linkedin/dr-elephant" rel="noopener ugc nofollow" target="_blank"> Dr. Elephant </a>，并添加了新的试探法，用各种运行时指标(执行器、作业、阶段等)来分析应用程序的配置。该服务提供调优建议，并提供如何正确编写spark作业的指南。这项服务减轻了用户调试和排除故障的痛苦，提高了速度。而且避免了资源浪费，提高了集群稳定性。下面是一个性能分析的例子。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lm"><img src="../Images/001f64bd60cb5a569a801b301ebe969d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aow1tV_v3oa0QExo"/></div></div></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ln"><img src="../Images/1350e3af493e9b83aee0de2ef18c379b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XchBIg8OMYLxKeXq"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx"><strong class="bd js">Figure 3: An overview of Dr. Elephant</strong></figcaption></figure><h1 id="43e2" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">影响</h1><p id="70bb" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">PySpark现已在我们的产品分析和数据科学以及广告团队中广泛使用。</p><ul class=""><li id="4a30" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">训练:用户可以使用mllib或任何Python机器学习框架(如TensorFlow)对任何大小的数据进行迭代训练模型。</li><li id="3bb4" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">推理:用户可以测试和生产他们的Python代码进行推理，而不需要依赖平台工程师。</li><li id="5988" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">即席分析:用户可以根据需要执行各种即席分析。</li></ul><p id="4700" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我们的用户现在可以自由探索各种Python依赖项，并使用Python UDF处理大规模数据。</p><p id="d4aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">确认</strong></p><p id="a0c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢(EM，机器学习平台团队)、(EM，数据处理平台团队)、Tais(我们的TPM)、Pinterest产品分析和数据科学组织(Sarthak Shah、、、Dan Lee、Ladi Ositelu)、计算平台团队(张哈利、June Liu)、数据处理平台团队(Zaheen Aziz)、Jupyter团队(Prasun Ghosh —技术负责人)的支持和合作<em class="ll">。</em></p><h2 id="6b27" class="lo jr hh bd js lp lq lr jw ls lt lu ka ip lv lw ke it lx ly ki ix lz ma km mb bi translated"><strong class="ak">附录—我们用例的一个例子(附录):</strong></h2><p id="dcca" class="pw-post-body-paragraph ie if hh ig b ih ko ij ik il kp in io ip kq ir is it kr iv iw ix ks iz ja jb ha bi translated">下面是一个例子，展示了我们的用户如何训练一个模型，并在他们的Jupyter笔记本上用PySpark大规模运行推理逻辑。我们在每个单元格中留下解释。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es mc"><img src="../Images/4e8db794782d292d2126b09ab4be103c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7LDs3kNqW6ePzrDD"/></div></div></figure></div></div>    
</body>
</html>