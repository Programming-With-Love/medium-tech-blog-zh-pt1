<html>
<head>
<title>Scaling Machine Learning Algorithms(Fbprophet/XGBoost) with pyspark on W-MLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在W-MLP上用pyspark扩展机器学习算法(Fbprophet/XGBoost)</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/scaling-machine-learning-algorithms-fbprophet-xgboost-with-pyspark-on-w-mlp-405fadca1c19?source=collection_archive---------1-----------------------#2019-12-18">https://medium.com/walmartglobaltech/scaling-machine-learning-algorithms-fbprophet-xgboost-with-pyspark-on-w-mlp-405fadca1c19?source=collection_archive---------1-----------------------#2019-12-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="ed7e" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated"><strong class="ak">沃尔玛—机器学习平台(W-MLP) </strong></h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es iw"><img src="../Images/f668a6ffd0035c90a7784bf02cbdd956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*2KUwmPirI77Hvm0sBzMb-w.jpeg"/></div><figcaption class="je jf et er es jg jh bd b be z dx">Pyspark+xgboost/fbprophet. Source: <a class="ae ji" href="https://miro.medium.com/max/1200/1*nPcdyVwgcuEZiEZiRqApug.jpeg" rel="noopener">https://miro.medium.com/max/1200/1*nPcdyVwgcuEZiEZiRqApug.jpeg</a></figcaption></figure><p id="4c0b" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">W-MLP是一个机器学习平台，为数据科学家和数据工程师提供端到端的能力，使他们能够更快地开发和部署模型。</p><p id="58bd" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">它还提供了连接和接收来自不同数据源的数据的功能，这些数据源用于在生产中培训、测试和部署模型。</p><p id="6ba0" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated"><strong class="jl hi">W-MLP提供的关键能力:</strong></p><ul class=""><li id="5f2a" class="kf kg hh jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">访问不同来源的数据。</li><li id="e805" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">采购、管理和维护自有虚拟机。</li><li id="8b4d" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">管理和维护不同项目的环境(库和工具)。</li><li id="987c" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">合作和发展的能力。</li><li id="7694" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">减少重复，因为多个团队可以创建相似的数据集、模型并解决相似的问题。</li><li id="4061" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">重用组件的兼容性问题(不同的工具、版本等)。</li></ul><h1 id="387a" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">问题陈述</strong></h1><blockquote class="ll lm ln"><p id="8e7d" class="jj jk lo jl b jm jn ii jo jp jq il jr lp jt ju jv lq jx jy jz lr kb kc kd ke ha bi translated">W-MLP遇到了各种各样的机器学习用例，这些用例的数据量非常大，而所使用的库本身并没有提供扩展用例的方法。我们能够支持西MLP的多个组织使用西MLP的pyspark扩展他们的预测算法。它的独特功能，如spark集群上库安装/分发的抽象，通过W-MLP平台上的jupyter notebook与现有hadoop集群进行交互的简单方式，以及将它们部署为具有调度功能的工作流，帮助这些用例轻松扩展并转移到生产环境。</p></blockquote><h1 id="5b21" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">使用案例:</strong></h1><p id="6684" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">1)在特定级别(如类别/室/部门/日期等)对数据进行分组后，对客户的数据源运行91天的预测。预测逻辑需要在大约90，000个这样的组上运行，其中每个组包含超过1000条记录。执行预测的首选库是fbprophet。Prophet是一种基于加法模型预测时间序列数据的过程，在该模型中，非线性趋势与每年、每周和每天的季节性以及假日影响相适应。</p><p id="9560" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">2)执行预测，其中数据分组在部门和细线编号处完成。总的数据大小接近35GB。首选库是XGBoost。在一个简单的python笔记本中处理如此大量的数据并完成SLA内的预测是不可行的。</p><p id="9c24" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">3)选择合适的商品组合极其重要，因为这是顾客感知商店的主要方式之一<br/>这里的挑战在于规模，我们有大约4500家商店，大约1700个类别。我们如何扩展算法，为我们提供所有4500家商店所有类别的实时分类？</p><p id="1ef3" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">在执行预测之前，上述用例在数据汇总和数据分组的方式上有许多共同的模式。由于可以在特定级别对数据进行分组，这为数据分区开辟了道路，而数据分区是分配工作负载的关键。<strong class="jl hi">上述用例中涉及的问题基本上可以归结为以下任务:</strong></p><p id="6b17" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">1)有效地划分数据。<br/> 2)为每个分区添加预测逻辑。<br/> 3)使首选库在所有spark worker节点及其所有依赖项上可用。<br/> 4)确定扩展用例所需的Spark执行器/内核和内存的数量。<br/> 5)向所有节点广播小数据。</p><h1 id="8b83" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">分区数据</strong></h1><p id="a073" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">可以根据感兴趣的特定列对数据进行重新划分，如下所示</p><pre class="ix iy iz ja fd lx ly lz ma aw mb bi"><span id="1eb2" class="mc ku hh ly b fi md me l mf mg">sparkDataFrame.repartition(*cols)</span></pre><p id="8dfe" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">Spark将检测指定列中的唯一值，并相应地对它们进行分区。因此，根据指定列的唯一值的数量，将会创建许多分区(如果您期望更少的分区数量，并注意到创建了200个分区，这是spark默认设置，可以使用<strong class="jl hi">spark . SQL . shuffle . partitions</strong>属性进行控制。只有预期数量的分区将有数据，您将看到其余的任务很快运行完成)。</p><p id="14ca" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">在spark中，分区等同于任务，这些小单元将分布在工作节点上执行计算。重新分区将涉及worker节点之间的数据洗牌，以确保具有相同值的列都被移动到同一个执行器。例如:-如果您对具有唯一值10、11、12的部门编号进行分区，spark将以这样的方式移动数据，即每个分区只有一个部门编号。一个可能减慢这一步的常见错误是加载不必要的列来触发Dataframe，并且在执行分区之前没有删除它们。上述用例有300多列，而实际计算中只需要150列。通过确保只需要执行预测所需的列，数据大小将显著减少并加快分区过程。</p><h1 id="4734" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">将首选库发送给执行者</strong></h1><p id="da5a" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">W-MLP抽象的航运图书馆的引擎盖下的执行者。你所需要做的就是从库向导安装这些库，然后当spark任务初始化时，W-MLP让所有的执行器都可以使用这些库。W-MLP使用CONDA环境来打包库，因此不需要担心与这些库相关联的所有依赖项或共享库。</p><h1 id="537d" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">添加每个分区的预测逻辑</strong></h1><p id="d43c" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">一旦重新分区发生，执行预测的逻辑可以添加到<em class="lo"> mapPartitions </em>方法中。即使在使用Spark之前，模型拟合和预测的逻辑也可以保持不变。Spark将负责在多个节点的多个分区上并行执行相同的逻辑。</p><pre class="ix iy iz ja fd lx ly lz ma aw mb bi"><span id="62fb" class="mc ku hh ly b fi md me l mf mg">sparkDataFrame.rdd.mapPartitions(forecasting_logic)<br/>def forecasting_logic(partition_list):<br/>    pdf = pd.DataFrame(partition_list)<br/>    model=your_prefferred_lib.fit(pdf)<br/>    predicted_pdf = model.predict()<br/>    return predicted_pdf.values.tolist()</span></pre><h1 id="2326" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">决定spark执行器/内核和内存</strong></h1><p id="7282" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">将代码移植到pyspark时出现的一个常见问题是如何决定需要多少资源。虽然这完全取决于用例，但是可以遵循一些通用的准则。</p><p id="7044" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">在对要进行分区的特定列执行group by之后，执行简单的spark SQL来进行计数，这将提示单个任务将要处理的记录数量。结合对数据的理解来看这个数字，将有助于得出一个单个任务所需内存量的大概数字。需要记住的一点是，这个内存不能超过Hadoop集群中executor节点可用的总内存。例如，如果分配给Hadoop集群中单个节点的最大内存是16 GB，那么我们就不能执行需要更大内存的任务。</p><h1 id="2e79" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">让我们来看一个用例示例</strong></h1><p id="235f" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">假设我们有一个根据部门id进行分区的数据。如果部门有20个唯一值，我们将得到20个分区。现在，如果我们可以分配20个内核，所有20个分区都可以并行计算。我们可以提供4个执行器和每个执行器5个内核的配置(4*5=20)。每个执行器最多5个内核是推荐的配置。然而，这意味着在一个执行程序中将同时运行5个任务。如果所有5个任务的数据都无法容纳在内存中，请确保分配较少的内核和较多的执行器。例如:- 10个执行者和每个执行者2个核心(10*2=20)。</p><p id="5a03" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">分配与分区数量一样多的执行器和核心可能在所有情况下都不可行。在这种情况下，查看在不影响同一队列中任何其他作业的情况下，可以从专用队列中分配给该作业的最大执行器和核心数</p><h1 id="b2b1" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">广播小数据/变量</strong></h1><p id="21cb" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">广播变量允许程序员在每台机器上缓存一个只读变量，而不是随任务一起发送一个副本。例如，它们可用于以高效的方式为每个节点提供大型输入数据集的副本。Spark还尝试使用高效的广播算法来分发广播变量，以降低通信成本。</p><pre class="ix iy iz ja fd lx ly lz ma aw mb bi"><span id="dd91" class="mc ku hh ly b fi md me l mf mg">item_attribute_data=item_attribute_data.collect()<br/>sc.broadcast(item_attribute_data)<br/># Above will broadcast item_attribute_data to all nodes of cluster.</span></pre><h1 id="4f70" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">监控pyspark作业</strong></h1><p id="69c2" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">Spark UI提供了关于工作进展的足够详细的信息。为了确保您的作业获得指定数量的资源(内核/内存)，请查看executor选项卡。您可能需要根据您的工作来调整内存需求、执行器或内核。查看spark UI中的日志，您将能够发现是否有许多任务由于内存不足而失败。在这种情况下，提供更多内存或减少每个执行器的核心数</p><h1 id="f760" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">示例代码片段:</h1><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="cbe0" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><strong class="ak">结论</strong></h1><p id="bf40" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">虽然这里讨论的用例主要是关于预测和扩展解决方案，但是这种模式可以用于任何ml算法，其中可以对数据进行分区(也可以放在内存中)以执行模型拟合/推理。一旦确定了分区逻辑，spark就可以负责分配工作负载。为预测编写的原始代码在移植到spark时只需很少甚至不需要修改，W-MLP图书馆管理使算法的扩展变得更加容易。</p><h1 id="fe91" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">作者</h1><ol class=""><li id="f414" class="kf kg hh jl b jm ls jp lt js mj jw mk ka ml ke mm kl km kn bi translated"><a class="ae ji" href="https://www.linkedin.com/in/shubhamgujarwasia/" rel="noopener ugc nofollow" target="_blank">舒布哈姆·阿格拉瓦尔</a>，软件工程师III，印度沃尔玛实验室</li><li id="df30" class="kf kg hh jl b jm ko jp kp js kq jw kr ka ks ke mm kl km kn bi translated"><a class="ae ji" href="https://www.linkedin.com/in/arun-sasidharan-nair-67270a73/" rel="noopener ugc nofollow" target="_blank">阿伦·奈尔</a>，印度沃尔玛实验室软件工程师IV</li></ol><h1 id="0d8c" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">参考</h1><p id="ae03" class="pw-post-body-paragraph jj jk hh jl b jm ls ii jo jp lt il jr js lu ju jv jw lv jy jz ka lw kc kd ke ha bi translated">1.<em class="lo">火花文档</em>:<a class="ae ji" href="https://spark.apache.org/docs/latest/" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/</a><br/>2。<em class="lo">FB prophet</em>:<a class="ae ji" href="https://facebook.github.io/prophet/docs/quick_start.html" rel="noopener ugc nofollow" target="_blank">https://facebook.github.io/prophet/docs/quick_start.html</a><br/>3。<em class="lo">py spark</em>:<a class="ae ji" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/api/python/index.html</a></p></div></div>    
</body>
</html>