<html>
<head>
<title>Apache Spark — The Swiss Army Knife for Data at Walmart</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark —沃尔玛数据的瑞士军刀</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/apache-spark-the-swiss-army-knife-for-data-at-walmart-3c1950da74ea?source=collection_archive---------4-----------------------#2019-08-28">https://medium.com/walmartglobaltech/apache-spark-the-swiss-army-knife-for-data-at-walmart-3c1950da74ea?source=collection_archive---------4-----------------------#2019-08-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d97baa6da8a0e1628b6640dbc5350755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tp8pTY8C_tEZr6B9CdcSAQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx">Pic Credit: <a class="ae it" href="https://www.bhphotovideo.com/images/images2500x2500/victorinox_53501_swisschamp_pocket_knife_91mm_1149550.jpg" rel="noopener ugc nofollow" target="_blank">BHPhotoVideo</a></figcaption></figure><p id="29c2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的业务需求很简单:接收、存储、分析数据，并将其作为有意义的信息发布(要么作为报告，要么作为Kafka的下游，等等)。)给客户。在沃尔玛，我们有一个新的行话:数据！我很确定这是整个行业的趋势。我们需要一个经济高效的解决方案，它不仅可以扩展到我们正在处理的数据的大小，而且足够灵活，能够以最小的工作量插入额外的数据源或数据接收器。</p><p id="d700" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">复杂性在于这样一个事实，即在过去的几年中，微服务架构出现了爆炸式增长。每个团队都可以自由地为他们的微服务选择任何数据库。这导致结合这些数据进行分析的复杂性增加。我们研究了多种选择，从ETL和报告工具，到像Clickhouse、Druid等开源数据库。虽然它们每个都有自己的优点，但没有一个完全符合我们的用例。进入阿帕奇火花！很快我们发现它可以用于我们所有的三个用例(存储、分析和发布)。它非常灵活，因为它是一个非常通用的框架，可以插入大多数数据源和数据存储，并且它还包含一个相当全面的API来分析这些数据。因此，我们开始在Spark上开发我们的解决方案，并很快意识到它可以成为我们几乎任何“数据”的首选框架！</p><p id="5612" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个博客不是教程，也不是对Apache Spark的深入研究，互联网上有足够的文档和培训。这是为了分享我们在沃尔玛使用Spark的各种使用案例的信息。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/738e8bd9f2ff209e9c43daedd090a70a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BPku3HXmB5lNkZrnUeCs8Q.png"/></div></div></figure><p id="4d94" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从高层次来看，我们的Spark用例分为以下几类:</p><ul class=""><li id="810f" class="jx jy hh iw b ix iy jb jc jf jz jj ka jn kb jr kc kd ke kf bi translated"><strong class="iw hi">流至存储</strong> <br/>作为我们审计平台的一部分，我们从各种系统获取审计事件，并将其存储在HDFS(作为Parquet或CSV)。然后，我们将这些数据用于分析、报告等。</li><li id="f360" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated"><strong class="iw hi">流对流</strong> <br/>我们从各种系统接收变化事件(主要通过卡夫卡)。我们将这些数据与其他数据源(集群内部的和外部的)结合起来，对其进行分析，并将解决的事件发布给其他下游消费者。例如，当一个项目属性发生变化时，比如价格，我们会收到通知，然后我们会将这种变化与其他项目数据(比如成本、描述等)结合起来。并将其发布到商店系统消费的Kafka主题。</li><li id="ffb3" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated"><strong class="iw hi">存储到流</strong> <br/>我们有一个Spark作业，它将大量DB2和Teradata表(大约数十亿行)加载到一个dataframe中，执行计算和聚合，然后在Kafka上发布这些信息。</li><li id="547c" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated"><strong class="iw hi">数据分析</strong> <br/>我们运行Spark作业来分析存储在HDFS/Hive中的数据并生成报告。事实证明，Spark SQL比Hive QL快一个数量级，我们能够在几秒钟而不是几分钟内生成报告。由于Spark原生支持Openstack Swift，我们将csv报告上传到存储云，企业客户可以轻松下载。我们使用一个名为<a class="ae it" href="https://github.com/spark-jobserver/spark-jobserver" rel="noopener ugc nofollow" target="_blank"> spark-jobserver </a>的令人敬畏的框架，它提供了提交和管理spark作业的API。</li><li id="fc21" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated"><strong class="iw hi">数据迁移</strong> <br/>我们有各种各样的数据库，有时需要在它们之间传输数据，这可能是退役项目或现代化项目的结果。例如DB2到Cassandra，DB2到Maria DB，DB2到Teradata，Cassandra到Solr，等等。Spark连接如此大量数据库的灵活性及其通用特性帮助我们在短时间内迁移了大量数据。</li></ul><p id="35b5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">需要注意的一点是，在沃尔玛的团队中，我们在现有的Hadoop集群上部署了Apache Spark，原因如下:</p><ol class=""><li id="b215" class="jx jy hh iw b ix iy jb jc jf jz jj ka jn kb jr kl kd ke kf bi translated">沃尔玛已经投资建设大规模的Hadoop集群。</li><li id="2b58" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kl kd ke kf bi translated">我们有超过2000TB的HDFS存储可用。</li><li id="66e4" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kl kd ke kf bi translated">我们有成千上万的核心可以支配，Spark在这个集群上的扩展非常漂亮。</li></ol><p id="6912" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">总结</strong> <br/>在处理数据方面，Apache Spark最终成为了我们的瑞士军刀。Spark是一个简单、可扩展的通用框架，可以处理几乎所有的事情。我相信我们只是触及了Spark的皮毛，我们正在进入一个全新的数据分析和数据科学世界，我们也将使用Spark。我不认为在不久的将来会远离它！</p></div></div>    
</body>
</html>