<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/event-stream-analytics-at-walmart-with-druid-dcf1a37ceda7?source=collection_archive---------0-----------------------#2017-11-24">https://medium.com/walmartglobaltech/event-stream-analytics-at-walmart-with-druid-dcf1a37ceda7?source=collection_archive---------0-----------------------#2017-11-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><p id="b7b6" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">德鲁伊在沃尔玛的事件流分析</strong></p><p id="7ec2" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">沃尔玛经常处理一些世界上最复杂的工程问题，并采用最新技术确保11，000多家实体店和众多在线网站以最高效率运行。在沃尔玛实验室，我们的工程团队经常被要求对要使用的最新工具进行评估、基准测试和决策。我们最近面临的一个更有趣的挑战是为我们的流数据提供高性能分析。</p><p id="e031" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">到处都是溪流</strong></p><p id="f717" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">WalmartLabs的许多数据集都是由我们的数字业务生成的，并且自然地被建模为事件流。这些事件流的范围可以从服务器日志、应用程序指标到产品购买。我们的目标是让我们组织中的适当人员能够在尽可能短的时间内轻松访问这些数据、分析这些数据并做出决策。</p><p id="81ae" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">任何从事和构建面向高容量、低延迟工作负载的数据堆栈的人都知道，一种技术通常不足以提供完整的解决方案。在数据交付、数据处理和查询方面，存在与大规模事件流相关联的众多挑战。通常需要一个完整的数据堆栈，但幸运的是，开源社区中有很好的技术可以帮助解决这些问题。</p><p id="d45e" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们利用Apache Kafka将事件从它们被创建的地方传递到下游系统，在那里它们可以被处理或查询。Kafka有很好的特性，允许我们将事件生产者从事件消费者中分离出来，并确保我们的事件总是被交付。</p><p id="26e1" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们数据管道的下一个阶段是丰富原始数据，我们使用Apache Storm等流框架，结合各种内部工具来实现这一点。Apache Storm是一个流处理系统，旨在转换和丰富数据。与Trident一起，Storm可以为我们的下游分析引擎提供恰好一次的负载。此外，鉴于真实世界的数据可能会非常嘈杂，我们开发了一个定制的日志刮刀，可以过滤掉任何对我们的分析系统无用的信息。</p><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es if"><img src="../Images/2cf6994e89c610f724770e360b0e3fe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7sVqHQgKanrmGKzgZyVr6Q.png"/></div></div></figure><p id="c635" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated"><strong class="hi ie">低延迟查询</strong></p><p id="edc0" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们提供低延迟分析的第一次尝试是利用Hadoop生态系统，即Hive，然后很快。我们面临的这两个基于Hadoop的SQL解决方案的问题是，查询有时需要几个小时才能完成，这极大地影响了我们快速做出决策的能力。尽管我们的数据是实时到达的，但随着数据量的增长，我们的查询很快成为决策周期中的瓶颈。我们很快意识到，我们旨在优化的工作流是这样一个工作流，我们可以查看我们的事件流(实时和历史事件)并对数据进行分割，以查看特定的子部分，确定趋势，找到根本原因，并采取相应的措施。我们需要一台OLAP发动机。</p><p id="8153" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">经过一番搜索，我们找到了Druid开源项目。Druid是一个OLAP引擎，针对低延迟数据接收(流接收)和极快的聚合进行了高度优化。它与卡夫卡和《风暴》原生地结合在一起，所以对我们来说入门相对容易。</p><p id="0c6a" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">德鲁伊的建筑很独特；它是一个搜索引擎和一个栏目数据库合二为一。Druid完全索引所有数据，类似于搜索引擎，但不是在搜索索引中索引数据，而是将数据存储在不可变的列中，类似于列数据库。列存储格式支持快速聚合，但此外，还会为字符串值创建倒排索引(就像在搜索引擎中一样)。这些倒排索引允许引擎快速删除查询中不必要的数据，以便引擎可以准确扫描完成查询所需的内容。</p><p id="6c42" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">德鲁伊在摄取时也做了一些巧妙的优化。例如，Druid可以在记录被摄取时对其进行预聚合。</p><p id="030e" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">假设我们有两个事件:</p><p id="1324" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">{ "时间戳":" 2017–01–01:12:10:01.005 z "，"属性":" foo "，"价格":3}</p><p id="1493" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">{ "时间戳":" 2017–01–01:12:10:01.007 z "，"属性":" foo "，"价格":4}</p><p id="1c38" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">我们不关心这两个事件发生的精确时间，但是我们关心一段时间内所有事件的总价格。因为这两个事件共享相同的“属性”值“foo ”,所以如果我们截断事件的时间戳(在本例中，截断到秒),我们可以将这两个记录组合在一起。</p><p id="7582" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">组合事件是:</p><p id="dbd4" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">{ "时间戳":" 2017–01–01:12:10:01Z "，"属性":" foo "，"价格":7}</p><p id="fa94" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">Druid提供了这种现成的汇总功能，在实践中，与原始数据大小相比，它使我们能够节省大量的存储空间。</p><p id="18cb" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">在我们切换到Druid之后，我们的查询延迟也下降到接近亚秒，总体来说，这个项目满足了我们的大部分需求。今天，我们的集群每天接收近1B+事件(2TB的原始数据)，Druid已经为我们做了很好的扩展。</p><p id="d09f" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">在家一定要试试这个！</p><p id="856e" class="pw-post-body-paragraph hf hg hh hi b hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ha bi translated">如果您有与我们类似的流数据工作负载，我们建议您查看我们提到的一些项目。当您考虑如何构建数据堆栈时，它们可能会有很大的帮助。</p></div></div>    
</body>
</html>