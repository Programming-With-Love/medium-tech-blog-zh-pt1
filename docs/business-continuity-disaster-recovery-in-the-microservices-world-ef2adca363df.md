# 微服务领域的业务连续性和灾难恢复

> 原文：<https://medium.com/walmartglobaltech/business-continuity-disaster-recovery-in-the-microservices-world-ef2adca363df?source=collection_archive---------0----------------------->

沃尔玛在美国几乎每个州以及全球许多国家都提供杂货提货和送货服务。沃尔玛的集成履行系统由应用程序和后端系统组成，使员工能够履行全球商店的全渠道电子商务订单。

![](img/2b9e6daea68e211ce28bc0106513e74f.png)

fulfilment in the e-commerce context

近年来，该系统在业务上取得了巨大的增长:

![](img/da8e00e1eed1b6892e8f8b568ba06546.png)

reference: [https://techcrunch.com/2019/08/13/walmart-tops-u-s-online-grocery-market-with-62-more-customers-than-next-nearest-rival/](https://techcrunch.com/2019/08/13/walmart-tops-u-s-online-grocery-market-with-62-more-customers-than-next-nearest-rival/)

为了支持这种规模，我们决定更新和重新设计产品。

这样做的一个关键要求是业务连续性。系统中的任何生产问题都会影响我们全球的客户。这个系统不能超出保证的时间表。

**灾难恢复**

分布式计算的[谬误](https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing)是由[L·彼得·多伊奇](https://en.wikipedia.org/wiki/L_Peter_Deutsch)和其他人在描述人们对分布式系统的错误假设时所做的一组观察。在云世界中，基础架构堆栈要密集得多，并且包括不受我们控制的组件。这意味着其中一些谬误会变得更加明显。

当云部署停止时，我们需要系统继续从“另一个地方”为客户服务。灾难恢复(DR)是一种设计结构，它允许从不同的数据中心使用这组服务和相关的基础架构组件(如消息代理和数据库)。

**高层架构**

像这样的系统通常被设计为多个微服务，它们使用消息传递和 API 相互协作，以实现所需的行为。每个服务都有一个自己拥有的数据库——从而强制隔离关注点和明确的契约。为了便于讨论，下面描述了高级体系结构:

![](img/d4863ee011c2a0ff86132c78cfca836c.png)

一些“前端”服务接受来自应用程序的请求，然后与其他“功能”服务一起支持系统用例。术语“事件驱动”也适用于这些类型的系统，因为每个服务都与其他服务松散耦合，并且只对事件(消息)做出反应。

这组微服务的特定部署称为“环”。

**复制**

灾难恢复解决方案的第一个模式是数据(数据库)在远程数据中心的可用性。最简单的方法是，对主区域中数据库的写入也写入远程区域。具体来说，当本地和远程数据库都保存了写入时，数据库写入完成。这里的问题是:

*   写入是跨 WAN 链路进行的，这些链路不提供严格的延迟 SLA。因此，数据库写入时间会增加，而且无法保证。
*   系统可用性现在有了其他的组成部分:远程数据库，本地和远程数据库之间的网络链接。复合系统的可靠性总是低于每个组件，这意味着整个系统的可靠性降低。

为了避免影响性能和可用性，通常采用的模式是*异步复制*，即当本地数据库提交时，数据库写入完成，事务被*发送*到远程数据库。在远程辅助站点上，事务与主数据库中的事务异步持久化。

例如，下图和参考资料描述了 SQL Server 采用的分布式可用性组(DAG)技术:

![](img/5189d0e2ba6b427e11ffb4d6ee0ca176.png)

参考:[https://docs . Microsoft . com/en-us/SQL/database-engine/avail ability-groups/windows/distributed-avail ability-groups](https://docs.microsoft.com/en-us/sql/database-engine/availability-groups/windows/distributed-availability-groups)

> 您可能会注意到消息传递没有被复制——这是因为对于事务性分布式系统来说，将复制的消息传递状态与 DB 状态结合起来变得非常困难。使用 DB 来重放消息要容易得多——如下所述。

**进入微服务**

在微服务架构中，每个服务都有自己的一组数据库。它们彼此独立地复制:

![](img/e8156f4a77a21c623423f11795cbe06b.png)

asynchronous replication

这里的问题是，整个系统状态本身分布在多个服务中，但是多个微服务的事务传送并没有按照“干净一致的路线”进行协调。因此，远程复制数据库集中特定“即时”/快照的集体状态可能不一致，或者在灾难发生时不可用！

为了说明这个问题，考虑下面的流程:

![](img/41e71bbfbd1da0dd09522e82505953ed.png)

在这里，两个数据库发生了变异，当它们在远程数据中心复制时，这两个远程数据库可能处于 4 种状态:

第一种和最后一种情况是可以的(是的，甚至“丢失数据”也是可以的)，因为整个系统现在处于*最后已知的一致状态*。然后我们可以建立和解的机制。更糟糕的是，系统实际上处于不一致的状态——场景 2、3。

在这种跨服务事务复制中会出现 3 个问题:

1.  中断的引用:ServiceX 中的状态引用了 CapabilityServiceP 中不存在的状态。因此，当应用程序(客户端)设计一个迫使 ServiceX 调用 CapabilityServiceP 的流时，未来的交互可能会中断——在这里，ServiceP 没有引用前者正在谈论的实体
2.  Split brain:很多时候，CapabilityServiceP 这样的服务提供了整个系统状态的统一视图。它通过为不同的应用程序显示物化视图来做到这一点。在灾难恢复过程中，物化视图可能有数据，但事实来源没有。这将导致类似“我在搜索页面上看到了商品，但当我进入详细页面时，我得到了 404！”
3.  悬空引用:这与内存管理中通常描述的现象相同:“父”ServiceX 没有对对象(“OrderB”)的引用，但“子”CapabilityServiceP 有关于“OrderB”的记录。反规范化(重复信息以避免连接并提高性能)加剧了这种情况。如果编码不正确，这些悬空引用会导致难以调试的问题。例如，在上面的例子中，如果 CapabilityServiceP 用于给出订单数量的估计，那么这将是一个错误的估计。

这个问题以前已经在备份的环境中研究过，如题为“微服务的一致灾难恢复:BAC 定理”的 IEEE 论文中所述。BAC 是备份可用性一致性的缩写，作者是 Pardon 和 Cesare Pautasso 以及 Olaf Zimmermann。本质上，它是著名的 CAP 定理的一个派生物，它说:

> 备份整个微服务体系结构时，不可能同时具备可用性和一致性

参考:[https://ieeexplore.ieee.org/document/8327550](https://ieeexplore.ieee.org/document/8327550)

既然看到了问题，那就来看看怎么解决吧。

**和解**

使一组微服务达到最近已知一致状态的主要设计模式是协调。本质上，每个服务都保存一个实体变异日志(EML ),记录随着时间戳发生的变化。提货服务的 EML 如下所示:

sample EML for picking

> 这种类型的构造也称为预写日志(WAL ),在 Cassandra 等数据库中用于类似的持久性保证。

一旦我们做到了这一点，在故障转移到远程站点时，一个指定的“恶霸”微服务会重放最后 n 分钟的突变。这个 n 是可调的，涵盖了数据库复制技术提供的“有限陈旧性”保证。在这里描述的系统中，重放通常意味着在其他服务正在监听的地方重新构造和重新发送消息。每个“非欺负者”/下游服务消费相关消息并构造其状态。

**等幂**

协调工作的一个关键要求是等幂，即服务需要能够处理重复的消息，而不改变最终的结果状态。这无论如何都会成为消息驱动的微服务的实际需求，因为消息系统(代理)提供“至少一次”语义。由于各种各样的附加条件，消息在传递给消费者的过程中可能会被复制。

```
Note : some systems like Kafka advertise “exactly-once” semantics, but the fine print is that it’s only possible in very narrow architectures — but that is another medium blog :P ) .
```

**高级解决方案**

总结一下到目前为止的讨论:

*   微服务集必须部署在多个位置(“云”)。让我们把每个部署称为一个环。
*   复制和协调与其他构造一起使用，如基于 GSLB 的负载平衡和监视器，以构建最终的解决方案

![](img/871ae13807de1c308fe63d96378f5343.png)

high-level architecture

监视器是一个健康监视和命令解决方案。它有一个两级体系结构，由一个工人和主体系结构组成。工作人员坐在一个环中，从环中的服务收集 CPU/内存利用率、API 延迟、数据库延迟、磁盘吞吐量等统计数据。它通过由每个组件和其他监视信标公布的健康检查 API 来实现这一点。

有许多像 Spring Boot 执行器这样的框架可以用来为每个服务的健康检查提供模板。这可以通过一个小的包装器库来增强，该包装器库对消息传递和 DB 等常见组件进行健康检查。这样的库允许对服务进行一致的指标报告，如下所示:

```
{
  "app": {
    "state": "UP",
    "name": "servicex",
    "id": "8c13a2@servicex"
  },
  "db": {
    "status": "UP"
  },
  "broker": {
    "status": "UP"
  }
}
```

监视器工作人员使用这些信号来判断服务的健康程度。然后，它将摘要和详细报告一起发送给 Monitor Master。然后，Monitor Master 将拼接全球环的单一窗格视图，并在需要时命令 DR 故障转移。

![](img/e2602b72bc45d880f8b65bf5bb614125.png)

infra metrics example — Elasticsearch in this case

![](img/d7f8cbecde61962cd62e1f7aea138978.png)

business metrics example — API requests and response times

这些允许规则判断一个环是否不健康。

所有的 API 都通过一个基于 GSLB 的负载均衡器。这实现了基于 DNS 的故障切换—应用程序不需要更改它配置的 FQDN，而是将 FQDN 引用的 VIP 更改到故障切换站点。实际上，每次应用程序执行 DNS 查找时，GSLB 系统都会给出服务的虚拟 IP 地址(VIP ),该地址是应用程序上下文(此处的上下文是指国家等)的当前活动/健康集群。

启动灾难恢复故障转移后，监控主机将启动一个工作流，如下所示:

1.  通过将所有流量重定向到临时 503 服务器，停止对故障主环的 API 调用

2.进行数据库故障转移

3.运行协调

4.调整 GSLB 以将 FQDN 指向故障转移环

值得一提的是，并非所有故障都需要灾难恢复。故障转移是有成本的，我们需要有选择地切换开关，如下一节所述。

**应用弹性**

当故障转移被触发时，对后端服务的 API 调用将经历一段时间的不连续。当然，我们已经设计将故障切换时间控制在限制范围内，但在此期间客户体验仍然可能会中断。

为了帮助渡过这一难关，以及其他问题(如不稳定的网络)，这些应用程序具有弹性，因此员工可以在后端中断的情况下继续使用这些应用程序。

所采用的模式描述如下:

![](img/55eda7a53739bda10c83aaeed0141232.png)

app resiliency

基本上使用了以下结构:

*   预取—在启动时获取所有需要的资源(例如图像)
*   本地存储—将详细信息存储在应用永久存储上，以便在应用重新启动/重启时可用
*   后台处理—应用程序和后端之间的协议，它获取本地存储中的数据，并将其与后端同步。这包括识别每个 UI 事务，并在后端将事务的有序列表缝合在一起。

当然，有很多细节被掩盖了——特别是像可靠性、转发、幂等性、应用程序本身被破坏的情况下的业务流程等等。再次担保未来的职位。

**结果— RPO & RTO**

灾难恢复解决方案的两个关键指标是恢复点目标(RPO)和恢复时间目标(RTO)。在任务关键型应用中，两者都非常关键，需要针对不同的使用情况进行不同的调整。

借助上述设计，我们能够展示*即时* RTO 和 RPO。实际工作流需要几分钟才能完成，但由于应用在故障切换期间具有弹性，因此*感知到的* RPO 和 RTO 是即时的！

当然，在现实世界的用例中，一些流将被阻塞，直到后端再次启动。但这种情况非常少，该解决方案允许客户使用该应用程序，即使在后端完全崩溃的情况下。

**成本优化**

上面的设计描述了一种主动-被动架构。远程部署不用于正常操作。上述设计通过启用环的“配对”和允许主动-主动行为，针对成本进行了优化。

每个环都有一个“对”,当发生故障转移时，该对的存储连接到一个幸存环。这描述如下:

![](img/79395e959ccff6cd0faac0426a60a83a.png)

active-active rings

**致谢**

要了解我们的员工对该系统的喜爱程度，请查看我们的员工制作的劲爆说唱歌曲:

♫♫ “tap that app” ♫♫

这项工作是沃尔玛实验室许多工程师合作的结果。主要撰稿人包括(按字母顺序排列)Abiy Hailemichael、Igor Yarkov、Kislaya Tripathi、Nitesh Jain 和 Noah Paci。