<html>
<head>
<title>How Tweets Are Analyzed By Twitter With The Help Of Pig?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter如何在Pig的帮助下分析推文？</h1>
<blockquote>原文：<a href="https://medium.com/edureka/pig-tutorial-2baab2f0a5b0?source=collection_archive---------0-----------------------#2016-11-28">https://medium.com/edureka/pig-tutorial-2baab2f0a5b0?source=collection_archive---------0-----------------------#2016-11-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/adce649569c9de67b8e7a0fdd2618815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*LenVSHd-wyBE73p63xG-zg.png"/></div><figcaption class="il im et er es in io bd b be z dx">Pig Tutorial - Edureka</figcaption></figure><p id="e0a4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">正如我在我的<a class="ae jn" rel="noopener" href="/edureka/hadoop-ecosystem-2a5fb6740177"> <strong class="ir hi"> <em class="jo"> Hadoop生态系统</em> </strong> </a>文章中提到的，Apache Pig是我们Hadoop生态系统中必不可少的一部分。所以，我想带你看一下这个Apache Pig教程，它是我们Hadoop教程系列<strong class="ir hi"> <em class="jo">的一部分。</em> </strong>在这篇阿帕奇猪教程文章中，我将谈到:</p><ul class=""><li id="138f" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">阿帕奇猪vs MapReduce</li><li id="134f" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">阿帕奇猪简介</li><li id="a42c" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">阿帕奇猪用在哪里？</li><li id="dff9" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Twitter案例研究</li><li id="c637" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">阿帕奇猪建筑</li><li id="ab14" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Pig拉丁数据模型</li><li id="eb93" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Apache Pig模式</li></ul><p id="a55d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在开始学习Apache Pig教程之前，我想让您问自己一个问题—“<strong class="ir hi"><em class="jo">虽然MapReduce是为了大数据分析而存在的，但为什么Apache Pig会出现在画面中呢？</em> </strong></p><p id="4d3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对此，甜蜜而简单的回答是:</p><p id="7fd1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="jo">大约10行Pig代码等于200行MapReduce代码</em> </strong>。</p><p id="1b70" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">用Java编写MapReduce作业对每个人来说都不是一件容易的事情。因此，Apache Pig成为不擅长Java或Python的程序员的福音。即使有人懂Java并且擅长MapReduce，他们也会更喜欢Apache Pig，因为使用Pig很容易。现在让我们来看看。</p><h1 id="2625" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">阿帕奇猪vs MapReduce</h1><p id="eb41" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">程序员在编写MapReduce任务时面临困难，因为它需要Java或Python编程知识。对他们来说，阿帕奇猪是救星。</p><ul class=""><li id="d005" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">Pig Latin是一种高级数据流语言，而MapReduce是一种低级数据处理范式。</li><li id="91c9" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">不用在MapReduce中编写复杂的Java实现，程序员可以使用Pig Latin非常容易地实现相同的实现。</li><li id="b3a8" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Apache Pig使用多查询方法(即使用Pig Latin的单个查询我们可以完成多个MapReduce任务)，这将代码长度减少了20倍。因此，这将开发周期缩短了近16倍。</li><li id="c123" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Pig提供了许多内置的操作符来支持数据操作，如连接、过滤、排序、分类等。而在MapReduce中执行相同的功能是一项巨大的任务。</li><li id="4d38" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">在Apache Pig中执行连接操作很简单。而在MapReduce中很难执行数据集之间的连接操作，因为它需要顺序执行多个MapReduce任务来完成工作。</li><li id="5654" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">此外，它还提供了MapReduce中没有的嵌套数据类型，如元组、包和地图。一会儿我会给你解释这些数据类型。</li></ul><p id="5a4e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们知道了为什么阿帕奇猪会出现，你会很好奇什么是阿帕奇猪？让我们在本文中继续前进，浏览Apache Pig的介绍和特性。</p><h1 id="b16d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">阿帕奇猪简介</h1><p id="0157" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">Apache Pig是一个平台，用于分析将它们表示为数据流的大型数据集。它旨在提供MapReduce的抽象，降低编写MapReduce程序的复杂性。我们可以使用Apache Pig在Hadoop中非常容易地执行数据操纵操作。</p><p id="e91f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">阿帕奇猪的特点是:</p><ul class=""><li id="dc9a" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">Pig使程序员能够在不了解Java的情况下编写复杂的数据转换。</li><li id="8e83" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Apache Pig有两个主要组件——<strong class="ir hi"><em class="jo">Pig拉丁语言</em> </strong>和<strong class="ir hi"> <em class="jo"> Pig运行时环境</em> </strong> <em class="jo">，</em>，Pig拉丁程序在其中执行。</li><li id="4923" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">对于大数据分析，Pig给出了一个简单的数据流语言，称为<strong class="ir hi"> <em class="jo"> Pig Latin </em> </strong>，它具有类似于SQL的功能，如连接、过滤、限制等。</li><li id="fdbc" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">使用脚本语言和SQL的开发人员利用了猪拉丁语。这使得开发人员<strong class="ir hi"> <em class="jo">很容易用Apache Pig进行</em> </strong>编程。Pig Latin提供了各种内置的操作符，如join、sort、filter等，用于读取、写入和处理大型数据集。由此可见，猪头有一套<strong class="ir hi"> <em class="jo">富套符</em> </strong>。</li><li id="a9fd" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">程序员使用Pig Latin编写脚本来分析数据，这些脚本由Pig MapReduce引擎在内部转换为Map和Reduce任务。在Pig之前，编写MapReduce任务是处理存储在HDFS的数据的唯一方法。</li><li id="7809" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">如果程序员想编写Pig中没有的自定义函数，Pig允许他们用自己选择的任何语言编写用户定义的函数(<strong class="ir hi"><em class="jo">【UDF】</em></strong>)，如Java、Python、Ruby、Jython、JRuby等。并把它们嵌入到猪文字中。这就给阿帕奇猪提供了<strong class="ir hi"><em class="jo"/></strong><em class="jo"/>的扩展性。</li><li id="3d1b" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Pig可以处理任何类型的数据，即来自不同来源的结构化、半结构化或非结构化数据。阿帕奇猪<strong class="ir hi"> <em class="jo">处理各种数据</em> </strong>。</li><li id="21aa" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">大约，10行pig代码等于200行MapReduce代码。</li><li id="61c3" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">它可以处理不一致的模式(对于非结构化数据)。</li><li id="6f69" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Apache Pig提取数据，对数据执行操作，并以所需格式将数据转储到<strong class="ir hi"><em class="jo"/></strong>HDFS中，即<strong class="ir hi"> ETL(提取转换负载)</strong>。</li><li id="24e6" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Apache Pig在执行前自动优化任务，即<strong class="ir hi"> <em class="jo">自动优化</em> </strong>。</li><li id="1d78" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">它允许程序员和开发人员专注于整个操作，而不用分别创建映射器和缩减器函数。</li></ul><p id="6afe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在了解了什么是Apache Pig之后，现在让我们了解一下在哪里可以使用Apache Pig，最适合Apache Pig的用例有哪些？</p><h1 id="387b" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">阿帕奇猪用在哪里？</h1><p id="7a4d" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">Apache Pig用于分析和执行涉及特定处理的任务。使用阿帕奇猪:</p><ul class=""><li id="8ae1" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">在我们需要处理的地方，像我们的博客，在线数据流等巨大的数据集。</li><li id="ca21" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">我们需要搜索平台的数据处理(需要处理不同类型的数据)，如<strong class="ir hi"> <em class="jo">雅虎使用Pig完成40%的工作，包括新闻提要和搜索引擎</em> </strong>。</li><li id="c614" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">我们需要处理时间敏感的数据负载。在这里，需要快速提取和分析数据。例如，机器学习算法需要时间敏感的数据负载，如twitter，需要快速提取客户活动的数据(即推文、转发推文和喜欢)，并分析数据以发现客户行为的模式，并像趋势推文一样立即提出建议。</li></ul><p id="614b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，在我们的Apache Pig教程中，让我们浏览一下<strong class="ir hi"> Twitter案例研究</strong>，以更好地了解Apache Pig如何帮助分析数据并使业务理解变得更容易。</p><h1 id="046b" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">Twitter案例研究</h1><p id="ef14" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">我将带你看一个Twitter的案例，在这个案例中，Twitter采用了Apache Pig。</p><p id="c1ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Twitter的数据正在加速增长(即10 TB数据/天)。因此，Twitter决定将存档数据转移到HDFS，并采用Hadoop来从中提取商业价值。</p><p id="809b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">他们的主要目标是分析存储在Hadoop中的数据，以得出以下每日、每周或每月的见解。</p><h2 id="cc06" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">计数操作:</h2><ul class=""><li id="75b8" class="jp jq hh ir b is lb iw lc ja lu je lv ji lw jm ju jv jw jx bi translated">twitter一天服务多少请求？</li><li id="ac1c" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">请求的平均延迟是多少？</li><li id="eefa" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">Twitter上每天有多少搜索？</li><li id="be54" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">收到多少个独特的查询？</li><li id="a5ec" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">有多少独立用户来访问？</li><li id="5dca" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">用户的地理分布如何？</li></ul><h2 id="b280" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">关联大数据:</h2><ul class=""><li id="ee83" class="jp jq hh ir b is lb iw lc ja lu je lv ji lw jm ju jv jw jx bi translated">移动用户的使用有何不同？</li><li id="2d64" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">群组分析:根据用户的行为，通过对用户进行分类来分析数据。</li><li id="9ad9" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">当站点出现问题时，哪里出错了？</li><li id="2bf1" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">用户经常使用哪些功能？</li><li id="549e" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">搜索更正和搜索建议。</li></ul><h2 id="fe31" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">研究大数据并产生更好的结果，如:</h2><ul class=""><li id="4a32" class="jp jq hh ir b is lb iw lc ja lu je lv ji lw jm ju jv jw jx bi translated">Twitter可以从用户的推文中分析出什么信息？</li><li id="9afb" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">谁跟随谁，在什么基础上？</li><li id="a4cf" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">跟随者与跟随者的比例是多少？</li><li id="ebfd" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">用户口碑如何？</li></ul><p id="b24d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">还有更多……</strong></p><p id="7184" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以，为了分析数据，Twitter最初使用MapReduce，这是一种基于HDFS的并行计算(即Hadoop分布式文件系统)。</p><p id="44b2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">例如，他们想分析在给定的tweet表中每个用户存储了多少tweet？</p><p id="d277" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用MapReduce，该问题将依次得到解决，如下图所示:</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/1d04196ecd70acaf864142d0bf673a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CWDs23M5zP1mVgXvsFsyVQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Twitter MapReduce Example - Pig Tutorial</figcaption></figure><p id="edec" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">MapReduce程序首先将键作为行输入，并将tweet表信息发送给mapper函数。然后，映射器功能将选择用户id并将单位值(即1)与每个用户id相关联。Shuffle函数会将相同的用户id排序在一起。最后，Reduce函数会将属于同一用户的所有tweets的数量加在一起。输出将是用户id，结合用户名和每个用户的tweets数量。</p><p id="8e98" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是在使用MapReduce时，他们面临一些限制:</p><ul class=""><li id="a1d4" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">分析通常需要用Java来完成。</li><li id="5c65" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">执行的连接需要用Java编写，这使得它更长并且更容易出错。</li><li id="bbc5" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">对于投影和过滤器，需要编写自定义代码，这使得整个过程变慢。</li><li id="56f3" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">使用MapReduce时，作业被分成许多阶段，这使得管理起来很困难。</li></ul><p id="2a8d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">于是，Twitter转移到阿帕奇猪进行分析。现在，连接数据集、分组、排序和检索数据变得越来越简单。你可以在下图中看到twitter如何使用Apache Pig来分析他们的大型数据集。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mg"><img src="../Images/99136defabcd2139bd512cdfcb683809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*jRSac5lEZhsZxCkrswuqTA.gif"/></div></div></figure><p id="bfe8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Twitter既有半结构化数据，如Twitter Apache日志、Twitter搜索日志、Twitter MySQL查询日志、应用程序日志，也有结构化数据，如推文、用户、阻止通知、电话、收藏夹、保存的搜索、转发推文、认证、短信使用、用户关注等。这很容易被阿帕奇猪处理。</p><p id="5341" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Twitter将其所有存档数据都转储到HDFS。它有两个表格，即用户数据和推文数据。用户数据包含关于用户的信息，如用户名，追随者，追随者，推文数量等。而tweet数据包含Tweet、其所有者、转发次数、点赞次数等。现在，Twitter使用这些数据来分析他们客户的行为，并改善他们过去的体验。</p><p id="4f60" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将看到Apache Pig如何解决MapReduce所解决的相同问题:</p><p id="8713" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">问题</strong> : <strong class="ir hi"> <em class="jo">在给定的tweet表中，分析每个用户存储了多少tweet？</em> </strong></p><p id="4f20" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下图显示了Apache Pig解决问题的方法:</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/56f6faba7eaaf3e0ca7b01ebf50032fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQw4CV7OtV_vhqVzy-dqzA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Twitter Solution - Pig Tutorial</figcaption></figure><p id="9b37" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上图显示了这个问题的逐步解决方案。</p><blockquote class="mh mi mj"><p id="69e2" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">1</strong>–首先，twitter将twitter表(即用户表和tweet表)导入HDFS。</p><p id="a5fb" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">2</strong>–然后Apache Pig将表加载(<strong class="ir hi"> LOAD </strong>)到Apache Pig框架中。</p><p id="1147" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">3</strong>–然后使用<strong class="ir hi"> COGROUP </strong>命令将tweet表和用户表连接并分组，如上图所示。</p><p id="6f6b" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">这导致了内袋数据类型，我们将在本文后面讨论。</p><p id="720f" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">生产的内袋示例(参考上图)–</p><p id="ec76" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(1，<strong class="ir hi"> {(1，Jay，xyz)，(1，Jay，pqr)，(1，Jay，lmn)} </strong>)</p><p id="2ced" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(2，<strong class="ir hi"> {(2，艾莉，abc)，(2，艾莉，vxy)} </strong>)</p><p id="6605" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(3，<strong class="ir hi"> {(3，山姆，斯图)} </strong>)</p><p id="e890" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">4</strong>–然后根据使用<strong class="ir hi">计数</strong>命令的用户对推文进行计数。因此，每个用户的推文总数可以很容易地计算出来。</p><p id="8c21" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">产生的元组示例为(id，tweet count)(参考上图)–</p><p id="98e3" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(1、<strong class="ir hi"> 3 </strong>)</p><p id="8fbd" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(2，<strong class="ir hi"> 2 </strong></p><p id="5c82" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(3、<strong class="ir hi"> 1 </strong></p><p id="7801" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">5</strong>–最后将结果与用户表连接，提取出产生结果的用户名。</p><p id="8a38" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">产生的元组示例为(id，name，tweet count)(参考上图)–</p><p id="dba3" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(1、<strong class="ir hi">杰、</strong> 3)</p><p id="85e7" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(2，<strong class="ir hi">艾莉，</strong> 2)</p><p id="a0ac" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">(3，<strong class="ir hi">山姆</strong>，1)</p><p id="b867" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi">步骤</strong><strong class="ir hi">6</strong>–最后，这个结果被存储回HDFS。</p></blockquote><p id="5512" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Pig不仅仅限于此操作。它可以执行我之前在这个用例中提到的各种其他操作。</p><p id="cac1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些见解有助于Twitter进行情感分析，并基于用户行为和模式开发机器学习算法。</p><p id="b536" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，在了解了Twitter案例研究之后，在这篇Apache Pig教程中，让我们深入了解一下Apache Pig和Pig Latin的数据模型的架构。这将有助于我们了解pig的内部工作原理。阿帕奇猪从它的建筑中汲取力量。</p><h1 id="ac8b" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">体系结构</h1><p id="1f94" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">为了编写Pig脚本，我们需要Pig拉丁语，为了执行它们，我们需要一个执行环境。Apache Pig的架构如下图所示。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/744ead1e58d834e01e56daf123c3759f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_nAICigi-yOQ6L3Qercfg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Architecture of Pig - Pig Tutorial</figcaption></figure><h2 id="a2f0" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">猪拉丁文字</h2><p id="8166" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">最初如上图所示，我们向Apache Pig执行环境提交Pig脚本，可以使用内置操作符用Pig拉丁语编写。</p><p id="4f34" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有三种方法可以执行Pig脚本:</p><blockquote class="mh mi mj"><p id="8577" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh"> Grunt Shell </em> : </strong>这是为执行所有Pig脚本而提供的Pig交互Shell。</p><p id="40f5" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh">脚本文件</em> : </strong>将所有Pig命令写入一个脚本文件，并执行Pig脚本文件。这是由Pig服务器执行的。</p><p id="56a4" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh">嵌入式脚本</em> : </strong>如果一些函数在内置操作符中不可用，我们可以通过编程创建用户定义的函数，使用其他语言如Java、Python、Ruby等来实现这些功能。并嵌入猪拉丁脚本文件<strong class="ir hi">。</strong>然后，执行脚本文件。</p></blockquote><h2 id="02c2" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">句法分析程序</h2><p id="df65" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">从上图可以看到，在通过Grunt或Pig服务器后，Pig脚本被传递给解析器。解析器进行类型检查并检查脚本的语法。解析器输出DAG(有向无环图)。DAG表示Pig拉丁语句和逻辑运算符。逻辑运算符表示为节点，数据流表示为边。</p><h2 id="15dc" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">【计算机】优化程序</h2><p id="18fb" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">然后DAG被提交给优化器。优化器执行优化活动，如拆分、合并、转换和重新排序操作符等。这个优化器为Apache Pig提供了自动优化功能。优化器的基本目标是在处理提取的数据时减少管道中任何时刻的数据量，为此，它执行以下功能:</p><ul class=""><li id="3d2f" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated"><strong class="ir hi"> <em class="jo">上推过滤器</em> : </strong>如果过滤器中有多个条件，且过滤器可以拆分，Pig拆分条件，分别上推每个条件。尽早选择这些条件有助于减少管道中剩余的记录数量。</li><li id="3f01" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated"><strong class="ir hi"><em class="jo">PushDownForEachFlatten</em>:</strong>在计划中尽可能晚地应用flattens，这将在复杂类型(如tuple或bag)和记录中的其他字段之间产生叉积。这使得管道中的记录数量很少。</li><li id="3888" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated"><strong class="ir hi"> <em class="jo"> ColumnPruner </em> : </strong>省略从不使用或不再需要的列，减小记录的大小。这可以在每个操作符之后应用，以便可以尽可能积极地修剪字段。</li><li id="bdee" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated"><strong class="ir hi"><em class="jo">MapKeyPruner</em>:</strong>省略从不使用的映射键，减小记录的大小。</li><li id="2e6c" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated"><strong class="ir hi"><em class="jo">limit optimizer</em>:</strong>如果在加载或排序操作符之后立即应用limit操作符，Pig会将加载或排序操作符转换为对限制敏感的实现，这不需要处理整个数据集。较早应用限制会减少记录的数量。</li></ul><p id="4458" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这只是优化过程的一部分。此外，它还通过执行<strong class="ir hi">加入</strong>、<strong class="ir hi">命令，通过</strong>功能执行<strong class="ir hi">分组。</strong></p><p id="48f9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要关机，自动优化，可以执行这个命令:</p><pre class="ly lz ma mb fd mn mo mp mq aw mr bi"><span id="87bf" class="lg ke hh mo b fi ms mt l mu mv">pig -optimizer_off [opt_rule | all ]</span></pre><h2 id="0710" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">编译程序</h2><p id="4264" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">在优化过程之后，编译器将优化后的代码编译成一系列MapReduce作业。编译器负责将Pig作业自动转换为MapReduce作业。</p><h2 id="0269" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">执行引擎</h2><p id="aa78" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">最后，如图所示，这些MapReduce作业被提交给执行引擎执行。然后执行MapReduce作业并给出所需的结果。使用“<strong class="ir hi"> DUMP </strong>”语句可将结果显示在屏幕上，并使用“<strong class="ir hi"> STORE </strong>”语句可将结果存储在HDFS中。</p><p id="0811" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在理解了架构之后，现在在这个Apache Pig教程中，我将向您解释Pig Latins的数据模型。</p><h1 id="874d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">Pig拉丁数据模型</h1><p id="6c22" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">Pig Latin的数据模型使Pig能够处理所有类型的数据。Pig Latin可以处理两种原子数据类型，如int、float、long、double等。以及复杂的数据类型，如tuple、bag和map。我将单独解释它们。下图显示了数据类型及其相应的类，我们可以使用这些类来实现它们:</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/54948ed7840dc436df1fbbd8add6928e.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*YhCtHcZTfvWhhb2SNDZdHw.png"/></div><figcaption class="il im et er es in io bd b be z dx">Pig Data Types - Pig Tutorial</figcaption></figure><h2 id="38c1" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">原子/标量数据类型</h2><p id="0be4" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">原子或标量数据类型是所有语言中使用的基本数据类型，如string、int、float、long、double、char[]、byte[]。这些也被称为原始数据类型。字段(列)中每个单元格的值都是原子数据类型，如下图所示。</p><p id="d578" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于字段，位置索引由系统自动生成(也称为<strong class="ir hi">位置符号</strong>)，用' $ '表示，从$0开始，增长$1，$2，依此类推…与下图相比，$0 =序号，$1 =波段，$2 =成员，$3 =原点。</p><p id="8161" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">标量数据类型有“1”、“Linkin Park”、“7”、“California”等。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/60c290c83b2bba90cde552e917e8a3a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WMG6FycY3SV3o-APG5Q_CA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Pig Latin Data Model - Pig Tutorial</figcaption></figure><p id="c738" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们将讨论猪拉丁语中的<strong class="ir hi"> <em class="jo">复杂数据类型</em> </strong>即Tuple、Bag和Map。</p><h2 id="8ae9" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">元组</h2><p id="7119" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">元组是一组有序的字段，每个字段可以包含不同的数据类型。您可以将它理解为存储在关系数据库的一行中的记录。一个元组是一行中的一组单元格，如上图所示。元组中的元素不一定需要附加模式。</p><p id="acc7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">元组由“()”符号表示。</p><p id="604c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">元组示例(加利福尼亚州林肯公园7号1号)</p><p id="47ee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于元组是有序的，我们可以使用字段的索引来访问每个元组中的字段，比如元组上面的$1 form将返回值‘Linkin Park’。您可以注意到，上面的元组没有附加任何模式。</p><h2 id="1ce3" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">包</h2><p id="0f2b" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">包是一组元组的集合，这些元组是表的行的子集或整行。一个包可以包含重复的元组，并且不强制要求它们必须是唯一的。</p><p id="2eaf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该包具有灵活的模式，即包内的元组可以具有不同数量的字段。一个包也可以有不同数据类型的元组。</p><p id="31d9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个包用“{}”符号表示。</p><p id="9109" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一个包的例子<strong class="ir hi"> {(加州林肯公园7号)，(金属乐队8号)，(洛杉矶超级死亡)} </strong></p><p id="45dd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是为了让Apache Pig有效地处理包，这些字段和它们各自的数据类型需要处于相同的序列中。</p><p id="165e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一套包</p><p id="b5fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> {(林肯公园，7，加州)，(金属乐队，8)，(超级死亡，洛杉矶)}，</strong></p><p id="f7c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> {(金属乐队，8岁，洛杉矶)，(超级死神，8岁)，(林肯公园，加州)} </strong></p><p id="c810" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">袋子有两种类型，即<strong class="ir hi">外袋</strong>或关系袋和<strong class="ir hi">内袋。</strong></p><p id="8db8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">外部包或关系只不过是一个元组包。这里的关系类似于关系数据库中的关系。为了更好地理解它，让我们举一个例子:</p><p id="12be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> {(加州林肯公园)，(洛杉矶金属乐队)，(洛杉矶超级死亡)} </strong></p><p id="09de" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面的袋子解释了<em class="jo">乐队</em>和他们的原产地<em class="jo">T21的关系。</em></p><p id="7453" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">另一方面，内包包含元组内的包。例如，如果我们根据<em class="jo">条带的来源</em>对<em class="jo">条带</em>元组进行排序，我们将得到:</p><p id="1ae3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">(洛杉矶，<strong class="ir hi"> {(金属乐队，洛杉矶)，(超级死神，洛杉矶)} </strong>)</p><p id="0af7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">(加州，<strong class="ir hi"> {(加州林肯公园)} </strong>)</p><p id="0635" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里，第一个字段类型是字符串，而第二个字段类型是包，它是元组中的内部包。</p><h2 id="8e30" class="lg ke hh bd kf lh li lj kj lk ll lm kn ja ln lo kr je lp lq kv ji lr ls kz lt bi translated">地图</h2><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/d7c72e1035b3877c4a273a03401df44e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HMIFRty2VzcNG-nAD9XmpA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx">Map Example - Pig Tutorial</figcaption></figure><p id="ae29" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">映射是用于表示数据元素的键值对。该键必须是一个char数组[]，并且应该像列名一样是唯一的，这样就可以对其进行索引，并且可以根据键来访问与其相关联的值。该值可以是任何数据类型。</p><p id="e39a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">地图由“[]”符号表示，键值由“#”符号分隔，如上图所示。</p><p id="a0fa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">地图示例-[乐队#Linkin Park，成员#7 ]，[乐队#Metallica，成员#8 ]</p><p id="d6e4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们学习了Pig Latin的数据模型。我们将理解Apache Pig如何处理模式以及如何处理无模式数据。</p><h1 id="6390" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">(计划或理论的)纲要</h1><p id="4b57" class="pw-post-body-paragraph ip iq hh ir b is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji lf jk jl jm ha bi translated">Schema为字段指定一个名称，并声明字段的数据类型。该模式在Pig Latin中是可选的，但是Pig鼓励您尽可能使用它们，因为在解析脚本时，错误检查变得有效，从而导致程序的有效执行。模式可以声明为简单和复杂数据类型。在LOAD function过程中，如果声明了模式，它也会附加到数据上。</p><p id="dfd1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Pig中关于图式的几点:</p><ul class=""><li id="d457" class="jp jq hh ir b is it iw ix ja jr je js ji jt jm ju jv jw jx bi translated">如果模式只包含字段名称，则字段的数据类型被视为字节数组。</li><li id="de8d" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">如果为字段指定了名称，则可以通过字段名和位置符号来访问该字段。而如果缺少字段名，我们只能通过位置符号来访问它，即$后跟索引号。</li><li id="6666" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">如果您执行任何关系组合的操作(如JOIN、COGROUP等)。)并且如果任何关系缺少模式，则产生的关系将具有空模式。</li><li id="c228" class="jp jq hh ir b is jy iw jz ja ka je kb ji kc jm ju jv jw jx bi translated">如果模式为空，Pig会将其视为一个字节数组，字段的实际数据类型将动态确定。</li></ul><p id="fa4b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我希望这篇Apache Pig教程文章内容丰富，并且您喜欢它。在本文中，您了解了Apache Pig的基础知识、它的数据模型和它的架构。Twitter案例研究可以帮助你更好地沟通。</p><p id="4772" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">到此，我们结束这篇关于猪的文章。</p><p id="1b18" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、Python、道德黑客等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="ac4f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中解释大数据其他各方面的其他文章。</p><blockquote class="mh mi mj"><p id="1d1d" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">1.<a class="ae jn" rel="noopener" href="/edureka/hadoop-tutorial-24c48fbf62f6"> Hadoop教程</a></p><p id="b15f" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">2.<a class="ae jn" rel="noopener" href="/edureka/hive-tutorial-b980dfaae765">蜂巢教程</a></p><p id="f956" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">3.<a class="ae jn" rel="noopener" href="/edureka/big-data-tutorial-b664da0bb0c8">大数据教程</a></p><p id="cf6f" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">4.<a class="ae jn" rel="noopener" href="/edureka/mapreduce-tutorial-3d9535ddbe7c">地图缩小教程</a></p><p id="1b65" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">5.<a class="ae jn" rel="noopener" href="/edureka/hbase-tutorial-bdc36ab32dc0"> HBase教程</a></p><p id="2303" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">6.<a class="ae jn" rel="noopener" href="/edureka/hdfs-tutorial-f8c4af1c8fde"> HDFS教程</a></p><p id="14cb" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">7.<a class="ae jn" rel="noopener" href="/edureka/hadoop-3-35e7fec607a"> Hadoop 3 </a></p><p id="041e" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">8.<a class="ae jn" rel="noopener" href="/edureka/apache-sqoop-tutorial-431ed0af69ee"> Sqoop教程</a></p><p id="394d" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">9.<a class="ae jn" rel="noopener" href="/edureka/apache-flume-tutorial-6f7150210c76">水槽教程</a></p><p id="dc89" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">10.<a class="ae jn" rel="noopener" href="/edureka/apache-oozie-tutorial-d8f7bbbe1591"> Oozie教程</a></p><p id="6c56" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">11.<a class="ae jn" rel="noopener" href="/edureka/hadoop-ecosystem-2a5fb6740177"> Hadoop生态系统</a></p><p id="3b1c" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">12.<a class="ae jn" rel="noopener" href="/edureka/hive-commands-b70045a5693a">HQL顶级配置单元命令及示例</a></p><p id="cb93" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">13.<a class="ae jn" rel="noopener" href="/edureka/create-hadoop-cluster-with-amazon-emr-f4ce8de30fd"> Hadoop集群搭配亚马逊EMR？</a></p><p id="b655" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">14.<a class="ae jn" rel="noopener" href="/edureka/big-data-engineer-resume-7bc165fc8d9d">大数据工程师简历</a></p><p id="f518" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">15.<a class="ae jn" rel="noopener" href="/edureka/hadoop-developer-cc3afc54962c"> Hadoop开发人员-工作趋势和薪水</a></p><p id="f6d8" class="ip iq jo ir b is it iu iv iw ix iy iz mk jb jc jd ml jf jg jh mm jj jk jl jm ha bi translated">16.<a class="ae jn" rel="noopener" href="/edureka/hadoop-interview-questions-55b8e547dd5c"> Hadoop面试问题</a></p></blockquote></div><div class="ab cl mx my go mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ha hb hc hd he"><p id="0dd5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="jo">原载于2016年11月28日www.edureka.co</em><em class="jo">T21</em><a class="ae jn" href="https://www.edureka.co/blog/pig-tutorial/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>