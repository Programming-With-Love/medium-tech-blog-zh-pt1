<html>
<head>
<title>Lessons from AlphaZero (part 3): Parameter Tweaking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AlphaZero的经验(第3部分):参数调整</h1>
<blockquote>原文：<a href="https://medium.com/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5?source=collection_archive---------0-----------------------#2018-06-20">https://medium.com/oracledevs/lessons-from-alphazero-part-3-parameter-tweaking-4dceb78ed1e5?source=collection_archive---------0-----------------------#2018-06-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/ebab5ce5f30a4713e802ccbfd8651b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*j_f2mRcrE05RNwNoK6uHtw.png"/></div></figure><p id="641e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是一系列讨论我们如何以有趣的方式复制和扩展DeepMind的AlphaZero算法的第三部分。 <a class="ae jk" rel="noopener" href="/oracledevs/lessons-from-implementing-alphazero-7e36e9054191"> <em class="jj">你可以在这里找到第一部分</em> </a> <em class="jj">。</em></p><p id="6c32" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">又见面了！在本周的文章中，我们将分享一些关于调整AlphaZero(超级)参数的想法。这些参数不是在训练期间学习的(像网络权重)，而是预先固定的。通过选择好的价值观，训练可能会进行得更快或更好。</p><p id="120f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这些参数中有许多会影响所谓的探索-利用权衡:算法需要在利用其现有知识和探索新的可能性之间进行平衡。当训练AlphaZero与高技能对手比赛时(如论文中所述)，探索很重要，但当训练它在更广泛的位置上发挥出色时，探索更重要。正如<a class="ae jk" rel="noopener" href="/oracledevs/lessons-from-alphazero-connect-four-e4a0ae82af68">上一篇文章</a>所述，我们的测试集包括不完美的游戏。因此，我们花了一些时间来调整我们的实现，以充分广泛地探索不仅是一个好的<em class="jj">最佳</em>玩家，而且是一个好的<em class="jj">一般</em>玩家。</p><h1 id="2dd7" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">AlphaZero中的超参数</h1><p id="4ed9" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">让我们来看看我们可能想要优化的一些超参数。在这里，我们将只看一眼他们是什么和做什么。</p><h2 id="8e97" class="ko jm hh bd jn kp kq kr jr ks kt ku jv iw kv kw jz ja kx ky kd je kz la kh lb bi translated">c_puct</h2><p id="07b9" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">在蒙特卡罗树搜索(MCTS)模拟过程中，该算法根据预期的游戏结果和已经探索的程度来评估潜在的下一步棋。常数<em class="jj"> c </em>用于控制这种折衷。</p><p id="eee5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">标准MCTS使用<a class="ae jk" href="https://jeremykun.com/2013/10/28/optimism-in-the-face-of-uncertainty-the-ucb1-algorithm/" rel="noopener ugc nofollow" target="_blank">置信上限-1 (UCB-1) </a>公式的一个变体，称为<a class="ae jk" href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search#Exploration_and_exploitation" rel="noopener ugc nofollow" target="_blank"> UCT(树木的UCB)</a>。AlphaZero使用了一个名为多项式上置信树(PUCT)的版本。如果我们处于状态<strong class="in hi"> s </strong>并考虑动作<strong class="in hi"> a </strong>，我们需要三个值来计算PUCT(s，a):</p><ul class=""><li id="8f87" class="lc ld hh in b io ip is it iw le ja lf je lg ji lh li lj lk bi translated"><strong class="in hi"> Q </strong> —平均动作值。这是采取行动<strong class="in hi">和</strong>的当前模拟的平均游戏结果。</li><li id="63fd" class="lc ld hh in b io ll is lm iw ln ja lo je lp ji lh li lj lk bi translated"><strong class="in hi"> P </strong> —从网络中获取的<em class="jj">先验概率</em>。</li><li id="16b9" class="lc ld hh in b io ll is lm iw ln ja lo je lp ji lh li lj lk bi translated"><strong class="in hi">N</strong>—<em class="jj">访问计数</em>，即我们在当前模拟过程中采取此操作的次数。</li></ul><p id="464a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们计算<strong class="in hi"> PUCT(s，a) = Q(s，a) </strong> + <strong class="in hi"> U(s，a) </strong>，其中<strong class="in hi"> U </strong>计算如下:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/c5266a0068ba61523efe6b96cfa6487d.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*zSpn7Evr-9UGdfsmZBWiEQ.png"/></div></figure><p id="19a3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意我们是如何在分子中对所有潜在的操作(<strong class="in hi"> b </strong>)求和的，分母中是正在考虑的操作(<strong class="in hi"> a </strong>)的访问次数。因此，少了<em class="jj">就少了</em>这个动作，多了<em class="jj"/><strong class="in hi">就多了</strong>。这鼓励探索。</p><p id="9cac" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通过增加<em class="jj"> c_puct </em>，我们将更多的权重放在这个探索项上。通过减少它，我们更加重视利用预期结果(<strong class="in hi"> Q </strong>)。</p><p id="6bba" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在尝试了一些值(从1到6)之后，我们发现大约4 是最佳的。</p><h2 id="9847" class="ko jm hh bd jn kp kq kr jr ks kt ku jv iw kv kw jz ja kx ky kd je kz la kh lb bi translated">狄利克雷(阿尔法)</h2><p id="502f" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">AlphaZero的一项创新是将噪音引入MCTS。</p><p id="e0f2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在MCTS模拟期间，我们从代表当前棋盘状态的根节点(<strong class="in hi"> s </strong>)重复模拟游戏。我们做的第一件事是向神经网络查询来自<strong class="in hi"> s </strong>的潜在动作的<em class="jj">先验概率</em>向量(<strong class="in hi"> p </strong>)。</p><p id="f3b2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">AlphaZero没有按原样使用<strong class="in hi"> p </strong>，而是根据<a class="ae jk" href="https://en.wikipedia.org/wiki/Dirichlet_distribution" rel="noopener ugc nofollow" target="_blank">狄利克雷分布</a>用参数ɑ，aka Dir(ɑ)添加噪声。为了帮助理解这意味着什么，让我们看一些具有不同ɑ的狄利克雷分布的例子。对于这些例子，我们假设有<strong class="in hi"> n </strong>个潜在的下一步行动。</p><p id="a98a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">首先回想一下狄利克雷的<em class="jj">支集</em>(即定义它的地方的值)是坐标非负且和为1的向量(x_1，x_2，…，x_n)的集合。如果n=3，那么一些例子将是(0.1，0.5，0.4)和(0.3，0，0.7)。这个集合也被称为(n维)单形。</p><p id="0826" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在注意Dir(1)是一致的。这意味着从其采样将产生上述两个向量(或任何其他有效向量)的机会均等。随着ɑ变小，狄利克雷开始偏好基向量附近的向量:(0.98，0.01，0.01)或者(0.1，0.9，0)会比(0.3，0.3，0.4)更容易被画出来。对于大于1的值，情况正好相反——基础向量被<em class="jj"> de </em>强调，更平衡的向量是首选。</p><p id="811a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了给<strong class="in hi"> p </strong>添加噪声，我们从Dir(ɑ)中采样一个值<strong class="in hi"> d </strong>，取一个加权和:x* <strong class="in hi"> p </strong> + (1-x)* <strong class="in hi"> d </strong>。因为<strong class="in hi"> p </strong>和<strong class="in hi"> d </strong>的坐标总和为1(并且权重<em class="jj"> x </em>和<em class="jj"> 1-x </em>总和为1)，所以该属性保留在加权总和中，使其成为有效的概率分布。在本文中，<em class="jj"> x </em>设定为0.75。下面我们就用<em class="jj"> x </em> =0.5来夸大<strong class="in hi"> d </strong>的效果。</p><p id="55af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当ɑ大于1时，这往往会“拉平”<strong class="in hi"> p </strong>，使我们不那么强烈地偏好任何一步棋:</p><div class="lr ls lt lu fd ab cb"><figure class="lv ii lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><img src="../Images/357968ba0edfe13f882e935898974be5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*RqY2dQcnPtjRFCTtx9uQPA.png"/></div></figure><figure class="lv ii mf lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><img src="../Images/71e32099c6f82164e0884c00c64bef66.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*JYUhNLqk4pYyZGB0juDuVQ.png"/></div></figure><figure class="lv ii mg lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><img src="../Images/949f6be2316bfbce92d89303befb9201.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*3a3nTAgwSgjI9eJgEaKfcQ.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx ml di mm mn">Dir(20) tends to <strong class="bd jn"><em class="mo">flatten</em></strong><em class="mo"> the weighted sum</em></figcaption></figure></div><p id="d3d4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对于\u\u&lt;1, it will cause a random component to become more emphasized:</p><div class="lr ls lt lu fd ab cb"><figure class="lv ii mp lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><img src="../Images/357968ba0edfe13f882e935898974be5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*RqY2dQcnPtjRFCTtx9uQPA.png"/></div></figure><figure class="lv ii lw lx ly lz ma paragraph-image"><img src="../Images/d1ab86c6e3ee6703d266b100dafbe34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*P46isA4x1X04HsOFolqmwQ.png"/></figure><figure class="lv ii mq lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><img src="../Images/4a884254117bb9b5dbe8e741ead0a7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*BeBmngEKgAyVOft4qGgsSA.png"/></div><figcaption class="mh mi et er es mj mk bd b be z dx mr di ms mn">Dir(0.8) tends to <strong class="bd jn">exaggerate</strong> (a random component of) the weighted sum</figcaption></figure></div><p id="e121" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">In both cases, we are encouraged to explore away from our prior (which strongly preferred the middle move).</p><p id="861b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">To pick a value, we first looked at the values they used for chess, shogi, and Go: 0.3, 0.15, and 0.03. The <a class="ae jk" href="https://en.wikipedia.org/wiki/Game_complexity" rel="noopener ugc nofollow" target="_blank">来说，这些游戏中合法移动的平均次数分别为35、92和250次。很难知道如何进行最佳外推，但合理的第一个猜测似乎是选择\593; = 10/n。由于在“连四”位置大约有四个合法移动，因此我们得到\593; = 2.5。确实，这个数大于1，而其他的都小于1，但是这个数在我们的测试中表现不错。稍微摆弄一下，我们发现<strong class="in hi"> 1.75 </strong>做得更好。</a></p><p id="93fe" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">更新:虽然我们训练的早期版本在a=1.75时表现最佳，但我们最终决定将a=1.0作为我们训练的最佳值。</strong></p><p id="f130" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">更多的研究(和计算时间)将有助于获得更多的洞察力。</p><h2 id="29bf" class="ko jm hh bd jn kp kq kr jr ks kt ku jv iw kv kw jz ja kx ky kd je kz la kh lb bi translated">温度，τ(τ)</h2><p id="a9ce" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">在MCTS完成一轮模拟之后，在它选择要走的一步棋之前，它已经为每个潜在的下一步棋累积了一个拜访计数(<strong class="in hi"> <em class="jj"> N </em> </strong>)。MCTS的工作使得好的棋最终比坏的棋更经常被访问，并且是在哪里玩的好的指示。</p><p id="ae0c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通常，这些计数被标准化，并用作选择实际移动的分布。但是所谓的<em class="jj">温度</em>参数(τ)可以用于首先对这些计数求幂:N^(1/τ).他们为游戏的前30步设置τ=1(这没有影响)，然后为游戏的其余部分将其设置为一个无穷小的值(这在标准化后会抑制除最大值以外的所有值)。</p><ul class=""><li id="f71a" class="lc ld hh in b io ip is it iw le ja lf je lg ji lh li lj lk bi translated">N <strong class="in hi"> </strong> = (1，2，3，4)</li><li id="6979" class="lc ld hh in b io ll is lm iw ln ja lo je lp ji lh li lj lk bi translated">归一化N: (0.1，0.2，0.3，0.4)</li><li id="b160" class="lc ld hh in b io ll is lm iw ln ja lo je lp ji lh li lj lk bi translated">使用τ=1: (0.1，0.2，0.3，0.4)</li><li id="2129" class="lc ld hh in b io ll is lm iw ln ja lo je lp ji lh li lj lk bi translated">使用τ~0: (0，0，0，1)</li></ul><p id="5223" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，前30个动作有些探索性，其余的将只播放访问次数最多的动作。</p><p id="6ea3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们决定玩玩这个。首先，我们尝试让τ为1，而不是减小它。这导致了性能的显著提高。受到这次成功的鼓舞，我们尝试了一些生活在边缘的游戏，并在整个游戏中将它提高到1.75:</p><ul class=""><li id="7167" class="lc ld hh in b io ip is it iw le ja lf je lg ji lh li lj lk bi translated">使用τ=1.75: (0.15，0.23，0.29，0.34)</li></ul><p id="bb8f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">τ越大，分布越平坦，导致勘探更加均匀。虽然τ=1.75在我们尝试的值中给出了最好的结果，但我们发现它并不比简单地增加c_puct好。所以我们干脆把它留在了<strong class="in hi"> 1 </strong>。</p><h1 id="f551" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">其他调整</h1><p id="2f0c" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">除了调整超参数，我们还尝试了一些其他的修改。</p><h2 id="dcc9" class="ko jm hh bd jn kp kq kr jr ks kt ku jv iw kv kw jz ja kx ky kd je kz la kh lb bi translated">Nvidia-TensorRT和int8</h2><p id="d0c9" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">Nvidia提供了一个<a class="ae jk" href="https://devblogs.nvidia.com/tensorrt-integration-speeds-tensorflow-inference/" rel="noopener ugc nofollow" target="_blank">推理优化工具</a>，将我们的推理速度提高了3-4倍。除了优化张量流图，它还支持<a class="ae jk" href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf" rel="noopener ugc nofollow" target="_blank"> 8位量化</a>，以精度换取吞吐量。</p><p id="3a1d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这种量子化的副作用是它鼓励探索。例如，如果神经网络预测两个位置具有稍微不同的结果(范围[-1，1]内的数字)，那么在精度稍微降低的情况下，它们可能看起来相等。</p><h2 id="5dca" class="ko jm hh bd jn kp kq kr jr ks kt ku jv iw kv kw jz ja kx ky kd je kz la kh lb bi translated">定位重复数据删除</h2><p id="cb60" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">当训练神经网络时，在最近的游戏中随机选择位置。因为Connect Four只有很少的合理开盘价，我们发现这导致早期董事会头寸的大量增加。这导致网络过于关注他们。</p><p id="5fa7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们通过在随机选择职位进行培训之前进行重复数据删除来缓解这个问题。在这个过程中，我们对先验值和结果值进行平均。这似乎很有效。</p><h1 id="4dbf" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">结论</h1><p id="1c58" class="pw-post-body-paragraph il im hh in b io kj iq ir is kk iu iv iw kl iy iz ja km jc jd je kn jg jh ji ha bi translated">正如许多机器学习一样，AlphaZero的论文有许多没有得到充分解释的“神奇数字”。很难知道做了多少探索来确定所提供的值。对于某些参数，有原则的方法可以帮助缩小选择范围，但总的来说，这是一个“试试看”的游戏</p><p id="1075" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jj">探索与利用</em>是强化学习中的一个核心概念，因此，我们所做的许多调整以各种方式影响了这种权衡。</p><p id="8178" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们当然还没有找到<em class="jj">最优</em>选择，但是通过大量实验，我们帮助AlphaZero在Connect Four上做得比“开箱即用”好得多。</p><p id="1974" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="jj">第4部分现公布</em> <a class="ae jk" rel="noopener" href="/oracledevs/lessons-from-alphazero-part-4-improving-the-training-target-6efba2e71628"> <em class="jj">此处</em> </a> <em class="jj">。</em></p></div></div>    
</body>
</html>