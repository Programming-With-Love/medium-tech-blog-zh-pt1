<html>
<head>
<title>Copy data from Cloud SQL to BigQuery using Apache Airflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Airflow将数据从云SQL复制到BigQuery</h1>
<blockquote>原文：<a href="https://medium.com/compendium/copy-data-from-cloud-sql-to-bigquery-using-apache-airflow-b51bdb277463?source=collection_archive---------0-----------------------#2019-02-22">https://medium.com/compendium/copy-data-from-cloud-sql-to-bigquery-using-apache-airflow-b51bdb277463?source=collection_archive---------0-----------------------#2019-02-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="5682" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">TLDR；<a class="ae jc" href="https://github.com/ael-computas/gcp_cloudsql_airflow_bigquery" rel="noopener ugc nofollow" target="_blank">链接到底部带有示例气流DAG </a>的代码回购。</p><p id="1a10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">去年，当谷歌将<a class="ae jc" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Airflow </a>变成<a class="ae jc" href="https://console.cloud.google.com/" rel="noopener ugc nofollow" target="_blank"> GCP </a>的托管服务时，我很兴奋——主要是因为我以前研究过Airflow，我发现用实际代码编写任务调度程序而不是点击很好。Airflow是GCP的第一个合适的任务调度器，在此之前，如果你想要一个调度器，你必须使用第三方服务或<a class="ae jc" href="https://cloud.google.com/scheduler/" rel="noopener ugc nofollow" target="_blank"> cron调度器</a>。如果您有像“每分钟ping一次”或“每小时重新加载缓存”这样的任务，Cron是不错的，但是一旦您开始有像“从那个源加载数据，然后把它放入另一个源，然后给某人发电子邮件”这样的任务，您就真的需要一个任务管理器了。因为你的工作会崩溃，然后你需要在中间重启一些东西，并关闭整个管道。你不希望在没有框架的情况下创建这些类型的脚本！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/4feae03b6cb16a56110080394ccd9822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrUaleE6B-fHyUIeO-TYGQ.png"/></div></div></figure><p id="615e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自从Airflow进入GCP以来，已经过去了将近一年的时间，虽然已经有了许多好的补充，使得GCP和BigQuery的集成更加容易，但是还没有文档介绍如何以重复的方式将数据从云SQL移动到BigQuery。希望在不久的将来会有一种简单的方法将数据从云SQL迁移到BigQuery。</p><h1 id="0e7e" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">第一种解决方案:使用gcloud和Cloud Composer实现自动化！</h1><p id="80f3" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">然而，谷歌做得好的是GCP的工具箱gcloud。您可以在GUI中做任何您能做的事情(甚至更多)，并且在贵由中可以做导出和导入。</p><p id="a2a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我现在要介绍的解决方案最适合“日常”范围内的批量数据传输。比方说，如果您想每天晚上将数据仓库表转移到BigQuery。</p><p id="82ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用<a class="ae jc" href="https://cloud.google.com/sdk/gcloud/" rel="noopener ugc nofollow" target="_blank"> gcloud </a>可以为Cloud Composer中的表触发导出作业(到CSV)到云存储。由于表导出也需要一个定制的SQL，所以您可以让导出变得更加智能，这样您就不必每天都做完整的复制。</p><p id="b0ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">所以我最初的计划是这样的:</strong></p><ol class=""><li id="2692" class="ks kt hh ig b ih ii il im ip ku it kv ix kw jb kx ky kz la bi translated">将表导出到云存储</li><li id="93cf" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">导入到BigQuery临时区域</li><li id="6cb8" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">可能是要合并和连接的BigQuery SQL。</li></ol><p id="1692" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在做了几个小时之后，我遇到了一个非常恼人的bug，需要我稍微修改一下管道。出于某种原因，谷歌不知道如何正确地将云SQL导出到CSV。如果在CSV中有一个空值，则导出会中断(“foo”、“bar”变成“foo”、“N”、“bar”)。<a class="ae jc" href="https://issuetracker.google.com/70153040" rel="noopener ugc nofollow" target="_blank"> bug已经存在很长时间了</a>，所以要使用导出，我们必须解决它。</p><p id="187e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就我而言，可以通过一些脚本破解和创造性地使用gsutil和sed来解决这个问题。相关的<a class="ae jc" href="https://github.com/ael-computas/gcp_cloudsql_airflow_bigquery/blob/f706487b14cd8c2912a0d036ee698a2337af0954/dags/cloudsql_to_bigquery.py#L231" rel="noopener ugc nofollow" target="_blank">代码可以在这里找到</a>。</p><p id="6ffb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我开始这个任务时，我没有真正考虑的其他情况是模式。仅使用一个CSV文件，您将在列上获得非常通用的名称(column 1、column 2等)。当我第一次写这个的时候，我计划添加一个JSON文件，其中包含每个要同步的表的数据模型，但是后来我想…为什么不从MySQL中获取呢？这样我们就不必花费(手动)时间来维护单独的数据模型。</p><p id="8db4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">幸运的是，在需要依赖关系的情况下，向Airflow添加新任务是非常容易的，所以进展非常顺利。</p><p id="805b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">重游步骤:</strong></p><ol class=""><li id="6701" class="ks kt hh ig b ih ii il im ip ku it kv ix kw jb kx ky kz la bi translated">在BigQuery数据集所在的位置创建一个存储桶，这将为您临时保存数据。您可能希望将保留策略设置为一个固定的时间(例如1周)，因为您将在此保存相当多的重复数据。</li><li id="c297" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">使用gcloud将表格以CSV格式导出到云存储</li><li id="c180" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">使用gcloud将MySQL模式(列名、类型)导出为CSV</li><li id="3a3e" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">从导出的CSV文件创建一个BigQuery JSON模式，并修改一些数据类型，比如MySQL DATE导出为YYYY-mm-dd hh:mm:ss，而BigQuery只希望它导出为YYYY-mm-dd</li><li id="12e6" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">修复由于这个bug导致的导出中的空值(<a class="ae jc" href="https://cloud.google.com/sql/docs/mysql/known-issues#import-export" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/SQL/docs/MySQL/known-issues # import-export</a>)——基本上导出的空值会破坏CSV。使用gsutil和sed。</li><li id="b051" class="ks kt hh ig b ih lb il lc ip ld it le ix lf jb kx ky kz la bi translated">将其导入到bigquery</li></ol><p id="f510" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">免责声明:我没有测试第4步如何处理非常大的文件。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/fa2f1baa3fa2d030ceb2a492e703afc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_W_p49xbnPO1BYs1fw0kg.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx">Example output</figcaption></figure></div><div class="ab cl ll lm go ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ha hb hc hd he"><p id="161c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第一步:水桶</strong></p><p id="bee8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯。只需在UI中创建bucket。授予对Composer服务帐户的访问权限。</p><p id="4fc9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤Bash导出脚本示例</strong></p><p id="1ef1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您要编写一个Bash脚本来完成这项工作，它可能看起来像这样:</p><pre class="je jf jg jh fd ls lt lu lv aw lw bi"><span id="30f3" class="lx jq hh lt b fi ly lz l ma mb">gcloud --project foo-bar sql export csv my-sql-instance gs://my-bucket/export_table_YYYYMMDD --database=production --query="SELECT * from example"</span></pre><blockquote class="mc md me"><p id="2546" class="ie if mf ig b ih ii ij ik il im in io mg iq ir is mh iu iv iw mi iy iz ja jb ha bi translated">小费！我用YearMonthDay进行后期处理，这样文件可以保留一段时间。在我导出到的存储桶中，我保留了14天，之后内容会被删除。通常一个作业会在某个时候崩溃，有一些数据可以查看会使调试容易得多。</p></blockquote><p id="0b26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我将使用上面创建的脚本作为我的气流管道的模板。</p><p id="27dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦你有了云存储中的数据，接下来如何处理它就有了很多选择。将它从这里转移到BigQuery要容易得多(数据流、云函数、查询联邦，可能还有更多)</p><p id="a487" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤3 &amp; 4:从云SQL (MySQL)获取模式</strong></p><p id="7131" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还需要获得模式:</p><pre class="je jf jg jh fd ls lt lu lv aw lw bi"><span id="3191" class="lx jq hh lt b fi ly lz l ma mb">gcloud --project foo-bar sql export csv my-sql-instance gs://my-bucket/export_table_YYYYMMDD --database=production --query="SELECT COLUMN_NAME,DATA_TYPE  FROM INFORMATION_SCHEMA.COLUMNS  WHERE TABLE_SCHEMA = '{{ params.export_database }}' AND TABLE_NAME = '{{ params.export_table }}' order by ORDINAL_POSITION;"</span></pre><p id="49f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该命令会将模式导出到一个CSV文件，然后一个小脚本可以将它转换成一个BigQuery模式。这个小脚本还可以清除表名，这样就不会出现像“带有/和奇怪字符的奇怪列”这样的列。你可以在GitHub 中找到<a class="ae jc" href="https://github.com/ael-computas/gcp_cloudsql_airflow_bigquery/blob/f706487b14cd8c2912a0d036ee698a2337af0954/dags/cloudsql_to_bigquery.py#L160" rel="noopener ugc nofollow" target="_blank"> Python脚本</a></p><p id="e664" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第五步:修复损坏的CSV </strong></p><pre class="je jf jg jh fd ls lt lu lv aw lw bi"><span id="b090" class="lx jq hh lt b fi ly lz l ma mb">gsutil cp gs://the/bucket/and/file.csv - \<br/>| sed 's/,"N,/,"",/g' | sed 's/,"N,/,"",/g' | sed 's/^"N,/"",/g' | sed 's/,"N$/,""/g' \<br/>| gsutil cp - gs://the/bucket/and/file.csv</span></pre><p id="52e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">想法来自<a class="ae jc" href="https://issuetracker.google.com/issues/64579566#comment22" rel="noopener ugc nofollow" target="_blank">https://issuetracker.google.com/issues/64579566#comment22</a></p><p id="b2ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤Bash导入脚本示例</strong></p><p id="6786" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BigQuery导入命令如下所示:</p><pre class="je jf jg jh fd ls lt lu lv aw lw bi"><span id="62cd" class="lx jq hh lt b fi ly lz l ma mb">bq --project foo-bar --location=EU load --replace --source_format=CSV my_dataset.my_table_YYYYMMDD gs://my-bucket/export_table_YYYYMMDD export_table_YYYYMMDD_schema.json</span></pre><p id="4bb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如您所见，我假设这里有一个模式文件(由前面的脚本创建)。BigQuery有自动检测模式的选项，但是我发现对于更复杂的表，创建显式模式是一个聪明的做法。</p><h1 id="f997" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">最后的想法</h1><p id="8f82" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我在GitHub上添加了一个示例，你可以从中收集一些关于如何自己做这件事的想法。它将3个表(2个维度和1个事实)完全同步到BigQuery。</p><p id="52a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://github.com/ael-computas/gcp_cloudsql_airflow_bigquery" rel="noopener ugc nofollow" target="_blank">https://github . com/ael-computas/GCP _ cloud SQL _ air flow _ big query</a></p><p id="5612" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个更灵活的解决方案是直接从云SQL数据库读取，使用它的API。例如，创建一个新的气流操作符，它使用流API来完成这项工作(并去掉glcoud/gsutil/bg命令)。这需要在Cloud Composer Kubernetes集群中运行云SQL代理，还可能需要一些其他步骤。</p><p id="9536" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也许我会回来创建这个操作符！</p><p id="6d6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编辑:<a class="ae jc" rel="noopener" href="/@ael_78866/copy-data-from-cloud-sql-to-bigquery-using-apache-airflow-cloud-composer-part-2-33aa02bf456a">链接到第2部分</a></p><p id="eb95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编辑:<a class="ae jc" rel="noopener" href="/@ael_78866/argo-workflows-as-alternative-to-cloud-composer-db4db2bea1af">如果您发现composer价格有点高，请链接到更便宜的工作流调度器</a></p></div></div>    
</body>
</html>