<html>
<head>
<title>Scaling Spark Streaming for Logging Event Ingestion</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为记录事件摄取扩展火花流</h1>
<blockquote>原文：<a href="https://medium.com/airbnb-engineering/scaling-spark-streaming-for-logging-event-ingestion-4a03141d135d?source=collection_archive---------1-----------------------#2018-11-20">https://medium.com/airbnb-engineering/scaling-spark-streaming-for-logging-event-ingestion-4a03141d135d?source=collection_archive---------1-----------------------#2018-11-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3d1c" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">Airbnb如何通过一个新颖的平衡Kafka阅读器来扩展Spark streaming，该阅读器可以近乎实时地从Kafka获取大量日志事件</h2></div><p id="d69a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由<a class="ae js" rel="noopener" href="/@billhao"> <em class="jt">【王昊】</em></a><a class="ae js" rel="noopener" href="/@LiyinTang"><em class="jt">【唐】</em> </a></p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/9aeaadc3b421d4784ecfc9ddaf231567.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8KwtBrEEgQJG5dAJYJcfg.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">Walking over a stream during <a class="ae js" href="https://www.airbnb.com/experiences/154403" rel="noopener ugc nofollow" target="_blank">an Airbnb Experience</a> in Kuala Lumpur. Searching, viewing, and booking such Experiences will all produce logging events that will be processed by our stream processing framework.</figcaption></figure><h1 id="f2d2" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">在Airbnb记录事件摄取</h1><p id="db55" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">日志事件从客户端(如移动应用程序和web浏览器)和在线服务发出，包含有关操作或操作的关键信息和上下文。每个事件都携带一条特定的信息。例如，当一个客人搜索Airbnb.com Malibu的海滨别墅时，搜索事件包含位置、入住和退房日期等。将被生成(并且为了隐私保护而被匿名化)。</p><p id="eacd" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在Airbnb，事件记录对于我们了解客人和主人，然后为他们提供更好的体验至关重要。它为商业决策提供信息，并推动搜索、实验、支付等工程功能的产品开发。作为一个例子，日志事件是训练机器学习模型用于列表搜索排名的主要来源。</p><p id="666b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">日志事件被近乎实时地接收到数据仓库中，并作为许多ETL和分析作业的来源。事件从客户端和服务发布到Kafka。Spark流作业(构建在Airbnb的流处理框架<a class="ae js" href="https://www.youtube.com/watch?v=tJ1uIHQtoNc" rel="noopener ugc nofollow" target="_blank"> Airstream </a>之上)不断从Kafka读取事件，并将事件写入HBase进行重复数据删除。最后，事件每小时从HBase转储到一个Hive表中。由于日志事件被输入到整个公司的许多管道中，并为许多仪表板提供动力，因此确保它们及时到达数据仓库并满足SLA非常重要。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lh"><img src="../Images/731602c67e9a18ad3232ddf482c3ecb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*93TvjWjYDVgBw2NNNS2Kvg.png"/></div></div></figure><p id="9266" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">生成的事件数量巨大且在快速增加。这给现有的接收基础设施带来了严峻的挑战，特别是将事件从Kafka接收到HBase的Spark流作业。在本文中，我们将讨论扩展基础架构所面临的挑战，以及一种能够支持更高吞吐量和更高效率的解决方案。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es li"><img src="../Images/0102681ad413e7e980727f6c03620203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2l3Kf4YA_r1jjfoq"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx">As Airbnb’s business grows, so does the number of events per week.</figcaption></figure><h1 id="6ff9" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">挑战</h1><h2 id="2a08" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated">1.火花并行性由Kafka分区的数量决定</h2><p id="125c" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">在目前的Spark Kafka连接器中，Kafka分区和Spark任务是一一对应的。基本上，一个Spark任务被实例化为从一个Kafka分区读取，以确保在Spark中处理事件时的顺序。然而，采用这种设计，我们不能简单地通过增加并行度和分配更多资源来扩展Spark流作业。</p><p id="a320" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了增加Spark并行性和吞吐量，必须为具有大型事件或高QPS事件的主题分配更多的Kafka分区。不幸的是，这是一个相当手工的过程，并且在有大量主题(不断增加)时不可伸缩。</p><p id="0488" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">另一个问题是，在Kafka中为一个主题分配更多的分区不能追溯到Kafka中已经存在的事件。附加分区仅可用于新事件。对我们来说，预测事件的高峰并事先给受影响的卡夫卡主题分配更多的分区是不切实际的。高峰可能在任何时候出现，可能是由于各种原因，如新产品功能或假期。</p><p id="a702" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当事件量达到临界水平时，大型Kafka主题通常无法足够快地被数据仓库接收。我们接下来将讨论的事件中的数据偏差加剧了这个问题。</p><h2 id="c0ab" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated"><strong class="ak"> 2。事件量和大小的偏差</strong></h2><p id="64f2" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">记录的不同事件类型在数量和大小上有很大差异。有些真的很稀疏，有些可能有几个数量级高的QPS。事件类型的大小可以从数百字节到数百千字节不等。下面的方框图显示了Kafka主题的平均事件大小的巨大变化(注意Y轴是对数标度)。尽管我们试图为更大的事件分配更多的分区，Kafka分区中仍然存在严重的偏差。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es li"><img src="../Images/87e4ff11a82a31ee9e06a62bcf4b410d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*APYi7XNp9ugouiDG"/></div></div></figure><p id="bdd4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于数据应用程序来说，偏斜通常是一个严重的问题。在这种情况下，一些Spark任务将比其他任务花费更长的时间来完成。当一个阶段中的所有任务完成后，一个Spark作业会转移到下一个阶段，这导致了许多执行器的闲置和资源的浪费。如果主题没有足够的分区，那么包含最大事件的Kafka分区将花费不合理的长时间来阅读。这导致火花流作业的滞后，因为批次是按顺序处理的。</p><h2 id="7db2" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated"><strong class="ak"> 3。近乎实时的摄取和迎头赶上的空间</strong></h2><p id="7acd" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">由于上述挑战，Spark流作业的吞吐量几乎没有上升空间。一旦作业由于各种问题(如坏数据节点或Hive Metastore中断)而延迟，就需要很长时间才能赶上进度。</p><p id="9726" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">例如，假设一个间隔为2分钟的作业平均在1分钟内处理一批。如果工作落后4个小时，则需要另外4个小时才能赶上。如果我们希望它在1小时内赶上，那就需要4倍的空间(即在24秒内处理每批)。除了从事故中恢复之外，处理季节性高峰也需要较大的净空高度。因此，对于接近实时的接收，在吞吐量上有额外的余量是至关重要的。</p><h1 id="d804" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">解决方案</h1><p id="d369" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">在理想的系统中，我们希望能够横向扩展Spark流作业(即通过增加并行性和分配更多资源来实现更高的吞吐量)。我们还希望这些作业负载均衡，这样每个任务花费大致相等的时间来阅读卡夫卡。</p><p id="e239" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了实现这两个目标，我们Airbnb数据平台团队开发了一个平衡的Spark Kafka阅读器，满足了这两个要求。</p><h2 id="2f9e" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated">平衡火花卡夫卡阅读器</h2><p id="5175" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">对于流式摄取，事件的排序不是必需的，因为摄取的事件被最低限度地处理，然后单独存储在HBase中。这允许我们重新思考模型，并寻找新的方法来解决扩展问题。因此，我们为Spark创建了一个新的平衡Kafka阅读器，它1)允许任意数量的拆分，因此可以增加并行性以提供更高的吞吐量；2)根据事件量和大小计算拆分。</p><p id="b8b7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在高层次上，平衡的卡夫卡读者工作如下:</p><ol class=""><li id="1563" class="lx ly hh iy b iz ja jc jd jf lz jj ma jn mb jr mc md me mf bi translated">它预先计算每个主题中的平均事件大小，并将其保存在CSV文件中。</li><li id="9d4a" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">当Spark流作业实例化平衡Kafka阅读器时，它会传递一个附加参数<em class="jt"> numberOfSplits </em>来指定所需的并行度<em class="jt">。</em></li><li id="3cb1" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">对于每个Kafka分区，它计算要读取的偏移范围(从当前偏移到最新偏移)，并应用<em class="jt">maxratepartition</em>约束(如果设置的话)。</li><li id="7854" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">它使用<strong class="iy hi">平衡分区算法</strong>(在下一节中描述)将偏移范围子集平均分配给分割。</li><li id="e424" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">每个Spark任务根据拆分从Kafka读取一个或多个偏移范围。</li></ol><p id="43d9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是一个简单的例子，有2个卡夫卡主题和3个分裂。与主题b相比，主题A中的事件具有更高的QPS，但大小更小。平衡的Kafka阅读器会将这些事件的子集分组在一起，以便每个拆分从Kafka读取1/3的数据。一个分割(分割2)将包括来自主题A的4个事件和来自主题B的1个事件，因此每个分割的总大小为8kb。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ml"><img src="../Images/214d98df574a385deec1cac37488f34f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3QWpLhgYZ8Gt29TWuJWXQ.png"/></div></div></figure><p id="701d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请注意，将来可以通过动态计算平均事件大小来改进步骤1，以便更好地考虑新主题和事件大小频繁变化的主题。</p><h2 id="e0da" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated">平衡划分算法</h2><p id="eb11" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">将偏移范围均匀分配给拆分的问题与NP-hard bin装箱问题非常相似。最优解的复杂算法和非最优解的快速算法确实存在非线性计算复杂性。然而，它们不能被使用，因为我们的问题有些不同，因为1)分裂(或箱)的数量是固定的；2)偏移范围(或项目)可以被分割成更小的部分。</p><p id="441d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们没有采用复杂的现有算法，而是开发了一种简单而有效的算法，如下图所示。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mm"><img src="../Images/3abcd8abbbb1215ebe9086ddaf764a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6KPV1ATnl2sYLl1pKGGdZw.png"/></div></div></figure><ol class=""><li id="7ea9" class="lx ly hh iy b iz ja jc jd jf lz jj ma jn mb jr mc md me mf bi translated">根据上面的公式计算理想的<em class="jt">每分割重量</em>。对于不在预计算列表中的新事件类型，请使用所有事件类型的平均大小。</li><li id="523d" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">从分割0开始。对于每个偏移范围</li><li id="6544" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">如果总重量小于<em class="jt">每次分割重量</em>，则将其分配给当前分割</li><li id="bdb8" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">如果不适合，将其分开，并指定适合的偏移范围子集</li><li id="e2ae" class="lx ly hh iy b iz mg jc mh jf mi jj mj jn mk jr mc md me mf bi translated">如果当前分割大于<em class="jt">每次分割的重量</em>，移动到下一个分割</li></ol><p id="cf1b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个算法的速度非常快，分裂次数为O。它只是依次经历了分裂和卡夫卡式的分割。结果是，大多数拆分的权重都非常平衡，除了最后一个拆分的权重可能要小得多(这很好，因为我们最多浪费了一个任务的资源)。在一次测试中，估计的<em class="jt">每次拆分的重量</em>为489，541，767，有20，000次拆分。最小和最大拆分的权重分别为278，068，116和489，725，277。第二小的拆分的权重为489，541，772。不包括最小的拆分，第二小拆分和最大拆分之间的差值为183，505(仅为最大权重的0.04%)。</p><p id="17f8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">平衡分区算法在测试和生产中都表现良好。Spark任务运行时间的方差(如下图所示)比原来的Spark Kafka阅读器分布均匀得多。大多数任务在2分钟内完成。其中一小部分花了2到3分钟。与大范围的事件QPS和大小相比，任务运行时间的小变化证明了平衡分区算法令人难以置信的有效性。通过考虑事件的大小和数量，它可以确保摄取工作负载在执行者之间均匀分布。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mn"><img src="../Images/ff88851e133bcbde1d60cb60099ac5e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HmSEU-5fp_ZRCaU3"/></div></div></figure><h2 id="da16" class="lj kl hh bd km lk ll lm kq ln lo lp ku jf lq lr kw jj ls lt ky jn lu lv la lw bi translated">上游和下游系统的改进</h2><p id="6324" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">平衡的Kafka阅读器是扩展日志事件的流摄取的关键部分。确保上游和下游系统中没有其他瓶颈也很重要。在这种情况下，我们改进了Kafka和HBase，以提高它们的吞吐量和可靠性。对于Kafka，经纪人被转移到吞吐量是其4倍的VPC。设置了一个流作业来监控每个Kafka分区的QPS，以便当事件量增加时，可以及时添加更多分区。对于下游HBase，HBase表的区域数量从200增加到1000，因此向HBase大容量加载事件可以具有更高的并行性(这由区域数量决定)。</p><p id="5764" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于Spark流作业，推测性执行可以更好地处理底层基础设施中的可靠性问题。例如，一个Spark任务可能由于从带有故障磁盘的坏数据节点中读取而停滞。有了推测性执行，作业就不太可能受到这类问题的影响。</p><h1 id="d474" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">最后的想法</h1><p id="d3bc" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">由于平衡的Kafka阅读器，从Kafka消费的Spark应用程序现在可以通过任意并行进行水平扩展。平衡分区算法很简单，并且已经证明非常有效。由于这些改进，用于接收日志事件的Spark流作业可以处理比以前多一个数量级的事件。系统的稳定性已经有了很大的提高，自从部署了更改之后，我们没有看到任何明显的滞后。</p><p id="3ed8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于未来的事件流量增长和峰值，用于记录事件摄取的Spark流作业将能够平稳高效地处理它们。不再担心事件中的偏差。如果由于底层基础设施的问题，工作碰巧滞后，it将能够快速赶上。</p><p id="fc65" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们这里解决的问题在大规模的Spark应用和一般的数据应用中并不少见。仔细理解数据本身以及如何在每个步骤中处理数据非常重要，这可以揭示潜在的瓶颈、数据偏差和优化机会。例如，Spark提供了一个漂亮的UI，显示每个作业的DAG。由此，我们可以了解一个作业是如何执行的，以及是否可以通过缓存、重新分区等方式进行调整以获得更好的性能。</p><h1 id="c355" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">承认</h1><p id="56ca" class="pw-post-body-paragraph iw ix hh iy b iz lc ii jb jc ld il je jf le jh ji jj lf jl jm jn lg jp jq jr ha bi translated">扩展日志事件的流接收涉及许多上游和下游系统。该项目是Airbnb数据平台和生产基础设施四个团队的共同努力。没有朱聪、帕拉·穆提亚、、罗尼·朱和加布·莱昂斯的巨大贡献，这是不可能的。我们感谢徐章对卡夫卡的热心帮助。我们要感谢、Jonathan Parks、Gurer Kiratli、Xinyao Hu和Aaron Siegel对这项工作给予的无与伦比的支持。</p><p id="0fcf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们非常感谢Gurer Kiratli和Xiaohan Zeng在校对这篇博文时给予的帮助。</p></div><div class="ab cl mo mp go mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ha hb hc hd he"><p id="61b9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> Airbnb的数据平台团队</strong>一直在寻找具备相关技能的优秀工程师！如果您对构建这样的数据基础设施充满热情，并有兴趣加入该团队，请查看<a class="ae js" href="https://www.airbnb.com/careers/departments/engineering" rel="noopener ugc nofollow" target="_blank">我们的空缺职位</a>并发送您的申请！</p></div></div>    
</body>
</html>