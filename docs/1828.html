<html>
<head>
<title>Capturing &amp; Displaying Data Transformations with Spline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用样条捕捉和显示数据转换</h1>
<blockquote>原文：<a href="https://medium.com/capital-one-tech/capturing-displaying-data-transformations-with-spline-f1b714960682?source=collection_archive---------5-----------------------#2021-11-22">https://medium.com/capital-one-tech/capturing-displaying-data-transformations-with-spline-f1b714960682?source=collection_archive---------5-----------------------#2021-11-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="0069" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">这个开源工具如何帮助自动跟踪和显示来自Apache Spark应用程序的数据血统</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/5fc1fdf769af017ed08c9d13e85ff857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oiIbFtcxqlQmpg4F.png"/></div></div></figure><p id="19de" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">作为一名数据工程师，我经常看到新的团队或团队成员被要求支持现有的数据模型，其中缺少关于输入、输出和所用数据移动的文档。这些输入、输出和移动共同构成了<strong class="jk hi">数据谱系</strong>，它是一组数据的历史，包括其来源、转换和随时间的移动。</p><p id="569c" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">尽管可以手动定义数据沿袭，但手动捕获数据沿袭(尤其是当应用程序的逻辑随时间变化时)可能非常耗时，并且容易出现人为错误。作为一名数据工程师，能够将数据谱系作为应用程序流的正常部分来捕获，并能够以易于理解的格式显示数据谱系以用于文档目的，这将是非常有益的。幸运的是，我在Capital One的一个团队中工作，该团队的主要职能是支持跨多个组织的现有数据模型，并与企业标准保持同步。我们在Spline中为我们的用例找到了一个很好的解决方案，Spline是一个开源工具，用于自动跟踪和显示来自Apache Spark应用程序的数据谱系。Spline由ABSA OSS维护，你可以在https://github.com/AbsaOSS的<a class="ae ke" href="https://github.com/AbsaOSS" rel="noopener ugc nofollow" target="_blank">阅读更多内容。</a></p><p id="7e97" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在这篇博客中，我将讲述:</p><ul class=""><li id="0c7e" class="kf kg hh jk b jl jm jo jp jr kh jv ki jz kj kd kk kl km kn bi translated">定义、捕获和显示数据沿袭的好处</li><li id="1f26" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">使用PySpark生成数据</li><li id="8170" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">用样条捕捉数据血统</li><li id="bc77" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">用样条线显示数据沿袭</li></ul><h1 id="81fd" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">定义、捕获和显示数据沿袭的好处</h1><p id="abcb" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">对生成和分析数据感兴趣的组织通常会<strong class="jk hi">将</strong>数据血统定义为应用程序和管道开发周期的一部分，即使是非正式的。然而，下面解释的<strong class="jk hi">捕获</strong>和<strong class="jk hi">显示</strong>数据谱系的额外步骤也有好处。</p><h2 id="594b" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">定义数据血统</h2><p id="f2db" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">定义数据沿袭可以在开发应用程序或管道之前完成。这通过以下方式使组织受益:</p><ul class=""><li id="4361" class="kf kg hh jk b jl jm jo jp jr kh jv ki jz kj kd kk kl km kn bi translated">支持根据输入包含的数据及其质量选择输入的能力</li><li id="e29a" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">识别所有必须发生的转换并确认它们的有效性</li><li id="2943" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">设定对输出格式的期望以及如何在下游使用数据</li></ul><p id="3d75" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在设计时做这项工作可以使组织在开发过程中避免麻烦，并且由于期望的明确定义，将促进与上游和下游合作伙伴的协作。</p><h2 id="4d78" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">捕获数据沿袭</h2><p id="3c4b" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">捕获数据沿袭对于确保在上一步中定义的转换和应用程序或管道实际执行的转换之间没有发生偏差非常重要。运行时捕获的数据沿袭还可以提供比设计时捕获的数据沿袭更多的信息，如记录计数和特定于分区的元数据。</p><h2 id="1e86" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">显示数据沿袭</h2><p id="23b6" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">通过以可视格式显示信息，显示数据沿袭有助于理解数据的来源和移动。这些信息可以作为应用程序或管道的业务逻辑的文档。</p><p id="24d1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">最重要的是，对于高度管制行业中的组织，可能需要数据沿袭来满足法规要求</p><h1 id="a64d" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">使用Spline捕获和显示数据沿袭</h1><p id="9203" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">首先，让我们从基础开始，包括关键的Spline组件和设置您的Spline服务器。然后我们将运行一个示例Spark作业，并展示Spline UI是如何工作的。</p><h2 id="0dfc" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">样条元件简介</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es me"><img src="../Images/6fec53664bb90b29e8aaaabf160795c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*X7ZX062hQw5PukEzyQ1l3g.png"/></div><figcaption class="mf mg et er es mh mi bd b be z dx">Diagram from Spline documentation at <a class="ae ke" href="https://absaoss.github.io/spline" rel="noopener ugc nofollow" target="_blank">https://absaoss.github.io/spline</a></figcaption></figure><p id="355a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在上图中，取自样条曲线文档，绿框是样条曲线组件。让我们来看看它们是如何工作的。</p><ul class=""><li id="f6da" class="kf kg hh jk b jl jm jo jp jr kh jv ki jz kj kd kk kl km kn bi translated"><strong class="jk hi">Spline Spark Agent</strong>—Spline Spark Agent作为Spark应用程序的依赖项导入。它将分析Spark作业的执行计划，以捕获数据沿袭。</li><li id="a0c4" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated"><strong class="jk hi"> Spline Rest网关</strong>—Spline Rest网关从Spline Spark代理接收数据沿袭，并将该信息保存在ArangoDB中。</li><li id="d5a0" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated"><strong class="jk hi">Spline UI</strong>—Spline UI可用于可视化所有存储的数据沿袭信息。</li></ul><h2 id="67cf" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">设置样条线服务器</h2><p id="7c21" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">我们将在<a class="ae ke" href="https://github.com/AbsaOSS/spline-getting-started" rel="noopener ugc nofollow" target="_blank">https://github.com/AbsaOSS/spline-getting-started</a>使用ABSA OSS提供的Docker镜像来创建我们的Spline服务器。</p><p id="0d82" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">首先，你应该<a class="ae ke" href="https://docs.docker.com/get-docker/" rel="noopener ugc nofollow" target="_blank">安装Docker </a>。然后，创建并导航到一个沙盒目录来保存本教程的文件。</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="e9cd" class="lq ku hh mk b fi mo mp l mq mr">mkdir spline-sandbox<br/>cd spline-sandbox</span></pre><p id="08e4" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">接下来，运行下面的来创建上图中的所有组件:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="ae6d" class="lq ku hh mk b fi mo mp l mq mr">curl -O https://raw.githubusercontent.com/AbsaOSS/spline-getting-started/main/docker/docker-compose.yml<br/><br/>curl -O https://raw.githubusercontent.com/AbsaOSS/spline-getting-started/main/docker/.env<br/><br/>docker-compose up</span></pre><p id="ca01" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">现在，如果您导航到<a class="ae ke" href="http://localhost:9090/" rel="noopener ugc nofollow" target="_blank"> http://localhost:9090/ </a>，您将看到一些数据血统已经存在于您的数据库中。这是因为docker-compose.yml包含一个spline-spark-agent映像，它为您运行一些示例。</p><p id="d838" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">让我们使用PySpark创建并运行一个新的Spark作业。</p><h2 id="79c8" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">用PySpark和Spline生成和捕获数据谱系</h2><p id="6338" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated"><a class="ae ke" href="http://spark.apache.org/docs/latest/api/python/" rel="noopener ugc nofollow" target="_blank"> PySpark </a>是一个允许开发者使用Python运行Apache Spark作业的工具。</p><p id="c5b6" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">通过运行以下命令设置PySpark环境:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="83f2" class="lq ku hh mk b fi mo mp l mq mr"># Install Python<br/>brew install python</span><span id="348b" class="lq ku hh mk b fi ms mp l mq mr">pip install 'pyspark==3.1.2'</span><span id="f9aa" class="lq ku hh mk b fi ms mp l mq mr"># Create and navigate to a new directory<br/>mkdir my-spark-job<br/>cd my-spark-job</span><span id="8564" class="lq ku hh mk b fi ms mp l mq mr"># Create input and output directories, and files<br/>mkdir -p data/input<br/>mkdir -p data/output<br/>touch my_spark_job.py<br/>touch data/input/user_favorites.csv<br/>touch data/input/locations.csv</span></pre><p id="792f" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">接下来，创建一个模拟数据集，表示一些匿名用户最喜欢的颜色和最喜欢的城市。将这些内容添加到user_favorites.csv:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="49fb" class="lq ku hh mk b fi mo mp l mq mr">id,favorite_color,favorite_city<br/>1,blue,anchorage<br/>2,red,denver<br/>3,orange,mesa<br/>4,yellow,bakersfield<br/>5,purple,portland</span></pre><p id="6e5c" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">然后，创建另一个包含位置的模拟数据集。将这些内容添加到locations.csv:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="f782" class="lq ku hh mk b fi mo mp l mq mr">id,city,state<br/>1,bakersfield,california<br/>2,portland,oregon<br/>3,anchorage,alaska<br/>4,mesa,arizona<br/>5,denver,colorado</span></pre><p id="6cfa" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">现在，让我们创建一个名为MySparkJob的Spark作业。在MySparkJob中，我们将使用上面的模拟数据集创建一个新的数据集，其中包含为匿名用户生成的昵称。将以下内容添加到my_spark_job.py中:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="907d" class="lq ku hh mk b fi mo mp l mq mr">from pyspark.sql import SparkSession</span><span id="4a35" class="lq ku hh mk b fi ms mp l mq mr"># Create SparkSession<br/>spark = SparkSession.builder.appName("MySparkJob").getOrCreate()</span><span id="11e7" class="lq ku hh mk b fi ms mp l mq mr"># Read user_favorites to DataFrame and create a temporary view<br/>user_favorites = (<br/>    spark.read.option("header", "true")<br/>    .option("inferschema", "true")<br/>    .csv("data/input/user_favorites.csv")<br/>)<br/>user_favorites.createOrReplaceTempView("user_favorites")</span><span id="eff9" class="lq ku hh mk b fi ms mp l mq mr"># Read locations to DataFrame and create a temporary view<br/>locations = (<br/>    spark.read.option("header", "true")<br/>    .option("inferschema", "true")<br/>    .csv("data/input/locations.csv")<br/>)<br/>locations.createOrReplaceTempView("locations")</span><span id="27c5" class="lq ku hh mk b fi ms mp l mq mr"># Join user_favorites and locations, and generate the nicknames<br/>nicknames = spark.sql("""<br/>SELECT<br/>  user_favorites.id,<br/>  CONCAT(<br/>    favorite_color,<br/>    ' ',<br/>    state<br/>  ) AS nickname<br/>FROM user_favorites<br/>JOIN locations<br/>ON user_favorites.favorite_city = locations.city<br/>""")</span><span id="4378" class="lq ku hh mk b fi ms mp l mq mr"># Write output and print final DataFrame to console<br/>nicknames.write.mode("overwrite").csv("data/output/nicknames")<br/>nicknames.show(20, False)</span></pre><p id="1fd9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我在代码中提供了解释每个步骤的注释。请注意，Spline只捕获写操作的数据沿袭。你可以在这里阅读更多关于这种行为的信息<a class="ae ke" href="https://github.com/AbsaOSS/spline-spark-agent#spark-features-coverage" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a0e3" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">现在，让我们运行Spark作业，并将Spline Spark代理作为依赖项包括在内:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="4d94" class="lq ku hh mk b fi mo mp l mq mr">spark-submit \<br/>  --packages za.co.absa.spline.agent.spark:spark-3.1-spline-agent-bundle_2.12:0.6.1 \<br/>  --conf spark.sql.queryExecutionListeners=za.co.absa.spline.harvester.listener.SplineQueryExecutionListener \<br/>  --conf spark.spline.producer.url=<a class="ae ke" href="http://localhost:8080/producer" rel="noopener ugc nofollow" target="_blank">http://localhost:8080/producer</a> \<br/>  my_spark_job.py</span></pre><p id="6310" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">如果查看该命令的输出，您会看到我们最终的数据帧如下所示:</p><pre class="ix iy iz ja fd mj mk ml mm aw mn bi"><span id="3bde" class="lq ku hh mk b fi mo mp l mq mr">+---+-----------------+<br/>|id |nickname         |<br/>+---+-----------------+<br/>|1  |blue alaska      |<br/>|2  |red colorado     |<br/>|3  |orange arizona   |<br/>|4  |yellow california|<br/>|5  |purple oregon    |<br/>+---+-----------------+</span></pre><p id="f7d8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">现在，让我们回到<a class="ae ke" href="http://localhost:9090/" rel="noopener ugc nofollow" target="_blank"> http://localhost:9090/ </a>，回顾Spline生成的数据谱系图。</p><h2 id="80e7" class="lq ku hh bd kv lr ls lt kz lu lv lw ld jr lx ly lf jv lz ma lh jz mb mc lj md bi translated">用样条线显示数据沿袭</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mt"><img src="../Images/3644a9edf7612e405c576b247dfd5c5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5-TY32xkQu8stp8L_a6OA.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx">Home Page</figcaption></figure><p id="3b51" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在Spline UI的主页上，您将看到一个执行事件列表。搜索您刚刚运行的Spark作业，我们称之为MySparkJob，并单击它。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mt"><img src="../Images/b63986f32e35c9cd71460a39b23b34a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQRmzjGqTyzyI_dhTgIyWA.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx">Overview Page</figcaption></figure><p id="312a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">您将到达一个概述页面，其中显示了输入、Spark作业和输出。单击MySparkJob节点角上带箭头的框。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mt"><img src="../Images/33ccbf6caaec9392771a2f36ed10a77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KLQ2vgLlNOiNk1rJmNID3w.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx">Details Page</figcaption></figure><p id="01dc" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">您将到达Spark作业的详细信息页面。在这里，如果您单击一个节点，您将看到该特定操作的详细信息。例如，如果您单击底部的项目节点，您将会看到作为所执行的选择操作的结果而发生的转换。</p><p id="2b52" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">如果您返回到主页，可以查看在构建Spline服务器的步骤中执行的其他示例Spark作业的详细信息。</p><h1 id="1bc0" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">资源</h1><ul class=""><li id="0442" class="kf kg hh jk b jl ll jo lm jr mu jv mv jz mw kd kk kl km kn bi translated">样条博客:【https://absaoss.github.io/spline T4】</li><li id="5598" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">https://github.com/AbsaOSS OSS GitHub组织:<a class="ae ke" href="https://github.com/AbsaOSS" rel="noopener ugc nofollow" target="_blank">ABSA</a></li><li id="28ad" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">样条—入门:<a class="ae ke" href="https://github.com/AbsaOSS/spline-getting-started" rel="noopener ugc nofollow" target="_blank">https://github.com/AbsaOSS/spline-getting-started</a></li></ul><h1 id="f466" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">结论</h1><p id="4b44" class="pw-post-body-paragraph ji jj hh jk b jl ll ii jn jo lm il jq jr ln jt ju jv lo jx jy jz lp kb kc kd ha bi translated">既然您已经看到了Spline的实际应用，那么您应该能够避免支持现有数据模型的缺陷，因为现有数据模型缺少关于模型中使用的数据的输入、输出和移动的文档。</p><p id="25bd" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">您现在还应该知道如何:</p><ul class=""><li id="f90f" class="kf kg hh jk b jl jm jo jp jr kh jv ki jz kj kd kk kl km kn bi translated">使用PySpark生成数据</li><li id="6f0d" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">用样条捕捉数据沿袭</li><li id="98a1" class="kf kg hh jk b jl ko jo kp jr kq jv kr jz ks kd kk kl km kn bi translated">用样条线显示数据沿袭</li></ul><p id="58e1" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">与所有开源项目一样，我鼓励您考虑为Spline做贡献。Spline库位于https://github.com/AbsaOSS<a class="ae ke" href="https://github.com/AbsaOSS" rel="noopener ugc nofollow" target="_blank">的ABSA OSS GitHub组织中，在那里你也可以阅读他们深入的文档。</a></p></div><div class="ab cl mx my go mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ha hb hc hd he"><p id="c8e2" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><em class="ne">披露声明:2021首创一号。观点是作者个人的观点。除非本帖中另有说明，否则Capital One不隶属于所提及的任何公司，也不被这些公司认可。使用或展示的所有商标和其他知识产权是其各自所有者的财产。</em></p><p id="0be6" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">【https://www.capitalone.com】最初发表于<a class="ae ke" href="https://www.capitalone.com/tech/software-engineering/spline-spark-data-lineage/" rel="noopener ugc nofollow" target="_blank"><em class="ne"/></a><em class="ne">。</em></p></div></div>    
</body>
</html>