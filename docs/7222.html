<html>
<head>
<title>Faster App Recovery With Bounded Queues</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用受限队列加快应用恢复</h1>
<blockquote>原文：<a href="https://medium.com/square-corner-blog/faster-app-recovery-with-bounded-queues-d546820a0abc?source=collection_archive---------1-----------------------#2017-06-21">https://medium.com/square-corner-blog/faster-app-recovery-with-bounded-queues-d546820a0abc?source=collection_archive---------1-----------------------#2017-06-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie"><p id="d2ba" class="if ig hh bd ih ii ij ik il im in io dx translated">注意，我们已经行动了！如果您想继续了解Square的最新技术内容，请访问我们的新家<a class="ae ip" href="https://developer.squareup.com/blog" rel="noopener ugc nofollow" target="_blank">https://developer.squareup.com/blog</a></p></blockquote><p id="a334" class="pw-post-body-paragraph iq ir hh is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm io ha bi translated">我们过去遇到的一个问题是，当一个Ruby应用程序由于下游问题而变得没有响应时。问题解决后，应用程序继续无响应或处理请求非常慢。虽然重启会立即清除，但我们恢复应用程序所需的手动步骤越少越好。</p><p id="b9e9" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">因为在产品上测试是不好的，我们需要一种简单的方法在本地复制它。</p><h1 id="592b" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">分身术</h1><p id="0813" class="pw-post-body-paragraph iq ir hh is b it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm io ha bi translated">在Square，我们的Ruby应用使用<a class="ae ip" href="https://www.nginx.com/" rel="noopener ugc nofollow" target="_blank"> NGINX </a>和<a class="ae ip" href="https://github.com/puma/puma" rel="noopener ugc nofollow" target="_blank"> Puma </a>来服务请求。我们写出一个简单的<a class="ae ip" href="https://gist.github.com/zanker/e0ca717bcc9cd11859872c2c73505758" rel="noopener ugc nofollow" target="_blank">服务器端测试用例</a>，我们可以通过使用<code class="du kv kw kx ky b">nginx -v ./nginx.conf</code>和<code class="du kv kw kx ky b">puma -C puma.rb</code>来运行它。然后我们设置客户端测试用例:</p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="ec5e" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">现在我们有一个测试端点，它在响应前休眠5秒钟，基准测试发出10个请求。使用我们的初始配置，基准看起来像:</p><pre class="kz la lb lc fd lg ky lh li aw lj bi"><span id="2dfa" class="lk jt hh ky b fi ll lm l ln lo">Starting…<br/>[0] 200 - 4.13 seconds elapsed<br/>[1] 200 - 9.13 seconds elapsed<br/>[2] 200 - 14.13 seconds elapsed<br/>[3] 200 - 19.13 seconds elapsed<br/>[4] 200 - 24.14 seconds elapsed<br/>[5] 200 - 29.14 seconds elapsed<br/>[6] 504 - 29.70 seconds elapsed<br/>[7] 504 - 29.80 seconds elapsed<br/>[8] 504 - 29.90 seconds elapsed<br/>[9] 504 - 30 seconds elapsed<br/>Took 30.0102 total, avg of 21.9242 in thread time, max 30, min 4.13</span></pre><p id="ec7e" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">请求#0到#5返回了<code class="du kv kw kx ky b">HTTP 200 Success</code>，请求#6到#9返回了<code class="du kv kw kx ky b">HTTP 504 Gateway Timeout</code>。这是意料之中的，因为我们的NGINX测试用例已经设置了<code class="du kv kw kx ky b">proxy_read_timeout 30s</code>，并且Puma被配置为一次处理一个请求，处理前6个请求大约需要30秒，NGINX中剩余的4个请求超时。</p><p id="affa" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">比较Puma日志，我们看到Puma看到了10个请求，它们都返回HTTP 200，NGINX看到了与客户端相同的请求，6个请求使用HTTP 200，4个请求使用HTTP 504。</p><p id="66ac" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">这是一个有趣的陷阱。客户端花了30秒等待响应，但是服务器花了50秒来处理它。事情是这样的:</p><pre class="kz la lb lc fd lg ky lh li aw lj bi"><span id="5962" class="lk jt hh ky b fi ll lm l ln lo">00:00 — [A] Client sends request A to Server<br/>00:01 — [A] NGINX buffers the HTTP request into memory and sends it to Puma<br/>00:01 — [A] Puma accepts the connection, reads the request into memory and queues it<br/>00:03 — [B] Client times out, sends request B to Server<br/>00:04 — [B] NGINX buffers the HTTP request into memory and sends it to Puma<br/>00:04 — [B] Puma accepts the connection, reads the request into memory and queues it<br/>00:05 — [A] Puma starts processing the request, and responds with it to NGINX<br/>00:06 — [A] NGINX throws the response away since the client closed the connection for A<br/>00:06 — [B] Puma starts processing the request, responds with it to NGINX<br/>00:07 — [B] Client receives the response for B</span></pre><p id="6b9e" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">如果客户端有自动重试功能就更好了。如果客户端在端点<code class="du kv kw kx ky b">/api/v1/update-user</code>上超时500毫秒，而该端点现在需要1000毫秒，则客户端每花费500毫秒，服务器就必须花费1000毫秒的处理时间。如果客户端重试3次，则客户端每花费1，500毫秒，服务器就会花费3，000毫秒。</p><p id="57c2" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">尤其是在微服务架构中，一个端点可以调用另一个服务，后者调用另一个服务，如此类推。我们很快就给自己下了药，由于请求积压，导致停机比原来更严重。</p><p id="adcb" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">理想情况下，我们的应用程序被配置为在过载时拒绝请求。它防止了上述级联故障的情况，并意味着应用程序可以恢复，而不必重新启动并清除所有长时间运行的请求。</p><p id="505d" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">在这种情况下，我们有一些杠杆可以调整。我们从最明显的开始，那就是彪马。</p><h1 id="b8b1" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">在Puma中限制请求</h1><p id="d59e" class="pw-post-body-paragraph iq ir hh is b it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm io ha bi translated">深入研究Puma代码，我们发现默认情况下，Puma有一个无限制的队列，接受来自套接字的连接，然后将其排队以在server.rb中进行处理:</p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="8591" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">仔细检查Puma中的thread_pool.rb，我们发现:</p><figure class="kz la lb lc fd ld"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="3b06" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">变量<code class="du kv kw kx ky b">@todo</code>是一个无限数组，它将HTTP请求存储在内存中，直到有线程可以处理为止。如果我们的应用程序跟不上，我们可能会有一个包含数百/数千个请求的队列，这些请求很久以前就超时了。该应用程序最终可能会赶上，但如果它正在处理的95%的请求已经超时，我们不想等待10分钟才能恢复。</p><p id="de93" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">看看server.rb的代码，<code class="du kv kw kx ky b">pool.wait_until_not_full unless queue_requests</code>选项看起来很有前途。事实证明，这正是我们想要的选择！我们可以让Puma只接受有线程可用的连接。</p><p id="fc39" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">注意，2017年6月初发布的Puma 3.9.0，现在只有<em class="lp">的</em>接受可以立即处理的连接。这个时间与我们的挖掘无关，是一个愉快的巧合。</p><p id="c1db" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">在所有这些之后，我们将<code class="du kv kw kx ky b">queue_requests false</code>添加到我们的Puma配置中，并重新运行测试……得到完全相同的结果。Puma处理了10个请求，基准测试中有6个成功，4个失败。</p><p id="d34f" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">根据以前使用套接字的经验，我们知道TCP套接字最终会使用syscall <a class="ae ip" href="https://linux.die.net/man/2/listen" rel="noopener ugc nofollow" target="_blank"> listen </a>(在Linux中)。查看文档，我们看到backlog参数“定义了sockfd的挂起连接队列可以增长到的最大长度”。</p><h1 id="b13a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">一路向下排队</h1><p id="614d" class="pw-post-body-paragraph iq ir hh is b it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm io ha bi translated">TCP的核心部分之一是缓冲。当客户端发送HTTP请求时，它们不会先连接，等待服务器接受，然后发送HTTP请求。它们试图一次发送所有内容，部分请求将存放在客户端和服务器之间的缓冲区中，直到服务器接受连接或超时。</p><p id="23ca" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">这对性能有好处，但当我们需要可预测的请求队列时就不是这样了。在这一点上，我们向另一位Square工程师Evan Miller询问了backlog和queues的语义，从而了解到Linux有一个握手后套接字的backlog(我们正在查看的backlog ),然后还有一个握手前套接字。这涉及到TCP如何工作的语义，我不会在这里介绍，但是<a class="ae ip" href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Connection_establishment" rel="noopener ugc nofollow" target="_blank">维基百科</a>有一篇文章解释了握手过程。</p><p id="1957" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">因为我们将NGINX放在Puma的前面，所以我们实际上有四个额外的队列:一个在Puma中是握手前和握手后，另一个在NGINX中。查看我们的服务器配置和文档，我们发现握手后队列的最大积压是128。</p><p id="4e74" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">我们将Puma配置为使用两倍于单个实例所能处理的积压。例如，如果我们的一个较小的应用程序可以同时处理10个请求，我们将backlog设置为20。考虑到有多个TCP队列，这并不完美，但它有助于缩小请求排队的范围。</p><p id="f0b0" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">我们已经为Puma这边做了力所能及的事情，但是还是没有看NGINX。</p><h1 id="02b3" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">在NGINX中限制请求</h1><p id="c6da" class="pw-post-body-paragraph iq ir hh is b it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm io ha bi translated">在与其他工程师聊天后，他们提到了<a class="ae ip" href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server" rel="noopener ugc nofollow" target="_blank"> max_conns </a>，这是一个NGINX选项，在1.11.5中可用(付费版本更早一些)。</p><p id="deb7" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">文档看起来很有希望，“限制代理服务器的最大同时活动连接数”，尽管它有一些进一步的警告，注意到由于保持活动连接，它可能会超过限制。</p><p id="85d4" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">我们使用了与backlog相同的默认设置:每个实例可以同时处理两倍的请求。对于我们的测试，服务器一次处理一个请求，我们设置<code class="du kv kw kx ky b">max_conns=3</code>。重新运行测试，我们看到:</p><pre class="kz la lb lc fd lg ky lh li aw lj bi"><span id="804e" class="lk jt hh ky b fi ll lm l ln lo">Starting…<br/>[0] 200 - 4.13<br/>[1] 200 - 9.14<br/>[2] 200 - 14.14<br/>[3] 502 - 0.01<br/>[4] 502 - 0<br/>[5] 502 - 0<br/>[6] 502 - 0<br/>[7] 502 - 0<br/>[8] 502 - 0<br/>[9] 502 - 0<br/>Took 14.14 total, avg of 2.74 in thread time, max 14.14, min 0</span></pre><p id="3737" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">Puma日志只显示了3个请求，nginx拒绝了另外7个请求，因为我们超过了最大连接数。</p><h1 id="607a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">摘要</h1><p id="d84a" class="pw-post-body-paragraph iq ir hh is b it kq iv iw ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm io ha bi translated">队列是有趣的，试图确保客户端和服务器之间的一切是复杂的。NGINX <code class="du kv kw kx ky b">max_conns</code>选项对于大多数情况来说已经足够好了，并且有一个额外的优势，就是在请求到达Ruby应用程序之前拒绝请求。TCP backlog和nginx队列更改是额外的一层保护，减少了长期请求隐藏在NGINX和Puma之间的队列中的机会。</p><p id="c5d0" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">随着这些变化，当应用程序由于下游问题而变慢时，我们预计会看到更多确定性的故障模式。他们不会排队等待超出应用程序实际处理能力的请求，而是会更快地对错误做出响应。</p><p id="7c24" class="pw-post-body-paragraph iq ir hh is b it jn iv iw ix jo iz ja jb jp jd je jf jq jh ji jj jr jl jm io ha bi translated">这些方法并不完美，但是单个宿主变得不健康的速度越快，它就可以越快地退出循环，并有机会赶上并再次变得健康。</p></div></div>    
</body>
</html>