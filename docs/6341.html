<html>
<head>
<title>Debugging Deadlock in PininfoService Ubuntu18 Upgrade: Part 2 of 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调试PininfoService Ubuntu18升级中的死锁:第2部分，共2部分</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-2-of-2-f49b654bff37?source=collection_archive---------4-----------------------#2022-03-09">https://medium.com/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-2-of-2-f49b654bff37?source=collection_archive---------4-----------------------#2022-03-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2396" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像做研究一样解决工程问题</p><p id="9de7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">李康南|关键价值系统软件工程师</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/bc9558003f9bac3b8fd01441ce859b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-4LK72kQ6lxVLxCZ"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">unlock deadlock for PininfoService</figcaption></figure><p id="f4cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个由两部分组成的博客系列的第2部分，讲述了在现实世界场景中将有状态系统升级到U18的深层系统调试技术。</p><p id="b494" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" rel="noopener" href="/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-1-of-2-116bce917ea2">在第1部分</a>中，我们缩小了观察到的两个问题——QPS掉线和内存使用不一致——来自PininfoService叶层。在本文中，我们将问题进一步缩小到<em class="jt"> GlobalCPUExecutor </em> (GCPU)，并最终找到问题的根本原因:一个<strong class="ig hi">死锁</strong>。</p><p id="e4d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更好地理解请求是如何流入和流出PininfoService的，这里简要总结了PininfoService中按顺序使用的线程(或池)(也可参考<a class="ae js" href="https://www.avabodh.com/thrift/internals.html" rel="noopener ugc nofollow" target="_blank">节约间隔</a>以了解FB节约服务器如何工作):</p><ul class=""><li id="1c3a" class="ju jv hh ig b ih ii il im ip jw it jx ix jy jb jz ka kb kc bi translated"><em class="jt">节俭接受线程</em>:接受来自客户端的连接</li><li id="f819" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><em class="jt">thriftopool</em>:通过PininfoService和向PininfoService发送请求的客户端之间建立的连接处理数据输入/输出</li><li id="2d96" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><em class="jt">thriftworerpool</em>:PininfoService逻辑中提供的线程管理器，用于处理aync_tm_ &lt; API &gt;函数调用</li><li id="b600" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><em class="jt"> GlobalCPUExecutor </em>:一个全局CPU池，用于委派繁重的工作，例如处理来自上游数据存储的响应</li><li id="6a42" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><em class="jt"> ThriftClientPool </em>:与上游数据存储对话的客户端池</li></ul><p id="52e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将深入探讨如何利用工具来调试观察到的两个问题(QPS掉线和内存使用不一致)，特别关注内存问题。</p><h1 id="c6e9" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">探究原因:QPS下降和不一致的内存使用</h1><p id="a675" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">为了找出QPS下降到0的原因，我们使用“tcpdump”工具来获得以下跟踪</p><p id="ed73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自显示从节约服务器卸载的输出包(<a class="ae js" href="https://www.tcpdump.org/manpages/tcpdump.1.html" rel="noopener ugc nofollow" target="_blank"> tcpdump </a>)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ll"><img src="../Images/b8d205d6af3afc474bdadd5a63f4ba6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u3vX0tQ0VVF3ZumJ9y2ewQ.png"/></div></div></figure><p id="5bff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">18:58:06.607828 IP 10 . 3 . 42 . 154 . 9090 &gt; 10 . 3 . 19 . 45 . 60262:Flags[p .]，seq 1055:1117，ack 7460，win 686，options [nop，nop，TS val 2486825918 ecr 507682922]，长度62 <br/> E..r^.@.@……<br/>。*.<br/>..-#..外键(foreign key)..Y &amp;..&amp; ….R1…..<br/>. 9……b . j……:………………例1……b..getMany..减载请求…</p><h2 id="4c0f" class="lm kj hh bd kk ln lo lp ko lq lr ls ks ip lt lu kw it lv lw la ix lx ly le lz bi translated">使用<a class="ae js" href="https://en.wikipedia.org/wiki/Five_whys#:~:text=Five%20whys%20(or%205%20whys,basis%20of%20the%20next%20question." rel="noopener ugc nofollow" target="_blank">五个为什么</a>进行减载分析</h2><p id="599c" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">在Pinterest，我们使用“五个为什么”作为关键的根本原因分析框架。下面是我们如何将它应用到这个场景中:</p><p id="d051" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">PininfoService传出数据包包含“减载”</p><pre class="jd je jf jg fd ma mb mc md aw me bi"><span id="8cca" class="lm kj hh mb b fi mf mg l mh mi">Why? This is likely due to hosts not able to process the amount of thrift request</span><span id="9678" class="lm kj hh mb b fi mj mg l mh mi">Why are hosts not able to process? Thrift server has <em class="jt">active_req (</em>130K)<em class="jt"> &gt; max request (~65K)</em>, thus load shedding</span><span id="239e" class="lm kj hh mb b fi mj mg l mh mi">Why is there such a high <em class="jt">active_req</em> queue? High <em class="jt">active_req</em> could either be due to: 1) traffic increase causing the thrift server overloading, or 2) deadlock which cause requests to be queued up and not passed on to the <em class="jt">ThriftWorkerPool</em> threads which aim to execute the async_tm_&lt;API&gt; function calls, otherwise QPS stats would have been reported from these API logics.</span><span id="d83c" class="lm kj hh mb b fi mj mg l mh mi">- We are able to rule out 1) since all the system metrics such as CPU, memory are still very low.</span><span id="9b2d" class="lm kj hh mb b fi mj mg l mh mi">- Thus, it’s likely a deadlock. But how does deadlock form? We need to investigate and answer this “why”. We turned to the inconsistent memory usage to try to gather more hints into the problem.</span></pre><h2 id="f0a8" class="lm kj hh bd kk ln lo lp ko lq lr ls ks ip lt lu kw it lv lw la ix lx ly le lz bi translated">内存使用调试</h2><p id="ae1b" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">我们还使用了<a class="ae js" href="https://github.com/goldshtn/linux-tracing-workshop/blob/master/bpf-memleak.md" rel="noopener ugc nofollow" target="_blank"> BPF工具</a>来验证没有检测到内存泄漏。接下来，通过两个工具从内存使用量不断增加的主机获取堆转储:jemalloc/jeprof ( <a class="ae js" href="https://github.com/jemalloc/jemalloc/wiki/Use-Case:-Heap-Profiling" rel="noopener ugc nofollow" target="_blank"> github </a>)和tcmalloc/gperftools(<a class="ae js" href="https://gperftools.github.io/gperftools/heapprofile.html" rel="noopener ugc nofollow" target="_blank">Gperftool wiki</a>)。这两个工具为堆转储提供了相似的功能，并生成了相似的结果。</p><p id="71d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自Gperftool的数据如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mk"><img src="../Images/bb4abe896a60c380233efcfbc8c00217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s4gGQ2OSjjNWkP3T"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd kk"><em class="ml">Graph 2.</em></strong> Heap profiling snippet of U18 leaf-only host with Gperftool (tcmalloc)</figcaption></figure><p id="ad36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与健康的U14主机相比，来自GCPU的这一超高百分比的堆消耗以及上面的"<a class="ae js" href="https://docs.google.com/document/d/17yYFBP80F0169Q1bAbw6Aoj81qO4nrJYpU61yL6V9Fc/edit#heading=h.13vvhnlfkzk3" rel="noopener ugc nofollow" target="_blank">五个为什么分析</a>"表明(如<strong class="ig hi">提示2</strong>)GCPU可能有"问题"。结合我们在本系列第1部分中描述的发现<a class="ae js" rel="noopener" href="/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-1-of-2-116bce917ea2">，线程池运行时参数调优对缓解这两个问题有很大的影响，我们相信线程池可能与这些问题有关，特别是GCPU。</a></p><h2 id="5d03" class="lm kj hh bd kk ln lo lp ko lq lr ls ks ip lt lu kw it lv lw la ix lx ly le lz bi translated">用GDB调试</h2><p id="f5d9" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">在一次<em class="jt">Test1–2</em>运行期间，<a class="ae js" href="https://man7.org/linux/man-pages/man1/top.1.html" rel="noopener ugc nofollow" target="_blank"> top </a>用于检查经历“QPS降至0”的U18仅叶主机和健康的U14主机的线程状态。虽然健康的U14主机有<em class="jt">thriftworperpool</em>、<em class="jt">thriftwlientpool</em>和GCPU线程主动执行任务并消耗CPU/内存，但U18测试主机的大多数线程都相当空闲。</p><p id="ed55" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，使用GDB来附加“卡住的”PininfoService进程，以探测线程，如下所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mm"><img src="../Images/84db63f673be4bb27bc9e1498d672fd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6fI_o-zqmwa85LgazZ9PIQ.png"/></div></div></figure><p id="82d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">需要探测四种类型的线程:</p><ul class=""><li id="d7ca" class="ju jv hh ig b ih ii il im ip jw it jx ix jy jb jz ka kb kc bi translated"><em class="jt"> pininfo-thrift </em>，<em class="jt">thrift ipool</em>threads。堆栈跟踪显示空闲。</li><li id="73a4" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated"><em class="jt"> work-pri-3 </em>，thriftworerpool<em class="jt">thriftworerpool</em>线程管理器管理的工作线程。堆栈跟踪显示空闲。</li><li id="d7f8" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">“<em class="jt"> g-cpu </em>”，来自GCPU的线程。堆栈跟踪如下。</li><li id="915f" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">“<em class="jt"> io- &lt;上游&gt; </em>”，线程来自<em class="jt"> ThriftClientPool </em>。堆栈跟踪如下。</li></ul><p id="483e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt">检查一个“g-cpu”线程</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mn"><img src="../Images/0ada0f55a6423a4c9977efe622b796ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aV0ArDUCLZIpeZLvV5rmSg.png"/></div></div></figure><p id="ce66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">g-cpu线程正在执行来自ThriftRouter的代码，thrift router正在阻塞等待删除一个<em class="jt"> ClientStatus </em>(即。节俭上游客户端)，其需要将来自<a class="ae js" href="https://github.com/pinterest/rocksplicator/blob/master/common/thrift_client_pool.h#L414" rel="noopener ugc nofollow" target="_blank"> thrift_client_pool.h </a>的<em class="jt">删除器</em>任务排队到<em class="jt">节俭客户端池</em>。显然，“<em class="jt">io-rockstorasync</em>”的<em class="jt"> ThriftClientPool </em>不可用，因此g-cpu线程正在等待。</p><p id="b8fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt">检查ThriftClientPool线程“io-RockstoreAsy”</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mo"><img src="../Images/cc7e59802accc5c8ff81f2930206cf89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1PYED16AvYQ3mw0zdUKYQ.png"/></div></div></figure><p id="c84f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt"> ThriftClientPool </em>线程正在为MultiGetRequest执行一个网络调用，它试图将“<em class="jt"> process_response </em>”任务排入GCPU队列。它执行GCPU代码以<strong class="ig hi">检查</strong>是否需要在该任务入队之前加入停止的GCPU线程。然后继续加入已停止的GCPU线程，<strong class="ig hi">等待<em class="jt"> std::thread </em>上的</strong>加入(阻塞！).但是,“停止”的GCPU线程无法成功加入，因为它们正在等待<em class="jt"> ThriftClientPool </em>执行<em class="jt"> Deleter </em>来释放GCPU线程内的thrift客户端。因此，GCPU和<em class="jt"> ThriftClientPool </em>互相阻塞等待，形成如下所示的死锁。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mp"><img src="../Images/a6bd8d2d28504547b1447859d8b12369.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vQGUlNtzm184QO-e"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx"><strong class="bd kk"><em class="ml">Scheme 4</em></strong>. Deadlock due to dynamic CPUThreadPoolExecutor</figcaption></figure><p id="a7dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过检查git对<a class="ae js" href="https://github.com/facebook/folly/blame/main/folly/executors/ThreadPoolExecutor.cpp#L449" rel="noopener ugc nofollow" target="_blank"> ThreadPoolExecutor.cpp </a>的指责，可疑的“ThreadPoolExecutor::ensure joined”是大约四年前由commit ( <a class="ae js" href="https://github.com/facebook/folly/commit/68a6b5b55b177ae5d9c60a65f9e79f3eb57d10af" rel="noopener ugc nofollow" target="_blank"> 68a6b5 </a>)添加的，介于我们的U14和U18 folly版本之间。这个pull请求添加了“动态CPUThreadPoolExecutor”，它在超时后创建CPUthreads并加入线程，这很可能就是我们的例子中发生的情况。由于这个动态特性可能被“—dynamic _ cputhreadpoolexecutor = false”禁用，我们通过添加这个标志重新运行测试(重用<a class="ae js" rel="noopener" href="/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-1-of-2-116bce917ea2"> part1 </a>中的<em class="jt">Test1–2</em>设置)。QPS保持稳定，内存使用增加到约200GB并保持稳定，因此问题(QPS降至0或内存使用不一致)得到解决！通过移除这种“动态CPUThreadPoolExecutor”更改，当<em class="jt"> ThriftClientPool </em>试图将一个“<em class="jt"> process_response </em>”任务入队并且GCPU队列已满时，它不会因GCPU已满而阻塞。入队操作将故障转移到<em class="jt"> ThritClientPool </em>线程本身，并完成入队操作，从而防止死锁。</p><h1 id="e726" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">将U18构建部署到U14生产环境的一台主机上</h1><p id="f3b3" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">在从测试环境中获得乐观的结果之后，具有以下优化运行时配置的U18构建正在向具有一个生产主机的canary环境推广(第1部分中的<strong class="ig hi"> <em class="jt">方案1 </em> </strong>):</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mq"><img src="../Images/98e54341e3e51ee8ddc2280965017b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*haQqrsh51QuBtt0nUO9cuA.png"/></div></div></figure><p id="30c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种单主机部署是有意义的，因为在当前生产环境设置中，该主机将接收与所有其他U14生产主机相同的流量。在U18到U14主机之间成功运行了两天多，性能相当之后，我们对整个服务应用了就地升级，并成功升级到U18，没有任何客户端影响。</p><h1 id="daf5" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">第二部分摘要</h1><p id="b727" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">在本文中，我们采用了使用jemalloc或tcmalloc进行堆转储的工具，这进一步指出了GCPU线程池正在消耗额外的堆使用率。最后，我们使用GDB来确定死锁，这是由于一个新的特性(即动态CPUThreadPoolExecutor)是在我们的U18 docker映像使用的后来的Folly版本中添加的。禁用此功能后，我们能够解决问题并成功完成U18升级。</p><h1 id="0a08" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">教训和最终结果</h1><p id="3a6c" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">回顾过去，我们意识到无论是“重新调整运行时参数”测试的结果(如<a class="ae js" rel="noopener" href="/pinterest-engineering/debugging-deadlock-in-pininfoservice-ubuntu18-upgrade-part-1-of-2-116bce917ea2"> <strong class="ig hi"> hint1 </strong> </a>)还是“内存使用调试”的堆转储(如<a class="ae js" href="https://docs.google.com/document/d/17yYFBP80F0169Q1bAbw6Aoj81qO4nrJYpU61yL6V9Fc/edit#heading=h.elbxqpjwqs82" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> hint2 </strong> </a>)都指出了GCPU的问题，而展望未来，我们需要花费大量精力来查明GCPU并最终使用GDB来找到死锁。</p><p id="72da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过禁用动态CPUThreadPoolExecutor，我们解除了U18升级。但仍需解决以下问题:</p><ul class=""><li id="f2ee" class="ju jv hh ig b ih ii il im ip jw it jx ix jy jb jz ka kb kc bi translated">首先是什么原因导致GCPU队列爆满？</li><li id="b3d2" class="ju jv hh ig b ih kd il ke ip kf it kg ix kh jb jz ka kb kc bi translated">禁用动态GCPU队列功能会给我们带来什么好处？</li></ul><p id="e138" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">调试让我们持续不断地学习。我们将继续努力解决这些和其他问题，以继续加强我们的技能，加深我们对系统的理解。</p><p id="316e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总结本案例研究，随着最后一个服务(PininfoService)被解除阻塞并成功升级到U18，再加上迁移另外约12K个有状态实例以提供只读数据的其他努力，我们能够将超过24K个有状态实例从U14升级到U18，而没有发生任何影响生产的事件。</p><h1 id="a288" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">确认</h1><p id="822e" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">Key Value Systems团队的U14到U18迁移是工程师Kangnan Li、Rakesh Kalidindi、Carlos Castellanos、Madeline Nguyen和Harold Cabalic几个月来的巨大努力，总共完成了12K以上有状态实例的升级。特别感谢刘波、Alberto Ordonez Pereira、Saurabh Joshi、Prem Kumar和Rakesh Kalidindi在调试过程中提供的丰富信息和帮助。感谢Key Value团队经理Jessica Chan、技术主管Rajath Prasadfor对这项工作的支持。</p><p id="6661" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt">要在Pinterest上了解更多工程知识，请查看我们的</em> <a class="ae js" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="jt">工程博客</em> </a> <em class="jt">，并访问我们的</em><a class="ae js" href="https://www.pinterestlabs.com/?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=li-march-8-2022" rel="noopener ugc nofollow" target="_blank"><em class="jt">Pinterest Labs</em></a><em class="jt">网站。要查看和申请公开招聘机会，请访问我们的</em> <a class="ae js" href="https://www.pinterestcareers.com/?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=li-march-8-2022" rel="noopener ugc nofollow" target="_blank"> <em class="jt">招聘</em> </a> <em class="jt">页面。</em></p></div></div>    
</body>
</html>