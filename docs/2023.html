<html>
<head>
<title>What is scikit learn — a beginner guide to popular machine learning Python library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是scikit learn——流行的机器学习Python库的初学者指南</h1>
<blockquote>原文：<a href="https://medium.com/duomly-blockchain-online-courses/what-is-scikit-learn-a-beginner-guide-to-popular-machine-learning-python-library-df810e52f016?source=collection_archive---------2-----------------------#2019-09-05">https://medium.com/duomly-blockchain-online-courses/what-is-scikit-learn-a-beginner-guide-to-popular-machine-learning-python-library-df810e52f016?source=collection_archive---------2-----------------------#2019-09-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/95862e7b795e182cb78ba1c1d41d3e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGKmjQR576_EcYscfGrHzg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.duomly.com" rel="noopener ugc nofollow" target="_blank">Duomly — programming online courses</a></figcaption></figure><p id="5c6d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文最初发表于:</p><div class="js jt ez fb ju jv"><a href="https://www.blog.duomly.com/what-is-scikit-learn-introduction-to-popular-machine-learning-and-data-science-python-library/" rel="noopener  ugc nofollow" target="_blank"><div class="jw ab dw"><div class="jx ab jy cl cj jz"><h2 class="bd hi fi z dy ka ea eb kb ed ef hg bi translated">什么是scikit learn -流行的机器学习和数据科学Python库介绍…</h2><div class="kc l"><h3 class="bd b fi z dy ka ea eb kb ed ef dx translated">Scikit-learn是用于数据科学和机器学习的最广泛使用的Python包之一。它使您能够…</h3></div><div class="kd l"><p class="bd b fp z dy ka ea eb kb ed ef dx translated">www.blog.duomly.com</p></div></div><div class="ke l"><div class="kf l kg kh ki ke kj in jv"/></div></div></a></div></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><p id="5adc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Scikit-learn是用于数据科学和机器学习的最广泛使用的Python包之一。它使您能够执行许多操作，并提供各种算法。Scikit-learn还提供了关于其类、方法和函数的优秀文档，以及对所用算法背景的解释。</p><p id="5f32" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Scikit-learn支持:</p><ul class=""><li id="922c" class="kr ks hh iw b ix iy jb jc jf kt jj ku jn kv jr kw kx ky kz bi translated">数据预处理，</li><li id="16a7" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">降维，</li><li id="901b" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">型号选择，</li><li id="fec0" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">回归，</li><li id="7939" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">分类，</li><li id="e710" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">聚类分析。</li></ul><p id="4fdd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它还提供了几个数据集，您可以用来测试您的模型。</p><p id="48d5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Scikit-learn并没有实现与机器学习相关的所有东西。例如，它不全面支持:</p><ul class=""><li id="f826" class="kr ks hh iw b ix iy jb jc jf kt jj ku jn kv jr kw kx ky kz bi translated">神经网络，</li><li id="ad28" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">自组织地图(Kohonen的网络)，</li><li id="a10b" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">关联规则学习，</li><li id="a6e3" class="kr ks hh iw b ix la jb lb jf lc jj ld jn le jr kw kx ky kz bi translated">强化学习，等等。</li></ul><p id="fcca" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Scikit-learn是建立在NumPy和SciPy之上的，所以您至少需要了解这两个库的基础知识才能有效地应用它。</p><p id="047a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Scikit-learn是一个开源包。像Python生态系统中的大多数东西一样，它甚至对于商业用途也是免费的。它是在BSD许可下授权的。</p><p id="1ff4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文旨在简明地介绍scikit-learn的一些可能性，但不涉及太多细节。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="c1d8" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据预处理</h1><p id="75db" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">您可以使用scikit-learn为机器学习算法准备数据:标准化或规范化数据、编码分类变量等等。</p><p id="0f23" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们首先定义一个NumPy数组:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="c05b" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; x = np.array([[0.1, 1.0, 22.8],<br/>...               [0.5, 5.0, 41.2],<br/>...               [1.2, 12.0, 2.8],<br/>...               [0.8, 8.0, 14.0]])<br/>&gt;&gt;&gt; x<br/>array([[ 0.1,  1. , 22.8],<br/>       [ 0.5,  5. , 41.2],<br/>       [ 1.2, 12. ,  2.8],<br/>       [ 0.8,  8. , 14. ]])</span></pre><p id="6676" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您通常需要以这样的方式转换数据，即每列(要素)的平均值为零，标准差为一。您可以应用sk learn . preprocessing . standard scaler类来完成此操作:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="0c6d" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler<br/>&gt;&gt;&gt; scaler = StandardScaler()<br/>&gt;&gt;&gt; scaled_x = scaler.fit_transform(x)<br/>&gt;&gt;&gt; scaler.scale_<br/>array([ 0.40311289,  4.03112887, 14.04421589])<br/>&gt;&gt;&gt; scaler.mean_<br/>array([ 0.65,  6.5 , 20.2 ])<br/>&gt;&gt;&gt; scaler.var_<br/>array([1.6250e-01, 1.6250e+01, 1.9724e+02])<br/>&gt;&gt;&gt; scaled_x<br/>array([[-1.36438208, -1.36438208,  0.18512959],<br/>       [-0.3721042 , -0.3721042 ,  1.4952775 ],<br/>       [ 1.36438208,  1.36438208, -1.23894421],<br/>       [ 0.3721042 ,  0.3721042 , -0.44146288]])<br/>&gt;&gt;&gt; scaled_x.mean().round(decimals=4)<br/>0.0<br/>&gt;&gt;&gt; scaled_x.mean(axis=0)<br/>array([ 1.66533454e-16, -1.38777878e-17,  1.52655666e-16])<br/>&gt;&gt;&gt; scaled_x.std(axis=0)<br/>array([1., 1., 1.])<br/>&gt;&gt;&gt; scaler.inverse_transform(scaled_x)<br/>array([[ 0.1,  1. , 22.8],<br/>       [ 0.5,  5. , 41.2],<br/>       [ 1.2, 12. ,  2.8],<br/>       [ 0.8,  8. , 14. ]])</span></pre><p id="9138" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有时，您会有一些分类数据，需要将其转换成有意义的数字。其中一种方法是使用sk learn . preprocessing . onehotencoder类。</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="7bcf" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; from sklearn.preprocessing import OneHotEncoder<br/>&gt;&gt;&gt; roles = np.array([('Tom', 'manager'),<br/>...                   ('Mary', 'developer'),<br/>...                   ('Ann', 'recruiter'),<br/>...                   ('Jim', 'developer')])<br/>&gt;&gt;&gt; roles<br/>array([['Tom', 'manager'],<br/>       ['Mary', 'developer'],<br/>       ['Ann', 'recruiter'],<br/>       ['Jim', 'developer']], dtype='&lt;u9')&gt;&gt;&gt; encoder = OneHotEncoder()<br/>&gt;&gt;&gt; encoded_roles = encoder.fit_transform(roles[:, [1]])<br/>&gt;&gt;&gt; encoded_roles.toarray()<br/>array([[0., 1., 0.],<br/>       [1., 0., 0.],<br/>       [0., 0., 1.],<br/>       [1., 0., 0.]])&lt;/u9')&gt;</span></pre><p id="3dfb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在上面的例子中，对象encoded_roles的第一列指示每个雇员是否是开发人员。第二个和第四个雇员(Mary和Jim)是。第二列与经理的职位有关。只有第一个员工(Tom)有这个职位。最后，第三列对应于招聘人员，第三个雇员(Ann)就是那个人。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="0f67" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">降维</h1><p id="f3e2" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">降维包括选择或提取多维数据集最重要的组成部分(特征)。Scikit-learn提供了几种降维方法。其中之一是主成分分析或PCA。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="3116" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">型号选择</h1><p id="76c2" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">在训练和测试机器学习模型时，需要将数据集随机分成训练集和测试集。这包括输入及其相应的输出。函数sk learn . model _ selection . train _ test _ split()在这种情况下很有用:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="8430" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; from sklearn.model_selection import train_test_split<br/>&gt;&gt;&gt; x, y = np.arange(1, 21).reshape(-1, 2), np.arange(3, 40, 4)<br/>&gt;&gt;&gt; x<br/>array([[ 1,  2],<br/>       [ 3,  4],<br/>       [ 5,  6],<br/>       [ 7,  8],<br/>       [ 9, 10],<br/>       [11, 12],<br/>       [13, 14],<br/>       [15, 16],<br/>       [17, 18],<br/>       [19, 20]])<br/>&gt;&gt;&gt; y<br/>array([ 3,  7, 11, 15, 19, 23, 27, 31, 35, 39])<br/>&gt;&gt;&gt; x_train, x_test, y_train, y_test =\<br/>...     train_test_split(x, y, test_size=0.4, random_state=0)<br/>&gt;&gt;&gt; x_train<br/>array([[ 3,  4],<br/>       [13, 14],<br/>       [15, 16],<br/>       [ 7,  8],<br/>       [ 1,  2],<br/>       [11, 12]])<br/>&gt;&gt;&gt; y_train<br/>array([ 7, 27, 31, 15,  3, 23])<br/>&gt;&gt;&gt; x_test<br/>array([[ 5,  6],<br/>       [17, 18],<br/>       [ 9, 10],<br/>       [19, 20]])<br/>&gt;&gt;&gt; y_test<br/>array([11, 35, 19, 39])</span></pre><p id="21bd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">除了执行普通的数据集分割，scikit-learn还提供了实施交叉验证的方法，通过网格搜索调整模型的超参数，计算显示模型性能的许多量(例如，决定系数、均方误差、解释方差得分、混淆矩阵、分类报告、f-measures等)。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="3b4f" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据集</h1><p id="c469" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">Scikit-learn提供了几个适合学习和测试模型的数据集。这些大多是众所周知的数据集。它们大到足以为测试模型提供足够的数据量，但也小到足以实现可接受的训练持续时间。</p><p id="1fdc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">例如，函数sklearn.datasets.load_boston()返回波士顿地区的房价数据(房价没有更新！).有506个观察值，而输入矩阵有13列(特征):</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="0c92" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; from sklearn.datasets import load_boston<br/>&gt;&gt;&gt; x, y = load_boston(return_X_y=True)<br/>&gt;&gt;&gt; x.shape, y.shape<br/>((506, 13), (506,))</span></pre><p id="feed" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该数据集适用于多变量回归。</p><p id="137d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">另一个例子是与葡萄酒相关的数据集。它可以通过函数sklearn.datasets.load_wine()获得:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="4208" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; from sklearn.datasets import load_wine<br/>&gt;&gt;&gt; x, y = load_wine(return_X_y=True)<br/>&gt;&gt;&gt; x.shape, y.shape<br/>((178, 13), (178,))<br/>&gt;&gt;&gt; np.unique(y)<br/>array([0, 1, 2])</span></pre><p id="9708" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个数据集适合分类。它包含了13个与来自意大利的三个不同的葡萄酒种植者相关的特征。有178个观察值。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="b926" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">回归</h1><p id="9af4" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">Scikit-learn支持多种回归方法，从线性回归和<em class="mw">k</em>-最近邻开始，通过多项式回归、支持向量回归、决策树等。到像随机森林和梯度推进这样的集成方法。它也支持神经网络，但不像TensorFlow这样的专业库那样支持。</p><p id="2e76" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将在这里展示随机森林回归。</p><p id="9bc1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们通常从导入我们需要的包、类和函数开始回归之旅:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="a8d1" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; from sklearn.datasets import load_boston<br/>&gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor<br/>&gt;&gt;&gt; from sklearn.model_selection import train_test_split</span></pre><p id="a14e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下一步是获取要处理的数据，并将数据集分成训练和测试子集。在本文中，我们将使用波士顿数据集:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="dfc0" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; x, y = load_boston(return_X_y=True)<br/>&gt;&gt;&gt; x_train, x_test, y_train, y_test =\<br/>...     train_test_split(x, y, test_size=0.33, random_state=0)</span></pre><p id="dc8a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有些方法要求您扩展(标准化)数据，而有些方法是可选的。这次我们将继续不缩放。</p><p id="63ee" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们需要创建我们的回归变量，并用为训练选择的数据子集来拟合(训练)它:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="8155" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; regressor = RandomForestRegressor(n_estimators=10, random_state=0)<br/>&gt;&gt;&gt; regressor.fit(x_train, y_train)<br/>RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,<br/>                      max_features='auto', max_leaf_nodes=None,<br/>                      min_impurity_decrease=0.0, min_impurity_split=None,<br/>                      min_samples_leaf=1, min_samples_split=2,<br/>                      min_weight_fraction_leaf=0.0, n_estimators=10,<br/>                      n_jobs=None, oob_score=False, random_state=0, verbose=0,<br/>                      warm_start=False)</span></pre><p id="26ca" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一旦模型被训练，我们检查它在训练集上的得分(决定系数)，以及在测试集上更重要的是，用数据<em class="mw">而不是</em>来拟合模型:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="7669" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; regressor.score(x_train, y_train)<br/>0.9680930547240916<br/>&gt;&gt;&gt; regressor.score(x_test, y_test)<br/>0.8219576562705848</span></pre><p id="6c46" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用该方法，一个足够好的模型可以用于预测具有一些新输入数据x_new的输出。predict():regressor . predict(x _ new)。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="e203" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">分类</h1><p id="9a4c" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">Scikit-learn执行分类的方式与回归非常相似。它支持各种分类方法，如逻辑回归和<em class="mw">k</em>-最近邻、支持向量机、朴素贝叶斯、决策树，以及集成方法，如随机森林、AdaBoost和梯度增强。</p><p id="decd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文说明了如何使用随机森林方法进行分类。这种方法与回归的情况非常相似。然而，现在我们使用葡萄酒数据集，定义分类器，并用分类精度而不是决定系数来评估它:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="ed0f" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; from sklearn.datasets import load_wine<br/>&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier<br/>&gt;&gt;&gt; from sklearn.model_selection import train_test_split</span><span id="fd47" class="mr lg hh mn b fi mx mt l mu mv">&gt;&gt;&gt; x, y = load_wine(return_X_y=True)<br/>&gt;&gt;&gt; x_train, x_test, y_train, y_test =\<br/>...     train_test_split(x, y, test_size=0.33, random_state=0)</span><span id="726a" class="mr lg hh mn b fi mx mt l mu mv">&gt;&gt;&gt; classifier = RandomForestClassifier(n_estimators=10, random_state=0)<br/>&gt;&gt;&gt; classifier.fit(x_train, y_train)<br/>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',<br/>                       max_depth=None, max_features='auto', max_leaf_nodes=None,<br/>                       min_impurity_decrease=0.0, min_impurity_split=None,<br/>                       min_samples_leaf=1, min_samples_split=2,<br/>                       min_weight_fraction_leaf=0.0, n_estimators=10,<br/>                       n_jobs=None, oob_score=False, random_state=0, verbose=0,<br/>                       warm_start=False)</span><span id="3c43" class="mr lg hh mn b fi mx mt l mu mv">&gt;&gt;&gt; classifier.score(x_train, y_train)<br/>1.0<br/>&gt;&gt;&gt; classifier.score(x_test, y_test)<br/>1.0</span></pre><p id="f187" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用该方法，可以使用足够好的模型来预测具有新输入数据的输出。predict():regressor . predict(x _ new)。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="eeff" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">聚类分析</h1><p id="9be5" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">聚类是scikit-learn中广泛支持的无监督学习的一个分支。除了<em class="mw"> k </em> -means聚类之外，它还使您能够应用相似性传播、谱聚类、凝聚聚类等。</p><p id="7d24" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将在本文中展示<em class="mw">k</em>-均值聚类。实施时，请注意标准化或规范化数据是否有意义，尤其是哪种距离度量是合适的(大多数情况下可能是欧几里德距离)。</p><p id="53c1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">同样，我们从导入和获取数据开始。这一次，我们将使用NumPy和sklearn.cluster.KMeans:</p><p id="bd29" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用该方法，一个足够好的模型可以用于预测具有一些新输入数据x_new的输出。predict():regressor . predict(x _ new)。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="658e" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">分类</h1><p id="ee1f" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">Scikit-learn执行分类的方式与回归非常相似。它支持各种分类方法，如逻辑回归和最近邻、支持向量机、朴素贝叶斯、决策树，以及集成方法，如随机森林、AdaBoost和梯度增强。</p><p id="5244" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文说明了如何使用随机森林方法进行分类。这种方法与回归的情况非常相似。然而，现在我们使用葡萄酒数据集，定义分类器，并用分类精度而不是决定系数来评估它:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="348d" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; from sklearn.cluster import KMeans</span><span id="c640" class="mr lg hh mn b fi mx mt l mu mv">&gt;&gt;&gt; x = np.array([(0.0, 0.0),<br/>...               (9.9, 8.1),<br/>...               (-1.0, 1.0),<br/>...               (7.1, 5.6),<br/>...               (-5.0, -5.5),<br/>...               (8.0, 9.8),<br/>...               (0.5, 0.5)])<br/>&gt;&gt;&gt; x<br/>array([[ 0. ,  0. ],<br/>       [ 9.9,  8.1],<br/>       [-1. ,  1. ],<br/>       [ 7.1,  5.6],<br/>       [-5. , -5.5],<br/>       [ 8. ,  9.8],<br/>       [ 0.5,  0.5]])</span></pre><p id="1443" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下一步是扩展数据，但这并不总是强制性的。然而，在很多情况下，这确实是一个好主意。然而，一旦数据预处理完成，我们就创建一个KMeans的实例，并用我们的数据来拟合它:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="77b0" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; cluster_analyzer = KMeans(n_clusters=3, init='k-means++')<br/>&gt;&gt;&gt; cluster_analyzer.fit()<br/>&gt;&gt;&gt; cluster_analyzer.fit(x)<br/>KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,<br/>       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',<br/>       random_state=None, tol=0.0001, verbose=0)</span></pre><p id="7ee9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们已经准备好获取结果，例如聚类中心的坐标和每个观察值所属的聚类的标签:</p><pre class="mi mj mk ml fd mm mn mo mp aw mq bi"><span id="4aaf" class="mr lg hh mn b fi ms mt l mu mv">&gt;&gt;&gt; cluster_analyzer.cluster_centers_<br/>array([[ 8.33333333,  7.83333333],<br/>       [-0.16666667,  0.5       ],<br/>       [-5.        , -5.5       ]])<br/>&gt;&gt;&gt; cluster_analyzer.labels_<br/>array([1, 0, 1, 0, 2, 0, 1], dtype=int32)</span></pre><p id="4280" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可以使用方法。predict()为新观测值获取最接近的聚类。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="1296" class="lf lg hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">结论</h1><p id="e278" class="pw-post-body-paragraph iu iv hh iw b ix md iz ja jb me jd je jf mf jh ji jj mg jl jm jn mh jp jq jr ha bi translated">本文展示了scikit-learn的基础知识，这是一个非常流行的数据科学和机器学习Python包。它是实现这些目的的基本Python库之一。</p><p id="174f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你想了解更多，你可以很容易地找到许多可用的资源。Duomly关于机器学习的课程涵盖了scikit-learn的许多功能。如前所述，官方文档是广泛而全面的。您应该在应用类或函数之前检查它。</p><figure class="mi mj mk ml fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/90b13908408f321b81be9f13a221830e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0V3J1azlWkx5mqUd.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx"><a class="ae it" href="https://www.duomly.com" rel="noopener ugc nofollow" target="_blank">Duomly — programming online courses</a></figcaption></figure><p id="7693" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢您的阅读！</p><p id="50ed" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">本文由我们的队友米尔科提供。</p></div></div>    
</body>
</html>