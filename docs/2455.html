<html>
<head>
<title>An Introduction to Convolution Neural Network (CNN) for A Beginner</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向初学者的卷积神经网络介绍</h1>
<blockquote>原文：<a href="https://medium.easyread.co/an-introduction-to-convolution-neural-network-cnn-for-a-beginner-88548e4b2a84?source=collection_archive---------4-----------------------#2020-03-07">https://medium.easyread.co/an-introduction-to-convolution-neural-network-cnn-for-a-beginner-88548e4b2a84?source=collection_archive---------4-----------------------#2020-03-07</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><figure class="gl gn jl jm jn jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi jk"><img src="../Images/b47e29c86dbc36c46938f53d179d5aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tfuw_LVaJxZPbkS1wG3p6g.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Photo by <a class="ae jz" href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Alina Grubnyak</a> on <a class="ae jz" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2b51" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="kc io"><em class="ky"/></strong>卷积神经网络【CNN】是深度学习中的一种算法，它是多层感知器(MLP)的发展，设计用于处理网格形式的数据，其中一种是二维图像，如图像或声音。</p><p id="e8a1" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">MLP是效果较好的图像分类方法之一。但是它也有不足之处，即只能识别图像中间的物体，而图像中心以外的物体不能被正确识别。所以解决MLP不足的最佳方案是卷积神经网络(CNN或ConvNet)。CNN不仅能识别图像中间的物体，还能识别图像右角或左角的物体。</p><h1 id="3bf9" class="kz la in bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">卷积神经网络</strong></h1><p id="82cd" class="pw-post-body-paragraph ka kb in kc b kd lx kf kg kh ly kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ig bi translated">你们中的一些人可能对什么是卷积神经网络(CNN)有很多疑问，不是吗？所以让我试着解释给你听。</p><p id="32e0" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如前所述，CNN是深度学习的一部分。CNN主要用于使用监督学习方法对标记数据进行分类。监督学习是机器学习中的一种学习方法，它通过训练数据来获得目标变量，从而对已经标记过的数据进行分类。CNN通常用于进行图像识别、图像分类、对象检测、人脸识别、尝试进行对象或场景检测、对象分割等。</p><p id="08af" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">深度学习的应用实例利用卷积神经网络对R软件的斜视或正常眼图像进行分类。或者脸书使用CNN的简单案例，即如何识别某人的脸并进行自动标记？</p><p id="67f0" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">CNN由具有权重、偏置和激活功能的神经元组成。卷积的体系结构分为三层，即卷积层、池层和全连接层。由这三层CNN构成，因此在处理图像时，该网络分为两大部分，即<strong class="kc io"> <em class="ky">特征提取层</em> </strong>和<strong class="kc io"> <em class="ky">全连接层</em> </strong>。</p><p id="0c8e" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">特征提取层由<strong class="kc io"> <em class="ky">卷积层</em> </strong>和<strong class="kc io"> <em class="ky">汇聚层</em> </strong>组成。全连通层仅由<strong class="kc io"> <em class="ky">全连通层</em> </strong>组成。</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi mc"><img src="../Images/ddcaeb5e83026ef501a3cd8612de58de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdtjPhsi1CAABTVshI0WQw.jpeg"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Types of layers in Convolution Neural Network</figcaption></figure></div><div class="ab cl mh mi hr mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ig ih ii ij ik"><h1 id="98e7" class="kz la in bd lb lc mo le lf lg mp li lj lk mq lm ln lo mr lq lr ls ms lu lv lw bi translated"><strong class="ak">特征提取层</strong></h1><p id="476d" class="pw-post-body-paragraph ka kb in kc b kd lx kf kg kh ly kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ig bi translated">这部分发生的过程是对由计算机从一幅图像翻译成数字形式的特征图像进行编码处理。当一幅图像给计算机时，它不能像我们一样看东西，但计算机会把那幅图像变成一个矩阵。现在，考虑下面的图像，计算机如何将图像处理成矩阵。</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/cd4c883a921b95df596b03d17d464194.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*ONmb8mcAlcSbsY5tiUmnYA.jpeg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">How computer translate image to be a matrix (image from <a class="ae jz" href="https://medium.com/nybles/a-brief-guide-to-convolutional-neural-network-cnn-642f47e88ed4" rel="noopener">this</a>)</figcaption></figure><p id="5412" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">特征提取层分为两部分，即卷积层ReLu(激活函数)和池层。那么，这两层有什么区别呢？下面继续下一部分。</p><h2 id="f0d3" class="mu la in bd lb mv mw dn lf mx my dp lj kl mz na ln kp nb nc lr kt nd ne lv nf bi translated"><strong class="ak">卷积层</strong></h2><p id="1360" class="pw-post-body-paragraph ka kb in kc b kd lx kf kg kh ly kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ig bi translated">卷积层是CNN的第一层，它由神经元组成，神经元以这样的方式排列，以形成具有长度和高度(像素)的过滤器。例如，给计算机的原始RGB图像的大小是5×5像素，因此在卷积层中作为特征提取层的第一层，大小是5×5×3。长度为5个像素，高度为5个像素，通道或滤镜数量为3(从RGB的颜色:红绿蓝)。</p><p id="9081" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated"><strong class="kc io"> <em class="ky">卷积神经网络中使用的参数有三个:</em> </strong></p><ul class=""><li id="6461" class="ng nh in kc b kd ke kh ki kl ni kp nj kt nk kx nl nm nn no bi translated"><strong class="kc io">填充(零填充)</strong></li></ul><p id="4dd0" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">零填充是一个参数，用于确定值为0的像素的数量，这些像素将添加到已转换为矩阵的输入图像的每一侧。</p><p id="f2c9" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">做零填充的目的是操纵卷积层的维度(做一个特征图)。通过执行补零步骤，我们可以将输出维度设置为与输入维度保持相同，或者至少输出维度不会显著降低。所以当使用更深的卷积层时，越来越多的特征被成功提取。</p><p id="ac4f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">此外，零填充能够提高模型的性能，因为卷积的过滤器将集中于零填充之间的真实信息。下面是如何在图像矩阵中应用零填充。</p><p id="7950" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">例如给定尺寸为5×5像素的输入图像。</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div class="gh gi np"><img src="../Images/342962f416e1f55706007ec0759f8072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*HaQWb_VsQXoCJAhDhDUJGw.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Application of zero paddings in the matrix of the input image</figcaption></figure><p id="9931" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">下面是用于计算卷积层输出特征图的公式:</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/52da2cb69dcb5270d736b167c4c9b9fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*7Ki7hwCcgaRwxC4uJDKOeA.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Equation of Convolutional Layer</figcaption></figure><ul class=""><li id="678f" class="ng nh in kc b kd ke kh ki kl ni kp nj kt nk kx nl nm nn no bi translated"><strong class="kc io">跨步</strong></li></ul><p id="bd45" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">步幅是一个确定滤波器移动次数的参数。跨距的最小值是1。如果stride = 1，则意味着卷积滤波器将水平移动1个像素，然后垂直移动。</p><p id="08a8" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">步幅值越小，从输入中获得的信息越详细，但是与步幅值越大相比，需要更多的计算。</p><p id="aa59" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">如果我们使用小步幅值，这并不意味着总能获得相当好的性能。</p><ul class=""><li id="a6eb" class="ng nh in kc b kd ke kh ki kl ni kp nj kt nk kx nl nm nn no bi translated"><strong class="kc io">过滤器</strong></li></ul><p id="245d" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">滤波器是指卷积过程中的输入层数。在具有红、绿、蓝(RGB)颜色值的图像中，这意味着有3个滤镜，那么使用的内核也将达到3个通道。滤镜滤镜的值是从原始颜色RGB颜色中得到的，所以滤镜的值是3。</p><h2 id="6445" class="mu la in bd lb mv mw dn lf mx my dp lj kl mz na ln kp nb nc lr kt nd ne lv nf bi translated"><strong class="ak">汇集层</strong></h2><p id="d77e" class="pw-post-body-paragraph ka kb in kc b kd lx kf kg kh ly kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ig bi translated">汇集层通常在卷积层之后。原则上，池图层由一个具有一定大小的过滤器组成，跨距将在所有要素地图区域内移动。</p><p id="4cab" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">常用的池层有最大池和平均池。例如，我们使用跨度= 2的最大池2 x 2像素，然后在所有过滤器的移动中，将选择2 x 2像素区域中的最大池值，而在平均池中。下面是最大池和平均池的应用。</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/cd082ba263489786dc9d031e34723d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*TEXNsN3Ec-fvNArNwTUCWw.png"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Max Pooling</figcaption></figure><figure class="md me mf mg gt jo gh gi paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="gh gi ns"><img src="../Images/418d66fabfbb856e52c079464023a498.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*IhW6YVwfC_zAhmxCLSWjrA.png"/></div></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Average Pooling</figcaption></figure><p id="0bc4" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">池层的目的是降低特征图的维数(下采样),这样可以快速增加计算量，因为更新的参数变得更小并克服过拟合。</p></div><div class="ab cl mh mi hr mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ig ih ii ij ik"><h1 id="4c42" class="kz la in bd lb lc mo le lf lg mp li lj lk mq lm ln lo mr lq lr ls ms lu lv lw bi translated"><strong class="ak">全连通层</strong></h1><p id="7429" class="pw-post-body-paragraph ka kb in kc b kd lx kf kg kh ly kj kk kl lz kn ko kp ma kr ks kt mb kv kw kx ig bi translated">全连接层(FC层)是用于确定哪个特征与某个类更协作的层，并且该层还具有将特征图变成一维向量的功能。</p><p id="fa86" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">全连通层有许多隐藏层、激活函数、输出层和损失函数。下图是CNN全连接层的架构。</p><figure class="md me mf mg gt jo gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/2a1ee800b76aebc29020e9bc4fa3467b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*MwnCiIMMBzf2F6wr8fuSTA.jpeg"/></div><figcaption class="jv jw gj gh gi jx jy bd b be z dk">Image of Fully Connected Layer in CNN</figcaption></figure><p id="293c" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">有<strong class="kc io">“展平</strong>”过程或重塑特征地图成为一个矢量，以便我们可以使用它作为下一个完全连接层的输入。它的发生是因为从特征提取层(卷积层和池层)得到的特征图仍然以多维数组的形式存在。</p><p id="cf27" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">完全连接的层的目的是使用作为来自特征提取层的结果的特征来将输入图像分类到最具协作性的类别中。</p></div><div class="ab cl mh mi hr mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ig ih ii ij ik"><p id="8b33" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">更多关于卷积神经网络的优秀论文讲解，建议大家访问CNN上斯坦福教程的这个<a class="ae jz" href="http://cs231n.github.io/convolutional-networks/#overview" rel="noopener ugc nofollow" target="_blank"> <strong class="kc io">链接</strong> </a> <strong class="kc io"> </strong>。</p><p id="2e86" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">希望你理解CNN的架构，并喜欢这个概述。如果你有任何疑问或建议或反馈，我感到自由，你可以在下面评论，以便我将来的文章取得更好的效果。</p><p id="5699" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">你也可以关注我来阅读我的文章！</p><p id="b90f" class="pw-post-body-paragraph ka kb in kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi translated">最后，我真的希望你喜欢阅读这篇文章，并请点击小按钮鼓掌家伙。<strong class="kc io">非常感谢！</strong></p></div><div class="ab cl mh mi hr mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ig ih ii ij ik"><figure class="md me mf mg gt jo"><div class="bz fp l di"><div class="nu nv l"/></div></figure></div></div>    
</body>
</html>