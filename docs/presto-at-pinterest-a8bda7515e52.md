# Pinterest 上的 Presto

> 原文：<https://medium.com/pinterest-engineering/presto-at-pinterest-a8bda7515e52?source=collection_archive---------1----------------------->

Ashish Singh | Pinterest 工程师，数据工程

作为一家数据驱动的公司，Pinterest 的许多关键商业决策都是基于对数据的洞察做出的。这些见解由大数据平台团队提供支持，使公司内的其他人能够处理数 Pb 的数据，以找到他们问题的答案。

数据分析是 Pinterest 的一项关键功能，不仅可以回答业务问题，还可以调试工程问题、区分功能优先级、识别用户面临的最常见问题以及了解使用趋势。因此，Pinterest 的工程师和非工程师同样需要这些分析能力。事实证明，SQL 及其变体为员工有效地表达他们的计算需求或分析提供了一个平台。它还在用户代码/查询和底层计算基础设施之间提供了强大的抽象，使基础设施能够在不影响用户的情况下发展。

为了向员工提供交互式查询的关键需求，我们多年来一直与 Presto(一个开源的分布式 SQL 查询引擎)合作。以 Pinterest 的规模运营 Presto 需要解决相当多的挑战。在本帖中，我们分享我们的旅程。

# 概观

下面的图 1 给出了 Presto 在 Pinterest 的部署概况。我们的基础设施建立在亚马逊网络服务(AWS) EC2 之上，我们利用 AWS S3 来存储我们的数据。这分离了计算层和存储层，并允许多个计算群集共享 S3 数据。我们有多个 Presto 集群服务于不同的使用情形。这些集群可以是长期的，也可以是短期的。两种主要的集群是临时集群和调度集群:前者服务于临时查询，后者服务于调度查询。将即席查询与预定查询分开，使我们能够为预定查询提供更好的 SLA，还可以更好地预测预定集群上的资源需求。

Pinterest 的分析需求由一个更传统的数据仓库提供，该数据仓库直到 2016 年才随着 Pinterest 的数据规模而扩展，后来被 Presto 取代。以 Pinterest 的规模运营 Presto 也面临着挑战。在加入 Presto 的早期，我们经常看到一些问题，包括 Presto 协调器崩溃和集群陷入接近零的工作并行。在这篇博客的后面，我们将解释这些问题的原因，并讨论我们如何解决它们。

# 部署

我们有数百 Pb 的数据和数万个 Hive 表。我们的 Presto 集群由 450 个 r4.8xl EC2 实例组成。Presto 集群总共拥有超过 100 TBs 的内存和 14K vcpu 内核。在 Pinterest 内部，我们每月有超过 1000 名活跃用户(Pinterest 共有 1600 多名员工)使用 Presto，他们每月在这些集群上运行约 40 万次查询。

Presto 以其从各种系统进行查询的能力而闻名，然而，Pinterest 目前只使用 Hive 连接器。Hive 和 Presto 共享同一个 Hive Metastore 服务。对于我们的用户来说，用 Hive 写数据，用 Presto 做只读分析是很常见的。此外，我们最近开始允许 Presto 创建表格和插入数据，主要原因如下。

1.  **运行大型查询的能力**我们通过查询的运行时间和它们在 Presto 上处理的数据来限制查询。写支持通过将大型查询分解成较小的查询，提供了运行大型查询的另一种方法。每个小查询都可以从前面查询的输出中读取，并写入一个中间表，然后由下一个查询使用。这是处理大型查询的更好方法，因为它提供了简单的可调试性、模块化、共享和检查点。如果一个子查询失败，只需要重新运行该子查询和后续的子查询，而不是整个大查询，这节省了时间和资源/金钱。
2.  **支持工作流**:Presto 的处理速度给用户留下了深刻的印象，用户一直在寻求在 Presto 上定义工作流的支持。由于只有读取能力，Presto 要么只能在提供最终输出的流程结束时提供服务，要么 Presto 输出将被带入工作流系统的内存中，然后传递给下一个作业/执行。这两种方法都非常有限。由于 Presto 支持 write，它可以很容易地在流中使用。

Pinterest 上的每个 Presto 集群都有工作人员负责混合专用 AWS EC2 实例和 Kubernetes pods。Pinterest 上的 Presto 部署应该与任何大规模 Presto 部署非常相似。有几个内部组件，即 Presto 控制器和 Presto 网关，我们将在接下来的小节中讨论。

# Presto 控制器

Presto 控制器是一项内部构建的服务，对我们的 Presto 部署至关重要。以下是迄今为止控制器提供的一些主要功能。

1.  健康检查
2.  慢速工人检测
3.  大量查询检测
4.  Presto 集群的滚动重启
5.  缩放集群

# 普雷斯托网关

Presto gateway 是一种位于客户端和 Presto 集群之间的服务。它本质上是智能 http 代理服务器。我们通过使用 Lyft 的【Presto-Gateway】(【https://github.com/lyft/presto-gateway】)在这方面领先一步。从那时起，我们在它的基础上增加了许多功能，我们计划将这些功能贡献给 Lyft 的版本。该服务使客户端不知道特定的 Presto 集群，并支持以下用途。其中一些功能正在积极开发中，我们正在慢慢地将我们所有的客户端从与特定集群对话转移到 Presto Gateway。

1.  基于规则的查询路由
2.  用户的资源使用限制和当前使用可见性
3.  整体 Presto 集群的运行状况可见性

# 监控/警报

提交给 Presto cluster 的每个查询都通过 Singer 记录到 Kafka 主题中。Singer 是 Pinterest 上的一个日志代理，我们在之前的[帖子](/@Pinterest_Engineering/scalable-and-reliable-data-ingestion-at-pinterest-b921c2ee8754)中讨论过。每个查询在提交和完成时都会被记录。当一个 Presto 集群崩溃时，我们将有查询提交事件，而没有相应的查询完成事件。这些事件使我们能够捕捉一段时间内集群崩溃的影响。JMX 和主机操作系统指标通过运行在所有 Pinterest 主机上的 [tcollector](http://opentsdb.net/docs/build/html/user_guide/utilities/tcollector.html) 记录到 OpenTSDB。使用来自 OpenTSDB 的指标，Presto 实时仪表板发布在 Statsboard 上(Pinterest 的指标监控 UI)。这对于调试服务问题非常方便。Statsboard 还有一个与 PagerDuty 相关的警报机制。

# 客户

有几个选项可供用户与 Presto 交互。最常见的是 DataHub(一个内部 web UI 工具)、Jupyter 和 Tableau。然而，有相当多的定制工具是通过 Presto 实现的。

# 分析

为了衡量 Pinterest 上 Presto 的使用情况，我们谨慎地决定优先处理哪些棘手问题。我们利用从 Presto 集群和 Presto 查询日志中收集的数据来获得信息性指标。下面是几个。

1.  哪些表在阅读时速度很慢？
2.  哪些查询在一起运行时会导致集群崩溃或停滞？
3.  哪些用户/团队正在运行长查询？
4.  配置的最佳阈值是多少？
5.  P90 和 P99 查询运行时？
6.  查询成功率？

![](img/72aeab3a44534befd06e0f66496487bd.png)

Figure 1: Presto deployment at Pinterest

# 挑战和我们的解决方案

## 深度嵌套和庞大的节俭模式

Presto 集群中的协调器对于整个集群操作非常重要。因此，这也是一个单点故障。直到去年年中，我们的 Presto 版本是基于开源的 Presto 版本 0.182。自那以后，对协调器进行了许多错误修复和改进，以更好地处理其关键职责。然而，即使有所改进，我们发现我们的 Presto 集群的协调器会被卡住，甚至因内存不足(OOM)而崩溃。

崩溃的最常见原因之一是非常大和嵌套非常深的节俭模式，这在我们的配置单元表中非常常见。例如，一个流行且常用的大型节俭模式有超过 1200 万个原语，深度为 41 级。这个模式在序列化为 string 时占用了 282 MB。我们有将近 500 个 hive 表，它们的模式中有超过 100K 个原语。

在 Presto 中，协调器的职责是从 Hive 目录的 Hive Metastore 中获取表的模式，然后在发送给 workers 的每个任务请求中序列化该模式。这种设计避免了 Hive Metastore 服务同时受到来自 Presto workers 的数百个请求的轰炸。然而，当模式非常大时，这种设计对协调器内存和网络有不利影响。

幸运的是，我们的大型深度嵌套模式问题仅限于使用节俭模式的表。在我们的部署中，创建了一个节俭模式 Java archive (jar)文件，并将其放入协调器和 Presto 集群的每个 worker 的类路径中，并在服务启动时加载。在每天的服务重启过程中，会创建并重新加载一个包含更新模式的新 jar。这使我们能够从任务请求中完全摆脱节俭模式:相反，只有节俭类名作为请求的一部分被传递，这极大地帮助稳定了部署中的 Presto coordinator。

# 缓慢或停滞的工人

Presto 的效率和速度在一定程度上得益于这样一个事实，即它总是启动 JVM，并准备开始在 workers 上运行任务。在一个 Presto worker 上，来自多个查询的多个任务共享一个 JVM。这种共享通常会导致繁重的查询，从而降低集群上所有其他查询的速度。对资源组强制实施内存约束(强制限制一个查询在给定时间在集群上可以消耗的内存量)对于解决高度多租户集群中的这些问题大有帮助。然而，我们仍然习惯于看到集群停滞不前。查询会停滞不前，工作并行度会下降到零并停留很长时间，通信错误开始出现，查询开始超时。

Presto 使用[多级反馈队列](https://en.wikipedia.org/wiki/Multilevel_feedback_queue)来确保缓慢的任务不会减慢一个工人的所有任务。随着时间的推移，这可能会导致工作人员积累大量缓慢的任务，因为快速任务将被优先考虑，并将很快完成。缓慢的 IO 任务也会累积在一个工作者身上。如前所述，我们所有的数据都存放在 AWS 中，如果某个前缀受到严重影响，S3 和 S3 会降低请求速度，这会进一步降低任务速度。如果一个工人行动缓慢或停滞不前，这种缓慢会逐渐蔓延到整个 Presto 集群。其他工作人员在等待慢工作人员的页面时会放慢速度，并将这种慢速度传递给其他工作人员。

解决这个问题需要良好的检测和公平的解决机制。我们采取跟踪检查的方式来发现工人的怠工。

1.  检查工作线程的 CPU 利用率是否低于集群的平均 CPU 利用率，并且这种差异会持续一段时间。
2.  检查是否有大量查询因内部错误而失败，这表明在一段时间内与超过阈值的工作人员交谈时失败。
3.  检查工作线程打开的文件描述符是否在一段时间内高于阈值。

一旦一个工人符合上述任何标准，Presto Controller 就会将该工人标记为关闭。首先尝试正常关机，但是在几次尝试中正常关机失败将导致控制器强制终止专用工作线程的 EC2 实例或关闭托管该工作线程的 Kubernetes pod。

# 多个集群中的资源不平衡

如图 1 所示，我们在 Pinterest 上有多个 Presto 集群。为了有效地利用所有 Presto 集群中的可用资源，应该向未充分利用的集群发送新的查询，或者必须将未充分利用的集群中的资源移动到查询将要运行的集群。前者更容易做到，但是在 Pinterest，不同的 Presto 集群有不同的访问模式和不同的特征。一些集群针对在其上运行的非常特殊类型的查询/用例进行了调优。例如，在计划的集群上运行即席查询(这意味着只运行计划的查询)会干扰计划的集群使用模式分析，还会对集群上的查询产生负面影响。这种查询之间的交互是我们更喜欢将资源从未充分利用的集群转移到过度利用的集群的原因。

将一个专用 EC2 实例从一个集群移动到另一个集群需要我们终止并重新配置该实例。这个过程很容易花费接近或超过十分钟的时间。在 Presto 世界中，10 分钟是一段很长的时间，而我们的 P90 查询延迟不到 5 分钟。相反，Kubernetes 平台为我们提供了在 Presto 集群中快速添加和删除工作人员的能力。在 Kubernetes 上培养一名新员工的最佳延迟不到一分钟。但是，当 Kubernetes 集群本身资源不足，需要扩展时，可能需要 10 分钟。在 Kubernetes 平台上部署的一些其他优势是，我们的 Presto 部署变得与云供应商、实例类型、操作系统等无关。

Presto controller service 负责在 Kubernetes 上添加/删除工人。对于每个集群，我们今天在 Kubernetes 上有一个静态的工人计数。但是，我们计划很快根据当前需求以及这些集群需求的历史趋势自动扩展集群。

# 不恰当的集群关闭

每天晚上，我们重新启动所有 Presto 集群，以加载更新的配置参数、节约模式、自定义[配置单元串行器/解串器](https://cwiki.apache.org/confluence/display/Hive/SerDe) (SerDe)和用户定义函数(UDF)。

在不影响任何正在运行的任务的情况下关闭服务的能力是服务的一个重要方面(通常称为正常关闭)。在开源的 Presto 中，没有办法启动集群的正常关闭。各种组织的 Presto 操作员通过控制到集群的流量来处理正常关机。我们也开始在 Pinterest 的 Presto Gateway 上做同样的事情。但是，目前有一些客户端与特定的 Presto 集群对话，并受到不适当的集群关闭的影响。即使有了 Presto Gateway，我们仍然会有一些客户端继续与特定的 Presto 集群通信，而不通过 Presto Gateway，这可能是出于安全原因，也可能是因为只有一个集群服务于特定的用例。

很快，人们就可以优雅地关闭一个工人。然而，仅仅这样还不足以确保整个集群的正常关闭。我们向 Presto coordinator 添加了一个正常关机功能，以执行整个集群的正常关机。当启动群集正常关闭时，会向群集的协调器发送关闭请求。在接收到一个正常关机请求时，类似于 Presto Workers，协调器将其状态更改为 ***SHUTTING_DOWN*** 。在这种状态下，Presto coordinator 不接受任何新的查询，而是等待所有现有查询完成后再自行关闭。在这种状态下，协调器会对任何新的查询做出错误响应，通知客户端集群正在关闭，并要求他们在一段时间内重试，通常是在最大允许查询运行时间左右。这种仅包含信息性消息的快速失败比以前客户端看到突然失败时的行为要好得多，这种行为会提示他们只需重试查询就可以再次看到那些失败。将来，我们计划添加一个无需重启进程就能重新加载 jar 的功能，并使一些配置参数动态化，以避免频繁重启集群的需要。

# LDAP 验证器不支持模拟

如图 1 所示，我们有各种客户端连接到 Presto 集群。其中一些是允许用户运行查询的服务。出于资源和会计目的，要求这些服务模拟每个用户，它们代表每个用户运行查询。如果使用 Kerberos 身份验证，这可以在 Presto 上完成。我们使用 LDAP 身份验证，它没有连接服务的方法来模拟和限制只有允许的服务才能这样做。我们向 LDAP 验证器添加了模拟支持，该验证器采用可配置的服务白名单，可以执行模拟。

# 摘要

Presto 被广泛使用，并在 Pinterest 的分析中发挥了关键作用。作为非常流行的交互式 SQL 查询引擎之一，Presto 发展非常快。Presto 的最新版本在稳定性和可伸缩性方面有很多改进。然而，对于 Pinterest scale，我们必须解决一些问题，才能成功地进行 Presto 操作和使用，比如优雅的集群关闭、大型深度嵌套节约模式的处理、LDAP 验证器中的模拟支持、缓慢的工作线程检测和工作线程的自动伸缩。其中一些也可以造福社区，我们计划回报社会。

在未来，我们希望继续提高可靠性、可伸缩性、可用性和性能，比如滚动重启、无需重启集群即可重新加载 jar，以及为用户提供集群资源利用率的可见性。我们还对任务的按需检查点非常感兴趣，以便无缝使用 [Amazon EC2 spot 实例](https://aws.amazon.com/ec2/spot/)，并使我们的用户能够获得查询运行时估计值，而无需等待查询完成。

*鸣谢:非常感谢杨普成、李丽达和整个大数据平台团队，他们帮助改善和扩展了 Pinterest 的 Presto 服务。*