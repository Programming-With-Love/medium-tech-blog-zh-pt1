<html>
<head>
<title>Improving Distributed Caching Performance and Efficiency at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高Pinterest的分布式缓存性能和效率</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/improving-distributed-caching-performance-and-efficiency-at-pinterest-92484b5fe39b?source=collection_archive---------0-----------------------#2022-05-12">https://medium.com/pinterest-engineering/improving-distributed-caching-performance-and-efficiency-at-pinterest-92484b5fe39b?source=collection_archive---------0-----------------------#2022-05-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="995c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">林义杰|软件工程师，存储和缓存</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/6e2454a4d5944d3d402901063e3ca634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*iWSBMFbrF6eNDNmVAXKVaw.jpeg"/></div></figure><h1 id="9bce" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">介绍</h1><p id="265a" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">Pinterest的分布式缓存系统，建立在开源技术<a class="ae kn" href="https://github.com/memcached/memcached/" rel="noopener ugc nofollow" target="_blank"> memcached </a>和<a class="ae kn" href="https://github.com/facebook/mcrouter" rel="noopener ugc nofollow" target="_blank"> mcrouter </a>之上，是生产基础设施栈的关键组件。Pinterest的缓存即服务平台负责全面降低应用延迟，减少总体云成本，并确保遵守严格的站点范围可用性目标。</p><p id="7bcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如今，Pinterest的memcached车队跨越了超过5000个EC2实例，涵盖了各种实例类型，并在计算、内存和存储方面进行了优化。总体而言，该机群每秒可处理高达约1.8亿个请求，网络吞吐量约为220 GB/s，活动内存和磁盘数据集约为460 TB，分布在约70个不同的集群中。</p><p id="6587" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为降低站点范围延迟的核心驱动因素，分布式缓存层受到严格的性能和延迟要求的制约。此外，车队庞大规模的一个重要后果是，即使很小的效率优化也会对总服务成本产生巨大影响。几年来在生产中大规模运行memcached的操作经验为实际优化提供了独特的见解，有助于提高整个缓存堆栈的性能和效率。</p><p id="f841" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将分享支持优化探索工作的可观察性和性能测试工具的一些背景，然后深入探讨当前在我们的生产环境中运行的实际优化，包括硬件选择策略、计算效率和网络性能。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es ko"><img src="../Images/8de75ad795b3e26e3c31bd6a7b5a96ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GGwVNRmRCSmKJYgb"/></div></div></figure><p id="3b02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">对公共云环境中虚拟机上运行的memcached进行性能优化的可用表面积的高级描述</em></p><h1 id="950f" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">监控、可观察性和评估</h1><p id="c8ca" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">所有性能优化工作都始于精确的定量测量和一个结构化的、可重复的机制，用于生成独立评估的工作负载。</p><p id="28d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多年来进行的所有绩效评估的关键监控先决条件包括:</p><ul class=""><li id="f0bf" class="ku kv hh ig b ih ii il im ip kw it kx ix ky jb kz la lb lc bi translated">请求吞吐量、网络吞吐量、资源利用率和硬件级参数的服务器端指标(NIC统计数据，如每个队列的数据包吞吐量和EC2许可耗尽、磁盘响应时间和进行中的I/O请求等。)</li><li id="36ff" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated">缓存请求百分比延迟、超时和错误率、每服务器可用性(SLIs)的客户端指标，以及顶级应用程序性能指标，如服务RPC P99响应时间</li></ul><p id="0b5c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pinterest利用合成负载生成和生产影子流量来评估调优和优化的影响。从历史上看，合成基准测试有助于检测最大负载下的性能退化或改进，而影子流量评估则更能反映真实大规模工作负载下的服务器资源利用率和整体性能。</p><ul class=""><li id="4748" class="ku kv hh ig b ih ii il im ip kw it kx ix ky jb kz la lb lc bi translated"><strong class="ig hi">合成负载生成:</strong> memtier_benchmark是一个开源工具，能够针对memcached集群生成合成负载，其参数可配置为并发客户端和线程的数量、读/写比率、数据大小和传输机制(明文或TLS)。</li><li id="7706" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated"><strong class="ig hi">Production shadow traffic:</strong><a class="ae kn" href="https://github.com/facebook/mcrouter" rel="noopener ugc nofollow" target="_blank">MC router</a>是一个开源的memcache-protocol路由代理，部署为Pinterest车队中的客户端sidecar。它提供构建块来设计具有可配置流量百分比和源/目标群集的透明影子流量路由策略，允许跨各种工作负载类别进行灵活的暗流量实验。</li></ul><p id="e924" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些工具共同支持高信号性能评估，对关键路径生产流量的影响为零或极小。</p><h1 id="d83f" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">性能和效率</h1><h2 id="3c67" class="li jl hh bd jm lj lk ll jq lm ln lo ju ip lp lq jy it lr ls kc ix lt lu kg lv bi translated">云硬件</h2><p id="e25f" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">Pinterest的分布式缓存服务于各种各样的工作负载。一般来说，每类工作负载都可以按照以下高级维度进行分类:</p><ul class=""><li id="fd01" class="ku kv hh ig b ih ii il im ip kw it kx ix ky jb kz la lb lc bi translated">吞吐量(计算)</li><li id="ae78" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated">数据量(内存和/或磁盘容量)</li><li id="c6a0" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated">数据带宽(网络和计算)</li><li id="819d" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated">延迟要求(计算)</li></ul><p id="c7a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然memcached可以任意水平伸缩以解决特定集群的瓶颈，但垂直伸缩单个硬件维度可以为特定工作负载带来更高的成本效益。在实践中，这需要对针对每个工作负载类优化的EC2实例类型的固定池进行标准化。</p><p id="02ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">工作负载概况:</strong>中等吞吐量，中等数据量</p><p id="e3df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> EC2实例族:</strong> <a class="ae kn" href="https://aws.amazon.com/ec2/instance-types/r5/" rel="noopener ugc nofollow" target="_blank"> r5 </a></p><p id="20eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基本原理:</strong> r5家族实例提供的vCPU-DRAM比率适用于Pinterest的大多数普通缓存用例。此实例类型被视为评估其他实例的“基线”。</p><p id="90d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">工作负载概况:</strong>高吞吐量，低数据量</p><p id="915d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> EC2实例族:</strong> <a class="ae kn" href="https://aws.amazon.com/ec2/instance-types/c5/" rel="noopener ugc nofollow" target="_blank"> c5 </a></p><p id="af84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基本原理:</strong> c5系列实例对于那些原本会插入r5类型但占用的内存少得多的用例来说更具成本效益。保持与r5相同的vCPU数量，使其能够以更低的总成本提供相同的吞吐量。</p><p id="e056" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">工作负载概况:</strong>高数据量，宽松的延迟要求</p><p id="0943" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> EC2实例族:</strong> <a class="ae kn" href="https://aws.amazon.com/ec2/instance-types/r5/" rel="noopener ugc nofollow" target="_blank"> r5d </a></p><p id="f4f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基本原理:</strong> r5d系列实例在功能上等同于r5系列实例，但具有由extstore用于辅助存储的实例协同定位NVMe SSD。r5d对于具有高数据量的群集来说是经济高效的，因此在将数据写入磁盘时，命中率会有明显的提高。由于磁盘速度较慢(相对于i3系列实例)，预计尾部延迟会更高。</p><p id="f0c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">工作负载概况:</strong>海量数据量，宽松的延迟要求</p><p id="206b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> EC2实例族:</strong> <a class="ae kn" href="https://aws.amazon.com/ec2/instance-types/i3/" rel="noopener ugc nofollow" target="_blank"> i3 </a>和<a class="ae kn" href="https://aws.amazon.com/ec2/instance-types/i3en/" rel="noopener ugc nofollow" target="_blank"> i3en </a></p><p id="1b27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基本原理:</strong> i3和i3en系列实例配备了一个快速且可调整大小的实例协同定位磁盘，对于磁盘上的工作数据相对于DRAM的比率非常高的工作负载，该磁盘显著提高了extstore性能。此外，它们提供与r5系列实例相当的内存容量，通过保持合理的DRAM与磁盘使用率来减少extstore抖动。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lw"><img src="../Images/1f70855a7506b80b59dcb38767bf5a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/0*n7exBjEZh9U2B3jt"/></div></figure><p id="1d30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">Pinterest memcached车队的EC2实例类型分布</em></p><p id="1ad8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特别是，使用<a class="ae kn" href="https://github.com/memcached/memcached/wiki/Extstore" rel="noopener ugc nofollow" target="_blank"> extstore </a>将存储容量从DRAM扩展到本地NVMe闪存磁盘层，可将每个实例的存储效率提高几个数量级，并相应减少相关的集群成本。EC2的存储优化实例类型提供了能够实现高随机IOPS和读/写吞吐量的本地连接固态驱动器，允许采用具有海量数据量和高请求吞吐量的extstore用例，而不会影响尾部延迟。</p><p id="5b31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">向设备群引入不同形式的存储优化EC2实例类型(特别是每个实例包含多个独立磁盘的i3en实例系列的较低层变体)进一步降低了成本，同时提高了I/O性能和成本效率。Pinterest使用RAID0级别的Linux软件RAID配置这些实例，以便将多个硬件块设备合并到一个逻辑磁盘中，供用户空间使用。通过在两个磁盘之间公平地分条读取和写入，RAID0将最大理论I/O吞吐量提高了一倍，在最佳情况下，以双倍的MTTF为代价，将有效磁盘响应时间减少了两倍。以增加理论故障率为代价来提高extstore的硬件性能是非常值得的。在公共云上运行工作负载需要将基础架构设计成短命的牲口，能够在实例故障时自我修复。用于mcrouter的拓扑控制平面自动并优雅地响应服务器容量的意外变化；实例丢失不是问题。</p><h2 id="81e3" class="li jl hh bd jm lj lk ll jq lm ln lo ju ip lp lq jy it lr ls kc ix lt lu kg lv bi translated">计算</h2><p id="3bbd" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">Pinterest上大约一半的缓存工作负载是受计算限制的(即纯粹受请求吞吐量限制)。计算效率的成功优化转化为在不影响服务能力的情况下缩小集群规模的能力。</p><p id="40ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更准确地说，memcached的计算效率被定义为在不增加请求延迟的情况下，实例CPU使用率每增加一个百分点，单个实例可以处理的<em class="kt">额外请求率</em>。简而言之，提高计算效率的优化就是允许memcached以更低的CPU使用率提供更高的请求速率，而不改变请求延迟特性。</p><p id="b755" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Pinterest，大多数工作负载(包括分布式缓存设备)都运行在专用的EC2虚拟机上。许多历史性的效率改进都源于硬件层本身的优化，比如迁移到不同的实例系列或升级到现有实例类型的更新版本。然而，在专用(虚拟化)机器上运行工作负载为软硬件边界的优化提供了独特的机会。</p><p id="625f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Memcached在Pinterest的有状态数据系统中有些独特，因为它是唯一的主要工作负载，在部署它的每个EC2实例上都有一组静态的长期工作线程。这与数据库工作负载形成对比，例如，数据库工作负载可能具有多个协同定位的进程，用于分离的存储和服务层。为此，一个简单但高效的优化是调整<a class="ae kn" href="https://man7.org/linux/man-pages/man7/sched.7.html" rel="noopener ugc nofollow" target="_blank">进程调度</a>，以便请求内核优先考虑memcached的CPU时间，代价是故意扣留主机上其他进程的CPU时间，如监控守护进程。这涉及到在一个实时调度策略SCHED_FIFO下运行memcached，该策略具有高优先级——指示内核有效地允许memcached在memcached线程变得可运行时，通过抢占(并因此故意饥饿)所有非实时进程来独占CPU。</p><h2 id="3efe" class="li jl hh bd jm lj lk ll jq lm ln lo ju ip lp lq jy it lr ls kc ix lt lu kg lv bi translated">$ sudo chrt--FIFO<priority>memcached…</priority></h2><p id="a292" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><em class="kt">在SCHED_FIFO实时调度策略下调用memcached的示例</em></p><p id="94b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在推广到所有计算密集型集群后，这一行代码的更改将客户端P99延迟降低了10%到40%，此外还全面消除了P99和P999延迟中的虚假峰值。此外，它还能够将稳态运行CPU使用率上限提高20%，而不会引入延迟回归。最终，这将memcached车队的总成本降低了近10%。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es ko"><img src="../Images/2cbc751b2098f808fc2b8d6cd36047da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8o0cgOWcaKh9ewaY"/></div></div></figure><p id="6d5e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">当实时调度部署到相应的专用memcached集群时，一项服务的客户端P99缓存延迟的周与周比较</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es ko"><img src="../Images/f5f2a74b4c0e29be5bbab1cd420ae0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZAxCYdUNWhQtIjVg"/></div></div></figure><p id="55c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">在启用实时调度(数据从/proc文件系统中的schedstat收集)之前和之后，memcached等待内核执行的时间与挂钟时间的比率</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es ko"><img src="../Images/2509f8658082102dd4fa7531a7621788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T4vXvHAbzOiDQd59"/></div></div></figure><p id="de66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">在金丝雀主机上启用实时调度后虚假延迟峰值的稳定(红色系列)</em></p><h2 id="851c" class="li jl hh bd jm lj lk ll jq lm ln lo ju ip lp lq jy it lr ls kc ix lt lu kg lv bi translated">建立工作关系网</h2><p id="421e" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">考虑网络性能时，有几个关键因素:</p><ul class=""><li id="b286" class="ku kv hh ig b ih ii il im ip kw it kx ix ky jb kz la lb lc bi translated"><strong class="ig hi">数据带宽、数据包吞吐量和TCP连接限制。</strong> EC2对每个实例的PPS、聚合带宽和TCP连接施加了<a class="ae kn" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-network-performance-ena.html" rel="noopener ugc nofollow" target="_blank">硬限制</a>(尽管仅当部署在具有TCP入口规则的安全组中时)。超过这些限制的超额使用由<a class="ae kn" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking-ena.html" rel="noopener ugc nofollow" target="_blank">弹性网络适配器(ENA) </a>驱动程序报告，并可通过ethtool访问。令人困惑的是，EC2还根据突发负载而不是稳态负载来表示总NIC带宽能力，因此需要某种程度的反复试验来确定具有可预测网络特征的memcached等工作负载的实际带宽上限。</li><li id="92e8" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated"><strong class="ig hi">连接延迟和可靠性。有没有一种方法可以使到memcached的初始TCP连接更快、更可靠，尤其是在成千上万个客户端同时建立连接的突发情况下？</strong></li><li id="a139" class="ku kv hh ig b ih ld il le ip lf it lg ix lh jb kz la lb lc bi translated"><strong class="ig hi">与TLS等传输层特性相关的开销。有没有办法减少TLS的加密/解密计算开销？此外，是否有办法降低初始设置成本(即TLS握手)？</strong></li></ul><p id="4fc0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从云消费者的角度来看，EC2强制实施的网络限制可以也应该被视为固有的硬件限制。不幸的是，除了横向扩展机群以减少每个实例的使用之外，没有任何机制可以解决这些限制。</p><p id="ab5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Pinterest的<a class="ae kn" href="https://pin.it/scaling-cache-infrastructure" rel="noopener ugc nofollow" target="_blank">缓存架构</a>中，mcrouter是一个通用路由代理，也是进入分布式缓存层的单一面向应用的入口点。每个mcrouter实例(实际上是服务集群中的每个主机)为集群中的每个memcached服务器创建一个静态大小的长期TCP连接池。连接池大小是根据主机系统上可用的逻辑核心数量确定的，对于规范的实例类型，通常在8到72之间。这导致每个服务器主机上建立了数万个以上的活动TCP连接，每个服务器集群的连接总数轻松超过100万个，因此需要一种策略来保持最少的连接延迟和大规模连接可靠性。</p><p id="b09a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae kn" href="https://datatracker.ietf.org/doc/html/rfc7413" rel="noopener ugc nofollow" target="_blank"> TCP快速开放(TFO) </a>是一种机制，用于通过在原本成本高昂的TCP 3WHS(三次握手)中优化掉一个RTT来减少建立TCP连接的延迟开销，同时还允许在握手期间立即传输早期数据。虽然最初是为连接到远程边缘服务器的不可靠家庭和移动网络上的最终用户设计的，但TFO也展示了在封闭云环境中连接可靠性的切实改进。在memcached中实现TFO支持将连续会话的平均TCP连接持续时间减少了约10%,这在跨越可用性区域边界建立的连接中最为明显。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="er es lx"><img src="../Images/1079850477db84aba5e63082c90f5783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q8Dv_rZzLI0F4I0v"/></div></div></figure><p id="d4ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">在TFO cookie设置期间和随后TFO发起的具有早期数据的会话期间，客户端和服务器之间交换的数据包</em></p><p id="0db2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另外，提高net.core.somaxconn的sysctl参数值以及memcached中用户空间<a class="ae kn" href="https://man7.org/linux/man-pages/man2/listen.2.html" rel="noopener ugc nofollow" target="_blank"> listen(2) </a> callsite中相关的监听积压大小，可以提高高吞吐量集群的突发连接可用性。以前，部署新的memcached二进制文件会导致服务器错误激增，这些错误是由来自数千个客户端mcrouter实例的大量同时入站连接所驱动的服务器端TCP接受队列耗尽而导致的。一个更大的监听积压阈值减少了每台服务器的停机时间，并修复了每当部署共享租户集群时短暂但频繁的SLO违规。</p><p id="9174" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，TLS在memcached和mcrouter之间的传输数据加密中起着重要的作用，它为Pinterest中100%的缓存流量启用，以符合站点范围的身份验证、授权和审计策略。即使使用硬件加速的加密技术，TLS也会增加不小的初始<em class="kt">和</em>稳态开销，这分别是由于网络I/O期间的连接后TLS握手和应用层加密/解密。在memcached中实现TLS会话恢复后，通过允许重用以前缓存的TLS会话，降低了整个车队的客户端连接超时率。解决稳态开销的一个途径是<a class="ae kn" href="https://www.kernel.org/doc/html/latest/networking/tls.html" rel="noopener ugc nofollow" target="_blank">内核TLS</a>(kTLS)——一种将TLS记录层从用户空间卸载到内核的机制，可以在软件中实现，也可以卸载到支持的专用NIC硬件，以实现完全透明的内联数据加密/解密。TLS会话恢复由Pinterest上传到memcached，从1.6.3版本开始提供；kTLS是一个正在进行的相对实验性的优化领域。</p><h1 id="1d95" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">未来的工作</h1><p id="898f" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">基础设施优化是Pinterest的一个关键目标，最终为Pinners带来更愉快的体验，同时减少我们自己的云成本足迹。我们期待着继续探索在堆栈的所有层提高缓存性能和效率的途径，从应用程序客户端和路由代理到服务器本身。在近期，我们打算继续评估软件内核TLS，探索memcached与新一代EC2实例类型的兼容性，以提高性价比特征，以及应用/代理端软件优化，如动态压缩，以提高存储效率。我们希望另外建立一个端到端的自动化性能回归测试框架，以跟踪这些优化的影响。</p><p id="d7dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢Pinterest的整个存储和缓存团队对这项工作的支持，特别是Ankita Girish Wagh和Xu。</p><p id="2cbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kt">要在Pinterest了解更多关于工程的知识，请查看我们的</em> <a class="ae kn" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="kt">工程博客</em> </a> <em class="kt">，并访问我们的</em><a class="ae kn" href="https://www.pinterestlabs.com/?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=lin-may-12-2022" rel="noopener ugc nofollow" target="_blank"><em class="kt">Pinterest Labs</em></a><em class="kt">网站。要查看和申请空缺职位，请访问我们的</em> <a class="ae kn" href="https://www.pinterestcareers.com/?utm_source=medium&amp;utm_medium=blog-article-link&amp;utm_campaign=lin-may-12-2022" rel="noopener ugc nofollow" target="_blank"> <em class="kt">招聘</em> </a> <em class="kt">页面</em></p></div></div>    
</body>
</html>