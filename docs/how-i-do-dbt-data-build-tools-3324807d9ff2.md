# 我如何做 dbt(数据构建工具)

> 原文：<https://medium.easyread.co/how-i-do-dbt-data-build-tools-3324807d9ff2?source=collection_archive---------0----------------------->

## 从我目前设置 dbt 的经验来看…

![](img/519233989e7803634b19f8e81f4cebe1.png)

Photo by [American Public Power Association](https://unsplash.com/@publicpowerorg?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

本文将讨论我在为我的团队建立 **dbt** 项目时从我的经验中学到的东西(关于如何做的技巧),我认为这些东西在尝试这些新的伟大工具时对其他数据工程团队是有价值的。

对于那些刚刚接触 **dbt** 的人来说，它基本上是一个遵循软件工程最佳实践的数据转换工具。 **dbt** 位于 ELT(提取、转换、加载)过程的 T 部分。

当然(显然，从字面上来看) **dbt** 是一个**易于使用的数据转换工具**，它需要最小的努力来设置，特别是对于那些使用云版本(cloud **dbt** )的人来说，云版本已经包括了所有的“数据工程基本功能”，如 CICD、松弛警报、调度程序和文档，但是在我们的工程人员中，总是有改进的空间。

> 改进是指增加日常使用 **dbt** 的数据团队(BI 和 DA)的易用性和便利性。

# **用 dbt_project.yml 组织一切**

首先第一件事，组织好一切我用 dbt_project.yml 来做，这是定义 **dbt** 项目结构的主要配置文件，像如何构造文件，定义变量。

*   **在**这里调用你需要的前挂钩和后挂钩和**。例如通过在模型组件中添加 ***start_log()*** 和 ***end_log()*** 宏作为钩子，它会将每个 SQL 模型的执行记录到表日志中。我还添加了***grant _ table()***作为后挂钩，在成功创建每个模型后，将表授予默认或特定的用户模式。**
*   **定义全局变量和设置**，除了 hook 之外，我还定义了全局变量和默认设置，在本例中，我为模式别名定义了全局变量，为表和 persist_docs 启用了默认的物化设置。
*   **结构化数据层**，最后一个是按目录结构组织数据层，在这个例子中，我尝试按 dir 名称组织 SQL 模型作为数据层( *data_mart* 目录用于 *data_mart* 层)，所以当有在 *data_mart* 层创建表的请求时，只需要将 SQL 文件放在 *data_mart* 目录中即可。你可以用其他方式来组织，比如业务单位或服务。

# **最大化宏用法**

宏是给你的**项目**添加功能的好方法。注意，在前面一点中，我使用了 ***grant_table()*** 宏作为钩子，自动将一个新创建的表授予用户。

我使用的另一个宏的例子是: ***source()*** ，***generate _ schema _ name()***，***primary _ key()***，***time zone _ default()***。除了将宏定义为函数，还可以作为模板**替代重复查询**(例如:***index()******partition()***)。

使用宏的 SQL 模型

> 宏的用法取决于您使用的数据仓库(PG、Snowflake、Bigquery 等)，在我的例子中，我使用宏 **partition()** 对 Postgres 中的表进行分区，但是在 BigQuery 中这个宏不可用，因为 **dbt** 有一个内置的宏来处理这个表分区( **partition_by()** 和 **cluster_by()** 宏)

# 定义模型模板

模型模板允许您使用预定义的每个团队的模板和设置开始开发 SQL 模型。这对使用 **dbt** 的用户/团队的**统一 SQL 模型和表格**非常有用。在我们的例子中，我定义了模型 template.sql 和 template_incremental.sql(用于增量模型),这样用户就可以根据需要使用和更改模板模型。

> 模板模型也可以用作如何使用宏或任何 dbt 配置属性的指南

# 利用 schema.yml

> “文档是你写给未来自己的情书”
> ~达米安·康威

事实证明，这不仅是为了你未来的自己，也是为了你未来的剧本。schema.yml 的主要用途是**为你的 **dbt** 项目提供文档**，它的另一个用途是存储模型元数据。稍后，当执行 SQL 模型时，此元数据将与调用日志/指标聚合在一起，并作为 **dbt** 工件文件( *target/run_result.json，target/manifest.json)* ，这些文件稍后可用于您的数据监控和警报平台**，在我们的案例中，元数据模型所有权将用于 slack 警报/通知以及其他用于管道报告/日志记录的元数据。**

# Cloud **dbt** 作为协作工具

Cloud **dbt** 非常适合协作和开发 SQL 模型，但只适合作为生产环境，所以我们不把它用作生产环境。而且…我们数据团队基本上有一个集中的编排平台(如 airflow、rundeck 等)来跨多个数据平台组织我们的数据管道。在我们的案例中，我们**分别托管 dbt 环境**，云上的开发环境 **dbt** ，以及使用 **dbt-cli 的内部生产环境。** **dbt** 通过使用 profiles.yml 中的目标，可以很容易地维护独立的生产和开发环境

> 那些在一个 BigQuery 项目(或类似项目)上使用 **dbt** 的人只需要指定目标并覆盖这两个内置宏( ***source()*** 和***generate _ schema _ name()***)就可以根据目标属性自动更改环境和模式。在 **dbt** 下使用宏 ***source()*** 从表源中查询数据，而***generate _ schema _ name()***在创建表时引用目标模式

我想现在就这样吧…

对于如何为您的团队建立 **dbt** 项目，您可能有不同的意见或偏好，所以请随意记下一些关于如何建立 **dbt** 项目的想法/建议。

你觉得这篇博文有帮助吗？如果是这样，那么把这篇文章带到你的下一次 DE 团队周会上，或者…你可以只是分享它，这样人们也可以找到这篇文章。谢谢你。