<html>
<head>
<title>Why You Should Start Writing Spark Custom Native Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么应该开始编写Spark自定义本机函数</h1>
<blockquote>原文：<a href="https://medium.com/version-1/why-you-should-start-writing-spark-custom-native-functions-427372c08b4?source=collection_archive---------2-----------------------#2021-09-03">https://medium.com/version-1/why-you-should-start-writing-spark-custom-native-functions-427372c08b4?source=collection_archive---------2-----------------------#2021-09-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8c113a17488ba87c84871cd4c2fde72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WxrhjcZwd_o5GgvItmeUsw.png"/></div></div></figure><p id="b828" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当人们需要做一些Spark中没有的事情时，他们首先尝试的事情之一是编写一个UDF，一个<strong class="ir hi">用户定义的函数</strong>，允许他们实现他们正在寻找的功能，但这是最好的方法吗？编写UDF对性能有什么影响？</p><p id="1ce5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这篇文章将着眼于实现一个函数，通过使用UDF和编写自定义Spark-Native代码，用两种不同的方法返回UUID，并比较它们的性能。</p><p id="79d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们开始吧！</p></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="26a5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这篇文章将遵循下一个结构。</p><ul class=""><li id="917f" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated"><strong class="ir hi"> 1。简介</strong></li><li id="980f" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 2。UUIDs的快速前言</strong></li><li id="1c9f" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 3。使用UDF的UUID实现</strong></li><li id="4a35" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 4。UUID用催化剂表达式实现</strong></li><li id="741c" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 5。性能比较</strong></li><li id="f51d" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 6。结论</strong></li><li id="945a" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi"> 7。资源</strong></li></ul></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="65b1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">注1 </strong>:这只适用于使用<strong class="ir hi"> scala </strong>的情况。</p><p id="17dd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">注2</strong>:Spark从3.0.0版本开始就提供了<strong class="ir hi"> UUID() </strong>函数，但是由于其简单性，实现它仍然是一个有用的练习。</p><p id="73c5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">你可以找到代码</strong>:<a class="ae ki" href="https://github.com/imdany/spark_catalyst_udf" rel="noopener ugc nofollow" target="_blank">https://github.com/imdany/spark_catalyst_udf</a></p></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><ol class=""><li id="e8c4" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm kj ka kb kc bi translated"><strong class="ir hi">简介</strong></li></ol><p id="4081" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你使用过Spark，你就会知道有些情况下Spark本身没有提供你需要的功能，所以你需要扩展它。</p><p id="17fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通常，您可以通过编写一个UDF来完成这项工作。但是你知道还有另一种选择吗？它们被称为<strong class="ir hi"> Catalyst表达式</strong>，我不得不说它们写起来并不简单，但是(剧透一下)它们可以把你的应用带到另一个性能水平。</p><p id="949b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以说正事吧！</p><p id="cd59" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> 2。UUIDs的快速介绍</strong></p><p id="733c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">UUID代表通用唯一标识符，这是一种非常常见的生成唯一字符串的方法，该字符串可以标识一段数据。这种机制有许多不同的实现，但最常用的是UUID版本4，ID如下所示:</p><blockquote class="kk kl km"><p id="ab4f" class="ip iq kn ir b is it iu iv iw ix iy iz ko jb jc jd kp jf jg jh kq jj jk jl jm ha bi translated">c896f 39a-6001–4e 62–9296-a 323 bee9b 047</p></blockquote><p id="a352" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个版本的关键点是组成标识符的位是随机生成的，没有内在逻辑。因此，仅通过查看UUID是无法识别来源信息的。</p><p id="35de" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">生成id时的另一个重要方面叫做“冲突”，这意味着在生成过程中会出现重复的字符串。引用自维基百科:</p><blockquote class="kk kl km"><p id="3a17" class="ip iq kn ir b is it iu iv iw ix iy iz ko jb jc jd kp jf jg jh kq jj jk jl jm ha bi translated">“为了使<strong class="ir hi">有50%的概率至少发生一次冲突，需要生成的随机版本4 UUIDs的数量是2.71万亿分之一……</strong></p><p id="1ea6" class="ip iq kn ir b is it iu iv iw ix iy iz ko jb jc jd kp jf jg jh kq jj jk jl jm ha bi translated">这个数字相当于大约85年每秒产生<strong class="ir hi">10亿个UUIDs。包含这么多UUID的文件，每个UUID 16字节，大约是45 <a class="ae ki" href="https://en.wikipedia.org/wiki/Exabyte" rel="noopener ugc nofollow" target="_blank">艾字节</a>。"</strong></p></blockquote><p id="05d5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以我们可以说，我们面对这个问题是难以置信的。</p><p id="5e41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Java/Scala已经在类<strong class="ir hi"> java.util.UUID. </strong>中实现了这个功能。这个类提供了一个名为<strong class="ir hi"> randomUUID() </strong>(你可以在这里查看源代码，<a class="ae ki" href="http://hg.openjdk.java.net/jdk8/jdk8/jdk/file/default/src/share/classes/java/util/UUID.java#l141%29." rel="noopener ugc nofollow" target="_blank"><em class="kn"/></a>)的方法，它为我们生成UUID，但是……我们如何从Spark中访问这个功能呢？</p><p id="753f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们看看如何使用UDF和Catalyst表达式方法在Spark中实现这个UUID生成器。</p><p id="72e9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">3.<strong class="ir hi">使用UDF的UUID实现</strong></p><p id="3165" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用UDF实现UUID生成器很简单，这是我可能在我参与的所有项目中见过的一段代码。</p><p id="5d13" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通过一些变化或不同的语法，我们可以这样写这个函数:</p><figure class="kr ks kt ku fd ii"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="dacf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这样，我们可以将UUID函数用于SQL表达式和Dataframe API。</p><p id="9d67" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里的要点是我们使用了现有的Java函数，但不是在Spark中。要使用Spark中的代码，我们可以将该代码包装在Spark提供的UDF方法周围，然后注册该UDF，如果我们想在SQL API中使用它的话。</p><p id="0a6a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">很简单，对吧？你可以用这种方法做很多很多不同的事情。这很容易做到，也很有效，但是还有其他方法来扩展spark的功能。</p><p id="8b17" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> 4。UUID用Catalyst表达式实现</strong></p><p id="bdc4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">编写catalyst表达式可能比UDF更复杂，但是正如您将在下一节中看到的，这样做有一些性能优势。让我们从基础开始，我们如何写它们:</p><p id="4d21" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">要在Spark中编写自定义函数，我们至少需要两个文件:第一个文件将通过扩展Catalyst功能来实现功能。第二个将使该功能可用。</p><ul class=""><li id="9626" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated"><strong class="ir hi">催化剂表达式</strong></li></ul><p id="a439" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">包含代码实现的文件需要在特定的包中创建，即:</p><p id="9c25" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">org . Apache . spark . SQL . catalyst . expressions</strong></p><p id="7cfc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们需要在Spark项目的那个文件夹中为我们的函数创建文件。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/6cdbca05fe06136d0159bb52a3d74510.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*mmlcyi6iWJXHCR8RM6WlJg.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Location of the file</figcaption></figure><p id="08f8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是事情变得非常复杂的时候。为了让Spark使用我们的函数，我们需要扩展可用的接口。我们可以实现许多不同的接口，找到正确的接口可能会很复杂，因为相关的文档并不丰富。化繁为简，我们来分析一下我们要实现什么— <strong class="ir hi">一个没有输入参数，返回一个字符串的函数。</strong></p><p id="cfc0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我发现我需要实现一个“<strong class="ir hi">叶子表情</strong>，所以我的类会这样开始:</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="87c0" class="lh li hh ld b fi lj lk l ll lm">case class Uuid() extends LeafExpression with CodegenFallback {</span><span id="cd93" class="lh li hh ld b fi ln lk l ll lm">    override def nullable: Boolean = ???</span><span id="0688" class="lh li hh ld b fi ln lk l ll lm">    override def eval(input: InternalRow): Any = ???</span><span id="cb39" class="lh li hh ld b fi ln lk l ll lm">    override def dataType: DataType = ???</span><span id="fbf3" class="lh li hh ld b fi ln lk l ll lm">}</span></pre><p id="3974" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，让我们从最简单的方法开始，来填充这个定义:</p><p id="b03d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于数据类型，我们希望返回一个字符串:</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="9489" class="lh li hh ld b fi lj lk l ll lm">override def dataType: DataType = StringType</span></pre><p id="7b1d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于可空值，因为我们不想从函数中返回空值:</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="9be1" class="lh li hh ld b fi lj lk l ll lm">override def nullable: Boolean = false</span></pre><p id="74b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后一位，“eval”<strong class="ir hi">，</strong>是将生成UUIDs的函数的实际评估。</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="3581" class="lh li hh ld b fi lj lk l ll lm">override def eval(input: InternalRow): Any = UTF8String.fromString(java.util.UUID.randomUUID().toString)</span></pre><p id="fafe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">就是这样！您可能注意到的唯一不寻常的事情是<strong class="ir hi"> UTF8String.fromString()。</strong>如果您尝试不使用它来运行代码，您会看到:</p><p id="0520" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">Java . lang . classcastexception:Java . lang . string不能转换为org . Apache . spark . unsafe . types . utf8 string</strong></p><p id="7289" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">之所以调用该方法，是因为Spark使用它将“外部字符串”转换成“Spark字符串”(<a class="ae ki" href="https://github.com/apache/spark/blob/master/common/unsafe/src/main/java/org/apache/spark/unsafe/types/UTF8String.java#L49" rel="noopener ugc nofollow" target="_blank"><em class="kn">https://github.com/apache/spark/…/UTF8String.java#L49</em></a>)</p><p id="6f1b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最终的代码如下所示:</p><figure class="kr ks kt ku fd ii"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="9f95" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">简单对吗？嗯，在这种情况下，是的，这是一个简单的实现，但它通常不像这样简单。</p><ul class=""><li id="434d" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated"><strong class="ir hi">函数包装器</strong></li></ul><p id="eac7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">既然我们已经编写了catalyst表达式，我们需要让它对Dataframe API可用。为此，我们需要创建一个文件。这个文件的位置不如前一个文件重要，但是为了进行排序，我通常把它放在:</p><p id="2ced" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> org.apache.spark.sql </strong></p><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/07637133b939e330f25dea614262e2fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*HBWNJdkUASc-9-bSUFjPYA.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Location of the Wrapper file</figcaption></figure><p id="8798" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">而这一次，我已经调用了它的CustomFunctions，它需要定义以下内容:</p><figure class="kr ks kt ku fd ii"><div class="bz dy l di"><div class="kv kw l"/></div></figure><p id="08bd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有了这段代码，我们就可以通过对象CustomFunctions使用函数<strong class="ir hi"> Uuid </strong>。</p><ul class=""><li id="7b4c" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated"><strong class="ir hi">用法</strong></li></ul><p id="1a7b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后一个问题是，我们如何使用这个函数？答案相当简单！</p><p id="6125" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们需要像导入其他函数一样导入它:</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="de85" class="lh li hh ld b fi lj lk l ll lm">import org.apache.spark.sql.CustomFunctions.UUID_CUSTOM</span></pre><p id="37d9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">并在我们的数据框架中使用它:</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="5043" class="lh li hh ld b fi lj lk l ll lm">.withColumn("uuid", UUID_CUSTOM())</span></pre><p id="38e5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> 5。性能比较</strong></p><p id="96a9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你可能会问自己的问题是，所有这些真的值得吗？好吧，让我们来看看这些数字。</p><p id="5695" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我使用UDF和catalyst表达式在不同大小的数据帧上运行了相同的代码，结果非常有趣。</p><pre class="kr ks kt ku fd lc ld le lf aw lg bi"><span id="53ff" class="lh li hh ld b fi lj lk l ll lm">// UDF version</span><span id="40dc" class="lh li hh ld b fi ln lk l ll lm">val data = spark.range(nRows).toDF("ID").withColumn("uuid_udf", expr("uuid_udf()"))</span><span id="f1c7" class="lh li hh ld b fi ln lk l ll lm">data.write.format("parquet").mode("overwrite").save(s"/tmp/test/UDF/${runID}")</span><span id="1dd3" class="lh li hh ld b fi ln lk l ll lm">--------</span><span id="25db" class="lh li hh ld b fi ln lk l ll lm">// Catalyst Version</span><span id="6af2" class="lh li hh ld b fi ln lk l ll lm">val data = spark.range(nRows).toDF("ID").withColumn("uuid", UUID_CUSTOM())</span><span id="1113" class="lh li hh ld b fi ln lk l ll lm">data.write.format("parquet").mode("overwrite").save(s"/tmp/test/catalyst/${runID}")</span></pre><p id="976f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我用4个不同的行数运行了每个函数，每个组合运行了100次，然后我得到了这些时间的平均值，结果是这样的:</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/863956a20f9da51ad7368025ad6a7b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*eH0vwBTGl5VEuIN59FazPQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx">Performance comparison (lower is better)</figcaption></figure><p id="9601" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于小数据帧，差异不是很明显。但是，当您增加数据帧的大小时，您可以开始看到Catalyst表达式的性能比UDF好得多。</p><p id="d5c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> 6。结论</strong></p><p id="2a0e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那么我应该停止使用UDF，开始写Catalyst表达式吗？</p><p id="9d6d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我不能回答你，因为这取决于许多不同的方面，如时间、可用资源或知识。</p><p id="e87f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是从测试的<strong class="ir hi">结果可以清楚地看出，如果你需要一个高性能的应用程序或者减少你的工作的执行时间，你应该考虑看看如何编写这些类型的catalyst表达式。</strong></p><p id="678f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> 7。资源</strong></p><p id="3690" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我还没有找到太多关于Catalyst表达式及其实现的文档。因此，如果您想深入了解这一点，我建议您查看一下spark源代码，寻找与您尝试的功能相似的现有功能，并在此基础上实现您的功能:</p><p id="1a41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">例子:</strong></p><p id="b279" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae ki" href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/stringExpressions.scala" rel="noopener ugc nofollow" target="_blank"><em class="kn">https://github . com/Apache/spark/blob/master/SQL/catalyst/src/main/Scala/org/Apache/spark/SQL/catalyst/expressions/string expressions . Scala</em></a></p><p id="f3fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae ki" href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/arithmetic.scala" rel="noopener ugc nofollow" target="_blank"><em class="kn">https://github . com/Apache/spark/blob/master/SQL/catalyst/src/main/Scala/org/Apache/spark/SQL/catalyst/expressions/算术. scala </em> </a></p><p id="204b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">表情:</strong></p><p id="87a0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae ki" href="https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Expression.scala" rel="noopener ugc nofollow" target="_blank"><em class="kn">https://github . com/Apache/spark/blob/master/SQL/catalyst/src/main/Scala/org/Apache/spark/SQL/catalyst/expressions/expression . Scala</em></a></p></div><div class="ab cl jn jo go jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ha hb hc hd he"><p id="81d4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">感谢阅读！</p><p id="2414" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">关于作者<br/> </strong> Daniel是Version 1的大数据开发人员，从事Version 1的数据分析实践，目前负责开发一个带有Databricks的分析平台。</p></div></div>    
</body>
</html>