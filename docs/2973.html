<html>
<head>
<title>KNN Algorithm: A Practical Implementation Of KNN Algorithm In R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KNN算法:KNN算法在R语言中的实际实现</h1>
<blockquote>原文：<a href="https://medium.com/edureka/knn-algorithm-in-r-a2d657bca691?source=collection_archive---------3-----------------------#2019-04-16">https://medium.com/edureka/knn-algorithm-in-r-a2d657bca691?source=collection_archive---------3-----------------------#2019-04-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/29a36bcc2219b07741238e171ba5365e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*auYPFZq911IU7tSzk4BxJA.jpeg"/></div></figure><p id="18f5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">随着我们生成的数据量的增加，对高级机器学习算法的需求也在增加。一种这样的算法是K最近邻算法。在这篇关于R语言中的KNN算法的博客中，你将理解KNN算法是如何工作的，以及它是如何用R语言实现的。</p><p id="4b50" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">R博客中的KNN算法将涉及以下主题:</p><ol class=""><li id="c58f" class="jj jk hh in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated">什么是KNN算法？</li><li id="52df" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">KNN算法的特点</li><li id="fb9a" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">KNN算法是如何工作的？</li><li id="ff81" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">KNN算法用例</li><li id="4bb1" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">KNN算法伪代码</li><li id="de30" class="jj jk hh in b io js is jt iw ju ja jv je jw ji jo jp jq jr bi translated">KNN算法在R语言中的实际实现</li></ol><h1 id="9d1d" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">什么是KNN算法？</h1><blockquote class="kv kw kx"><p id="b1e1" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">代表K最近邻的KNN是一种受监督的机器学习算法，它根据相邻数据点的特征将新数据点分类到目标类中。</p></blockquote><p id="df8d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们用一个简单的例子来理解KNN算法。假设我们想要一台机器来区分猫和狗的图像。要做到这一点，我们必须输入一个猫和狗的图像数据集，我们必须训练我们的模型根据某些特征来检测动物。例如，尖耳朵等特征可以用来识别猫，类似地，我们可以根据狗的长耳朵来识别狗。</p><figure class="ld le lf lg fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lc"><img src="../Images/4bdda97beb9005e4ff602fcd92fc9eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dZm3ziB_9HOwOUEX.png"/></div></div></figure><p id="44be" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="ky">什么是KNN算法？—R—edu reka中的KNN算法</em></p><p id="1799" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在训练阶段研究数据集后，当一张新图像被赋予模型时，KNN算法将根据其特征的相似性将其分类为猫或狗。因此，如果新图像有尖耳朵，它会将该图像归类为猫，因为它与猫图像相似。以这种方式，KNN算法基于数据点与其相邻数据点的相似程度来分类数据点。</p><p id="d349" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在让我们讨论一下KNN算法的特点。</p><h1 id="a7d0" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">KNN算法的特点</h1><p id="7277" class="pw-post-body-paragraph il im hh in b io ll iq ir is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji ha bi translated">KNN算法具有以下特点:</p><ul class=""><li id="a038" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">KNN是一种监督学习算法，它使用带标签的输入数据集来预测数据点的输出。</li><li id="5124" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">它是最简单的机器学习算法之一，可以很容易地实现各种各样的问题。</li><li id="0111" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">主要是基于特征相似度。KNN检查一个数据点与其相邻数据点的相似程度，并将该数据点分类到与其最相似的类别中。</li></ul><figure class="ld le lf lg fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lr"><img src="../Images/03681e6375b1c11d5d0c29b19bb57600.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IoP7QwP-EDDUcDWo5A_LA.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx"><em class="lw">Features of KNN — KNN Algorithm In R — Edureka</em></figcaption></figure><ul class=""><li id="91a6" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">与大多数算法不同，KNN是一个非参数模型，这意味着它不对数据集做任何假设。这使得算法更有效，因为它可以处理现实的数据。</li><li id="d701" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">KNN是一种惰性算法，这意味着它记忆训练数据集，而不是从训练数据中学习判别函数。</li><li id="310b" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">KNN可用于解决分类和回归问题。</li></ul><h2 id="19c0" class="lx jy hh bd jz ly lz ma kd mb mc md kh iw me mf kl ja mg mh kp je mi mj kt mk bi translated">KNN算法示例</h2><p id="0853" class="pw-post-body-paragraph il im hh in b io ll iq ir is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji ha bi translated">为了让你理解KNN算法是如何工作的，让我们考虑下面的场景:</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/b92da9021fa1b99d68c3036c60f2bce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*ithfmb1y9ZCS7wO3NIBErQ.png"/></div></figure><ul class=""><li id="863e" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">在上图中，我们有两类数据，即A类(正方形)和B类(三角形)</li><li id="5709" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">问题陈述是通过使用KNN算法将新的输入数据点分配给两个类中的一个</li><li id="13a3" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">KNN算法的第一步是定义“K”的值。但是KNN算法中的“K”代表什么呢？</li><li id="dabc" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">“K”代表最近邻的数量，因此得名“K最近邻”(KNN)。</li></ul><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/16a98b86cbaffaa5cf415b76e854418c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*BRZ6HoBuoTehP626jLsOFw.png"/></div></figure><ul class=""><li id="a63b" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">在上图中，我将“K”的值定义为3。这意味着该算法将考虑最接近新数据点的三个邻居，以便决定该新数据点的类别。</li><li id="ff16" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">数据点之间的接近程度是通过使用欧几里德距离和曼哈顿距离来计算的，我将在下面解释。</li><li id="4493" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">在K = 3时，邻居包括两个正方形和一个三角形。因此，如果我基于“K”= 3对新数据点进行分类，那么它将被分配到A类(正方形)。</li></ul><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/6452697936b4291d77175e7459d6cf35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*igoPTvJ5FPPbf1UWdoqEUw.png"/></div></figure><ul class=""><li id="6d85" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">但是如果‘K’值设置为7呢？在这里，我基本上是告诉我的算法寻找七个最近的邻居，并将新的数据点分类到它最相似的类别中。</li><li id="0005" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">在K = 7时，邻居包括三个正方形和四个三角形。因此，如果我基于“K”= 7对新数据点进行分类，那么它将被分配到B类(三角形)，因为它的大多数邻居都属于B类。</li></ul><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/0ad380e6ab111979c45094e046713c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*cfvr1ou4eyBqoqf1vjBoDw.png"/></div></figure><p id="7cac" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">实际上，在实现KNN算法时，需要考虑更多的因素。这将在博客的演示部分讨论。</p><p id="3188" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">前面我提到过，KNN使用欧几里得距离作为一种度量来检查新数据点与其邻居之间的距离，让我们看看如何进行。</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/9e7b5ba6b41cea5cfbf24ee7938fe708.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*u9iRyUsvQjkE4xachpt1Pw.png"/></div></figure><ul class=""><li id="fd3c" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">考虑上面的图像，这里我们将使用欧几里德距离度量来测量P1和P2之间的距离。</li><li id="20e2" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">P1和P2的坐标分别是(1，4)和(5，1)。</li><li id="9052" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">欧几里德距离可以这样计算:</li></ul><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/a429a118da5f2e30e52a1ee44d547100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*3KFIHuvCHMMTVwlCVqcChA.png"/></div></figure><p id="be82" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">就这么简单！KNN利用简单的措施来解决复杂的问题，这就是为什么KNN是这样一个常用算法的原因之一。</p><p id="fa01" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">总而言之，让我们看看KNN算法的伪代码。</p><h1 id="7f75" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">KNN算法伪代码</h1><p id="26c9" class="pw-post-body-paragraph il im hh in b io ll iq ir is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji ha bi translated">考虑一下布景，(Xi，Ci)，</p><ul class=""><li id="efac" class="jj jk hh in b io ip is it iw jl ja jm je jn ji lq jp jq jr bi translated">其中Xi表示特征变量，而‘I’是范围从i=1，2，…的数据点..，n</li><li id="b287" class="jj jk hh in b io js is jt iw ju ja jv je jw ji lq jp jq jr bi translated">Ci表示每个I的Xi的输出类</li></ul><p id="cbce" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假设类的总数由‘c’表示，条件<em class="ky"> Ci ∈ {1，2，3，…，c} </em>对于‘I’的所有值都是可接受的。</p><p id="d594" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在让我们假设有一个数据点“x ”,它的输出类需要预测。这可以通过使用K-最近邻(KNN)算法来完成。</p><p id="12e7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> KNN算法伪代码:</strong></p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="292a" class="lx jy hh mo b fi ms mt l mu mv">head(loan.subset)</span><span id="7636" class="lx jy hh mo b fi mw mt l mu mv">Creditability Age..years. Sex...Marital.Status Occupation Account.Balance Credit.Amount</span><span id="90da" class="lx jy hh mo b fi mw mt l mu mv">1             1          21                    2          3               1          1049</span><span id="b44f" class="lx jy hh mo b fi mw mt l mu mv">2             1          36                    3          3               1          2799</span><span id="d043" class="lx jy hh mo b fi mw mt l mu mv">3             1          23                    2          2               2           841</span><span id="ec33" class="lx jy hh mo b fi mw mt l mu mv">4             1          39                    3          2               1          2122</span><span id="686e" class="lx jy hh mo b fi mw mt l mu mv">5             1          38                    3          2               1          2171</span><span id="c9bd" class="lx jy hh mo b fi mw mt l mu mv">6             1          48                    3          2               1          2241</span><span id="76f5" class="lx jy hh mo b fi mw mt l mu mv">Length.of.current.employment Purpose</span><span id="e178" class="lx jy hh mo b fi mw mt l mu mv">1                            2       2</span><span id="cb6e" class="lx jy hh mo b fi mw mt l mu mv">2                            3       0</span><span id="8166" class="lx jy hh mo b fi mw mt l mu mv">3                            4       9</span><span id="285e" class="lx jy hh mo b fi mw mt l mu mv">4                            3       0</span><span id="b48c" class="lx jy hh mo b fi mw mt l mu mv">5                            3       0</span><span id="4e23" class="lx jy hh mo b fi mw mt l mu mv">6                            2       0</span></pre><p id="6af1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">上述伪代码可用于通过使用KNN算法来解决分类问题。</p><p id="1eb9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们进入KNN的实际实现之前，让我们看看KNN算法的一个真实世界的用例。</p><h1 id="b329" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">KNN算法用例</h1><p id="6bf6" class="pw-post-body-paragraph il im hh in b io ll iq ir is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji ha bi translated">你肯定在亚马逊购物过！你有没有注意到，当你购买一个产品时，亚马逊会根据你的购买情况给你一个推荐列表？不仅如此，亚马逊还展示了一个部分，上面写着，“购买了这件商品的顾客也购买了这件商品”。</p><p id="5773" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">机器学习在亚马逊的推荐系统中发挥着巨大的作用。推荐引擎背后的逻辑是根据具有相似购物行为的其他客户向客户推荐产品。</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/675d4bf18f1dc2bb2cb8b217c8a800e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*zY1UePBWRWKn4NoiUpamTQ.png"/></div></figure><p id="baac" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">考虑一个例子，假设一个热爱推理小说的客户A买了《权力的游戏》和《指环王》系列图书。现在，几个星期后，另一个阅读相同类型书籍的顾客B购买了《指环王》。他没有购买《权力的游戏》系列图书，但亚马逊推荐给客户B，因为他的购物行为和书籍选择与客户a非常相似。</p><p id="db9a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，亚马逊根据顾客购物行为的相似程度向顾客推荐产品。这种相似性可以通过实现主要基于特征相似性的KNN算法来理解。</p><p id="3b67" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在你已经知道了KNN是如何工作的，以及它是如何在现实世界的应用程序中使用的，让我们来讨论使用R语言实现KNN。如果你不熟悉R语言，你可以看看我们的机器学习专家录制的这个视频。</p><h1 id="26ee" class="jx jy hh bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">KNN算法在R语言中的实际实现</h1><p id="4724" class="pw-post-body-paragraph il im hh in b io ll iq ir is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji ha bi translated"><strong class="in hi">问题陈述:</strong> <em class="ky">研究一个银行信贷数据集，建立一个机器学习模型，根据申请人的社会经济概况预测其贷款是否能被批准。</em></p><p id="43cc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">数据集描述:</strong>银行信贷数据集包含约1000名申请人的信息。这包括他们的账户余额、信用额度、年龄、职业、贷款记录等。通过使用这些数据，我们可以预测是否批准申请人的贷款。</p><figure class="ld le lf lg fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lr"><img src="../Images/42ed9fc8c5941acd71f99852d2f41372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gl5ECSVgkWM19KnIZZ5Xeg.png"/></div></div></figure><p id="aab2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">逻辑:</strong>这个问题陈述可以使用KNN算法来解决，该算法将申请人的贷款请求分为两类:</p><p id="8e92" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在你知道了这个项目的目标，让我们从编码部分开始。</p><p id="5e6a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第一步:导入数据集</em> </strong></p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="d67d" class="lx jy hh mo b fi ms mt l mu mv">#Import the dataset loan &lt;- read.csv("C:/Users/zulaikha/Desktop/DATASETS/knn dataset/credit_data.csv")</span></pre><p id="4cc9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">导入数据集后，让我们看看数据集的结构:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="fdc7" class="lx jy hh mo b fi ms mt l mu mv">str(loan) 'data.frame': 1000 obs. of 21 variables: $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ...</span></pre><p id="2c72" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">注意,“可信度”变量是我们的输出变量或目标变量。可信度变量的值表示申请人的贷款是被批准还是被拒绝。</p><p id="2970" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第二步:数据清理</em> </strong></p><p id="69a1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从数据集的结构中，我们可以看到有21个预测变量将帮助我们决定是否必须批准申请人的贷款。</p><p id="093f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">其中一些变量在预测申请人的贷款时并不重要，例如，诸如电话、并发等变量。学分、持续时间、当前地址、公寓类型等。这样的变量必须去除，因为它们只会增加机器学习模型的复杂性。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="cc05" class="lx jy hh mo b fi ms mt l mu mv">loan.subset&lt;-loan[c('Creditability','Age..years.','Sex...Marital.Status','Occupation','Account.Balance','Credit.Amount','Length.of.current.employment','Purpose')]</span></pre><p id="a6a1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在上面的代码片段中，我过滤了预测变量。现在，让我们看看我们的数据集是什么样子的:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="d559" class="lx jy hh mo b fi ms mt l mu mv">str(loan.subset)<br/>'data.frame': 1000 obs. of 8 variables:<br/>$ Creditability : int 1 1 1 1 1 1 1 1 1 1 ...<br/>$ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ...<br/>$ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ...<br/>$ Occupation : int 3 3 2 2 2 2 2 2 1 1 ...<br/>$ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ...<br/>$ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ...<br/>$ Length.of.current.employment: int 2 3 4 3 3 2 4 2 1 1 ...<br/>$ Purpose : int 2 0 9 0 0 0 0 0 3 3 ...</span></pre><p id="3f5e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们已经将21个变量缩减为8个对构建模型有重要意义的预测变量。</p><p id="6dd7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第三步:数据归一化</em> </strong></p><p id="0531" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">您必须始终对数据集进行归一化，以使输出保持无偏。为了解释这一点，让我们来看看我们的数据集中的前几个观察结果。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="e2fc" class="lx jy hh mo b fi ms mt l mu mv">head(loan.subset)</span><span id="4fc2" class="lx jy hh mo b fi mw mt l mu mv">Creditability Age..years. Sex...Marital.Status Occupation Account.Balance Credit.Amount</span><span id="66e0" class="lx jy hh mo b fi mw mt l mu mv">1             1          21                    2          3               1          1049</span><span id="8a92" class="lx jy hh mo b fi mw mt l mu mv">2             1          36                    3          3               1          2799</span><span id="a858" class="lx jy hh mo b fi mw mt l mu mv">3             1          23                    2          2               2           841</span><span id="fe67" class="lx jy hh mo b fi mw mt l mu mv">4             1          39                    3          2               1          2122</span><span id="8407" class="lx jy hh mo b fi mw mt l mu mv">5             1          38                    3          2               1          2171</span><span id="7cc3" class="lx jy hh mo b fi mw mt l mu mv">6             1          48                    3          2               1          2241</span><span id="025c" class="lx jy hh mo b fi mw mt l mu mv">Length.of.current.employment Purpose</span><span id="4157" class="lx jy hh mo b fi mw mt l mu mv">1                            2       2</span><span id="71b6" class="lx jy hh mo b fi mw mt l mu mv">2                            3       0</span><span id="b234" class="lx jy hh mo b fi mw mt l mu mv">3                            4       9</span><span id="5ed7" class="lx jy hh mo b fi mw mt l mu mv">4                            3       0</span><span id="6d30" class="lx jy hh mo b fi mw mt l mu mv">5                            3       0</span><span id="8b09" class="lx jy hh mo b fi mw mt l mu mv">6                            2       0</span></pre><p id="1617" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意信用额变量，它的值范围是1000，而其余的变量是个位数或两位数。如果数据没有标准化，将会导致不良的结果。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="0e95" class="lx jy hh mo b fi ms mt l mu mv">#Normalization<br/>normalize &lt;- function(x) {<br/>return ((x - min(x)) / (max(x) - min(x))) }</span></pre><p id="f54c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在下面的代码片段中，我们将规范化数据集存储在“loan.subset.n”变量中，并且我们还删除了“credential”变量，因为它是需要预测的响应变量。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="e6ae" class="lx jy hh mo b fi ms mt l mu mv">loan.subset.n &lt;- as.data.frame(lapply(loan.subset[,2:8], normalize))</span></pre><p id="1455" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是标准化的数据集:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="e8ce" class="lx jy hh mo b fi ms mt l mu mv">head(loan.subset.n)</span><span id="d815" class="lx jy hh mo b fi mw mt l mu mv">Age..years. Sex..Marital Occupation Account.Balance Credit.Amount</span><span id="3cb3" class="lx jy hh mo b fi mw mt l mu mv">1  0.03571429   0.3333333   0.6666667    0.0000000      0.04396390</span><span id="8e51" class="lx jy hh mo b fi mw mt l mu mv">2  0.30357143   0.6666667   0.6666667    0.0000000      0.14025531</span><span id="0f86" class="lx jy hh mo b fi mw mt l mu mv">3  0.07142857   0.3333333   0.3333333    0.3333333      0.03251898</span><span id="c766" class="lx jy hh mo b fi mw mt l mu mv">4  0.35714286   0.6666667   0.3333333    0.0000000      0.10300429</span><span id="14fe" class="lx jy hh mo b fi mw mt l mu mv">5  0.33928571   0.6666667   0.3333333    0.0000000      0.10570045</span><span id="93a6" class="lx jy hh mo b fi mw mt l mu mv">6  0.51785714   0.6666667   0.3333333    0.0000000      0.10955211</span><span id="4acc" class="lx jy hh mo b fi mw mt l mu mv">Length.of.current.employment Purpose</span><span id="0de3" class="lx jy hh mo b fi mw mt l mu mv">0.25                0.2</span><span id="e68d" class="lx jy hh mo b fi mw mt l mu mv">0.50                0.0</span><span id="443f" class="lx jy hh mo b fi mw mt l mu mv">0.75                0.9</span><span id="a7ff" class="lx jy hh mo b fi mw mt l mu mv">0.50                0.0</span><span id="0034" class="lx jy hh mo b fi mw mt l mu mv">0.50                0.0</span><span id="9130" class="lx jy hh mo b fi mw mt l mu mv">0.25                0.0</span></pre><p id="c7ca" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">清理数据集并格式化后，下一步就是数据拼接。数据拼接基本上包括将数据集分成训练数据集和测试数据集。这是在下面的代码片段中完成的:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="6284" class="lx jy hh mo b fi ms mt l mu mv">set.seed(123)<br/>dat.d &lt;- sample(1:nrow(loan.subset.n),size=nrow(loan.subset.n)*0.7,replace = FALSE) #random selection of 70% data.<br/>train.loan &lt;- loan.subset[dat.d,] # 70% training data<br/>test.loan &lt;- loan.subset[-dat.d,] # remaining 30% test data</span></pre><p id="8cc1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在获得训练和测试数据集后，下面的代码片段将为“可信度”变量创建一个单独的数据框架，以便我们的最终结果可以与实际值进行比较。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="60af" class="lx jy hh mo b fi ms mt l mu mv">#Creating seperate dataframe for 'Creditability' feature which is our target.<br/>train.loan_labels &lt;- loan.subset[dat.d,1]<br/>test.loan_labels &lt;-loan.subset[-dat.d,1]</span></pre><p id="c755" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第五步:建立机器学习模型</em> </strong></p><p id="a0c3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这个阶段，我们必须使用训练数据集建立模型。因为我们使用KNN算法来构建模型，所以我们必须首先安装r提供的“类”包。这个包中有KNN函数:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="c0f1" class="lx jy hh mo b fi ms mt l mu mv">#Install class package<br/>install.packages('class')<br/># Load class package<br/>library(class)</span></pre><p id="7d2d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，我们将计算训练数据集中的观察次数。我们这样做的原因是我们想初始化KNN模型中“K”的值。寻找最佳K值的方法之一是计算数据集中观察值总数的平方根。这个平方根会给你K值。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="211a" class="lx jy hh mo b fi ms mt l mu mv">#Find the number of observation<br/>NROW(train.loan_labels)<br/>[1] 700</span></pre><p id="c283" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，我们的训练数据集中有700个观察值。700的平方根约为26.45，因此我们将创建两个模型。一个“K”值为26，另一个“K”值为27。</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="60d7" class="lx jy hh mo b fi ms mt l mu mv">knn.26 &lt;- knn(train=train.loan, test=test.loan, cl=train.loan_labels, k=26)<br/>knn.27 &lt;- knn(train=train.loan, test=test.loan, cl=train.loan_labels, k=27)</span></pre><p id="ec14" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第六步:模型评估</em> </strong></p><p id="3868" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">建立模型后，是时候计算所创建模型的准确性了:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="9e38" class="lx jy hh mo b fi ms mt l mu mv">#Calculate the proportion of correct classification for k = 26, 27<br/>ACC.26 &lt;- 100 * sum(test.loan_labels == knn.26)/NROW(test.loan_labels)<br/>ACC.27 &lt;- 100 * sum(test.loan_labels == knn.27)/NROW(test.loan_labels)<br/>ACC.26<br/>[1] 67.66667<br/>ACC.27<br/>[1] 67.33333</span></pre><p id="903a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如上所示，K = 26时的精度为67.66，K = 27时的精度为67.33。我们还可以用表格形式对照实际值检查预测结果:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="cc6c" class="lx jy hh mo b fi ms mt l mu mv"># Check prediction against actual value in tabular form for k=26</span><span id="1c4e" class="lx jy hh mo b fi mw mt l mu mv">table(knn.26 ,test.loan_labels)</span><span id="d30f" class="lx jy hh mo b fi mw mt l mu mv"><br/>test.loan_labels<br/>knn.26   0     1<br/>0        11    7<br/>1        90   192<br/>knn.26<br/>[1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1</span><span id="6f6a" class="lx jy hh mo b fi mw mt l mu mv">[51] 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span><span id="08ba" class="lx jy hh mo b fi mw mt l mu mv">[101] 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span><span id="aebd" class="lx jy hh mo b fi mw mt l mu mv">[151] 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1</span><span id="511c" class="lx jy hh mo b fi mw mt l mu mv">[201] 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1</span><span id="d4ec" class="lx jy hh mo b fi mw mt l mu mv">[251] 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1</span><span id="daf9" class="lx jy hh mo b fi mw mt l mu mv">Levels: 0 1</span><span id="7f94" class="lx jy hh mo b fi mw mt l mu mv"># Check prediction against actual value in tabular form for k=27 table(knn.27 ,test.loan_labels) test.loan_labels knn.27 0 1 0 11 8 1 90 191 knn.27<br/>[1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1<br/>[51] 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1<br/>[101] 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1<br/>[151] 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1<br/>[201] 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1<br/>[251] 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1<br/>Levels: 0 1</span></pre><p id="a2e6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">你也可以用混淆矩阵来计算准确度。为此，我们必须首先安装臭名昭著的Caret包:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="fb71" class="lx jy hh mo b fi ms mt l mu mv">install.packages('caret')<br/>library(caret)</span></pre><p id="47b9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，让我们使用混淆矩阵来计算K值设置为26的KNN模型的准确性:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="f3d8" class="lx jy hh mo b fi ms mt l mu mv">confusionMatrix(table(knn.26 ,test.loan_labels))<br/>Confusion Matrix and Statistics<br/>test.loan_labels<br/>knn.26   0   1<br/>0  11   7<br/>1  90 192<br/>Accuracy : 0.6767<br/>95% CI : (0.6205, 0.7293)<br/>No Information Rate : 0.6633<br/>P-Value [Acc &gt; NIR] : 0.3365<br/>Kappa : 0.0924<br/>Mcnemar's Test P-Value : &lt;2e-16<br/>Sensitivity : 0.10891<br/>Specificity : 0.96482<br/>Pos Pred Value : 0.61111<br/>Neg Pred Value : 0.68085<br/>Prevalence : 0.33667<br/>Detection Rate : 0.03667<br/>Detection Prevalence : 0.06000<br/>Balanced Accuracy : 0.53687<br/>'Positive' Class : 0</span></pre><p id="fd81" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，从输出中，我们可以看到我们的模型预测结果的准确率为67.67%，这是很好的，因为我们使用的是一个小数据集。需要记住的一点是，你提供给机器的数据(最优数据)越多，模型的效率就越高。</p><p id="cae7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> <em class="ky">第七步:优化</em> </strong></p><p id="a0ab" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了提高模型的精确度，可以使用n种技术，如肘法和最大百分比精确度图。在下面的代码片段中，我创建了一个循环，用于计算从1到28的“K”值的KNN模型的精确度。这样，您可以检查哪个“K”值将产生最准确的模型:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="26a8" class="lx jy hh mo b fi ms mt l mu mv">i=1</span><span id="2ede" class="lx jy hh mo b fi mw mt l mu mv">k.optm=1</span><span id="3be7" class="lx jy hh mo b fi mw mt l mu mv">for (i in 1:28){</span><span id="4f5c" class="lx jy hh mo b fi mw mt l mu mv">+ knn.mod &lt;- knn(train=train.loan, test=test.loan, cl=train.loan_labels, k=i)</span><span id="7ddc" class="lx jy hh mo b fi mw mt l mu mv">+ k.optm[i] &lt;- 100 * sum(test.loan_labels == knn.mod)/NROW(test.loan_labels)</span><span id="49bd" class="lx jy hh mo b fi mw mt l mu mv">+ k=i</span><span id="b2c7" class="lx jy hh mo b fi mw mt l mu mv">+ cat(k,'=',k.optm[i],'</span><span id="ff4f" class="lx jy hh mo b fi mw mt l mu mv">')</span><span id="4b43" class="lx jy hh mo b fi mw mt l mu mv">+ }</span><span id="5c44" class="lx jy hh mo b fi mw mt l mu mv">1 = 60.33333</span><span id="1c12" class="lx jy hh mo b fi mw mt l mu mv">2 = 58.33333</span><span id="d172" class="lx jy hh mo b fi mw mt l mu mv">3 = 60.33333</span><span id="b050" class="lx jy hh mo b fi mw mt l mu mv">4 = 61</span><span id="57ed" class="lx jy hh mo b fi mw mt l mu mv">5 = 62.33333</span><span id="dc1e" class="lx jy hh mo b fi mw mt l mu mv">6 = 62</span><span id="5e22" class="lx jy hh mo b fi mw mt l mu mv">7 = 63.33333</span><span id="5fa4" class="lx jy hh mo b fi mw mt l mu mv">8 = 63.33333</span><span id="c5eb" class="lx jy hh mo b fi mw mt l mu mv">9 = 63.33333</span><span id="8c2f" class="lx jy hh mo b fi mw mt l mu mv">10 = 64.66667</span><span id="5f3f" class="lx jy hh mo b fi mw mt l mu mv">11 = 64.66667</span><span id="b595" class="lx jy hh mo b fi mw mt l mu mv">12 = 65.33333</span><span id="5e0f" class="lx jy hh mo b fi mw mt l mu mv">13 = 66</span><span id="47bf" class="lx jy hh mo b fi mw mt l mu mv">14 = 64</span><span id="a461" class="lx jy hh mo b fi mw mt l mu mv">15 = 66.66667</span><span id="288b" class="lx jy hh mo b fi mw mt l mu mv">16 = 67.66667</span><span id="5a52" class="lx jy hh mo b fi mw mt l mu mv">17 = 67.66667</span><span id="57bf" class="lx jy hh mo b fi mw mt l mu mv">18 = 67.33333</span><span id="3c29" class="lx jy hh mo b fi mw mt l mu mv">19 = 67.66667</span><span id="73d2" class="lx jy hh mo b fi mw mt l mu mv">20 = 67.66667</span><span id="32a1" class="lx jy hh mo b fi mw mt l mu mv">21 = 66.33333</span><span id="5076" class="lx jy hh mo b fi mw mt l mu mv">22 = 67</span><span id="a130" class="lx jy hh mo b fi mw mt l mu mv">23 = 67.66667</span><span id="6b8b" class="lx jy hh mo b fi mw mt l mu mv">24 = 67</span><span id="3f7b" class="lx jy hh mo b fi mw mt l mu mv">25 = 68</span><span id="2de5" class="lx jy hh mo b fi mw mt l mu mv">26 = 67.66667</span><span id="bc1b" class="lx jy hh mo b fi mw mt l mu mv">27 = 67.33333</span><span id="667f" class="lx jy hh mo b fi mw mt l mu mv">28 = 66.66667</span></pre><p id="3612" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从输出中可以看出，对于K = 25，我们实现了最高精度，即68%。我们也可以用图形来表示，就像这样:</p><pre class="ld le lf lg fd mn mo mp mq aw mr bi"><span id="4c89" class="lx jy hh mo b fi ms mt l mu mv">#Accuracy plot<br/>plot(k.optm, type="b", xlab="K- Value",ylab="Accuracy level")</span></pre><figure class="ld le lf lg fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mx"><img src="../Images/5ea9ee4bbd2e2dcb048f5a2ba89e83a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*87WRy4ui6cmD9eYEgEjytQ.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx"><em class="lw">Accuracy Plot — KNN Algorithm In R — Edureka</em></figcaption></figure><p id="5aea" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">上图显示，对于25的“K”值，我们获得了最高的精度。现在您已经知道了如何构建KNN模型，我将让您来构建一个“K”值为25的模型。</p><p id="6938" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这就把我们带到了本文的结尾，在这里我们学习了机器学习中的分类。我希望你清楚本教程中与你分享的所有内容。</p><p id="8b44" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你想查看更多关于Python、DevOps、Ethical Hacking等市场最热门技术的文章，你可以参考Edureka的官方网站。</p><p id="4846" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请留意本系列中的其他文章，它们将解释数据科学的各个方面。</p><blockquote class="kv kw kx"><p id="b7a1" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 1。</em> <a class="ae my" rel="noopener" href="/edureka/data-science-tutorial-484da1ff952b"> <em class="hh">数据科学教程</em> </a></p><p id="7a12" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 2。</em> <a class="ae my" rel="noopener" href="/edureka/math-and-statistics-for-data-science-1152e30cee73"> <em class="hh">数据科学的数学与统计</em> </a></p><p id="cd15" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 3。</em><a class="ae my" rel="noopener" href="/edureka/linear-regression-in-r-da3e42f16dd3"><em class="hh">R中的线性回归</em> </a></p><p id="82ea" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 4。</em> <a class="ae my" rel="noopener" href="/edureka/machine-learning-algorithms-29eea8b69a54"> <em class="hh">机器学习算法</em> </a></p><p id="539a" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 5。</em><a class="ae my" rel="noopener" href="/edureka/logistic-regression-in-r-2d08ac51cd4f"><em class="hh">R中的逻辑回归</em> </a></p><p id="7f2d" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 6。</em> <a class="ae my" rel="noopener" href="/edureka/classification-algorithms-ba27044f28f1"> <em class="hh">分类算法</em> </a></p><p id="f8aa" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 7。</em> <a class="ae my" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="de6e" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 8。</em> <a class="ae my" rel="noopener" href="/edureka/a-complete-guide-on-decision-tree-algorithm-3245e269ece"> <em class="hh">决策树中的R </em> </a></p><p id="bf8b" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 9。</em> <a class="ae my" rel="noopener" href="/edureka/introduction-to-machine-learning-97973c43e776"> <em class="hh">机器学习入门</em> </a></p><p id="6d57" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 10。</em> <a class="ae my" rel="noopener" href="/edureka/naive-bayes-in-r-37ca73f3e85c"> <em class="hh">朴素贝叶斯在R </em> </a></p><p id="5e21" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 11。</em> <a class="ae my" rel="noopener" href="/edureka/statistics-and-probability-cf736d703703"> <em class="hh">统计与概率</em> </a></p><p id="0d25" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">12。 <a class="ae my" rel="noopener" href="/edureka/decision-trees-b00348e0ac89"> <em class="hh">如何创建一个完美的决策树？</em>T11】</a></p><p id="31a1" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 13。</em> <a class="ae my" rel="noopener" href="/edureka/data-scientists-myths-14acade1f6f7"> <em class="hh">关于数据科学家角色的十大误区</em> </a></p><p id="4504" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 14。</em> <a class="ae my" rel="noopener" href="/edureka/data-science-projects-b32f1328eed8"> <em class="hh">顶级数据科学项目</em> </a></p><p id="160d" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">15。 <a class="ae my" rel="noopener" href="/edureka/data-analyst-vs-data-engineer-vs-data-scientist-27aacdcaffa5"> <em class="hh">数据分析师vs数据工程师vs数据科学家</em> </a></p><p id="cb22" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">16。 <a class="ae my" rel="noopener" href="/edureka/types-of-artificial-intelligence-4c40a35f784"> <em class="hh">人工智能的种类</em> </a></p><p id="b99e" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">17。<a class="ae my" rel="noopener" href="/edureka/r-vs-python-48eb86b7b40f"><em class="hh">R vs Python</em></a></p><p id="5d65" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 18。</em> <a class="ae my" rel="noopener" href="/edureka/ai-vs-machine-learning-vs-deep-learning-1725e8b30b2e"> <em class="hh">人工智能vs机器学习vs深度学习</em> </a></p><p id="0990" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 19。</em> <a class="ae my" rel="noopener" href="/edureka/machine-learning-projects-cb0130d0606f"> <em class="hh">机器学习项目</em> </a></p><p id="c1b3" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">20。 <a class="ae my" rel="noopener" href="/edureka/data-analyst-interview-questions-867756f37e3d"> <em class="hh">数据分析师面试问答</em> </a></p><p id="cbea" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 21。</em> <a class="ae my" rel="noopener" href="/edureka/data-science-and-machine-learning-for-non-programmers-c9366f4ac3fb"> <em class="hh">面向非程序员的数据科学和机器学习工具</em> </a></p><p id="0313" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 22。</em> <a class="ae my" rel="noopener" href="/edureka/top-10-machine-learning-frameworks-72459e902ebb"> <em class="hh">十大机器学习框架</em> </a></p><p id="477b" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 23。</em> <a class="ae my" rel="noopener" href="/edureka/statistics-for-machine-learning-c8bc158bb3c8"> <em class="hh">用于机器学习的统计</em> </a></p><p id="bfa9" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 24。</em> <a class="ae my" rel="noopener" href="/edureka/random-forest-classifier-92123fd2b5f9"> <em class="hh">随机森林中的R </em> </a></p><p id="daa5" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 25。</em> <a class="ae my" rel="noopener" href="/edureka/breadth-first-search-algorithm-17d2c72f0eaa"> <em class="hh">广度优先搜索算法</em> </a></p><p id="386f" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 26。</em><a class="ae my" rel="noopener" href="/edureka/linear-discriminant-analysis-88fa8ad59d0f"><em class="hh">R中的线性判别分析</em> </a></p><p id="3ce0" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 27。</em> <a class="ae my" rel="noopener" href="/edureka/prerequisites-for-machine-learning-68430f467427"> <em class="hh">机器学习的先决条件</em> </a></p><p id="d758" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 28。</em> <a class="ae my" rel="noopener" href="/edureka/r-shiny-tutorial-47b050927bd2"> <em class="hh">互动WebApps使用R闪亮</em> </a></p><p id="83a1" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">29。 <a class="ae my" rel="noopener" href="/edureka/top-10-machine-learning-books-541f011d824e"> <em class="hh">机器学习十大书籍</em> </a></p><p id="f9fe" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh">三十。</em> <a class="ae my" rel="noopener" href="/edureka/supervised-learning-5a72987484d0"> <em class="hh">监督学习</em> </a></p><p id="6370" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated"><em class="hh"> 31。</em> <a class="ae my" rel="noopener" href="/edureka/10-best-books-data-science-9161f8e82aca"> <em class="hh"> 10本最好的数据科学书籍</em> </a></p><p id="880f" class="il im ky in b io ip iq ir is it iu iv kz ix iy iz la jb jc jd lb jf jg jh ji ha bi translated">32。 <a class="ae my" rel="noopener" href="/edureka/machine-learning-with-r-c7d3edf1f7b"> <em class="hh">机器学习使用R </em> </a></p></blockquote></div><div class="ab cl mz na go nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ha hb hc hd he"><p id="d141" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="ky">原载于2019年4月16日</em><a class="ae my" href="https://www.edureka.co/blog/knn-algorithm-in-r/" rel="noopener ugc nofollow" target="_blank"><em class="ky">https://www.edureka.co</em></a><em class="ky">。</em></p></div></div>    
</body>
</html>