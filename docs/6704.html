<html>
<head>
<title>Python Scrapy tutorial for beginners — 03 — How to go to the next page</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python初学者Scrapy教程— 03 —如何进入下一页</h1>
<blockquote>原文：<a href="https://medium.com/quick-code/python-scrapy-tutorial-for-beginners-03-how-to-go-to-the-next-page-d29827e0544b?source=collection_archive---------0-----------------------#2019-09-12">https://medium.com/quick-code/python-scrapy-tutorial-for-beginners-03-how-to-go-to-the-next-page-d29827e0544b?source=collection_archive---------0-----------------------#2019-09-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/d75cbef8c367dba3cd2ae724adcfee0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*o2jZZ_RsGFJDYV-w"/></div></figure><p id="09e8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在上一课中，<a class="ae jj" href="https://letslearnabout.net/tutorial/python-scrapy-tutorial-for-beginners-02-extract-all-the-data/" rel="noopener ugc nofollow" target="_blank">用Scrapy提取所有数据，</a>我们设法获取了所有书籍的URL，然后从每本书中提取数据。我们被限制在主页上的书籍，因为我们不知道如何使用Scrapy进入下一页。</p><p id="a306" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">直到现在。</p><p id="edbb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这篇文章中，你将学习如何:</p><ul class=""><li id="ea32" class="jk jl hh in b io ip is it iw jm ja jn je jo ji jp jq jr js bi translated">导航到“下一页”</li><li id="3be9" class="jk jl hh in b io jt is ju iw jv ja jw je jx ji jp jq jr js bi translated">解决路由问题</li><li id="78ec" class="jk jl hh in b io jt is ju iw jv ja jw je jx ji jp jq jr js bi translated">提取每本书的所有数据</li></ul><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="kc kd l"/></div></figure><blockquote class="ke kf kg"><p id="cd58" class="il im kh in b io ip iq ir is it iu iv ki ix iy iz kj jb jc jd kk jf jg jh ji ha bi translated">本课的视频版本</p></blockquote></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><h1 id="dcec" class="ks kt hh bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">我们的游戏计划</h1><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/04de43eb2040d88c5e6dee7c28bbfcf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*e2gDwtRCXgf7ZZzx"/></div></figure><p id="6b62" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">最初，我们只是列出所有书籍的网址，然后，一个接一个，我们提取数据。</p><p id="d2a3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因为我们有20本书，所以我们只列出了20本书的URL，然后解析这20个URL，产生结果。</p><p id="1f98" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们只需要再增加一个步骤。</p><p id="771b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们将列出20个图书URL，解析它们，然后，如果有“下一页”,我们将导航到它以重复这个过程，列出并产生新的20个图书URL，直到没有更多的页面。</p><p id="cb76" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们的<a class="ae jj" href="https://letslearnabout.net/python/beautiful-soup/your-first-web-scraping-script-with-python-beautiful-soup/" rel="noopener ugc nofollow" target="_blank">美汤教程</a>中，我们使用了同样的策略:</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/b40632eb66d0d474bd7c4ac8fe7c66c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*EvKY56wV18nI15aK"/></div></figure><p id="29f6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这就是我们现在要开始使用的。</p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><h1 id="300c" class="ks kt hh bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">检查是否有“下一页”可用</h1><p id="2353" class="pw-post-body-paragraph il im hh in b io lq iq ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji ha bi translated">让我们从第二课中使用的代码开始，<a class="ae jj" href="https://letslearnabout.net/tutorial/python-scrapy-tutorial-for-beginners-02-extract-all-the-data/" rel="noopener ugc nofollow" target="_blank">提取所有数据</a></p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="lv kd l"/></div></figure><p id="d73c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">由于这目前正在工作，我们只需要在for循环结束后检查是否有“下一步”按钮。右键单击下一步按钮:</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es lw"><img src="../Images/1e751d2d396ecce6cef8f1f260928069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/0*L2brakmWURISRS_K"/></div></figure><p id="0cb8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下一页URL在一个<em class="kh">标签内，一个</em>标签内，一个<em class="kh"> li </em>标签内。您知道如何提取它，所以创建一个我们可以导航到的<em class="kh"> next_page_url </em>。请注意，它是一个部分URL，所以您需要添加基本URL。就像我们以前做的那样，你可以自己做。试试看。</p><p id="b213" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我是这样做的:</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="lv kd l"/></div></figure><p id="a8a3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">使用<em class="kh">scrapy crawl spider-o next _ page . JSON</em>运行代码并检查结果。</p><p id="6d24" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是怎么回事？文件中只有20个元素！让我们检查日志，看看发生了什么事。</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/c11f7237befcb9c286e71ca2c9720c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/0*LkMfY0vbXqb0p9cr"/></div></figure><p id="c978" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们设法弄到了第一批20本书，但是突然之间，我们再也买不到更多的书了…</p><p id="d5dc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="kh">books.toscrape.com</em>是<a class="ae jj" href="https://scrapinghub.com/" rel="noopener ugc nofollow" target="_blank">抓取中心</a>做的一个网站，用来培训人们抓取网页，里面有你需要注意的小陷阱。比较成功的URL(蓝色下划线)和失败的URL(红色下划线)。每条路线上都缺少一个<em class="kh">/目录</em>。他们添加它不是为了让你失败。</p><p id="c2f3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们解决这个问题。</p><h1 id="fa49" class="ks kt hh bd ku kv ly kx ky kz lz lb lc ld ma lf lg lh mb lj lk ll mc ln lo lp bi translated">解决“图书”路线问题</h1><p id="a898" class="pw-post-body-paragraph il im hh in b io lq iq ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji ha bi translated">由于有些URL缺少<em class="kh">/目录</em>，我们来检查一下:如果路由没有，我们就把它加到部分URL的前缀上。就这么简单。</p><p id="d23b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">继续之前，请自行尝试。你可以在这里查看我的代码:</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="lv kd l"/></div></figure><p id="195c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们再次运行代码！应该管用吧？<em class="kh">刺儿头爬行蜘蛛-o next_page.json </em></p><p id="d6b1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在我们有更多的书了！但只有40岁。我们设法得到了第一个20，然后是下一个20。然后，发生了一件事。我们没有从第二页拿到第三页。让我们转到第二页，看看“下一步”按钮是怎么回事，并将其与第一个按钮(及其到第二个按钮的链接)进行比较</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ie"><img src="../Images/798343d17e7467c59160118dfbda808a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*RHgbML19vTteYu0G"/></div></div></figure><p id="4a80" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们遇到了与书籍相同的问题:一些链接有<em class="kh">/目录</em>，一些没有。</p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><h1 id="0177" class="ks kt hh bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">解决“下一个”路由问题</h1><p id="696d" class="pw-post-body-paragraph il im hh in b io lq iq ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji ha bi translated">因为我们有同样的问题，所以我们有同样的解决方案。一个你可以轻松解决的问题。你为什么不试试？同样，你只需要检查链接和前缀<em class="kh">/目录</em>，以防子字符串不存在。</p><p id="ce3b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你不能解决它，这是我的解决方案:</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="lv kd l"/></div></figure><p id="26db" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">您可以看到这种模式:我们获取部分URL，检查是否缺少<em class="kh">/catalog</em>，如果缺少，我们添加它。然后，我们添加base_url，我们就有了我们的绝对url。</p><p id="f949" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">再次运行蜘蛛:<em class="kh">刺儿爬蜘蛛-o next_page.json </em>。</p><p id="7d80" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在我们有1000本书了。每一个都是。🙂</p><p id="37c0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这是最后的代码:</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="lv kd l"/></div></figure></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><h1 id="3d98" class="ks kt hh bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h1><p id="f05b" class="pw-post-body-paragraph il im hh in b io lq iq ir is lr iu iv iw ls iy iz ja lt jc jd je lu jg jh ji ha bi translated">你今天达到了一个里程碑。现在你可以从一个网站中提取每一个元素。</p><p id="6c6b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">你已经知道了你需要得到第一页上的所有元素，单独地删除它们，以及如何转到下一页重复这个过程。让我再一次展示这张图表:</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/3362ff64574ac6d78b8e8c038e25c4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*CVLnNvNeLDKfDack"/></div></figure><p id="ad36" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">不仅如此。这个例子很棘手，因为我们必须检查部分URL是否有<em class="kh">/目录</em>来添加它。</p><p id="9948" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">通常情况下，用Scrapy对网站进行分页更容易，因为“下一步”按钮包含完整的URL，所以这个例子比正常情况下更难，但你还是成功了！</p><p id="c17a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">但是…如果我告诉你这比我们以前做的更容易呢？</p><p id="e4e9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">不要拿着你的干草叉去我家，而是去第四课<a class="ae jj" href="https://letslearnabout.net/tutorial/python-scrapy-tutorial-for-beginners-04-crawler-rules-and-linkextractor/" rel="noopener ugc nofollow" target="_blank">那里你将学习如何使用爬行器以更简单的方式刮每一件物品。</a></p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><p id="4496" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><a class="ae jj" href="https://www.youtube.com/channel/UC9OLm6YFRzr4yjlw4xNWYvg?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank">我的Youtube教程视频</a></p><p id="c2e3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><a class="ae jj" href="https://github.com/david1707/scrapy_tutorial/tree/02_lesson" rel="noopener ugc nofollow" target="_blank">Github上的最终代码</a></p><p id="411c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><a class="ae jj" href="https://twitter.com/DavidMM1707" rel="noopener ugc nofollow" target="_blank">在推特上联系我</a></p><p id="3f8d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><a class="ae jj" href="https://letslearnabout.net/tutorial/python-scrapy-tutorial-for-beginners-02-extract-all-the-data/" rel="noopener ugc nofollow" target="_blank">上一课:02 —创建您的第一个蜘蛛</a></p></div><div class="ab cl kl km go kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ha hb hc hd he"><p id="9a34" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><em class="kh">原载于2019年9月12日</em><a class="ae jj" href="https://letslearnabout.net/tutorial/python-scrapy-tutorial-for-beginners-03-how-to-go-to-the-next-page/" rel="noopener ugc nofollow" target="_blank"><em class="kh">【https://letslearnabout.net】</em></a><em class="kh">。</em></p></div></div>    
</body>
</html>