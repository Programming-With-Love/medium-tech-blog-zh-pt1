<html>
<head>
<title>Powering Pinterest ads analytics with Apache Druid</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Druid支持Pinterest广告分析</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/powering-pinterest-ads-analytics-with-apache-druid-51aa6ffb97c1?source=collection_archive---------1-----------------------#2020-01-16">https://medium.com/pinterest-engineering/powering-pinterest-ads-analytics-with-apache-druid-51aa6ffb97c1?source=collection_archive---------1-----------------------#2020-01-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1031" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">菲利普·亚罗什|软件工程师，合作伙伴工程部<br/>王伟鸿|工程经理，合作伙伴工程部</p><h2 id="0bf8" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">变化</strong></h2><p id="c701" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">当我们在2014年推出促销pin时，我们选择Apache HBase作为我们的数据库来存储和提供我们所有的报告指标。在我们广告业务的初期，这是一个合适的选择，因为所需的报道功能数量和整体流量都很低。此外，HBase目前在业内已有良好的记录，我们知道如何成功运营HBase集群。</p><p id="52c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">五年后，我们的业务已经成熟。随着我们的ads规模急剧增加，我们向合作伙伴报告的指标的复杂性也在增加，这使得HBase不足以满足我们的精细分析需求。因此，我们调查了可用的选项，并决定将德鲁伊作为我们下一次迭代的核心组件。</p><h2 id="da4f" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">为什么是德鲁伊？</strong></h2><p id="d83d" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">HBase在访问随机数据点时工作得非常好，但它不是为快速分组和聚合而构建的。过去，我们通过预先构建这些数据视图解决了这一问题，但随着我们报告所需功能的扩展，不再可能存储这么多不同的切片。Druid允许我们绕过所有这些复杂的数据切片摄取逻辑，并且还支持:</p><ul class=""><li id="6920" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">通过卡夫卡实时摄取</li><li id="eecb" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">摄取数据的自动版本控制</li><li id="d045" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">基于用户设置粒度的数据预聚合</li><li id="d243" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">计数型问题的近似算法</li><li id="3294" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">SQL接口</li><li id="2d28" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">易于理解的代码和一个非常支持的社区</li></ul><h2 id="6af0" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">数据摄取</strong></h2><p id="b531" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">Druid支持两种摄取模式:原生和Hadoop。两者都是通过对霸王节点的REST调用来启动的。在本机摄取的情况下，直接在MiddleManager节点上生成一个线程来读取输入数据，而在Hadoop的情况下，Druid启动一个MapReduce作业来并行读取输入。在这两种情况下，获取的数据会根据其输出数据源(表)和时间间隔自动进行版本控制。一旦最新版本的数据可用，Druid将自动开始提供最新版本的数据，并使旧的数据段保持禁用状态，以防我们需要恢复到以前的版本。由于我们有几个不同的数据管道将相同维度的不同指标集生成到一个数据源中，这对我们来说是一个问题。我们如何保持数据版本化，但又不让每个独立的管道覆盖前一个管道的输出？</p><p id="a4a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">命名空间</strong> <strong class="ig hi">碎片规格</strong>被证明是答案。<strong class="ig hi"> </strong>德鲁伊的标准版本管理方法是通过数据源名称、时间间隔和写入时间。我们扩展了这个系统，增加了一个名称空间标识符。然后，我们在数据源中为每个名称空间构建了一个单独的版本化时间间隔时间线，而不是每个数据源只有一个时间线:</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/e3922aa9c1e6a65e19d1856103af833e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RjeF8Qr7zd4TIL_Edg0FxQ.png"/></div></div></figure><p id="c68f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这也意味着我们需要改变现有的摄取机制来创建带有名称空间的段，或者发明一种新的摄取机制。由于我们每天接收数十亿个事件，本机接收对我们来说太慢了，我们并不热衷于建立新的Hadoop集群和更改Hadoop索引代码以符合名称空间。</p><p id="2172" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相反，我们选择改编<a class="ae lc" href="https://github.com/metamx/druid-spark-batch" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">meta MX/druid-spark-batch</strong></a><strong class="ig hi">项目来使用Spark编写我们自己的数据摄取。</strong>原始的druid-spark-batch项目以类似于Hadoop索引器的方式工作，但是它不是启动Hadoop作业，而是启动spark作业。我们的项目运行在一个独立的作业中，根本不需要使用Druid集群的任何资源。它的工作原理如下:</p><ol class=""><li id="08eb" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb ld ki kj kk bi translated">过滤掉不属于输出间隔的事件</li><li id="f4d4" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">根据配置的粒度和每个段文件的行数，将数据划分为多个间隔</li><li id="4534" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">使用Druid的IncrementalIndex类池在磁盘上并行持久化中间索引文件</li><li id="26cc" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">使用最终合并过程将所有索引文件收集到一个段文件中</li><li id="edf6" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">推向深层存储</li><li id="9f1d" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">构造元数据并将其写入MySQL</li></ol><p id="0404" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦元数据被写入，Druid协调器将在下一次拉元数据表时找到新的段，并将新的段分配给历史节点。</p><h2 id="9b00" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">集群设置</strong></h2><p id="c9fc" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">通常，查询广告数据的日期范围分为三类:</p><ol class=""><li id="c9e0" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb ld ki kj kk bi translated">要显示的最近时间段</li><li id="f88b" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">年度同比绩效报告</li><li id="a644" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb ld ki kj kk bi translated">旧的历史数据的随机即席查询。</li></ol><p id="5a5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近一天的查询数量远远超过所有其他报告类型。基于这种理解，我们将德鲁伊集群划分为三个历史层级:</p><ul class=""><li id="6541" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">“热”层在昂贵的计算优化节点上提供最新数据，以处理大型QPS。</li><li id="4f60" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">中型计算上的“冷”层，大量磁盘空间优化节点。为热层中最后一年的无数据数据提供服务。</li><li id="52c2" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">低计算节点上的“冰冷”层具有更多磁盘空间。提供所有其他历史数据。</li></ul><p id="c63f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">热层中的每个历史记录都具有非常低的最大数据容量，以保证节点服务的所有数据段都加载到内存中，而无需进行页面交换。这确保了我们大多数用户驱动的查询的低延迟。对较旧数据的查询通常由自动化系统或报告导出进行，这种方式考虑到了较高的延迟，而不是较高的运营成本。</p><p id="7aee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然这对于一般的查询模式非常有效，但也有意外高负载的情况，这需要集群具有更高的QPS容忍度。这里显而易见的解决方案是增加这些特定情况下的历史节点数量，但是Druid的数据再平衡算法在规模上非常慢。一旦一组新的服务器加入机群，数TB的集群可能需要数小时甚至数天来均衡地重新平衡数据。为了构建一个高效的自动扩展解决方案，我们等不起这么久。</p><p id="169d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于优化重新平衡算法在大型生产系统上部署风险很大，因此我们决定为镜像层实施一个<strong class="ig hi">解决方案。</strong>该系统使用最大二分匹配将镜像层中的每个节点链接到主层中的一个节点。一旦链接建立，镜像历史不需要等待重新平衡算法分配段。相反，它将从主层提取链接节点所服务的数据段列表，并从深层存储下载这些数据段进行服务。它不需要担心复制，因为我们希望这些镜像层会非常频繁地打开和关闭，只在流量大的时候运行。有关更多信息，请参见下文:</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/d5fa1ebffb919338d4dd929bc0acfb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MbZNeevlakEnvCN4MPzJvA.png"/></div></div></figure><p id="78e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在测试过程中，我们借助镜像层解决方案实现了显著的自动扩展改进。现在，从服务器启动到查询服务所花费的时间中，最重要的一部分是来自深层存储的有限I/O带宽。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es le"><img src="../Images/d61a73ae3ce2a702c28f62ab0204d90b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2BIq1ei_s2wCrcKM"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx"><em class="lj">Time taken to load 31 TB of data. 2 hours for natural rebalancing. 5 minutes for mirroring tier.</em></figcaption></figure><h2 id="c3dd" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">查询建筑</strong></h2><p id="5ffe" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">我们的Druid部署是面向外部的，支持从我们的ads管理系统进行交互查询，以及通过我们的外部API进行编程查询。通常，这些查询模式在每个用例中看起来非常不同，但是在所有情况下，我们都需要一个服务来快速有效地构造Druid查询，并拒绝任何无效的查询。对我们的API的编程访问意味着我们会收到大量请求无效日期的查询，或者要求没有度量的实体的重复查询。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lk"><img src="../Images/a7b96d651c0944d5ac7e4709d5ac4c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*drBR8pUPQ71Zg5S9"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx"><em class="lj">Percent of queries returning empty results per API client. Some clients request non-existent metrics up to 90% of the time.</em></figcaption></figure><p id="1c06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">构造并要求Druid执行这些查询是可能的，但是会增加开销，这在低延迟系统中是无法承受的。为了简化对不存在的实体的查询，我们<strong class="ig hi">开发了一个元数据存储，列出了实体及其包含度量的时间间隔</strong>。如果查询请求的实体在指定的时间间隔内没有度量，我们可以立即返回并减轻Druid的额外网络和CPU工作负载。</p><p id="268e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Druid支持两种API来查询数据:native和SQL。SQL支持是Apache方解石支持的新特性。在后端，它获取一个Druid SQL查询，解析它，分析它，并将其转换为一个Druid原生查询，然后执行该查询。SQL支持有很多优点——它对用户更加友好，而且在构建更高效的特别查询方面肯定比用户使用一些不熟悉的JSON更好。</p><p id="f2af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在实现我们的查询构造函数和执行服务时，SQL是我们的第一选择，这是因为我们熟悉SQL。它起作用了，但是我们很快发现了某些Druid无法完成的查询模式，并追踪问题到SQL解析器中的<strong class="ig hi">性能瓶颈，对于具有数千个过滤器或许多复杂投影的查询。最后，我们选择了<strong class="ig hi">，使用本地查询作为我们访问Druid </strong>的主要路径，保持SQL对延迟不敏感的内部用例的支持。</strong></p><h2 id="8f29" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">系统调谐</strong></h2><p id="981a" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">来自一个键值世界，源自我们的API层的单个查询被定制为低复杂度，以允许最佳数量的点查找。这也意味着单独查询每个实体，导致后端的高QPS。为了最大限度地减少对我们整个基础设施的破坏，我们希望保持我们的更改简单，并尽可能接近简单地将HBase换成Druid。实际上，这被证明是完全不可能的。</p><p id="821c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Druid以贪婪的方式保持服务器之间的网络连接，每个查询使用一组新的连接。它还会打开每个查询的对象句柄，这是高QPS系统中的主要瓶颈。为了减轻网络负载，我们<strong class="ig hi">通过批量处理被请求实体的数量来增加每个查询的复杂性。</strong>我们观察到我们的系统在过滤类型查询中处理1，000到2，000个请求的实体时表现最佳，尽管每个部署会有所不同。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es le"><img src="../Images/f603e625e271d5141a7cb5bb493acd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QUJD4JKbVL3waTYs"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx"><em class="lj">QPS after implementing query batching. 15,000 request / second peaks lowered by 10x</em></figcaption></figure><p id="da61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在服务器端，我们发现Druid文档建议的<strong class="ig hi">基本集群调优指南非常有用</strong>。一个不明显的注意事项是，在给定所配置的合并缓冲区数量的情况下，随时可以执行多少个GroupBy查询。应尽可能避免GroupBy查询，而不是Timeseries和TopN查询。这些类型的查询不需要合并缓冲区，因此需要较少的资源来执行。在我们的堆栈中，我们可以选择<strong class="ig hi">基于查询类型</strong>施加速率限制，以避免在给定已配置的合并缓冲区数量的情况下一次执行太多的GroupBy查询。</p><h2 id="efa1" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">未来</strong></h2><p id="946f" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated">我们很兴奋完成了将德鲁伊投入生产的漫长旅程，但是当然我们的工作还在继续。随着Pinterest业务的增长，我们在核心Druid分析平台上的工作也必须随之发展。将我们所有的努力无缝地贡献给主德鲁伊库可能是困难的，但是我们希望与社区分享我们的努力。即在一些特性上，比如Druid段的Spark写入器和读取器、用于自动伸缩的镜像层，以及开发一种新的多路复用IPC协议来代替HTTP。随着ads analytics的成熟，我们也加入了其他团队的用例，帮助他们发现如何最好地大规模使用Druid来满足他们的需求。</p><h2 id="f569" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated"><strong class="ak">致谢</strong></h2><p id="cd10" class="pw-post-body-paragraph ie if hh ig b ih jx ij ik il jy in io ip jz ir is it ka iv iw ix kb iz ja jb ha bi translated"><em class="ll">这个项目是多个团队的共同努力:Ads数据、Ads API和存储缓存。撰稿人和顾问包括露西拉·查尔默、张天英、朱利安·贾菲、埃里克·阮、、、张和韦恩·赵。</em></p><p id="bfeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ll">这也要归功于Imply.io的领导者吉安·梅里诺和·杨，他们向我们介绍并帮助我们引导德鲁伊。</em></p><blockquote class="lm"><p id="e7f7" class="ln lo hh bd lp lq lr ls lt lu lv jb dx translated">我们正在建造世界上第一个视觉发现引擎。全球超过3.2亿人使用Pinterest来梦想、计划和准备他们在生活中想做的事情。来加入我们吧！</p></blockquote></div></div>    
</body>
</html>