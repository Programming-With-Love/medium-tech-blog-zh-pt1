<html>
<head>
<title>PyTorch Tutorial — Implementing Deep Neural Networks Using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch教程—使用PyTorch实现深度神经网络</h1>
<blockquote>原文：<a href="https://medium.com/edureka/pytorch-tutorial-9971d66f6893?source=collection_archive---------1-----------------------#2018-10-29">https://medium.com/edureka/pytorch-tutorial-9971d66f6893?source=collection_archive---------1-----------------------#2018-10-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/990eb5aed47bdb775d1cd76a78c5e3d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*XYbla5GvyQDzx0qZKHyg-g.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx">PyTorch Tutorial — Edureka</figcaption></figure><p id="347f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们从这篇<strong class="ir hi"> PyTorch教程</strong>文章开始，首先确立一个事实，即深度学习是今天<strong class="ir hi">每个人</strong>都在使用的东西，从<strong class="ir hi">虚拟协助</strong>到在<strong class="ir hi">购物</strong>时获得<strong class="ir hi">推荐</strong>！随着更好地利用深度学习的更新工具的出现，编程和实现变得更加容易。</p><p id="2a0a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本<strong class="ir hi"> PyTorch教程</strong>将按以下顺序让您<strong class="ir hi">全面了解</strong>py torch:</p><ul class=""><li id="3815" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">PyTorch是什么？</li><li id="31bb" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">PyTorch的特点</li><li id="d7af" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">安装PyTorch</li><li id="f28a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">NumPy桥</li><li id="e717" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">PyTorch:亲笔签名的模块</li><li id="08e2" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">用例:图像分类器</li></ul><h1 id="adb8" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">Python中的深度学习框架</h1><p id="5609" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">对于编码和处理深度学习来说，Python是首选的，因此有很多框架可供选择。比如:</p><ul class=""><li id="e560" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">张量流</li><li id="e47d" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">PyTorch</li><li id="a56c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">克拉斯</li><li id="615e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">Theano</li><li id="fd62" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">千层面</li></ul><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es le"><img src="../Images/c47732bac5f51d277f544eb449d4e019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pvyx8-QWdo_WBghNOd-zGA.png"/></div></div></figure><h1 id="c0f4" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch是什么？</h1><p id="e60b" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">这是一个基于<strong class="ir hi"> Python的</strong>科学计算<strong class="ir hi">包</strong>针对两组受众:</p><ul class=""><li id="4d45" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">NumPy的一个<strong class="ir hi">替代</strong>，以利用<strong class="ir hi">GPU</strong>的能力。</li><li id="7906" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">深度学习<strong class="ir hi">研究平台</strong>提供最大的<strong class="ir hi">灵活性</strong>和<strong class="ir hi">速度</strong>。</li></ul><h1 id="8614" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch的特点—亮点</h1><ol class=""><li id="33c2" class="jn jo hh ir b is kz iw la ja ln je lo ji lp jm lq jt ju jv bi translated"><strong class="ir hi">Python的本地支持</strong>及其库的使用</li><li id="fa46" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">在脸书的<strong class="ir hi">开发中被积极使用，用于平台中所有的深度学习需求。</strong></li><li id="dc99" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">PyTorch确保了一个<strong class="ir hi">易于使用的API </strong>，这有助于在使用API时更容易使用和更好理解。</li><li id="f1c4" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated"><strong class="ir hi">动态计算图</strong>是这里的一大亮点，因为它们确保了图形的动态构建——在代码执行的每一点，图形都是独立构建的，并且可以在运行时进行操作。</li><li id="fc92" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated"><strong class="ir hi"> PyTorch很快</strong>和<strong class="ir hi">感觉很自然</strong>，因此确保容易编码和快速处理。</li><li id="4d91" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated"><strong class="ir hi">对CUDA </strong>的支持确保了代码可以在GPU上运行，从而减少了运行代码所需的时间，提高了系统的整体性能。</li></ol><h1 id="c3b3" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">安装PyTorch</h1><p id="4d06" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">在本文中，让我们看看在您的机器上安装PyTorch是多么简单。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/7f29cf634c3ec73e79b6631f6c4ba01d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*vEne7MrK5m9vLGYBa-JzYA.png"/></div></figure><p id="44e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">基于系统属性，如<strong class="ir hi">操作系统</strong>或包管理器，这是非常简单的<strong class="ir hi">。它可以从<strong class="ir hi">命令提示符</strong>安装，也可以安装在<strong class="ir hi"> IDE </strong>中，如<strong class="ir hi"> PyCharm </strong>等。</strong></p><p id="9d66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在本文的下一部分，让我们看看<strong class="ir hi"> NumPy </strong>是如何集成到PyTorch中的。</p><h2 id="c20d" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">张量</h2><p id="0188" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">张量类似于NumPy的n维数组，另外张量也可以在GPU上使用，以加速计算。</p><p id="a91a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们构造一个简单的张量并检查输出。首先，让我们看看如何构建一个5×3的矩阵，它是未知的:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="0e46" class="ls kc hh mh b fi ml mm l mn mo">x = torch.empty(5, 3)<br/>print(x)</span></pre><p id="76a1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="841c" class="ls kc hh mh b fi ml mm l mn mo">tensor([[8.3665e+22, 4.5580e-41, 1.6025e-03],<br/>        [3.0763e-41, 0.0000e+00, 0.0000e+00],<br/>        [0.0000e+00, 0.0000e+00, 3.4438e-41],<br/>        [0.0000e+00, 4.8901e-36, 2.8026e-45],<br/>        [6.6121e+31, 0.0000e+00, 9.1084e-44]])</span></pre><p id="e0b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们构造一个随机初始化的矩阵:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="c6c7" class="ls kc hh mh b fi ml mm l mn mo">x = torch.rand(5, 3)<br/>print(x)</span></pre><p id="6575" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="9709" class="ls kc hh mh b fi ml mm l mn mo">tensor([[0.1607, 0.0298, 0.7555],<br/>        [0.8887, 0.1625, 0.6643],<br/>        [0.7328, 0.5419, 0.6686],<br/>        [0.0793, 0.1133, 0.5956],<br/>        [0.3149, 0.9995, 0.6372]])</span></pre><p id="d5cb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">直接从数据构建张量:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="d5f3" class="ls kc hh mh b fi ml mm l mn mo">x = torch.tensor([5.5, 3]) <br/>print(x)</span></pre><p id="daba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="6c82" class="ls kc hh mh b fi ml mm l mn mo">tensor([5.5000, 3.0000])</span></pre><h2 id="dbd1" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated"><strong class="ak">张量运算</strong></h2><p id="5953" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">操作有多种语法。在下面的例子中，我们将看看加法运算:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="b9cd" class="ls kc hh mh b fi ml mm l mn mo">y = torch.rand(5, 3) <br/>print(x + y)</span></pre><p id="ce24" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="5f1e" class="ls kc hh mh b fi ml mm l mn mo">tensor([[ 0.2349, -0.0427, -0.5053],<br/>            [ 0.6455,  0.1199,  0.4239],<br/>            [ 0.1279,  0.1105,  1.4637],<br/>            [ 0.4259, -0.0763, -0.9671],<br/>            [ 0.6856,  0.5047,  0.4250]])</span></pre><p id="2818" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">调整大小:</strong>如果您想要调整张量的形状/大小，您可以使用“torch.view”:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="0472" class="ls kc hh mh b fi ml mm l mn mo">x = torch.randn(4, 4)<br/>y = x.view(16)<br/>z = x.view(-1, 8) # the size -1 is inferred from other dimensions<br/>print(x.size(), y.size(), z.size())</span></pre><p id="9533" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="2af6" class="ls kc hh mh b fi ml mm l mn mo">torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])</span></pre><h1 id="430d" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch的数字</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mp"><img src="../Images/6ca5a70d1c76a8a10afac25631495fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-bN7I2agChvO1khEr4WUA.png"/></div></div></figure><p id="35eb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> NumPy是Python编程语言的库</strong>，增加了对大型多维<strong class="ir hi">数组</strong>和<strong class="ir hi">矩阵</strong>的支持，以及对这些数组进行操作的大量<strong class="ir hi">高级数学函数</strong>。</p><p id="7eb9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它还被用作:</p><ul class=""><li id="259f" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi">库</strong>提供<strong class="ir hi">工具</strong>用于集成C/C++和FORTRAN代码。</li><li id="2599" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">运算具有<strong class="ir hi">线性代数</strong>、<strong class="ir hi">傅立叶变换</strong>和<strong class="ir hi">随机数</strong>功能。</li></ul><p id="20ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">除了其明显的科学用途，NumPy还可以用作通用数据的有效<strong class="ir hi">多维容器</strong>，并且可以定义任意数据类型。</p><p id="0a2d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这允许<strong class="ir hi"> NumPy </strong>到<strong class="ir hi">无缝</strong>并快速<strong class="ir hi">将</strong>与各种<strong class="ir hi">数据库集成！</strong></p><h1 id="f834" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">NumPy桥——阵列和张量</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/5ba892d3628672aff2a16fd4080cdfe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*8aHFTuPyDxRzlOSngpP0oQ.png"/></div></figure><p id="13f9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">将</strong>火炬张量转换为NumPy数组，反之亦然<strong class="ir hi">轻而易举！</strong></p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mr"><img src="../Images/4643a9c470a80b3e430cf341278650e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWoLs1oczSOz0gMN1-rOvg.png"/></div></div></figure><p id="5660" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Torch张量和NumPy数组将<strong class="ir hi">共享它们的底层内存位置</strong>，改变一个将改变另一个。</p><h1 id="54e3" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">将Torch张量转换为NumPy数组:</h1><p id="6923" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">创建火炬张量:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="48ee" class="ls kc hh mh b fi ml mm l mn mo">a = torch.ones(5) <br/>print(a)</span></pre><p id="bfe1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="20da" class="ls kc hh mh b fi ml mm l mn mo">tensor([1., 1., 1., 1., 1.])</span></pre><p id="12ba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">创建NumPy数组:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="09c7" class="ls kc hh mh b fi ml mm l mn mo">b = a.numpy() <br/>print(b)</span></pre><p id="6478" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="645a" class="ls kc hh mh b fi ml mm l mn mo">[1. 1. 1. 1. 1.]</span></pre><p id="25e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们执行<strong class="ir hi">求和运算</strong>并检查<strong class="ir hi">值的变化</strong>:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="9c10" class="ls kc hh mh b fi ml mm l mn mo">a.add_(1)<br/>print(a)<br/>print(b)</span></pre><p id="db62" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="ddd1" class="ls kc hh mh b fi ml mm l mn mo">tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]</span></pre><h1 id="4c99" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">将NumPy数组转换为Torch张量:</h1><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="ed6e" class="ls kc hh mh b fi ml mm l mn mo">import numpy as no<br/>a = np.ones(5)<br/>b = torch.from_numpy(a)<br/>np.add(a, 1, out=a)<br/>print(a)<br/>print(b)</span></pre><p id="13c7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="cc5f" class="ls kc hh mh b fi ml mm l mn mo">[2. 2. 2. 2. 2.] <br/>tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</span></pre><p id="92ae" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以，如你所见，就是这么<strong class="ir hi">简单</strong>就这么简单！</p><p id="c40f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，让我们看看PyTorch的<strong class="ir hi">亲笔签名模块</strong>。</p><h1 id="1591" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch:亲笔签名的模块</h1><p id="215a" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated"><strong class="ir hi">亲笔签名</strong>包为张量上的所有操作提供<strong class="ir hi">自动微分</strong>。</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ms"><img src="../Images/c6155fdc8c8f8e20e0e4164f5b54973c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cv528oQsCW9iHSjaFQ4iyg.png"/></div></div></figure><p id="b3e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是一个<strong class="ir hi">的运行定义框架</strong>，这意味着你的反向开发是由你的代码如何运行来定义的，并且每一次<strong class="ir hi">迭代</strong>都可以<strong class="ir hi">不同</strong>。</p><p id="31e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，在这篇文章中，让我们看一个有趣而简单的用例。</p><h1 id="8408" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch用例:训练图像分类器</h1><p id="2d54" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">一般来说，当你必须处理图像、文本、音频或视频数据时，你可以使用<strong class="ir hi">标准python包</strong>将数据加载到<strong class="ir hi"> Numpy </strong>数组中。然后你可以把这个阵列转换成一个<strong class="ir hi">火炬。*张量</strong>。</p><ul class=""><li id="1d19" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">对于<strong class="ir hi">图像</strong>，像<strong class="ir hi">枕头</strong>和<strong class="ir hi"> OpenCV </strong>这样的包是有用的。</li><li id="93d3" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">对于<strong class="ir hi">音频</strong>，包如<strong class="ir hi"> Scipy </strong>和<strong class="ir hi"> Librosa </strong>。</li><li id="357c" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">对于<strong class="ir hi">文本</strong>，基于原始Python、<strong class="ir hi"> Cython </strong>的加载或<strong class="ir hi"> NLTK </strong>和<strong class="ir hi"> SpaCy </strong>都是有用的。</li></ul><p id="6033" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">具体到视觉，有一个名为<strong class="ir hi"> torchvision </strong>的包，其中有<strong class="ir hi">数据加载器</strong>用于常见数据集，如<strong class="ir hi"> Imagenet、CIFAR10、MNIST等</strong>。和图像数据转换器。</p><p id="5fb9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这为<strong class="ir hi">提供了巨大的便利</strong>和<strong class="ir hi">避免了编写样板代码。</strong></p><p id="e9e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于本教程，我们将使用<strong class="ir hi"> CIFAR10 </strong>数据集。</p><p id="1bd5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它有<strong class="ir hi">类</strong>:‘飞机’，‘汽车’，‘鸟’，‘猫’，‘鹿’，‘狗’，‘青蛙’，‘马’，‘船’，‘卡车’。CIFAR-10中的图像大小为3x32x32，即32×32像素的3通道彩色图像，如下所示:</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/a15227b8ee25f0c038da6095201bb15c.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*LcxB-QedGr9Yg6ETwNHKMQ.png"/></div></figure><h1 id="6351" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">PyTorch:训练CIFAR10分类器</h1><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ms"><img src="../Images/41656ea86b758dbb4a69f1b10e682fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qWkXx849oUOW-MUQsWtYqg.png"/></div></div></figure><p id="b3a8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将依次执行以下步骤:</p><ol class=""><li id="d5a6" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm lq jt ju jv bi translated">加载和规范化CIFAR10</li><li id="0464" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">定义一个卷积神经网络</li><li id="cf95" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">定义损失函数</li><li id="a40e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">根据训练数据训练网络</li><li id="a332" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm lq jt ju jv bi translated">根据测试数据测试网络</li></ol><h2 id="09a8" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">加载和规范化CIFAR10</h2><p id="5d2f" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">使用<strong class="ir hi">火炬视觉</strong>，加载cifar 10<strong class="ir hi">非常容易</strong>！</p><p id="b85a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它就像下面这样简单:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="d0f5" class="ls kc hh mh b fi ml mm l mn mo">import torch<br/>import torchvision<br/>import torchvision.transforms as transforms</span></pre><p id="4d5c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">torchvision数据集的输出是范围[0，1]的<strong class="ir hi"> PILImage </strong>图像。我们把它们转换成归一化范围[-1，1]的张量。</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="5d3c" class="ls kc hh mh b fi ml mm l mn mo">transform = transforms.Compose(<br/>[transforms.ToTensor(),<br/>transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])<br/>trainset = torchvision.datasets.CIFAR10(root='./data', train=True,<br/>download=True, transform=transform)<br/>trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,<br/>shuffle=True, num_workers=2)<br/>testset = torchvision.datasets.CIFAR10(root='./data', train=False,<br/>download=True, transform=transform)<br/>testloader = torch.utils.data.DataLoader(testset, batch_size=4,<br/>shuffle=False, num_workers=2)<br/>classes = ('plane', 'car', 'bird', 'cat',<br/>'deer', 'dog', 'frog', 'horse', 'ship', 'truck')</span></pre><p id="392e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="19e3" class="ls kc hh mh b fi ml mm l mn mo">Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz Files already downloaded and verified</span></pre><p id="72e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，让我们打印一些来自<strong class="ir hi">数据集的<strong class="ir hi">训练图像</strong>！</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="3948" class="ls kc hh mh b fi ml mm l mn mo">import matplotlib.pyplot as plt<br/>import numpy as np<br/> <br/># functions to show an image<br/> <br/> <br/>def imshow(img):<br/>img = img / 2 + 0.5 # unnormalize<br/>npimg = img.numpy()<br/>plt.imshow(np.transpose(npimg, (1, 2, 0)))<br/> <br/> <br/># get some random training images<br/>dataiter = iter(trainloader)<br/>images, labels = dataiter.next()<br/> <br/># show images<br/>imshow(torchvision.utils.make_grid(images))<br/># print labels<br/>print(' '.join('%5s' % classes[labels[j]] for j in range(4)))</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/ff2cab9a35a1bee62defbcb1ca8d673d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*gFTBmSL1C0DUzuY79WOHrQ.png"/></div></figure><p id="7ed2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="93e8" class="ls kc hh mh b fi ml mm l mn mo">dog  bird horse horse</span></pre><h2 id="7331" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">定义一个卷积神经网络</h2><p id="456e" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">考虑使用<strong class="ir hi">三通道图像</strong>(红色、绿色和蓝色)的情况。下面是定义CNN架构的<strong class="ir hi">代码</strong>:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="a7ff" class="ls kc hh mh b fi ml mm l mn mo">import torch.nn as nn<br/>import torch.nn.functional as F<br/> <br/> <br/>class Net(nn.Module):<br/>def __init__(self):<br/>super(Net, self).__init__()<br/>self.conv1 = nn.Conv2d(3, 6, 5)<br/>self.pool = nn.MaxPool2d(2, 2)<br/>self.conv2 = nn.Conv2d(6, 16, 5)<br/>self.fc1 = nn.Linear(16 * 5 * 5, 120)<br/>self.fc2 = nn.Linear(120, 84)<br/>self.fc3 = nn.Linear(84, 10)<br/> <br/>def forward(self, x):<br/>x = self.pool(F.relu(self.conv1(x)))<br/>x = self.pool(F.relu(self.conv2(x)))<br/>x = x.view(-1, 16 * 5 * 5)<br/>x = F.relu(self.fc1(x))<br/>x = F.relu(self.fc2(x))<br/>x = self.fc3(x)<br/>return x<br/> <br/> <br/>net = Net()</span></pre><h2 id="e327" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">定义损失函数和优化器</h2><p id="d126" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">我们将需要<strong class="ir hi">定义</strong>损失函数。在这种情况下，我们可以利用<strong class="ir hi">分类交叉熵</strong>损失。我们也将使用<strong class="ir hi"> SGD </strong>和<strong class="ir hi">动量</strong>。</p><p id="8ced" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">基本上，交叉熵损失是一个范围从0到1的概率值。<strong class="ir hi">完美模型</strong>的交叉熵损失为<strong class="ir hi"> 0 </strong>，但也有可能<strong class="ir hi">的期望值</strong>可能是0.2，但你得到的是2。这将导致<strong class="ir hi">非常高的损耗</strong>并且完全没有效率！</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="289e" class="ls kc hh mh b fi ml mm l mn mo">import torch.optim as optim<br/> <br/>criterion = nn.CrossEntropyLoss()<br/>optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)</span></pre><h2 id="7c0b" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">训练网络</h2><p id="77ff" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">这是事情开始变得有趣的时候！我们只需让<strong class="ir hi">在<strong class="ir hi">数据迭代器</strong>上循环</strong>，然后<strong class="ir hi">将</strong>输入到<strong class="ir hi">网络</strong>和<strong class="ir hi">优化</strong>。</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="9583" class="ls kc hh mh b fi ml mm l mn mo">for epoch in range(2): # loop over the dataset multiple times<br/> <br/>running_loss = 0.0<br/>for i, data in enumerate(trainloader, 0):<br/># get the inputs<br/>inputs, labels = data<br/> <br/># zero the parameter gradients<br/>optimizer.zero_grad()<br/> <br/># forward + backward + optimize<br/>outputs = net(inputs)<br/>loss = criterion(outputs, labels)<br/>loss.backward()<br/>optimizer.step()<br/> <br/># print statistics<br/>running_loss += loss.item()<br/>if i % 2000 == 1999: # print every 2000 mini-batches<br/>print('[%d, %5d] loss: %.3f' %<br/>(epoch + 1, i + 1, running_loss / 2000))<br/>running_loss = 0.0<br/> <br/>print('Finished Training')</span></pre><p id="7873" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="19f7" class="ls kc hh mh b fi ml mm l mn mo">[1,  2000] loss: 2.236<br/>[1,  4000] loss: 1.880<br/>[1,  6000] loss: 1.676<br/>[1,  8000] loss: 1.586<br/>[1, 10000] loss: 1.515<br/>[1, 12000] loss: 1.464<br/>[2,  2000] loss: 1.410<br/>[2,  4000] loss: 1.360<br/>[2,  6000] loss: 1.360<br/>[2,  8000] loss: 1.325<br/>[2, 10000] loss: 1.312<br/>[2, 12000] loss: 1.302<br/>Finished Training</span></pre><h2 id="c465" class="ls kc hh bd kd lt lu lv kh lw lx ly kl ja lz ma kp je mb mc kt ji md me kx mf bi translated">根据测试数据测试网络</h2><p id="ca73" class="pw-post-body-paragraph ip iq hh ir b is kz iu iv iw la iy iz ja lb jc jd je lc jg jh ji ld jk jl jm ha bi translated">我们已经在<strong class="ir hi">训练数据集</strong>上为<strong class="ir hi"> 2遍</strong>训练了网络。但是我们需要<strong class="ir hi">检查</strong>网络是否已经学习了任何东西。</p><p id="c980" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将通过<strong class="ir hi">预测神经网络输出的类别标签</strong> l，并<strong class="ir hi">对照实际情况对其进行检查。</strong>如果预测是<strong class="ir hi">正确的</strong>，我们<strong class="ir hi">将</strong>样本添加到正确预测的列表中。</p><p id="b6d0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好了，第一步！让我们展示一个测试集中的图片来熟悉一下。</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="02e0" class="ls kc hh mh b fi ml mm l mn mo">dataiter = iter(testloader)<br/>images, labels = dataiter.next()<br/> <br/># print images<br/>imshow(torchvision.utils.make_grid(images))<br/>print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/b6f5cb1d596a64c744c6f37a18804ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*5SrPkgtTv2-tuRW5eaLVvA.png"/></div></figure><p id="6ee4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="323a" class="ls kc hh mh b fi ml mm l mn mo">GroundTruth: cat ship ship plane</span></pre><p id="7c66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">好了，现在让我们看看神经网络认为上面这些例子是什么:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="db80" class="ls kc hh mh b fi ml mm l mn mo">outputs = net(images)</span></pre><p id="3ad1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">输出为10个等级的<strong class="ir hi">能量</strong>。一个类别的能量越高，网络越认为该图像属于特定的类别。那么，让我们得到<strong class="ir hi">最高能量</strong>的指数:</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="ce68" class="ls kc hh mh b fi ml mm l mn mo">predicted = torch.max(outputs, 1)<br/> <br/>print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]<br/>for j in range(4)))</span></pre><p id="2927" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="cdc6" class="ls kc hh mh b fi ml mm l mn mo">Predicted: cat car car plane</span></pre><p id="a9a8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="mw">结果好像还不错。</em>T59】</strong></p><p id="90dd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，让我们看看网络在整个数据集上的表现！</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="87c5" class="ls kc hh mh b fi ml mm l mn mo">correct = 0<br/>total = 0<br/>with torch.no_grad():<br/>for data in testloader:<br/>images, labels = data<br/>outputs = net(images)<br/>_, predicted = torch.max(outputs.data, 1)<br/>total += labels.size(0)<br/>correct += (predicted == labels).sum().item()<br/> <br/>print('Accuracy of the network on the 10000 test images: %d %%' % (<br/>100 * correct / total))</span></pre><p id="9897" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="c28c" class="ls kc hh mh b fi ml mm l mn mo">Accuracy of the network on the 10000 test images: 54 %</span></pre><p id="c2b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">那看起来<strong class="ir hi">比chance </strong>要好，后者是<strong class="ir hi"> 10% </strong>的准确率(从10个类中随机挑选一个类)。</p><p id="7623" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">看来好像网络学到了什么！</strong></p><p id="5875" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有哪些<strong class="ir hi">表现好</strong>的课，<strong class="ir hi">表现不好</strong>的课？</p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="1ef4" class="ls kc hh mh b fi ml mm l mn mo">class_correct = list(0. for i in range(10))<br/>class_total = list(0. for i in range(10))<br/>with torch.no_grad():<br/>for data in testloader:<br/>images, labels = data<br/>outputs = net(images)<br/>_, predicted = torch.max(outputs, 1)<br/>c = (predicted == labels).squeeze()<br/>for i in range(4):<br/>label = labels[i]<br/>class_correct[label] += c[i].item()<br/>class_total[label] += 1<br/> <br/> <br/>for i in range(10):<br/>print('Accuracy of %5s : %2d %%' % (<br/>classes[i], 100 * class_correct[i] / class_total[i]))</span></pre><p id="3d92" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">输出:</strong></p><pre class="lf lg lh li fd mg mh mi mj aw mk bi"><span id="b081" class="ls kc hh mh b fi ml mm l mn mo">Accuracy of plane : 61 %<br/>Accuracy of   car : 85 %<br/>Accuracy of  bird : 46 %<br/>Accuracy of   cat : 23 %<br/>Accuracy of  deer : 40 %<br/>Accuracy of   dog : 36 %<br/>Accuracy of  frog : 80 %<br/>Accuracy of horse : 59 %<br/>Accuracy of  ship : 65 %<br/>Accuracy of truck : 46 %</span></pre><p id="c130" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这篇<strong class="ir hi"> PyTorch教程</strong>文章中，我们确保<strong class="ir hi">训练</strong>一个小型的<strong class="ir hi">神经网络</strong>，该网络<strong class="ir hi">对</strong>图像进行分类，结果完全符合预期！</p><p id="f6ea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="mw">这就把我们带到了“PyTorch教程”这篇文章的结尾。我希望这篇文章对你有所帮助，并增加了你的知识价值。</em></p><p id="6864" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你想查看更多关于人工智能、DevOps、道德黑客等市场最热门技术的文章，那么你可以参考<a class="ae mx" href="https://www.edureka.co/blog/?utm_source=medium&amp;utm_medium=content-link&amp;utm_campaign=pytorch-tutorial" rel="noopener ugc nofollow" target="_blank"> Edureka的官方网站。</a></p><p id="27e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请留意本系列中的其他文章，它们将解释深度学习的各个其他方面。</p><blockquote class="my mz na"><p id="f198" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">1.<a class="ae mx" rel="noopener" href="/edureka/tensorflow-tutorial-ba142ae96bca">张量流教程</a></p><p id="6ec2" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">2.<a class="ae mx" rel="noopener" href="/edureka/tensorflow-object-detection-tutorial-8d6942e73adc">tensor flow中的对象检测</a></p><p id="c4ca" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">3.<a class="ae mx" rel="noopener" href="/edureka/perceptron-learning-algorithm-d30e8b99b156">感知器学习算法</a></p><p id="1a0f" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">4.<a class="ae mx" rel="noopener" href="/edureka/neural-network-tutorial-2a46b22394c9">神经网络教程</a></p><p id="0ca7" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">5.什么是反向传播？</p><p id="9526" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">6.<a class="ae mx" rel="noopener" href="/edureka/convolutional-neural-network-3f2c5b9c4778">卷积神经网络</a></p><p id="e413" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">7.<a class="ae mx" rel="noopener" href="/edureka/capsule-networks-d7acd437c9e">胶囊神经网络</a></p><p id="fcbb" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">8.<a class="ae mx" rel="noopener" href="/edureka/recurrent-neural-networks-df945afd7441">递归神经网络</a></p><p id="8287" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">9.<a class="ae mx" rel="noopener" href="/edureka/autoencoders-tutorial-cfdcebdefe37">自动编码器教程</a></p><p id="d7d9" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">10.<a class="ae mx" rel="noopener" href="/edureka/restricted-boltzmann-machine-tutorial-991ae688c154">受限玻尔兹曼机教程</a></p><p id="274e" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">11.<a class="ae mx" rel="noopener" href="/edureka/pytorch-vs-tensorflow-252fc6675dd7"> PyTorch vs TensorFlow </a></p><p id="df89" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">12.<a class="ae mx" rel="noopener" href="/edureka/deep-learning-with-python-2adbf6e9437d">用Python进行深度学习</a></p><p id="5be2" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">13.<a class="ae mx" rel="noopener" href="/edureka/artificial-intelligence-tutorial-4257c66f5bb1">人工智能教程</a></p><p id="4144" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">14.<a class="ae mx" rel="noopener" href="/edureka/tensorflow-image-classification-19b63b7bfd95">张量流图像分类</a></p><p id="02ea" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">15.<a class="ae mx" rel="noopener" href="/edureka/artificial-intelligence-applications-7b93b91150e3">人工智能应用</a></p><p id="475f" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">16.<a class="ae mx" rel="noopener" href="/edureka/become-artificial-intelligence-engineer-5ac2ede99907">如何成为一名人工智能工程师？</a></p><p id="b02d" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">17.<a class="ae mx" rel="noopener" href="/edureka/q-learning-592524c3ecfc">问学习</a></p><p id="45bb" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">18.<a class="ae mx" rel="noopener" href="/edureka/apriori-algorithm-d7cc648d4f1e"> Apriori算法</a></p><p id="fc41" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">19.<a class="ae mx" rel="noopener" href="/edureka/introduction-to-markov-chains-c6cb4bcd5723">用Python实现马尔可夫链</a></p><p id="7abd" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">20.<a class="ae mx" rel="noopener" href="/edureka/artificial-intelligence-algorithms-fad283a0d8e2">人工智能算法</a></p><p id="3d06" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">21.<a class="ae mx" rel="noopener" href="/edureka/best-laptop-for-machine-learning-a4a5f8ba5b">机器学习的最佳笔记本电脑</a></p><p id="2719" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">22.<a class="ae mx" rel="noopener" href="/edureka/top-artificial-intelligence-tools-36418e47bf2a">12大人工智能工具</a></p><p id="959b" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">23.<a class="ae mx" rel="noopener" href="/edureka/artificial-intelligence-interview-questions-872d85387b19">人工智能(AI)面试问题</a></p><p id="767e" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">24.<a class="ae mx" rel="noopener" href="/edureka/theano-vs-tensorflow-15f30216b3bc"> Theano vs TensorFlow </a></p><p id="40e4" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">25.<a class="ae mx" rel="noopener" href="/edureka/what-is-a-neural-network-56ae7338b92d">什么是神经网络？</a></p><p id="4b66" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">26.<a class="ae mx" rel="noopener" href="/edureka/pattern-recognition-5e2d30ab68b9">模式识别</a></p><p id="1f6e" class="ip iq mw ir b is it iu iv iw ix iy iz nb jb jc jd nc jf jg jh nd jj jk jl jm ha bi translated">27.<a class="ae mx" rel="noopener" href="/edureka/alpha-beta-pruning-in-ai-b47ee5500f9a">人工智能中的阿尔法贝塔剪枝</a></p></blockquote></div><div class="ab cl ne nf go ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ha hb hc hd he"><p id="d432" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="mw">原载于2018年10月29日www.edureka.co</em><em class="mw">的</em> <a class="ae mx" href="https://www.edureka.co/blog/pytorch-tutorial/" rel="noopener ugc nofollow" target="_blank"> <em class="mw">。</em></a></p></div></div>    
</body>
</html>