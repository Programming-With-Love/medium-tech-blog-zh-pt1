<html>
<head>
<title>Large Scale Hadoop Upgrade At Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pinterest上的大规模Hadoop升级</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/large-scale-hadoop-upgrade-at-pinterest-a23a112deb73?source=collection_archive---------2-----------------------#2022-03-30">https://medium.com/pinterest-engineering/large-scale-hadoop-upgrade-at-pinterest-a23a112deb73?source=collection_archive---------2-----------------------#2022-03-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/e978e19c47b0f9e21cad640d4802a8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zhVzS5i20PcnbyyP"/></div></div></figure><p id="bb1e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">张永军|软件工程师；威廉·汤姆|软件工程师；王绍文|软件工程师；Bhavin Pathak |软件工程师；批处理平台团队</p><p id="7056" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Pinterest的批处理平台Monarch由超过30个<a class="ae jn" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> Hadoop YARN </a>集群组成，17k+节点完全建立在<a class="ae jn" href="https://aws.amazon.com/ec2/?ec2-whats-new.sort-by=item.additionalFields.postDateTime&amp;ec2-whats-new.sort-order=desc" rel="noopener ugc nofollow" target="_blank"> AWS EC2 </a>之上。2021年初，Monarch还在Hadoop 2.7.1上，已经五岁了。由于反向移植上游变更(特性和错误修复)的复杂性日益增加，我们决定是时候投资进行版本升级了。我们选定了Hadoop 2.10.0，这是当时Hadoop 2的最新版本。</p><p id="53f9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本文分享了我们将Monarch升级到Hadoop 2.10.0的经验。为简单起见，我们用Hadoop 2.10指代Hadoop 2.10.0，用Hadoop 2.7指代Hadoop 2.7.1。</p><h1 id="02de" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">挑战</h1><p id="0cfd" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">自从Pinterest的批处理平台开始(大约2016年)以来，我们一直在使用Hadoop 2.7。随着时间的推移，我们的平台处理的工作负载不断增长和发展，作为回应，我们进行了数百次内部更改来满足这些需求。这些内部补丁大多数都是Pinterest特有的，需要大量的时间投入才能将其移植到Hadoop 2.10。</p><p id="472d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">大多数业务关键型批处理工作负载都在Monarch上运行，因此我们的最高优先级是以不会对这些工作负载造成集群停机或性能/SLA影响的方式执行升级。</p><h1 id="c668" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">升级策略</h1><p id="4094" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">因为许多用户定义的应用程序与Hadoop 2.7紧密耦合，所以我们决定将升级过程分为两个独立的阶段。第一阶段是将平台本身从Hadoop 2.7升级到Hadoop 2.10，第二阶段是将用户定义的应用升级到使用2.10。</p><p id="9245" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在升级的第一阶段，我们将允许用户的工作继续使用Hadoop 2.7依赖项，同时我们专注于平台升级。这增加了额外的开销，因为我们需要使Hadoop 2.7作业与Hadoop 2.10平台兼容，但这将使我们有更多的时间从事第二阶段的工作。</p><p id="a040" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于平台和用户应用的规模，上述两个阶段都需要逐步完成:</p><ul class=""><li id="5701" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">我们需要逐个升级Monarch集群</li><li id="efdf" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">我们需要将用户应用程序批量升级到2.10版，而不是2.7版</li></ul><p id="99f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当时，我们没有一个灵活的构建管道来允许我们构建两个独立版本的作业工件，它们具有独立的hadoop direct和transitive依赖关系。同样，我们要求所有用户(公司的其他工程师)单独验证从2.7到2.10的10，000多项不同的工作迁移也是不合理的。为了支持上述增量升级，我们需要在迁移之前运行许多验证，以确保使用Hadoop 2.7构建的绝大多数应用程序将继续在2.10集群中工作。</p><p id="da52" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们为升级过程提出的高级步骤是:</p><ol class=""><li id="6941" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm lf kx ky kz bi translated">Hadoop 2.10发布准备:将Hadoop 2.7内部分支上的所有补丁移植到普通的Apache Hadoop 2.10</li><li id="e519" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">将Monarch集群逐步升级到Hadoop 2.10(一个接一个)</li><li id="b0ee" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">逐步(分批)升级用户应用程序以使用Hadoop 2.10</li></ol><h1 id="cfbd" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">Hadoop 2.10版本准备</h1><p id="dd76" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">Pinterest 2.7版本包括许多在开源Hadoop 2.7基础上进行的内部更改，这些更改需要移植到Hadoop 2.10。然而，Hadoop 2.7和Hadoop 2.10之间有显著的变化。正因为如此，将Pinterest Hadoop 2.7的变化应用到vanilla Hadoop 2.10上是一项重要的任务。</p><p id="308c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">以下是我们在Hadoop 2.7上制作，然后移植到Hadoop 2.10的一些内部补丁示例:</p><ul class=""><li id="0356" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">Monarch构建在EC2之上，使用S3作为持久存储。任务的输入和输出通常在S3上。添加了DirectOutputFileCommitter，使任务能够将结果直接写入目标位置，以避免在S3复制结果文件的开销。</li><li id="3ff4" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">添加应用程序主服务器和历史服务器端点，以便为给定作业的所有任务获取特定计数器的值。</li><li id="a0d4" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">在提供容器日志时添加范围支持，这允许获取指定容器日志的一部分。</li><li id="e961" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">为日志聚合添加节点Id分区，以便集群中不同节点的日志可以写入不同的S3分区，这有助于避免达到S3访问速率限制。</li><li id="4b81" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">新创建的Namenodes可能有不同的IP地址，这是一个在故障转移时解析NN RPC套接字地址的附加功能。</li><li id="e8e2" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">如果分配的映射器数量与总映射器数量之比超过配置的阈值，则禁用抢占减少器。</li><li id="01fe" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">将磁盘使用监视器线程添加到AM，这样，如果磁盘使用超过了配置的限制，应用程序将被终止。</li></ul><h1 id="08d2" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">将Monarch集群升级到Hadoop 2.10</h1><h2 id="2c41" class="lg jp hh bd jq lh li lj ju lk ll lm jy ja ln lo kc je lp lq kg ji lr ls kk lt bi translated">集群升级方法探索</h2><p id="21b1" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我们评估了将Monarch集群升级到Hadoop 2.10的多种方法。每种方法都有自己的优点和缺点，我们将在下面进行概述。</p><p id="6ffd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">方法一:使用CCR </strong></p><p id="c58a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">正如在<a class="ae jn" href="https://blog.planview.com/how-to-manage-resource-effectively-and-efficiently/" rel="noopener ugc nofollow" target="_blank">高效资源管理</a>文章中提到的，我们开发了跨集群路由(CCR)来平衡各个集群之间的工作负载。为了最大限度地减少对现有2.7集群的影响，一种选择是构建新的Hadoop 2.10集群，并将工作负载逐步迁移到新的集群。如果出现任何问题，我们可以将工作负载路由回其原始集群，修复问题，然后再次路由回2.10集群。</p><p id="f8fd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们从这种方法开始，并在一些小型生产和开发集群上对其进行了评估。没有任何重大问题，但是我们发现了一些缺点:</p><ul class=""><li id="f2fd" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">我们必须为每个集群迁移构建一个新的并行集群。对于大的纱簇(高达几千个节点)，这变得昂贵</li><li id="6fa9" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">工作负载需要批量迁移，这非常耗时。因为Monarch是一个如此大的平台，这个升级过程可能需要很长时间才能完成。</li></ul><p id="2361" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">方式二:滚动升级</strong></p><p id="1063" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">理论上，我们可以尝试工作节点的滚动升级，但是滚动升级可能会影响集群上的所有工作负载。如果我们遇到任何问题，回滚将是昂贵的。</p><p id="f3ae" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">方法三:就地升级</strong></p><p id="ffaa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">利用与我们将集群从一种实例类型就地升级到另一种实例类型类似的方法，我们可以:</p><ol class=""><li id="2c9f" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm lf kx ky kz bi translated">将新实例类型的几个canary主机作为节点的新自动扩展组(canary ASG)插入到集群中</li><li id="899c" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">评估相对于基本ASG(现有实例类型)的金丝雀ASG</li><li id="b466" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">扩展金丝雀ASG</li><li id="ef92" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">ASG基地的规模</li></ol><p id="2c55" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通常，这适用于没有服务级别变化的小型基础架构级别变化。作为一项探索，我们想看看我们能否在Hadoop 2.10升级中做到同样的事情。我们必须做出的一个重要假设是，Hadoop 2.7和2.10组件之间的通信是兼容的。这种方法的步骤是:</p><ol class=""><li id="0252" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm lf kx ky kz bi translated">将Hadoop 2.10 canary工作节点(运行HDFS数据节点和YARN节点管理器)添加到Hadoop 2.7集群</li><li id="8c2f" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">发现并解决出现的问题</li><li id="dfaf" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">增加Hadoop 2.10工作节点的数量，减少Hadoop 2.7工作节点的数量，直到2.7节点完全被2.10节点取代</li><li id="8bf0" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm lf kx ky kz bi translated">升级所有管理器节点(名称节点、日志节点、资源管理器、历史服务器等)。这个过程的工作方式类似于用Hadoop 2.10节点替换工作节点。</li></ol><p id="ab44" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在将这种有风险的方法应用到生产集群之前，我们对dev Monarch集群进行了广泛的评估。除了一些我们将在后面描述的小问题之外，这是一次无缝升级体验。</p><p id="d0f8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">最终确定升级方法</strong></p><p id="4d4d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如前所述，作业工件最初是用Hadoop 2.7依赖项构建的。这意味着他们可能将Hadoop 2.7 jars带入分布式缓存。然后在运行时，我们将用户类路径放在集群上的库路径之前。这可能会导致Hadoop 2.10 canary节点上的依赖问题，因为Hadoop 2.7和2.10可能依赖于不同版本的第三方jar。</p><p id="72b9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在使用方法I对一些小型集群进行升级后，我们发现这种方法需要太长时间来完成所有Monarch集群的升级。此外，考虑到我们最大的monarch集群的规模(多达3k个节点),我们无法在如此短的时间内获得足够的EC2实例来替换这些集群！).我们评估了利弊，决定采用方法三，因为我们可能会大大加快升级过程，并且大多数依赖问题可以很快得到解决。如果我们无法快速解决某些作业的问题，我们可以使用CCR将作业路由到另一个Hadoop 2.7集群，然后花时间解决问题。</p><h2 id="ec94" class="lg jp hh bd jq lh li lj ju lk ll lm jy ja ln lo kc je lp lq kg ji lr ls kk lt bi translated">问题和解决方案</h2><p id="f7d9" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">在我们最终确定了方法三之后，我们的主要焦点就变成了识别任何问题并尽快解决它们。概括地说，我们遇到了三类问题:由于Hadoop 2.7和Hadoop 2.10之间的不兼容而导致的服务级别问题，用户定义的应用程序中的依赖性问题，以及其他各种问题。</p><p id="47af" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">不兼容行为问题</strong></p><ul class=""><li id="d1c6" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">重启Hadoop 2.10 NM导致容器被杀死。我们发现Hadoop 2.10引入了一个默认为FALSE的新配置<em class="lu">yarn . node manager . recovery . supervised</em>。为了防止重启NMs时容器被杀死，我们需要设置TRUE。当启用此配置时，正在运行的节点管理器在退出时不会尝试清理容器，因为假设它会立即重启并恢复容器。</li><li id="6584" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">在2.10金丝雀节点上安排AM时作业停滞:在<a class="ae jn" href="https://issues.apache.org/jira/browse/MAPREDUCE-6515" rel="noopener ugc nofollow" target="_blank"> MAPREDUCE-6515 </a>中添加了应用程序优先级，假定该字段始终在PB响应中设置。在版本分离的集群(2 . 7 . 1 resource manager+2.10 worker)中，情况并非如此，因为RM返回的PB响应将不包含appPriority字段。我们检查这个字段是否在protobuf中，如果不在，我们忽略更新applicationPriority。</li><li id="b534" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated"><a class="ae jn" href="https://issues.apache.org/jira/browse/HADOOP-13680" rel="noopener ugc nofollow" target="_blank"> HADOOP-13680 </a>使得<em class="lu"> fs.s3a.readahead.range </em>从Hadoop 2.8开始使用getLongBytes，支持“32M”格式的值(内存后缀K，M，G，T，P)。但是，Hadoop 2.7代码无法处理这种格式。这会中断混合Hadoop版本集群中的作业。我们对Hadoop 2.7添加了一个修复，使其与Hadopop 2.10行为兼容。</li><li id="60a1" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">Hadoop 2.10意外地在io.serialization config的多个值之间引入了空格，这导致了ClassNotFound错误。我们进行了修复，删除了配置值中的空格。</li></ul><p id="655f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">依赖问题</strong></p><p id="e2f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们执行Hadoop 2.7到2.10的就地升级时，我们面临的大多数依赖关系问题都是由于Hadoop服务和用户应用程序之间共享的不同版本的依赖关系造成的。解决方案要么是修改用户的作业以与Hadoop平台依赖项兼容，要么是在我们的作业工件或Hadoop平台分发中屏蔽版本。以下是一些例子:</p><ul class=""><li id="8bbe" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">Hadoop 2.7 jars被放入分布式缓存，并导致Hadoop 2.10 canary节点上的依赖性问题。我们在Hadoop 2.7版本中实现了一个解决方案，以防止这些jar被添加到分布式缓存中，以便所有主机都使用已经部署到主机的Hadoop jars。</li><li id="bc6f" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">Woodstox-core包。Hadoop-2.10.0依赖于woodstox-core-5.0.3.jar，而一些应用程序依赖于另一个依赖于wstx-asl-3.2.7.jar的模块。woodstox-core-5.0.3.jar和wstx-asl-3.2.7.jar之间的不兼容导致了作业失败。我们的解决方案是在Hadoop 2.10中屏蔽woodstox-core-5.0.3.jar。</li><li id="974c" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">我们有一些基于Hadoop 2.7实现的内部库或类。它们不能在Hadoop 2.10上运行。例如，我们有一个名为s3DoubleWrite的类，它同时将输出写入两个S3位置。开发它是为了帮助我们在3个存储桶之间迁移日志。由于我们不再需要那个类，我们弃用它来解决依赖性问题。</li><li id="d0f5" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">一些Hadoop 2.7库被打包到用户的bazel jars中，并在运行时导致一些依赖问题。我们采取的解决方案是将用户应用程序从Hadoop jars中分离出来。更多细节可以在后面的相关章节中找到。</li></ul><p id="03ef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">其他杂项问题</strong></p><ul class=""><li id="f856" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">我们在dev集群上执行的验证之一是确保我们可以在升级过程的中途回滚。当我们试图将NameNode回滚到Hadoop 2.7时，revert出现了一个问题。我们发现NameNode没有收到来自升级后的DataNodes的块报告。我们确定的解决方法是手动触发阻止报告。我们后来发现了潜在的问题HDFS-12749 (DN可能不会在NN重启后向NN发送块报告)并将其反向传输。</li><li id="4a16" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">当捆绑了Hadoop 2.7 jars的Hadoop流作业部署到Hadoop 2.10节点时，预期的2.7 jar不可用。这是因为我们使用集群提供的jar来满足大多数用户工件分发的依赖性，以减少工件的大小。然而，所有Hadoop依赖项都有编码在jar名称中的版本。解决方案是使Hadoop流作业捆绑包Hadoop jars不带版本字符串，以便提供的Hadoop依赖项在运行时始终位于类路径中，而不管它运行的节点是Hadoop 2.7还是2.10。</li></ul><h1 id="1d66" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">将用户应用升级到Hadoop 2.10</h1><p id="aa9d" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">为了将用户应用升级到Hadoop 2.10，我们需要确保Hadoop 2.10在编译时和运行时都能使用。第一步是确保Hadoop 2.7 jars没有与用户jar一起发布，以便在运行时使用部署到集群的Hadoop jar(2.7节点中使用2.7 jar，2.10节点中使用2.10 jar)。然后我们改变了用户应用构建环境，使用Hadoop 2.10而不是2.7。</p><h2 id="095a" class="lg jp hh bd jq lh li lj ju lk ll lm jy ja ln lo kc je lp lq kg ji lr ls kk lt bi translated">将用户应用从Hadoop jars中分离出来</h2><p id="09fc" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">在Pinterest，大多数数据管道都使用Bazel制造的胖罐子。这些jar包含所有的依赖项，包括升级前的Hadoop 2.7客户端库。我们总是支持来自那些fat jar的类，而不是来自本地环境的类，这意味着当在具有Hadoop 2.10的集群上运行那些fat jar时，我们仍将使用Hadoop 2.7类。</p><p id="bbfb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了永久解决这个问题(在2.10集群中使用2.7 jars)，我们决定将用户的Bazel jars与Hadoop库分离；也就是说，我们不再在胖用户Bazel jar中提供Hadoop jar，已经部署到集群节点的Hadoop jar将在运行时使用。</p><p id="1173" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Bazel java_binary rules有一个名为deploy_env的参数，它的值是表示这个二进制文件的部署环境的其他java_binary目标的列表。我们设置这个属性来从用户jar中排除所有Hadoop依赖项及其子依赖项。这里的挑战是，许多用户应用程序都依赖于Hadoop所依赖的库。这些公共库很难识别，因为它们没有被明确指定，因为它们已经作为节点管理器部署的一部分在Hadoop workers上提供了。在测试期间，我们投入了大量的精力来识别这些类型的情况，并修改了用户的bazel规则，以显式地添加那些隐藏的依赖关系。</p><h2 id="24ac" class="lg jp hh bd jq lh li lj ju lk ll lm jy ja ln lo kc je lp lq kg ji lr ls kk lt bi translated">将Hadoop bazel目标从2.7升级到2.10</h2><p id="ce42" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">在将用户应用与Hadoop Jars分离之后，我们需要将Hadoop bazel目标从2.7升级到2.10，这样我们就可以确保构建和运行时环境中使用的Hadoop版本是一致的。Hadoop 2.7和Hadoop 2.10在这个过程中又出现了一些依赖冲突。我们通过构建测试确定了这些依赖项，并相应地将它们升级到正确的版本。</p><h1 id="8769" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">摘要</h1><p id="cb12" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">将17k以上的节点从一个Hadoop版本升级到另一个版本，同时不对应用程序造成重大中断，这是一个挑战。我们设法做到了高质量、合理的速度和成本效益。我们希望以上分享的经验能对社区有益。</p><h1 id="396a" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">确认</h1><p id="bf66" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">感谢批处理平台团队的、郭衡哲、桑迪普·库马尔、波格丹一世·皮西卡、康奈尔·多纳吉，他们在整个升级过程中提供了很多帮助。感谢Soam Acharya、Keith Regier致力于解决FGAC集群中遇到的问题。感谢金俊成、李凡和王春燕一路走来的支持。感谢工作流团队、查询团队和我们平台用户团队的支持。</p><p id="eefc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lu">要在Pinterest了解更多关于工程的知识，请查看我们的</em> <a class="ae jn" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="lu">工程博客</em> </a> <em class="lu">，并访问我们的</em><a class="ae jn" href="https://www.pinterestlabs.com/?utm_source=medium&amp;utm_medium=blog-link&amp;utm_campaign=zhang-et-al-march-30-2022" rel="noopener ugc nofollow" target="_blank"><em class="lu">Pinterest Labs</em></a><em class="lu">网站。要查看和申请空缺职位，请访问我们的</em> <a class="ae jn" href="https://www.pinterestcareers.com/?utm_source=medium&amp;utm_medium=blog-link&amp;utm_campaign=zhang-et-al-march-30-2022" rel="noopener ugc nofollow" target="_blank"> <em class="lu">招聘</em> </a> <em class="lu">页面</em></p></div></div>    
</body>
</html>