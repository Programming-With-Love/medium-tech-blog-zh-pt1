<html>
<head>
<title>Spark: Mocking Read, ReadStream, Write and WriteStream</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark:模仿读、读流、写和写流</h1>
<blockquote>原文：<a href="https://medium.com/walmartglobaltech/spark-mocking-read-readstream-write-and-writestream-b6fe70761242?source=collection_archive---------2-----------------------#2022-09-29">https://medium.com/walmartglobaltech/spark-mocking-read-readstream-write-and-writestream-b6fe70761242?source=collection_archive---------2-----------------------#2022-09-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/ccaade58f6cb25ea83438a2ea7afd667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nbEjCsuu9okEtFPzf_3ocQ.jpeg"/></div></div></figure><p id="cd85" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi jn translated">spark管道的低代码覆盖率是由于缺少源和汇的单元测试用例造成的。我们大多数spark scala管道的代码覆盖率低于70%。我们希望它在85–95%的范围内。</p><figure class="jx jy jz ka fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jw"><img src="../Images/2cafcf6cfdbe69d8ff78906593975a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YG6neXlg3bNNjCLaHIEGng.png"/></div></div></figure><p id="52db" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Spark支持多个批处理和流源，像</p><ol class=""><li id="57bf" class="kb kc hh ir b is it iw ix ja kd je ke ji kf jm kg kh ki kj bi translated">战斗支援车</li><li id="96e6" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">JSON</li><li id="de74" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">镶木地板</li><li id="ff35" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">妖魔</li><li id="4661" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">文本</li><li id="9455" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">JDBC/ODBC连接</li><li id="dc5a" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">卡夫卡</li></ol><p id="7388" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为spark读写编写测试用例的限制降低了整体代码覆盖率，因此降低了流水线的整体质量分数。由于读取和写入是数据管道中无处不在的一部分，相应的代码行在所有代码行中占很大比例。</p></div><div class="ab cl kp kq go kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ha hb hc hd he"><p id="d391" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们来看看提高spark scala管道代码质量度量的分步指南。</p></div><div class="ab cl kp kq go kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ha hb hc hd he"><p id="541f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面是嘲讽概念的总结</p><p id="a09c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">单元测试用例编写中的嘲讽</strong>是测试编写代码的行为和逻辑</p><p id="64ba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">模拟</strong>用于行为验证，它完全控制对象及其方法</p><p id="3968" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">存根是<strong class="ir hi"> </strong>用于保存本质上受限制的数据，并用于在单元测试用例期间返回</p><p id="520e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> Spy </strong>用于部分模仿，其中只有选择的行为需要被模仿，其余的需要是对象的原始行为</p><p id="46af" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们进入火花细节</p><p id="4937" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">基于Maven的依赖关系</strong></p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="c14a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们用一个spark类的例子，其中源是<strong class="ir hi">配置单元</strong>和<strong class="ir hi"/><strong class="ir hi"/>接收器是<strong class="ir hi"> JDBC。</strong></p><p id="f9d8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ky"> DummySource.scala </em>从Hive中读取一个表，应用一个过滤器，然后写入一个JDBC表。</p><blockquote class="kz la lb"><p id="c000" class="ip iq ky ir b is it iu iv iw ix iy iz lc jb jc jd ld jf jg jh le jj jk jl jm ha bi translated">我们跳过应用其他逻辑的转换，因为可以使用<strong class="ir hi">存根</strong>进行测试</p></blockquote><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="a05d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们不需要编写代码连接到源或接收器的单元测试用例。所以这里我们想要模拟spark的读写行为。在我们研究解决方案之前，最好先熟悉一下Spark DataFrameReader和DataFrameWriter</p><p id="5585" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因为我们要模拟下面的两个类，所以了解所有的方法/行为是很重要的</p><div class="lf lg ez fb lh li"><a href="https://spark.apache.org/docs/3.2.1/api/scala/org/apache/spark/sql/DataFrameReader.html" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab dw"><div class="lk ab ll cl cj lm"><h2 class="bd hi fi z dy ln ea eb lo ed ef hg bi translated">spark 3 . 2 . 1 Scala doc-org . Apache . spark . SQL . data frame reader</h2><div class="lp l"><h3 class="bd b fi z dy ln ea eb lo ed ef dx translated">spark 3 . 2 . 1 Scala doc-org . Apache . spark . SQL . data frame reader</h3></div><div class="lq l"><p class="bd b fp z dy ln ea eb lo ed ef dx translated">火花3.2.1斯卡拉多克-org.apache.spark.sql.DataFrameReaderspark.apache.org</p></div></div></div></a></div><div class="lf lg ez fb lh li"><a href="https://spark.apache.org/docs/3.2.1/api/scala/org/apache/spark/sql/DataFrameWriter.html" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab dw"><div class="lk ab ll cl cj lm"><h2 class="bd hi fi z dy ln ea eb lo ed ef hg bi translated">spark 3 . 2 . 1 Scala doc-org . Apache . spark . SQL . data frame writer</h2><div class="lp l"><h3 class="bd b fi z dy ln ea eb lo ed ef dx translated">spark 3 . 2 . 1 Scala doc-org . Apache . spark . SQL . data frame writer</h3></div><div class="lq l"><p class="bd b fp z dy ln ea eb lo ed ef dx translated">火花3.2.1斯卡拉多克-org.apache.spark.sql.DataFrameWriterspark.apache.org</p></div></div></div></a></div></div><div class="ab cl kp kq go kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ha hb hc hd he"><h2 id="1002" class="lr ls hh bd lt lu lv lw lx ly lz ma mb ja mc md me je mf mg mh ji mi mj mk ml bi translated">嘲笑阅读</h2><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="e829" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这里的目标是避免连接到源，并且仍然得到一个数据帧，以便我们的过滤器逻辑被单元测试。所以我们从嘲笑火花会议开始</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="1a94" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">SparkSession.read返回<em class="ky">org . Apache . spark . SQL . DataFrameReader，</em>所以现在我们将模仿data frame reader</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="c53d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们拥有所有需要的模拟对象。是时候控制这些行为了。当spark.read被调用时，我们需要<em class="ky"> mockSpark </em>返回<em class="ky"> mockDataFrameReader </em></p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="e7be" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在调用spark.read.table时返回DataFrame的地方，还需要添加一个行为，为此我们创建了一个存根对象</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="9f29" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们添加所需的行为</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="ef28" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们通过添加断言来完成我们的测试。</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="9090" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们已经通过模仿spark的Hive read完成了单元测试用例。</p><p id="16c3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将在目前所学的基础上继续努力。从模仿开始</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="7f20" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在添加行为</p><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><blockquote class="kz la lb"><p id="c7d9" class="ip iq ky ir b is it iu iv iw ix iy iz lc jb jc jd ld jf jg jh le jj jk jl jm ha bi translated">doNothing用于void方法</p></blockquote><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure><h2 id="e389" class="lr ls hh bd lt lu lv lw lx ly lz ma mb ja mc md me je mf mg mh ji mi mj mk ml bi translated">卡夫卡式的嘲讽</h2><p id="b6fa" class="pw-post-body-paragraph ip iq hh ir b is mm iu iv iw mn iy iz ja mo jc jd je mp jg jh ji mq jk jl jm ha bi translated">流媒体源需要一组不同的类来模拟，如<em class="ky">org . Apache . spark . SQL . streaming . datastreamreader</em>和<em class="ky">org . Apache . spark . SQL . streaming . datastreamwriter</em></p><p id="4a53" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面是使用上述步骤的示例测试用例</p><ol class=""><li id="ad2e" class="kb kc hh ir b is it iw ix ja kd je ke ji kf jm kg kh ki kj bi translated">模拟的</li><li id="7613" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">行为</li><li id="08e4" class="kb kc hh ir b is kk iw kl ja km je kn ji ko jm kg kh ki kj bi translated">主张</li></ol><figure class="jx jy jz ka fd ii"><div class="bz dy l di"><div class="kw kx l"/></div></figure></div><div class="ab cl kp kq go kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ha hb hc hd he"><h1 id="febe" class="mr ls hh bd lt ms mt mu lx mv mw mx mb my mz na me nb nc nd mh ne nf ng mk nh bi translated"><strong class="ak">结论</strong></h1><p id="c3f4" class="pw-post-body-paragraph ip iq hh ir b is mm iu iv iw mn iy iz ja mo jc jd je mp jg jh ji mq jk jl jm ha bi translated">Mocking帮助我们实现了超过80%的代码覆盖率，并被推荐用于所有基于JVM的spark管道。</p></div><div class="ab cl kp kq go kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ha hb hc hd he"><blockquote class="kz la lb"><p id="2cca" class="ip iq ky ir b is it iu iv iw ix iy iz lc jb jc jd ld jf jg jh le jj jk jl jm ha bi translated">快乐学习</p></blockquote></div></div>    
</body>
</html>