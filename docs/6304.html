<html>
<head>
<title>Interactive Querying with Apache Spark SQL at Pinterest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Pinterest上使用Apache Spark SQL进行交互式查询</h1>
<blockquote>原文：<a href="https://medium.com/pinterest-engineering/interactive-querying-with-apache-spark-sql-at-pinterest-2a3eaf60ac1b?source=collection_archive---------2-----------------------#2021-07-12">https://medium.com/pinterest-engineering/interactive-querying-with-apache-spark-sql-at-pinterest-2a3eaf60ac1b?source=collection_archive---------2-----------------------#2021-07-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8a6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Sanchay Javeria |软件工程师，大数据查询平台，数据工程</p><p id="dd56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Ashish Singh |数据工程大数据查询平台技术主管</p><p id="1238" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了实现通过我们的视觉发现引擎为每个人带来灵感的使命，Pinterest在很大程度上依赖于做出数据驱动的决策，以改善超过4.75亿月活跃用户的Pinner体验。可靠、快速且可扩展的交互式查询对于实现这些数据驱动的决策至关重要。过去，我们在Pinterest 上发表过<a class="ae jc" rel="noopener" href="/pinterest-engineering/presto-at-pinterest-a8bda7515e52"> Presto如何服务于这个功能。在这里，我们将分享如何使用Apache Spark SQL构建一个可伸缩、可靠、高效的交互式查询平台，每天处理数百Pb的数据。通过对各种架构选择、挑战以及我们应对这些挑战的解决方案的详细讨论，我们分享了我们如何通过Spark SQL成功实现交互式查询。</a></p><h1 id="d2ce" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">计划查询与交互式查询</h1><p id="e041" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">查询是用户从Pinterest的数据中获取理解的最受欢迎的方式。这种分析的应用存在于所有商业/工程功能中，如机器学习、广告、搜索、家庭反馈推荐、信任和安全等。提交这些查询主要有两种方式:预定的和交互的。</p><ol class=""><li id="97ac" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><strong class="ig hi">预定查询</strong>是按预定义的频率运行的查询。这些查询通常有严格的服务级别目标(SLO)。</li><li id="6adf" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><strong class="ig hi">交互式查询</strong>是在需要时执行的查询，通常不会按照预先定义的节奏重复。与预定查询不同，用户等待交互式查询完成，并不知道可能导致查询失败的潜在问题。这些特征使得交互式查询平台的需求不同于预定的查询平台。</li></ol><p id="bab3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在接下来的章节中，我们将深入探讨如何在Pinterest上使用Spark SQL扩展交互式查询。我们首先讨论如何在Pinterest使用Spark SQL，以及使用Spark SQL进行交互式查询所面临的挑战。接下来，我们将介绍该架构，并讨论我们如何应对一路走来所面临的挑战。</p><h1 id="6657" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">Spark SQL交互式查询</h1><p id="8dca" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们支持Hive、Presto和Spark SQL来查询数据。然而，我们正在贬低Hive而支持Spark SQL，给我们留下了两个主要的查询引擎(即Presto和Spark SQL)。Presto用于快速交互查询，本<a class="ae jc" rel="noopener" href="/pinterest-engineering/presto-at-pinterest-a8bda7515e52">帖子</a>对此进行了介绍。Spark SQL用于所有计划的查询(在Hive弃用完成后不久)和大型数据集上的交互式查询。下面是我们在从Hive迁移到Spark SQL时考虑的支持使用Spark SQL进行交互查询的各种方法。</p><h2 id="74f2" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">Apache Spark的节俭JDBC/ODBC服务器</h2><p id="910e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">Apache Spark的节俭JDBC/ODBC服务器(STS)类似于HiveServer2，允许客户端通过JDBC/ODBC协议执行Spark SQL查询。JDBC/ODBC协议是各种客户端提交查询的最流行方式之一。使用STS将允许现有的JDBC/ODBC协议支持工具与Spark SQL无缝协作。然而，这种方法不能在提交给同一节俭服务器的查询之间提供适当的隔离。</p><p id="8194" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单个查询的问题可能会影响在同一节约服务器上运行的所有其他查询。在过去使用Hiveserver2进行交互查询时，我们看到了几个问题，其中一个错误的查询导致整个服务器崩溃，导致所有并发运行的查询终止/失败。在大多数情况下，这是由于单个查询以本地模式运行，而查询优化占用了太多内存，或者是由于加载本机jar的查询导致服务器上的内核死机。根据我们的经验，我们决定不选择这种方法。</p><h2 id="814e" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">Spark SQL查询作为Apache纱线上的shell命令应用程序</h2><p id="9b9c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">另一个运行Spark SQL查询的通用机制是通过spark-sql命令行界面(CLI)。但是，对于交互式应用程序而言，CLI方法不能很好地工作，也不能提供最佳的用户体验。</p><p id="5fb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以构建一个服务，从各种客户端启动spark-sql CLI，作为我们的纱线集群上的shell命令应用程序。但是，这将导致等待在纱线集群上分配容器，然后为每个查询启动火花会话的前期成本。此过程可能需要几分钟，具体取决于群集上的资源可用性。</p><p id="441f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，这种方法会导致交互查询的用户体验较差，因为用户可能需要等待几分钟才能找到语法问题。此外，这种方法很难检索结果、提供语句级进度更新，或者在出现故障时很难从驱动程序日志中获取异常堆栈跟踪。这些是我们对于出色的交互式查询体验的一些要求。</p><h2 id="95ca" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">具有批处理会话的Apache Livy</h2><p id="e1a3" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated"><a class="ae jc" href="https://livy.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Livy </a>是一项通过RESTful界面与Spark cluster进行交互的服务。使用Livy，我们可以轻松地将Spark SQL查询提交给我们的纱线集群，并通过简单的REST调用来管理Spark上下文。这是对我们复杂的Spark基础设施的理想抽象，并且将允许与面向用户的客户端直接集成。</p><p id="bf75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Livy提供两个作业提交选项:批处理和交互。批处理模式类似于spark-submit，用于提交批处理申请。在批处理模式下，查询的所有语句都一起提交以供执行。这使得我们为交互式查询设想的一些可用性特性变得很困难，例如:对在哪里运行基于语句的查询做出不同的选择，支持用SQL语句更改spark会话的功能，以及创建可重用的用户会话/缓存。我们将在本文后面详细讨论这些功能。</p><h2 id="fbad" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">具有交互会话的Apache Livy</h2><p id="1806" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">与Apache Livy的批处理会话不同，交互会话使我们能够启动一个会话，将查询和/或语句作为单独的请求提交，并在完成后显式结束该会话。</p><p id="f9df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，Livy还提供了多租户、通过会话恢复实现的高可用性以及故障隔离，这些都是我们最优先考虑的体系结构。这帮助我们选择Livy作为在Pinterest进行交互式Spark SQL查询的理想解决方案。</p><h1 id="4c4a" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">体系结构</h1><p id="916f" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">下面的图1描述了Spark SQL的查询执行体系结构和交互查询用例的请求流的概述。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es li"><img src="../Images/8cc56ab0e1c0fe596dd58cfebe4543ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rXVWZg30aCzDRBOB"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx"><em class="ly">Figure 1: Request flow for scheduled and interactive querying with Spark SQL at Pinterest</em></figcaption></figure><p id="df12" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图中提出的一个显而易见的问题是<em class="lz">为什么</em>我们需要分别处理DDL和DML查询。我们将在后面的文章中讨论这个体系结构的这个和其他有趣的方面，同时讨论我们在成功使用Spark SQL进行交互查询时所面临的挑战以及我们如何解决这些挑战。图1中的控制流程在下面详细说明，用于交互式DML和DDL查询。</p><h2 id="22ad" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">交互式DML查询</h2><ol class=""><li id="8fff" class="kg kh hh ig b ih kb il kc ip ma it mb ix mc jb kl km kn ko bi translated">像<a class="ae jc" href="http://querybook.org/" rel="noopener ugc nofollow" target="_blank"> Querybook </a>和Jupyter这样的客户向Livy提交交互式DML查询。</li><li id="dd6d" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">Livy从纱线资源管理器(RM)请求一个容器来运行远程火花上下文(RSC)客户端。</li><li id="fd8d" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">RM分配一个容器，RSC客户端在其中启动。该RSC客户端随后启动RSC驱动程序程序。</li><li id="6eb5" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">Livy通过与RSC Client通信来跟踪查询进度，RSC Client运行驱动程序。</li><li id="7af6" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">Spark SQL驱动程序从Hive Metastore服务(HMS)获取查询规划所需的表元数据。</li><li id="b1d3" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">基于资源需求，驱动程序要求RM提供容器以启动执行程序。</li><li id="51c6" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">Spark SQL驱动程序分配任务并协调执行程序之间的工作，直到完成用户查询的所有Spark作业。</li></ol><h2 id="7556" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">交互式DDL查询</h2><ol class=""><li id="d657" class="kg kh hh ig b ih kb il kc ip ma it mb ix mc jb kl km kn ko bi translated">客户端向Livy提交交互式DDL查询。</li><li id="53b5" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">Livy从本地会话池中获取一个Spark会话(细节将在后面的章节中讨论),并作为当前请求用户正确地更新用户凭证。</li><li id="e555" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">本地Spark SQL驱动程序从HMS获取查询计划的表元数据，并根据需要执行DDL操作。</li></ol><h1 id="301e" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">挑战和我们的解决方案</h1><p id="796e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">本节讨论我们必须解决的各种挑战，以便在Pinterest上成功地使用Spark SQL进行交互式查询。</p><h2 id="bae8" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">无缝查询提交</h2><p id="51bc" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">虽然Livy提供了一个可靠的解决方案来提交查询作为Spark作业，但是我们需要用户使用一个标准接口从任何客户端提交查询，该接口可以用作一个插件依赖项，以便轻松地与Livy通信。</p><p id="a337" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在Livy上构建了一个通用的符合DB-API的Python客户机，名为BigPy，多个查询客户机使用它来提交查询。在BigPy中，我们提供了一个接口来实现以下功能:</p><ul class=""><li id="3052" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb md km kn ko bi translated">状态轮询:它监视Livy会话的状态，并向客户机报告应用程序是成功、失败还是当前正在运行。此外，我们报告了spark应用程序的完成百分比。</li><li id="ce91" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">跟踪链接:它返回所有跟踪链接来监控Spark应用程序的状态，包括到Spark UI、驱动程序日志和Dr. Elephant的链接，后者用于监控性能和调优Spark应用程序。</li><li id="fd02" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">结果检索:它提供了以分页方式从AWS S3这样的对象存储中检索查询结果的能力。</li><li id="4dc5" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">异常检索:Spark驱动程序和执行器日志经常会很嘈杂，查找查询失败的原因会很麻烦。BigPy返回异常，它的堆栈直接跟踪到客户端，以获得更轻松的调试体验。</li></ul><p id="c40b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BigPy支持跨多个不同系统与Livy交互的模块化方式，提供了与客户端代码的清晰分离。</p><h2 id="82a7" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">快速元数据查询</h2><p id="d7b2" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">spark-shell实用程序在集群模式下向RM发送一个纱线应用请求。RM启动应用程序主机(AM ),然后应用程序主机启动驱动程序。驱动程序进一步向RM请求更多用于启动执行器的容器。我们发现，这种资源分配过程可能需要几分钟的时间来开始处理每个查询，这大大增加了数据定义语言(DDL)/仅元数据查询的延迟，这些查询通常是低延迟的元存储操作。</p><p id="817e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DDL查询在驱动程序上执行，不需要额外的执行器或与DML查询相同的隔离。为了减轻容器分配对YARN集群和Spark会话启动时间的冗余延迟，我们在Apache Livy中实现了一个本地会话池，它维护一个以本地模式运行的Spark会话池。</p><p id="3a6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个问题有两个部分:1)将查询识别为DDL语句，2)实现Spark应用程序的缓存池来处理这些查询。我们利用“SparkSqlParser”来获得用户查询的逻辑计划，以识别DDL查询。由于这个逻辑计划只是一个从“TreeNode”类继承的逻辑操作符树，我们可以很容易地遍历这个树，并根据一组DDL执行命令检查每个节点的类。如果逻辑计划的所有节点都与DDL命令匹配，我们将该查询标识为DDL。实际上，它看起来像这样:</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es me"><img src="../Images/90d88afde5a7af45d3a31cf859252a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQShJ7-4J9mix_ptqZ3Kwg.png"/></div></div></figure><p id="987a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们知道查询是一个DDL语句，我们就将它路由到一个缓存的Spark应用程序。我们在Livy中构建了这个缓存应用程序池，由一个本地运行的Spark驱动程序池表示。它设计为完全自力更生，具有以下特点:</p><ul class=""><li id="afb5" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb md km kn ko bi translated">陈旧应用程序的自动垃圾收集和启动新应用程序</li><li id="ccd8" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">一个守护线程，监视池的运行状况，并将查询路由到下一个可用的应用程序</li><li id="38c1" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">以可配置的步调重新启动应用程序，以确保它获取最新的资源(例如模式jar ),从而确保数据的新鲜</li><li id="a65b" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb md km kn ko bi translated">在启动时异步启动轻量级元数据操作，以初始化“SparkContext ”,并建立到metastore的实时连接，以实现更快的后续操作</li></ul><p id="e148" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过这种设计，我们将查询延迟从70秒减少到平均10秒(大约6.3倍的改进)。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mf"><img src="../Images/a3b9ab0df9d32704cea1fb06b0cfc11d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ztcoPTqkaAo4B7y_"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx"><em class="ly">Figure 2: Wall clock time comparison for DDL queries run in local vs. cluster mode</em></figcaption></figure><h2 id="cb32" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">快速失败:更快的语法检查</h2><p id="445c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">以集群模式运行每个查询的另一个缺点是，在最坏的情况下，语法检查至少需要启动应用程序所需的时间。在临时环境中，用户通常希望语法问题早点出现，而等待几分钟才报告一个语法问题会带来令人沮丧的体验。我们通过使用“SparkSqlParser”来改进这一点，并在启动YARN应用程序之前获取查询的逻辑计划。如果查询包含语法错误，解析器将在生成逻辑计划时抛出“ParseException ”,并方便地返回行号和列号，我们将这些信息报告给客户端。通过这种方式，我们将整体语法检查延迟从几分钟减少到了不到两秒钟(提高了30倍以上)。</p><h2 id="f57d" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">错误处理建议</h2><p id="fcc0" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">在特定环境中，查询失败是不言而喻的。然而，修复这些故障通常是一个令人生畏的循环:浏览驱动程序日志，通过自我诊断或寻求外部帮助找到解决方案，然后重试查询。为了简化这一过程，我们提供了一些常见问题的自动故障排除信息，这些问题乍一看很难解决。该解决方案包括四个部分:</p><p id="d99c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> I .根据最后一个查询的执行状态，使YARN应用失败</strong></p><p id="189e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">集群模式下Livy交互会话的一个问题是，它们总是向YARN AM报告“成功”状态。这是因为Livy提交给“SparkLauncher”的远程驱动程序启动了一个Spark上下文，在该上下文中运行一些查询，然后关闭该上下文。不管查询运行的状态如何，报告的最终状态将始终是SparkContext是否能够成功关闭。这是对用户和平台主的误导。为了减轻这个问题，我们在单个交互式会话中跟踪最终查询运行的状态，如果查询失败，则在远程驱动程序中抛出运行时异常。这有助于正确地向AM报告状态，并用故障原因(如果有的话)填充纱线诊断。</p><p id="408c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">二。识别用户查询中的常见错误</strong></p><p id="a7e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们用查询的失败原因正确地填充了YARN诊断，我们就可以利用添加到YARN集群中的额外日志来方便地在SparkSQL表中跟踪遇到的错误。然后，我们查看了失败堆栈跟踪的历史，并使用正则表达式对它们进行了分类。根据频率，我们获得了前n名错误的列表。</p><p id="a3ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们利用<a class="ae jc" href="https://github.com/linkedin/dr-elephant" rel="noopener ugc nofollow" target="_blank">大象博士</a>来跟踪Spark应用启发和度量，并添加了一个错误分类机制，该机制查看应用的纱线诊断信息，并基于正则表达式引擎对其进行分类。使用上面的正则表达式，我们将通过REST API暴露的常见错误的故障排除信息添加到Dr. Elephant web UI和其他外部客户端，如Querybook。</p><p id="427c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">三世。Livy中的大象博士集成</strong></p><p id="ade2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在Livy中为每个启动的Spark应用程序集成了上面提到的Dr. Elephant API。该端点在每次查询运行时返回给客户端，便于查看故障排除信息。</p><p id="ce0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">四。客户端集成</strong></p><p id="4c6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在从Livy获取Dr. Elephant故障排除分析端点之后，客户机从API中提取该信息，并将其显示在查询日志中。这样，当我们看到查询失败时，我们可以提供常见错误的故障排除信息，帮助用户更快地诊断问题。</p><h2 id="7675" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">资源利用率可见性</h2><p id="d449" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">查看我们的ad-hoc集群上的历史内存消耗指标，我们注意到应用程序经常过度分配执行器和驱动程序内存，导致不必要的资源浪费。另一方面，对于内存不足(OOM)的应用程序，我们的用户经常要求我们让他们更容易地抢先捕捉这些问题，以便更快地返回他们的查询。</p><p id="700c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这个问题，我们直接在客户机上显示实时内存消耗信息，包括所有执行器使用的最大、最小和平均内存。我们还标记消费不足和过度消费，并提示用户根据启发采取行动。</p><p id="54de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们通过使用<a class="ae jc" href="https://spark.apache.org/docs/latest/monitoring.html#metrics" rel="noopener ugc nofollow" target="_blank"> Spark指标库</a>的自定义指标接收器来收集每个Spark应用程序的实时内存消耗信息。然后，我们在BigPy中使用这些指标，并检查它们是否违反了任何资源阈值，以UI友好的减价表格式将信息返回给客户端。这种方法的一个例子可以在下面的GIF中的Querybook上看到:</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mg"><img src="../Images/ffa7ddc74739559612facb476adb3066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2hj4VuoxYYzrPiNs"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx"><em class="ly">Figure 3: Realtime driver/executor(s) memory consumption information with various aggregations</em></figcaption></figure><h2 id="8737" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">大型结果处理和状态跟踪</h2><p id="ab2a" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">默认情况下，Livy对查询结果集的限制是1，000行。增加这个限制并不理想，因为结果集存储在内存中，增加这个限制可能会在像我们这样的内存受限环境中导致大规模问题。为了解决这个问题，我们为每个查询的最终结果实现了AWS S3重定向。这样，大型结果集可以以多部分的方式上传到S3，而不会影响服务的整体性能。在客户端，我们稍后检索REST响应中返回的最终S3输出路径，并以分页的方式从S3获取结果。这使得在列出路径对象时检索速度更快，而没有S3超时的风险。这种重定向也可以在查询级别进行配置，因此如果用户希望查询返回少于1，000行的数据，可以直接从REST端点进行检索，而不需要对文件存储进行额外的调用。</p><p id="0629" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还提供实时进度更新，这是通过对Spark SQL查询的已完成和活动任务数与任务总数进行平均而获得的。在上面图3的GIF中可以看到一个预览。</p><h2 id="eacd" class="ku je hh bd jf kv kw kx jj ky kz la jn ip lb lc jr it ld le jv ix lf lg jz lh bi translated">Livy操作改进</h2><p id="cb71" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们平均每天看到大约1，500个临时SparkSQL查询，为了支持这一负载，我们的系统必须为我们的用户保持健康和可靠。我们对可靠性和稳定性进行了大量改进，使我们能够为Livy维持99.5%的正常运行时间SLO。一些重要亮点:</p><p id="8077" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">有效负载均衡</strong></p><p id="41ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据设计，Livy是一个有状态的web服务。它在内存中存储会话的状态，如查询运行、每个查询的状态、最终结果等等。因为我们的客户端遵循HTTP轮询机制来获取这些属性，所以很难在上面添加经典/应用负载平衡器。为了解决这个问题，我们在应用程序级别实现了负载平衡算法，以循环方式将每个查询路由到最不繁忙的Livy实例。在这里,“繁忙”是由在特定Livy实例上运行的“活动”会话的数量来定义的。这种简单而有效的机制使我们能够在整个车队中更均匀地分配负载。</p><p id="1a39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">指标&amp;日志记录改进</strong></p><p id="8b6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们向Livy添加了事件监听器支持，其中事件被定义为任何Livy活动，包括会话创建和向会话提交语句。我们使用这些侦听器将JSON对象记录到本地磁盘，跟踪各种事件。无论何时出现问题，这都可以实现更快的调试和使用监控。</p><p id="fad8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">指标</strong></p><p id="ac34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还使用<a class="ae jc" href="https://scalatra.org/guides/2.4/monitoring/metrics.html" rel="noopener ugc nofollow" target="_blank"> Scalatra指标</a>来跟踪关键的服务水平指标，例如健康检查、MAU、用户/查询的DAU计数、缓存的会话命中率、查询成功率等等。这些顶级指标对于跟踪跨集群的整体临时活动非常重要。</p><h1 id="a0cd" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">摘要</h1><p id="758c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">为了支持使用SQL分析和处理数百Pb的数据，我们正在Pinterest上整合Spark SQL和Presto。虽然Presto仍然是资源需求有限的快速交互式查询的最流行的查询引擎选择，但我们使用Spark SQL来支持所有规模的查询。交互式查询用例与预定查询有不同的需求。这些特性包括无缝查询提交、快速元数据查询、快速语法检查以及更好的调试和调优支持。基于我们对交互式查询的需求和可用开源解决方案提供的功能，我们决定用Apache Livy构建Spark SQL交互式查询平台。然而，Livy并没有满足我们开箱即用的要求，我们添加了各种功能来弥合这一差距。在这篇文章中，我们讨论了我们的架构选择和改进，以使交互式查询在Pinterest上取得成功。我们计划将这些变化的大部分回馈给开源社区。</p><h1 id="5498" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">感谢</h1><p id="bd59" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">让Spark SQL交互式查询获得成功需要Pinterest许多团队的努力。特别感谢大数据查询平台团队的Zaheen Aziz、TPM团队的Hannah Chen、数据隐私团队的Keith Regier、SRE团队的Rakesh Kalidindi and、Ashim Shrestha以及批处理平台团队的Zirui Li、Daniel Dai and、Soam Acharya。这是一项巨大的努力，如果没有管理层的帮助，这是不可能的。感谢金柱成、王春燕和戴夫·伯吉斯给予的坚定支持和指导。</p><p id="05ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lz">要在Pinterest了解更多关于工程的知识，请查看我们的</em> <a class="ae jc" href="https://medium.com/pinterest-engineering" rel="noopener"> <em class="lz">工程博客</em> </a> <em class="lz">，并访问我们的</em><a class="ae jc" href="https://labs.pinterest.com/?utm_source=medium&amp;utm_medium=blog-article&amp;utm_campaign=singh-javeria-july-12-2021" rel="noopener ugc nofollow" target="_blank"><em class="lz">Pinterest Labs</em></a><em class="lz">网站。要查看和申请空缺职位，请访问我们的</em> <a class="ae jc" href="https://www.pinterestcareers.com/?utm_source=medium&amp;utm_medium=blog-article&amp;utm_campaign=singh-javeria-july-12-2021" rel="noopener ugc nofollow" target="_blank"> <em class="lz">职业</em> </a> <em class="lz">页面。</em></p></div></div>    
</body>
</html>