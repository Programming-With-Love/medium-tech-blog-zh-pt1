# 宇宙的热寂和使用 Python 字典和集合的快速算法

> 原文：<https://medium.com/capital-one-tech/heat-death-of-the-universe-and-faster-algorithms-using-python-dict-and-set-f31517e7fa76?source=collection_archive---------9----------------------->

![](img/13656574e127d15818eb890db719d97f.png)

有些事情我们无法计算。或者我应该说，我们不应该试图用一种基于简单暴力和无知的算法来计算它们。让我们快速浏览一下算法和复杂性的星系。在这个过程中，我们将获得一些让我们的软件运行更快的技巧。

我对大爆炸的模糊理解包括一个(可能不正确的)想法，即它膨胀并变冷。我脑海中挥之不去的事实是仙女座星系将在大约 50 亿年后，即 5E+9 年与我们的星系相撞。平均一年大概有 3.2E+7 秒。姑且称之为 5E+9 * 3.2E+7 = 16E+16 秒。差不多吧。

很大的数字，对吧？

除非我们正在实现 O *(n！)*种算法。这是我们未来非常现实的一部分。

假设我们的 CPU 需要 10 纳秒来完成一次 Python 浮点乘法。十亿次 1E+9 的乘法只需要一秒钟。在我们被天体扰动消灭之前，我们还有时间做 1.6E+26 的乘法。

假设我们有一个想要面对的优化问题。我们需要找到完美的(完美！)二十多种不同操作的排列。也许我们正试图将 26 件物品密集地打包到一个有限的体积中，或者优化 26 辆出租车之间的路线，或者涉及检查许多事物的替代安排的大量类似问题中的任何一个。

还有 *26！*排列组合，4E+26。为了确认完美的排列，在一次银河碰撞使得地球上不太可能存在生命之后，我们仍然会很好地进行计算。

我们使用“Big-O”符号来概括整体复杂性以及复杂性随着数据值数量的增加而增加的方式。阿 *(n！)*针对 *n* =3 或 *n* =4 值的优化有 6 或 24 种排列。但是需要优化更多的值？就像宇宙的膨胀理论一样，计算变得非常大非常快。

# 还有其他我们无法计算的东西吗？

这里有一个简单的文字问题需要思考:

> *假设我们有一个数字集合。我们希望这些值的子集具有最接近给定目标的值。*

事实证明，对于一组 *n* 值，有 *2**n* 个子集。如果我们有 88 个值的集合，在我们找到完美的子集之前，银河碰撞就会发生。

这类问题是潜在的。我们有时会意外地遇到“秘密组合学”——涉及排列或子集的问题。

这里还有一个例子可以思考。一对快速增长的网络创业公司拥有大量客户，其中一些是重复的。他们如何比较所有的客户并删除重复的客户？这种比较不仅仅是简单的乘法或加法，它需要 100 微秒来完成一次数据库读取和各个字段的比较。一万次比较需要一秒钟。

如果我们有一千万个客户，1E+7，这意味着必须有 1E+14 个比较。

我们正在讨论具有以下结构的代码:

```
for record in company_1:
    for record in company_2:
        if match:
```

这种嵌套循环的复杂度描述为 *O(n )* 。每一个 *n* 客户都必须与剩余的 *n-1* 客户进行比较。在讨论计算复杂性的一般顺序时,“Big-O”符号规则抛弃了加法和减法。对于 n=10，000，000，我们将进行 *n* 次运算:1E+7**2 = 1E+14 次比较。以每秒 1E+5 的速度，这将需要 1E+14/1E+5 = 1E+9 秒的时间。那是 31 年，比一颗叫做大熊座 61 的恒星发出的光到达我们这里的时间还要短。这种计算不是等到永远的十二分之一，而是需要很长很长的时间。

如果我们将比较速度提高 100 倍，我们仍然在谈论四个月的计算。分布在 64 个并发处理器上，需要将近 45 个小时的工作。

# 我们能做什么？

我们可以将所有这些算法描述为各种“搜索”。一个例子搜索了 *26！*寻找最合适的单品。另一个例子通过 288 个子集寻找精确匹配。提高我们算法性能的第一步是，当我们设计涉及搜索的软件时，要有意识。用一架 3 英寸的望远镜，我们可以看到大约 500 万颗恒星，甚至更多

接下来，对 *O(n！)*和 *O(2ⁿ)* 的情况。这些并不常见，而且很难编码。我们经常在试图跟踪所有相关变量时感到沮丧。当算法变得复杂时，这是一个提示，我们应该寻找一个聪明的近似。这方面有很多优秀的库，重要的是要认识到权衡决策:现在的近似答案比几十亿年后的正确答案更好。

除了这两个天文上的糟糕情况，我们还想尽可能避免更多的手术。如果我们正在填充一个矩阵的单元格，而这个矩阵有数百万行(和列)，我们不会对结果满意。当商业价值以秒计算时，等待数月或数年似乎并不理想。

在某些情况下，我们不使用文字矩阵数据对象。每当我们在 Python 中嵌套 for-loops 时，我们都有可能做与填充矩阵单元格相同的工作。

回头看看客户的重复数据消除，一种更好的方法不是尝试将每个客户与其他每个客户进行比较。我们需要考虑分而治之的策略。使用二分法将导致被描述为 *O(n log₂n)* 的复杂度；这更接近于 2.3E+8 比较，节省了大量时间。在每秒 1E+5 次比较的情况下，我们只讨论了 40 分钟，这是光从太阳到木星的时间。

在 Python 中，等分模块提供了一种快速搜索排序列表的方法。如果我们要进行重复查找，初始排序的成本可能会分摊到大量不太昂贵的`bisect.bisect()`操作中。

考虑一个常见的自然语言处理(NLP)问题，即从文档中删除“停用词”。停用词列表相对较小，通常不到 200 个词。

强力过滤器会将源文档中的每个单词与每个停用词进行比较。这将是 *O(d⨉s)* ，其中 *d* 是文档的大小，s 是停用词列表的大小。对于 1，000 个单词和 200 个停用词的文档来说，这似乎很快:100，000 次比较将花费不到一秒的时间。(1，000 x 200 / 2，因为我们实际上只填充了对称矩阵的一半。)但是。如果我们每秒处理几十个 API 请求，这将变成越来越大的计算负担。

如果我们使用`bisect` 查找，我们可以把它变成 *O(d⨉log₂s)* ，或者大约 8000 次比较，而不是 100000 次。

一个密切相关的方法是用稍微聪明一点的排序代替简单的循环。这也能把 *O(n )* 变成 *O(n log₂n)* 。当我们对项目进行排序后，可以很容易地将它们划分到相关的匹配组中，因为下一组记录将比远处的记录更加相关。

# 事半功倍的更多方法

`bisect`模块将搜索算法从 *O(n)* 删减到 *O(log₂ n)* 。这可能是一个巨大的进步。创建排序列表并不是没有成本的，但是如果成本可以分摊到许多操作中，那就太容易了。

使用集合或映射将二分法 *O(log₂ n)* 搜索变为 *O(1)* 查找。 *O(1)* 表示时间不变；搜索不随数据集的大小而变化。集合和字典使用哈希算法将密钥对象转换为直接标识值的数字。在处理空间分配和碰撞方面有一些微妙之处，但是加速是惊人的。

回到停用词的例子，检查集合成员比使用二等分搜索列表有很大的优势。

我们有三种常用的搜索方法:

*   对列表的强力检查。 *O(n)* 。如果重复这样做，它将成为计算时间的黑洞，将 CPU 与结果捆绑在一起，而这些结果似乎无法到达我们可以看到和使用它们的地方。
*   对排序列表中的一个项目进行排序并使用二等分定位。 *O(log₂ n)* 。这需要一点点小心，但它只是中子星的一种，拉进了很多资源。我们可以加快速度并产生有用的结果。
*   对集合或字典的散列查找。 *O(1)* 。一个 70 纳秒的哈希计算是光传播大约 21 米所需的时间。做几百万个这样的动作不到一秒钟。这是一流的表现，

# 工具和技术

大数据和数据科学意味着我们在开始之前必须小心谨慎。我们不能将大量的数据转储到一个数据帧中，然后开始计算，并希望能够奏效。我们需要花一点时间做一些计算，以确保计算将在我们的有生之年完成。

这有几个整体部分。

1.  理解外部循环结构，Big-O 复杂性。
2.  了解循环结构内部的计算成本。在 IPython 或 Jupyter 笔记本上工作时，我们可以利用`%%timeit` 魔法来获得计算的时间细节。
3.  插入时间和尺寸的具体值。
4.  决定这样做是否值得，或者是否需要更多的思考。

例如，假设我们嵌套了 For 循环，复杂性为 *O(n^2)* 。我们可以使用`%%timeit`来查看需要 220 个“n”来进行计算的循环内部。当 n 为 15000 时，我们得到 15000 * 15000 * 220 * 1E-9 = 49.5 秒的功。对于某种分析工作来说还不错。对于网络交易来说可能不太理想。

这不会给我们计算的总成本；还有其他难以预测的操作系统和语言开销。

在开始之前，我们需要知道我们是否要用 70 纳秒走 20 米；或者我们会花四个小时去海王星，花 375 年去昴宿星；或者，我们已经开始了一个两百万年的旅程，带我们去仙女座星系？

有时候，处理一个简单的列表或数据库查询会花费很长时间。使用排序列表和`bisect`模块，或者用 Python 字典和集合替换列表，可以将旅程从几个小时缩短到几秒钟。

# 相关:

*   [Python 3 类型提示:填充还是装饰？](/capital-one-tech/python-3-type-hints-filling-or-garnish-b91bd760214a)
*   [规范到小黄瓜到代码](/capital-one-tech/spec-to-gherkin-to-code-902e346bb9aa)
*   [猛烈抨击——用 Python 替换 Shell 脚本](/capital-one-tech/bashing-the-bash-replacing-shell-scripts-with-python-d8d201bc0989)

*披露声明:这些观点是作者的观点。除非本帖中另有说明，否则 Capital One 不属于所提及的任何公司，也不被其认可。使用或展示的所有商标和其他知识产权都是其各自所有者的所有权。本文为 2019 首都一。*