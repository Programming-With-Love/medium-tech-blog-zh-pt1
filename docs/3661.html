<html>
<head>
<title>Large File Processing using Apache Camel with AWS S3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Camel和AWS S3处理大型文件</h1>
<blockquote>原文：<a href="https://medium.com/globant/large-file-processing-using-apache-camel-with-aws-s3-37c6633082cd?source=collection_archive---------0-----------------------#2021-04-23">https://medium.com/globant/large-file-processing-using-apache-camel-with-aws-s3-37c6633082cd?source=collection_archive---------0-----------------------#2021-04-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/23ce1a82e4b393e052f2751f1535d78b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mpkhyCHFuHJshquUW3AO8Q.png"/></div></div></figure><h1 id="fed5" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><strong class="ak">简介</strong></h1><p id="69dd" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">Apache Camel是一个开源集成框架，使您能够快速轻松地集成各种使用或产生数据的系统。Camel支持Gregor Hohpe和Bobby Woolf的优秀著作中的大多数企业集成模式，以及来自微服务架构的更新的集成模式，通过应用开箱即用的最佳实践来帮助您解决集成问题。</p><p id="e5fc" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">更多详细信息请访问— <a class="ae kq" href="https://camel.apache.org/" rel="noopener ugc nofollow" target="_blank">骆驼遗址</a></p><p id="1125" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在早先的一篇文章中，我的同事<a class="kr ks ge" href="https://medium.com/u/c7b424f3e32?source=post_page-----37c6633082cd--------------------------------" rel="noopener" target="_blank">拉克什·拉夫勒卡</a>解释了我们在这里<a class="ae kq" rel="noopener" href="/globant/file-processing-with-apache-camel-aws-services-6c18ee6c49f">遵循的方法</a></p><p id="290d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在这篇文章中，我将分享大文件处理用例的细节。</p><h2 id="cb3d" class="kt iq hh bd ir ku kv kw iv kx ky kz iz jy la lb jd kc lc ld jh kg le lf jl lg bi translated">用例</h2><p id="2484" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><em class="lh">我们的要求是通过Camel从AWS S3桶中读取一个大文件</em><strong class="jp hi"><em class="lh">(&gt;1.5 GB)</em></strong><em class="lh">，对其进行处理，然后将生成的输出文件</em><strong class="jp hi"><em class="lh">(&gt;1.5 GB)</em></strong><em class="lh">上传到目的地S3桶中。</em></p></div><div class="ab cl li lj go lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ha hb hc hd he"><h1 id="5eaf" class="ip iq hh bd ir is lp iu iv iw lq iy iz ja lr jc jd je ls jg jh ji lt jk jl jm bi translated">通过实例学习</h1><p id="fc4f" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">用一个具体的例子学习总是比较容易的！这就是为什么在这篇文章中，我将向你展示如何为这个场景创建一条骆驼路线。</p><ol class=""><li id="aaa8" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk lz ma mb mc bi translated"><strong class="jp hi">从S3读取文件</strong> —要从S3读取文件，我们有以下两种选择:</li></ol><ul class=""><li id="3220" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"> <em class="lh">读取整个文件</em> </strong> —该操作仅适用于文件<strong class="jp hi">小于25 MB </strong>的情况。</li></ul><blockquote class="me mf mg"><p id="0829" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">Ex — aws2-s3://test-bucket？S3 client = # client &amp; repeat count = 1 &amp; deleteAfterRead = false &amp; fileName = testfile . dat</p></blockquote><ul class=""><li id="6498" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"> <em class="lh">分块读取文件</em> </strong> —在这种方法中，您需要设置一个额外的骆驼S3选项，名为<strong class="jp hi"> getObjectRange </strong>。此选项用于下载对象的指定范围字节。在这篇文章中，我们将使用这个选项来读取大文件数据，关于HTTP范围头的更多信息，请参见和</li></ul><blockquote class="me mf mg"><p id="e37b" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">Ex — aws2-s3://test-bucket？S3 client = # client &amp; repeat count = 1 &amp; deleteAfterRead = false &amp; fileName = testfile . dat &amp;<strong class="jp hi">operation = getObjectRange</strong></p></blockquote><p id="8110" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">2.<strong class="jp hi">将文件上传到S3存储桶— </strong>要将文件上传到S3，我们有以下两个选项:</p><ul class=""><li id="aeb3" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"> <em class="lh">上传整个文件</em> </strong> —该选项仅适用于<strong class="jp hi">小于25 MB </strong>的情况。</li></ul><blockquote class="me mf mg"><p id="21cc" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">Ex — aws2-s3://test-bucket？s3Client=#client</p></blockquote><ul class=""><li id="5592" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"> <em class="lh">多部分上传</em> </strong> —为了分部分上传文件，我们需要设置另外两个选项，称为<strong class="jp hi">多部分上传和部分大小</strong>。此选项用于上传大于25 MB的文件<strong class="jp hi"/>，但是您可以更改部分大小，因为我已更改为10 MB，这意味着一个上传部分的大小为10MB。</li></ul><blockquote class="me mf mg"><p id="ae05" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">Ex — aws2-s3://test-bucket？S3 client = # client &amp;<strong class="jp hi">multipart upload = true&amp;partSize = 10485760</strong></p></blockquote><p id="9244" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">更多关于骆驼AWS S3组件的内幕会在这里找到<a class="ae kq" href="https://camel.apache.org/components/3.9.x/aws2-s3-component.html" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi"><em class="lh"/></strong></a>。</p><p id="291e" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">为了分块读取文件，我们必须有文件长度来转换成范围，所以下一个问题是你如何知道文件长度？接下来是<strong class="jp hi"> AWS S3 SDK </strong>，我们需要对S3做额外的<strong class="jp hi"> HeadObjectRequest </strong>如下-</p><blockquote class="me mf mg"><p id="2f5e" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">head object request head object request = head object request . builder()。桶(“测试桶”)。key("testfile.dat ")。build()；<br/>head object response head response = S3 client . head object(head object request)；<br/>int file length = head response . content length()。int value()；</p></blockquote><p id="b17d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">注意</strong>—“<em class="lh">要处理S3操作我们必须有</em><strong class="jp hi"><em class="lh">S3 client</em></strong><em class="lh">并且你可以借助</em><strong class="jp hi"><em class="lh">ApacheHttpClient</em></strong><em class="lh">库</em>”。</p><p id="e0f1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">有了文件长度后，我们需要按照自己的逻辑定义范围。<br/>例如，假设文件大小为<strong class="jp hi"> 8192000 </strong>字节，那么范围数组列表包含4个对象- <strong class="jp hi"> (0，2047999)(2048000–4095999)..直到字节的结尾</strong>，我们将使用camel的<strong class="jp hi"> split body </strong>函数迭代这个范围列表。</p><p id="c2f5" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">好了，到目前为止，我们已经完成了基本步骤，现在让我们为这个用例创建路线。</p><h1 id="c9df" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">骆驼路线定义</h1><blockquote class="me mf mg"><p id="0848" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">从(直接(“开始”)<br/>。noStreamCaching() <br/>。<br/>。<strong class="jp hi">处理</strong>(后置处理器)<br/>。choice() <br/>。when(header(AWS2S3Constants。内容_长度)。isGreaterThan(MULTIPART _ LIMIT))<br/>。to(" <strong class="jp hi"> aws2-s3://test-bucket？S3 client = # client&amp;multipart upload = true&amp;partSize = 10485760</strong>"<br/>。否则()<br/>。to(" <strong class="jp hi"> aws2-s3://test-bucket？S3 client = # client</strong>"<br/>。end() <br/>。end() <br/>。<strong class="jp hi">拆分(body()) </strong> <br/>。<br/>串流()。process(exchange-&gt;{<br/><strong class="jp hi">item dto item =(item dto)exchange . getin()。getBody()；<br/> exchange.getIn()。setHeader(AWS2S3Constants。RANGE_START，item . get from())；<br/> exchange.getIn()。setHeader(AWS2S3Constants。RANGE_END，item . getto())；<br/> exchange.getIn()。setHeader(AWS2S3Constants。KEY，test file . dat)；</strong> <br/> }) <br/>。to(" <strong class="jp hi"> aws2-s3://test-bucket？S3 client = # client&amp;repeat count = 1&amp;deleteAfterRead = false&amp;fileName = testfile . dat&amp;operation = getObjectRange</strong>"<br/>。<br/>进程(FileProcessor)。<br/>元帅(bindy)。到(<strong class="jp hi">文件(tempFilePath)。fileExist("Append ")。文件名(临时文件名)</strong> ) <br/>。end()；</p></blockquote><p id="8fc2" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">路线说明</strong></p><ol class=""><li id="b33d" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk lz ma mb mc bi translated">执行从名为start的直接端点开始，在这个直接端点上，我们将传递我们创建的范围数组列表。</li></ol><p id="26f4" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">要启动路线，你有两个选择-</p><ul class=""><li id="f953" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"><em class="lh"/></strong>使用监制模板-</li></ul><blockquote class="me mf mg"><p id="df4b" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">producer template pt = context . createproducer template()；<br/>pt . send body(<strong class="jp hi">" start "</strong>，createRangeData())；</p><p id="1f54" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">createRangeData方法将返回<strong class="jp hi">列表&lt;项到&gt;T47】</strong></p></blockquote><ul class=""><li id="cc6c" class="lu lv hh jp b jq kl ju km jy lw kc lx kg ly kk md ma mb mc bi translated"><strong class="jp hi"> <em class="lh">从任何路线调用</em></strong>—</li></ul><blockquote class="me mf mg"><p id="b79d" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">from(timer("startTimer ")。重复计数(1))。noStreamCaching() <br/>。过程(e - &gt; e.getIn()。set body(createRangeData())<br/>。到(<strong class="jp hi">直接(“开始”)</strong>)。end()；</p></blockquote><p id="4e3b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">2.为了迭代范围列表，我们使用了<strong class="jp hi">分割体函数</strong>来进一步获取和处理范围对象。</p><p id="4b17" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">3.我添加了一个处理器，它将添加一些必要的S3头，如关键，开始范围和结束范围。</p><p id="8218" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">4.一旦标题准备好，我们需要从S3获取特定的范围数据。为此，我使用了一个函数来请求range对象。</p><p id="608e" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">5.收到range对象后，我们需要处理它。处理逻辑取决于您的业务场景。<strong class="jp hi"> getObjectRange </strong>操作将在camel交换中返回一个字节流，因此，要在<strong class="jp hi">处理器</strong>中获得该流，您需要添加以下代码-</p><blockquote class="me mf mg"><p id="8a18" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">ResponseInputStream RES =(ResponseInputStream)exchange . getin()。getBody()；<br/>byte[]message bytes = RES . read all bytes()；这些消息字节将根据您的逻辑进一步使用。</p><p id="1546" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">Camel还提供了一个使用并行流并行处理数据的工具，如-<br/><strong class="jp hi">——为此您需要添加。route中的parallelProcessing()函数，并且您还可以覆盖camel上下文中的默认ThreadPoolProfile，如context . getexecutorservicemanager()。setDefaultThreadPoolProfile(MyThreadPoolProfile)；<br/> <strong class="jp hi">使用Executor或任何其他框架</strong>——如果您想使用Executor Service或Akka等多线程框架并行处理数据，请在处理器内部使用。</strong></p><p id="7de3" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">点击<a class="ae kq" href="https://camel.apache.org/components/3.9.x/eips/split-eip.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">此处</strong> </a>了解camel中并行处理的更多详情。</p></blockquote><p id="1d9b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">6.一旦您的处理完成，我们需要使用camel bindy整理数据以生成CSV文件，但您可以根据您的业务需求将其整理成固定长度的文件等。</p><p id="1dfc" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">7.然后我们将数据发送到<a class="ae kq" href="https://camel.apache.org/components/3.9.x/file-component.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">文件组件</strong> </a>。</p><p id="b75d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">注意—“<em class="lh">这只是我们存储到本地文件系统的已处理数据的一个范围，或者您可以说我们正在逐个收集数据，一旦收集了所有范围的数据，我们就会将该文件上传到s3 </em>”。</p><p id="c321" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">8.为了启动上传，我们添加了onCompletion hook并添加了<strong class="jp hi">后处理器</strong>，它运行用于数据的最终处理，因此在其中我们只将文件对象设置为交换体。</p><blockquote class="me mf mg"><p id="ea93" class="jn jo lh jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">File File = new File(tempfile path+"/"+TEMP _ File _ NAME)；<br/> message.setBody(文件)；</p></blockquote><p id="4f90" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">9.最后，我们将使用<strong class="jp hi"> multiPartUpload </strong>选项向s3发出上传请求。</p></div><div class="ab cl li lj go lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ha hb hc hd he"><h1 id="3ce4" class="ip iq hh bd ir is lp iu iv iw lq iy iz ja lr jc jd je ls jg jh ji lt jk jl jm bi translated"><strong class="ak">结论</strong></h1><p id="7984" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这就是我们如何用Camel和AWS S3来处理大文件。在我们当前的AWS配置(<strong class="jp hi"> CPU — 1024单元&amp; RAM — 2048 Mib </strong>)上，我们能够在不到15分钟的时间内处理几乎<strong class="jp hi"> 1.5 Gb </strong>的文件。</p><p id="8e99" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">希望你喜欢这篇报道。如果你有任何问题/意见，请给我留言！</p></div></div>    
</body>
</html>