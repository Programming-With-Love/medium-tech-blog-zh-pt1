<html>
<head>
<title>Mengenal Jenis-Jenis Algoritma Cache</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Mengenal Jenis-Jenis Algoritma Cache</h1>
<blockquote>原文：<a href="https://medium.easyread.co/mengenal-jenis-jenis-algoritma-cache-d03be94d72a7?source=collection_archive---------2-----------------------#2019-04-14">https://medium.easyread.co/mengenal-jenis-jenis-algoritma-cache-d03be94d72a7?source=collection_archive---------2-----------------------#2019-04-14</a></blockquote><div><div class="fc ib ic id ie if"/><div class="ig ih ii ij ik"><div class=""/><div class=""><h2 id="af75" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk translated">Mengenal Prinsip Dasar dari Algoritma Cache dan atau Page Replace Algorithm</h2></div><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kc"><img src="../Images/d796ff9ad973aec7bbcca9dc236f5bfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H3Ou_SFpvJMEM2Qg"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Photo by <a class="ae ks" href="https://unsplash.com/@mattartz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Matt Artz</a> on <a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="28e6" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">TLDR; (Too Long, Didn’t Read):</p><ul class=""><li id="5c1d" class="lp lq in kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">Sedikit penjelasan tentang Cache.</li><li id="3147" class="lp lq in kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">Saya sedikit menjelaskan perbedaan LRU dan LFU.</li><li id="0797" class="lp lq in kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">Saya sempatkan membuat simple library Go (Golang) dengan implementasi dari LRU dan LFU di sini <a class="ae ks" href="https://github.com/bxcodec/gotcha" rel="noopener ugc nofollow" target="_blank"> https://github.com/bxcodec/gotcha </a> .</li></ul></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><p id="03bc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Dalam dunia Software Engineering, ada sebuah istilah yang cukup lazim disebut dan diketahui oleh para engineer, yakni “cache”. Cache atau dalam bahasa Indonesia disebut <a class="ae ks" href="https://id.wikipedia.org/wiki/Tembolok_(komputer)" rel="noopener ugc nofollow" target="_blank"> Tembolok </a> .</p><h2 id="3edf" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">Apa itu Cache?</h2><p id="26dd" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc nf le lf lg ng li lj lk nh lm ln lo ig bi translated">Versi Wikipedia, menyatakan cache adalah <a class="ae ks" href="https://id.wikipedia.org/wiki/Mekanisme" rel="noopener ugc nofollow" target="_blank"> mekanisme </a> penyimpanan <a class="ae ks" href="https://id.wikipedia.org/wiki/Data" rel="noopener ugc nofollow" target="_blank"> data </a> sekunder berkecepatan tinggi yang digunakan untuk menyimpan data / instruksi yang sering diakses¹.</p><p id="e96f" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Prinsip kerja cache sangatlah sederhana, yakni menyimpan sementara data/file yang nantinya dapat digunakan secara berulang oleh sistem tersebut.</p><p id="eb6b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika dibuat dalam sebuah analogi, saya akan berikan contoh seperti sebuah warung makan.</p><p id="3c0a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Sebut saja, terdapat sebuah warung makan, dimana terdapat berbagai menu. Salah satu menu andalahnya adalah minuman Es Teh Manis. Teh manis yang dicampur dengan es batu. Es Teh Manis adalah menu paling favorit di warung makan tersebut. Saat pembeli bingung mau memilih minum apa, pasti jawaban tercepat yang disebutkan adalah Es Teh Manis.</p><p id="7dab" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Untuk membuat segelas Es Teh Manis, dibutuhkan 4 bahan, yaitu air putih, bubuk teh (celup/saring), gula, dan es. Dan untuk membuat segelas Es Teh Manis kita sebut saja butuh 5 menit untuk best-case, worst-case mungkin bisa sampai 10 menit kalau pembuatnya perfectsionis :D.</p><p id="fdf3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah, misalnya di warung makan tersebut, sedang ada rombongan yang makan, dan sangat ramai. Sehingga banyak pesanan menumpuk, khususnya pesanan Es Teh Manis, sebut saja semua pelanggan memesan Es Teh Manis, jika sang pelayan membuat Es Teh Manis dengan sistem pergelas, maka sangat lah lama.</p><p id="6bac" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jalur cepatnya adalah, untuk memangkas beberapa hal yang tidak penting, sang pelayan pun berinisiatif untuk membuatnya ke dalam satu Teko teh manis lalu di tuang satu persatu ke dalam gelas beserta Esnya. Tentu dengan metode ini penyajian Es Teh Manis akan menjadi lebih cepat.</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e86e49fb85079d42f564faccd958756f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*U0Fg00q8uQCjtygx36WxQA.jpeg"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Iced Tea from Google Image Search</figcaption></figure><p id="b04a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Untuk membuat teh langsung satu teko mungkin butuh 10menit. Namun untu menuangkanya kedalam gelas butuh 1 Menit pergelasnya. Hitung kotor, satu teko sebut saja setara 6 gelas. Jadi total untuk server 6 gelas sekitar 16 Menit.</p><p id="c8b2" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Bandingkan jika disajikan secara satu-persatu didalam gelas, untuk membuat Es Teh Manis pergelasnya satu-persatu butuh 5 menit x 6 gelas sekitar 30 menit-an. Hemat 14 Menit jika menggunakan Teko.</p></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><p id="4c45" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah dari analogi diatas, bisa kita cocokkan kedalam sebuah sistem dan cache. <br/> Sistem bisa kita ibaratkan sebagai Rumah Makan tersebut. Lalu pelanggan pada analogi tersebut bisa kita sebut sebagai user pada sistem kita. Lalu Teko pada analogi tersebut yang dibuat oleh pelayan bisa kita ibaratkan menjadi <code class="fe nj nk nl nm b">cache</code> .</p><p id="38c9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Misalnya adalah kita sebut saja Medium adalah sistem kita. Suatu ketika seorang terkenal menulis di Medium, lalu Medium pun mengirim push notification ke aplikasi mobile Medium. Push tersebut adalah artikel yang baru dipublish oleh orang tersebut di Medium.</p><p id="a38d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Dan saat push notif tersebut dibuka, maka di aplikasi Medium akan melakukan request get article detail semisal seperti berikut.</p><pre class="kd ke kf kg gt nn nm no np aw nq bi"><span id="1bee" class="mk ml in nm b gy nr ns l nt nu">GET /article/56234505</span></pre><p id="1574" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah, untuk mendapatkan article detail, misal banyak proses yang berat.</p><ul class=""><li id="0e67" class="lp lq in kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">Get from DB</li><li id="4dbe" class="lp lq in kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">Get Author name from Author Service</li><li id="863c" class="lp lq in kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">Get Publication name from Publication Service</li></ul><p id="7016" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah misalnya per-aksi yang dilakukan membutuhkan 50ms. Lalu karena ada 3 aksi(syncronize belum menggunakan concurent/paralel/thread) maka total waktu yang dibutuhkan adalah 150ms/requestnya setiap user.</p><p id="2d88" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika ada 1000 user yang membuka push notif tersebut, maka akan ada 1000 user secara bersamaan melakukan request yang secara bersamaan dengan permintaan yang sama.</p><p id="5c08" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Maka setiap user akan rata-rata membutuhkan 150ms masing-masing user. Jika dihitung costnya secara “akumulatif”, 150 * 1000 = 150.000ms total akumulatif semua proses itu.</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nv"><img src="../Images/cc131e8e19194e1e2da08d4adac73855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fSQ_JRS1J-IZZvBPdDiebw.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">sistem tanpa cache</figcaption></figure><p id="c69d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Saat-saat seperti inilah, cache itu bisa digunakan. Untuk kasus sistem tersebut, kita bisa menggunakan cache. Misal untuk mengambil dari cache hanya butuh 20ms atau malah lebih kecil.</p><p id="a1e3" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Coba kita pasang langsung cache pada semua proses itu, jadi yang 150ms hanya terjadi pada user pertama saja. Selanjutnya user berikutnya akan menggunakan data dari cache. Sehingga, tidak perlu proses panjang, hanya sekali ambil dari cache, saja dan hanya butuh 20ms saja. Sudah hemat 130ms (150–20) secara akumulatif tanpa menggunakan async/thread/paralel.</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi nw"><img src="../Images/44e2f2943b6201f8abba02511a426b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dH23QLI2EK2qA7B3dc26mw.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">sistem dengan cache</figcaption></figure><p id="46b7" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Sehingga, ketika user melakukan request artikel detail, sistem kita tidak perlu lagi akses Database, service Author dan Publication, tinggal mengambil data dari cache saja.</p><p id="7265" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah seperti itulah, kira-kira cara kerjanya cache dalam kehidupan sehari-hari pada context yang masih mudah dan sederhana :D.</p></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><h1 id="1f05" class="nx ml in bd mm ny nz oa mp ob oc od ms jt oe ju mv jw of jx my jz og ka nb oh bi translated">Algoritma pada Cache</h1><p id="dd93" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc nf le lf lg ng li lj lk nh lm ln lo ig bi translated">Dahulu kala, ketika saya baru mengenal tentang <code class="fe nj nk nl nm b">cache</code> awalnya saya berpikir itu hanyalah sesimple sebuah <code class="fe nj nk nl nm b">hashmap</code> yang dimana ada <code class="fe nj nk nl nm b">key</code> dan <code class="fe nj nk nl nm b">value</code> .</p><p id="3918" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Pada cache, kita dapat retrieve dan set value dengan kompleksitas O(1) saja. Karena untuk insertion dan retrieve pada hashmap juga adalah O(1), jadi saya pikir ya cache itu hanya sebatas hashmap saja.</p><p id="205a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Namun, semakin kesini, saya pun pelajari makin dalam, dan saya melihat ini seharusnya seperti pelajaran basic yang penting dan harusnya ada diperkuliahan, tetapi sayang tidak saya dapatkan dulu, atau saya lupa mungkin :D 😈</p><p id="5f91" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Beberapa hari belakangan saya pun belajar tentang Cache dan algoritma yang digunakan, dan saya pun tersadar, cache tidak hanya sesimple hashmap saja hehe.</p><p id="d359" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Sebenarnya ada banyak algoritma Cache, tetapi untuk mengecilkan scope. Saya hanya akan bahas 2 algoritma saja. Kedua tersebut adalah berikut.</p><ul class=""><li id="c0fd" class="lp lq in kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">LRU: Least Recently Used</li><li id="8ece" class="lp lq in kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">LFU: Least Frequently Used</li></ul><p id="6606" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Untuk algoritma lain, seperti ARC, 2Q, etc, silahkan di cari saja. Semua algoritma tersebut mempunya kekurangan dan kelebihan. Dan biasanya di pakai di sistem operasi dan untuk disk management di OS.</p><p id="d641" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">2 Algoritma ini saya pilih karena pada Redis (aplikasi Cache yang sangat terkenal sekarang ini) menggunakan LRU algorithm untuk redis v3 kebawah, dan untuk redis v4 keatas mereka memperkenalkan LFU algorithm.</p><p id="c8a4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jadi Redis memang memakai 2 Algoritma ini untuk sistem mereka. Jelasnya bisa di baca disini tentang algoritma Cache yang digunakan Redis: <a class="ae ks" href="https://redis.io/topics/lru-cache" rel="noopener ugc nofollow" target="_blank"> https://redis.io/topics/lru-cache </a></p><h2 id="b01a" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">Cache Least Recently Used (LRU) Algorithm</h2><p id="d698" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc nf le lf lg ng li lj lk nh lm ln lo ig bi translated">Nah, yang pertama adalah LRU. LRU adalah salah satu algoritma page replacement yang biasa digunakan dalam Arsitektur Komputer, yaitu bagaimana OS melakukan manajemen memori dan alokasi memori sehingga proses yang dilakukan akan cepat.</p><p id="0c58" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Prinsip kerja LRU sama seperti namanya, Least Recently Used. Jadi yang paling lama tidak dipakai (di retrieve) oleh user yang akan dihapus jika terjadi overflow size.</p><p id="64a9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Untuk jelasnya, saya akan coba buat skenario simple terkait LRU cache, semoga mudah dipahami.</p></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><p id="7f2d" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Semisal, terdapat 3 fragment/node atau kotak kosong yang akan di isi oleh value atau yang kita sebut item yang di cache. Nah 3 fragment inilah yang akan kita isi berulang-ulang, dan mekanisme pengisiannya itulah kita menggunakan LRU.</p><p id="3d9a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika disimpulkan LRU konsepnya mirip dengan seperti Stack tetapi bukan stack. Jika stack konsepnya adalah LIFO, tetapi LRU berdasarkan pemakaian yang terakhir yang paling lama dilakukan(Least Recently Used).</p><p id="b1c8" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Untuk insertnya, mirip dengan Stack, setiap ada insert cache-item baru, maka item tersebut akan diposisikan di urutan paling depan.</p><p id="80b9" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Contoh:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oi"><img src="../Images/2c8e5c0e555b350e7deefd070aa67a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKmR0L91lD_3a1MWlmkHbg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Insert new item to LRU cache</figcaption></figure><p id="84a4" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Lalu jika dari banyak list yang ada di dalam cache terdapat request yang hit, dimana itemnya ada di dalam cache maka item tersebut akan diletakkan di posisi depan.</p><p id="da71" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Contoh:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi oj"><img src="../Images/e8f978044a4a47cd637a759298142179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzmy_QCIlwCZDcODw7Iqrg.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Reorder by recently used</figcaption></figure><p id="be80" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah, lalu, jika suatu saat ada kondisi dimana cache list sudah penuh. Dan terdapat request untuk insert new cache item untuk disimpan ke dalam cache. Karena Cachenya listnya dibatasi (misal 3) dan sudah penuh, makanya akan dilakukan penghapusan dari Fragment cache list.</p><p id="e3fe" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Ketika penghapusan Item, yang dihapus adalah item yang posisinya paling belakang. Dimana item tersebut adalah item yang sangat paling lama tidak dipakai ~ Least Recent Used (LRU) item.</p><p id="71d5" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Contoh:</p><figure class="kd ke kf kg gt kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi ok"><img src="../Images/fb2e4db5dbe49430a8a4b23d85dc19a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5EpX1IL_GT3VmKA2rOipA.png"/></div></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">remove LRU item.</figcaption></figure><p id="e1bf" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Nah itu saja. Konsepnya adalah, jika hendak insert ke dalam cache, setiap item baru akan diposisikan didepan. Jika melakukan retrieve item dan itemnya ada, maka item tersebut juga akan diposisikan di paling depan.</p><p id="391c" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Selanjutnya, jika harus menghapus karena ada item baru, maka item yang dihapus adalah item yang ada dipaling belakang yang merupakan item yang tidak dipakai lagi.</p></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><h2 id="debb" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">Cache Least Frequently Used (LFU) Algorithm</h2><p id="5b83" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc nf le lf lg ng li lj lk nh lm ln lo ig bi translated">Kemudian adalah algoritma LFU. Algoritma LFU adalah jenis algoritma yang mirip penggunaannya seperti LRU. Jika pada algoritma LRU kita mengurutkan posisi cache item berdasarkan recent (yang baru saja dipakai), maka LFU mengurutkan berdasarkan item yang paling sering kita gunakan (frequent).</p><p id="cd13" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika pada LRU setiap kali terdapat aksi yang insert/get maka item tersebut akan berada disposisi depan. Tetapi LFU, akan dilakukan counter(penghitungan). Jika insert item, counternya default: 1. Lalu setiap kita lakukan aksi <em class="ol"> retrieve </em> item, maka counter item tersebut akan bertambah.</p><p id="991b" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Sehingga diposisi depan, adalah item yang memiliki counter paling banyak. Dan diposisi belakang, item yang counternya paling sedikit. Dan sama seperti LRU, jika terdapat penghapusan, maka item yang dihapus adalah item yang paling belakang.</p><h2 id="04eb" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">Kesimpulan</h2><p id="c258" class="pw-post-body-paragraph kt ku in kv b kw nd jo ky kz ne jr lb lc nf le lf lg ng li lj lk nh lm ln lo ig bi translated">Jadi setelah belajar banyak tentang LRU dan LFU, saya pun tersadar, cache itu bukan hanya sekedar HashMap. Meskipun menggunakan HashMap didalamnya, tetapi masih ada beberapa algoritma yang harus dipikirkan untuk mengatur urutan penghapusan dan manajemen memori.</p><p id="f0f2" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika kita membuat simple cache sistem, dengan memanfaatkan HashMap, jika kita tidak memikirkan bagaimana metode penghapusan item, maka HashMap tersebut akan gendut, dan semakin besar size map, maka semakin banyak memori yang digunakan, yang nantinya dapat menyebabkan OOM (Out of Memory).</p><p id="bf40" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Tetapi dengan menerapkan Algoritma LFU/LRU sebagai metode penghapusan item, maka akan menjamin Cache tersebut tidak akan <em class="ol"> grow </em> secara terus-menerus dan dan tidak menyebabkan OOM karena sudah ada batasan fix jumlah item yang bisa dicache, dan penghapusan setiap prosesnya.</p></div><div class="ab cl md me hr mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ig ih ii ij ik"><p id="f16a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Lalu Kemudian, tanpa banyak pikir panjang, sebelum ilmunya hilang, saya pun meng-implemetasikan LRU dan LFU pada sebuah library kecil. Saya pun membuat sebuah libary in memory cache yang bisa digunakan secara langsung di Golang.</p><p id="49fc" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Kamu bisa lihat library yang saya buat disini: <a class="ae ks" href="https://github.com/bxcodec/gotcha" rel="noopener ugc nofollow" target="_blank"> https://github.com/bxcodec/gotcha </a> . Library ini saya buat dengan 2 algoritma yang bisa di switch LFU dan LRU. Sebenarnya library ini adalah hal kecil, karena sudah banyak library sejenis diluar sana, tetapi untuk pembeda dari yang lain, plannya saya akan tambahkan dengan konsep Expiry time dan manajemen Maximum memory.</p><p id="4f90" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Ini masih proses pengembangan, masih banyak yang harus saya benahi, agar lebih rich dan multiguna. Tetapi untuk sekedar Setter Getter in memory Cache, library ini sudah dapat digunakan.</p><p id="3c3a" class="pw-post-body-paragraph kt ku in kv b kw kx jo ky kz la jr lb lc ld le lf lg lh li lj lk ll lm ln lo ig bi translated">Jika teman-teman tertarik untuk belajar bersama, teman-teman bisa gunakan libary tersebut, dan submit issue atau buat Pull Request (PR). Hehe</p><h2 id="1e09" class="mk ml in bd mm mn mo dn mp mq mr dp ms lc mt mu mv lg mw mx my lk mz na nb nc bi translated">References</h2><ul class=""><li id="2017" class="lp lq in kv b kw nd kz ne lc om lg on lk oo lo lu lv lw lx bi translated">[1] Tembolok(komputer) <a class="ae ks" href="https://id.wikipedia.org/wiki/Tembolok_(komputer)" rel="noopener ugc nofollow" target="_blank"> https://id.wikipedia.org/wiki/Tembolok_(komputer) </a></li></ul></div></div>    
</body>
</html>